{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'not sarcastic', 'score': 0.9997287392616272}]\n"
     ]
    }
   ],
   "source": [
    "# Testing a sarcasm detector from huggingface\n",
    "from transformers import pipeline\n",
    "sarcasm_detector = pipeline(\"text-classification\", model=\"MohamedGalal/arabert-sarcasm-detector\")\n",
    "text = \"طبعا الجو جميل جداً اليوم، ممطر وبارد وأنا أحب أن أتمشى تحت المطر بدون مظلة!\"\n",
    "result = sarcasm_detector(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcasm Detection Result: ساخر\n"
     ]
    }
   ],
   "source": [
    "# Testing Gemini Flash 2.0 API with LangChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "def analyze_sarcasm(text):\n",
    "    \"\"\"Analyzes sarcasm in an Arabic text using Gemini Flash 2.0 API with LangChain.\"\"\"\n",
    "    \n",
    "    # Initialize the LangChain Gemini model\n",
    "    model = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        temperature=0,\n",
    "        api_key=\"AIzaSyB-C-HkY-PKqlj1zwkWchO3NqAkNy5E9hs\",\n",
    "    )\n",
    "    \n",
    "    # Define prompt\n",
    "    prompt = f\"هل النص التالي ساخر؟ '{text}' أجب فقط بـ 'ساخر' أو 'غير ساخر'.\"\n",
    "    \n",
    "    # Get response\n",
    "    response = model.invoke(prompt)\n",
    "    \n",
    "    return response.content  # Extract text response\n",
    "\n",
    "# Example usage\n",
    "text = \"طبعا الجو جميل جداً اليوم، ممطر وبارد وأنا أحب أن أتمشى تحت المطر بدون مظلة!\"\n",
    "result = analyze_sarcasm(text)\n",
    "print(f\"Sarcasm Detection Result: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the current sarcasm models in hugging face is not working good so let's use the Gemini API to get sarcasm labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73110e5d60d747579afa92d82c8f7da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing sarcasm:   0%|          | 0/426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pausing for 60 seconds after processing 15 episodes...\n",
      "Pausing for 60 seconds after processing 30 episodes...\n",
      "Pausing for 60 seconds after processing 45 episodes...\n",
      "Pausing for 60 seconds after processing 60 episodes...\n",
      "Pausing for 60 seconds after processing 75 episodes...\n",
      "Pausing for 60 seconds after processing 90 episodes...\n",
      "Pausing for 60 seconds after processing 105 episodes...\n",
      "Pausing for 60 seconds after processing 120 episodes...\n",
      "Pausing for 60 seconds after processing 135 episodes...\n",
      "Pausing for 60 seconds after processing 150 episodes...\n",
      "Pausing for 60 seconds after processing 165 episodes...\n",
      "Pausing for 60 seconds after processing 180 episodes...\n",
      "Pausing for 60 seconds after processing 195 episodes...\n",
      "Pausing for 60 seconds after processing 210 episodes...\n",
      "Pausing for 60 seconds after processing 225 episodes...\n",
      "Pausing for 60 seconds after processing 240 episodes...\n",
      "Pausing for 60 seconds after processing 255 episodes...\n",
      "Pausing for 60 seconds after processing 270 episodes...\n",
      "Pausing for 60 seconds after processing 285 episodes...\n",
      "Pausing for 60 seconds after processing 300 episodes...\n",
      "Pausing for 60 seconds after processing 315 episodes...\n",
      "Pausing for 60 seconds after processing 330 episodes...\n",
      "Pausing for 60 seconds after processing 345 episodes...\n",
      "Pausing for 60 seconds after processing 360 episodes...\n",
      "Pausing for 60 seconds after processing 375 episodes...\n",
      "Pausing for 60 seconds after processing 390 episodes...\n",
      "Pausing for 60 seconds after processing 405 episodes...\n",
      "Pausing for 60 seconds after processing 420 episodes...\n",
      "Sarcasm analysis completed for 426 episodes and saved to sarcasm.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "episode_sarcasm = []\n",
    "\n",
    "for i, transcript in enumerate(tqdm(df['episode_transcript'], desc=\"Analyzing sarcasm\")):\n",
    "    # Add a 60-second pause after every 15 requests to respect API rate limits\n",
    "    if i > 0 and i % 15 == 0:\n",
    "        print(f\"Pausing for 60 seconds after processing {i} episodes...\")\n",
    "        time.sleep(60)    \n",
    "\n",
    "    sarcasm = analyze_sarcasm(transcript)\n",
    "    episode_sarcasm.append(sarcasm)\n",
    "\n",
    "df['sarcasm'] = episode_sarcasm\n",
    "df.to_csv(\"sarcasm.csv\", index=False)\n",
    "\n",
    "print(f\"Sarcasm analysis completed for {len(episode_sarcasm)} episodes and saved to sarcasm.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
