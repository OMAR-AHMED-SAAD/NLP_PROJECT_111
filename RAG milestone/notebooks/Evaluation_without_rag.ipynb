{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from evaluate) (0.31.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langchain-huggingface) (0.3.59)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langchain-huggingface) (0.21.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langchain-huggingface) (4.49.0)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langchain-huggingface) (4.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.3.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (2.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.4.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "import subprocess\n",
    "from tqdm.notebook import tqdm\n",
    "from langchain_community.llms import Ollama\n",
    "from tqdm.notebook import tqdm\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"microsoft/phi-4\",\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.0,\n",
    "    max_new_tokens=512,\n",
    "    model_kwargs={\"device_map\": \"cuda\", \"torch_dtype\": torch.float16},\n",
    ")\n",
    "chat = ChatHuggingFace(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "def extract_answer(cot_output: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Given a chain-of-thought LLM output ending with:\n",
    "      ... \n",
    "      Answer: <the extractive answer>\n",
    "    this returns the <the extractive answer> string.\n",
    "    If no “Answer:” line is found, returns None.\n",
    "    \"\"\"\n",
    "    # Look for a line that starts with “Answer:” (case-sensitive),\n",
    "    # optionally preceded by whitespace, and capture the rest of the line.\n",
    "    match = re.search(r'^[ \\t]*Answer:\\s*(.+)$', cot_output, flags=re.MULTILINE)\n",
    "    if not match:\n",
    "        return None\n",
    "    return match.group(1).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Santa Clara, California\n"
     ]
    }
   ],
   "source": [
    "output = \"\"\"Reasoning:\n",
    "1. I see “Santa Clara, California” mentioned as the location.\n",
    "2. The question asks “Where did Super Bowl 50 take place?”\n",
    "Answer: Santa Clara, California\n",
    "\"\"\"\n",
    "\n",
    "answer = extract_answer(output)\n",
    "print(answer)  # \"Santa Clara, California\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py): started\n",
      "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=25025 sha256=cfce015a8da8ec8bbbc043538247ffde4d78da4961ad477cc74ff3e1a9c16083\n",
      "  Stored in directory: c:\\users\\001\\appdata\\local\\pip\\cache\\wheels\\1e\\19\\43\\8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: absl-py, rouge_score\n",
      "Successfully installed absl-py-2.2.2 rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\001\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"squad\", split=\"validation\")\n",
    "ds_shuffled = ds.shuffle(seed=42)\n",
    "ds_sample = ds_shuffled.select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_metric = load(\"squad\")\n",
    "rouge_metric = load(\"rouge\")\n",
    "bleu_metric  = load(\"bleu\")\n",
    "\n",
    "def evaluate(chain, cot_used: bool=False, ds=ds_sample):\n",
    "    squad_preds, squad_refs = [], []\n",
    "    texts_pred, texts_ref = [], []  # for BLEU/ROUGE we need flat lists of strings\n",
    "\n",
    "    for ex in tqdm(ds, desc=\"Evaluating on SQuAD + BLEU/ROUGE\"):\n",
    "        raw = chain.predict(\n",
    "            retrieved_SQuAD_passage=ex[\"context\"],\n",
    "            user_question=ex[\"question\"]\n",
    "        ).strip()\n",
    "\n",
    "        # If using CoT, extract final answer\n",
    "        if cot_used:\n",
    "            raw = extract_answer(raw) or \"Unsure about answer.\"\n",
    "\n",
    "        # 1) build SQuAD v1 inputs\n",
    "        squad_preds.append({\n",
    "            \"id\": ex[\"id\"],\n",
    "            \"prediction_text\": raw,\n",
    "        })\n",
    "        squad_refs.append({\n",
    "            \"id\": ex[\"id\"],\n",
    "            \"answers\": {\n",
    "                \"text\": ex[\"answers\"][\"text\"], \n",
    "                \"answer_start\": ex[\"answers\"][\"answer_start\"]\n",
    "            }\n",
    "        })\n",
    "\n",
    "        # 2) build flat strings for BLEU/ROUGE\n",
    "        #    here we pick the FIRST gold answer as the reference\n",
    "        texts_pred.append(raw)\n",
    "        texts_ref.append(ex[\"answers\"][\"text\"][0])\n",
    "\n",
    "    # 3) compute SQuAD exact_match & F1\n",
    "    squad_results = squad_metric.compute(\n",
    "        predictions=squad_preds, \n",
    "        references=squad_refs\n",
    "    )\n",
    "\n",
    "    # 4) compute ROUGE (returns rouge1, rouge2, rougeL, etc.)\n",
    "    rouge_results = rouge_metric.compute(\n",
    "        predictions=texts_pred, \n",
    "        references=texts_ref\n",
    "    )\n",
    "\n",
    "    # 5) compute BLEU (returns 'bleu' score)\n",
    "    bleu_results = bleu_metric.compute(\n",
    "        predictions=texts_pred, \n",
    "        references=[[r] for r in texts_ref]  \n",
    "        # BLEU expects list of list of references per prediction\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        **squad_results,\n",
    "        \"rouge1\": rouge_results[\"rouge1\"],\n",
    "        \"rouge2\": rouge_results[\"rouge2\"],\n",
    "        \"rougeL\": rouge_results[\"rougeL\"],\n",
    "        \"bleu\":   bleu_results[\"bleu\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phi4 + Zero Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an expert extractive question-answering system.\n",
    "        Use only the provided context to answer the question.\n",
    "        Always output the answer using the exact wording and phrasing as it appears in the context.\n",
    "        If the answer is not contained in the context, reply “Unsure about answer.”\n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Context:\n",
    "        {retrieved_SQuAD_passage}\n",
    "\n",
    "        Question:\n",
    "        {user_question}\n",
    "\n",
    "        'Answer:'\n",
    "        \"\"\"\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\001\\AppData\\Local\\Temp\\ipykernel_33388\\3706294773.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain_zero_shot_prompt = LLMChain(llm=chat, prompt=zero_shot_prompt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd98064226b64dba92a92a08d417346b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on SQuAD + BLEU/ROUGE:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot Prompting Results: {'exact_match': 17.8, 'f1': 47.865771366810996, 'rouge1': np.float64(0.4337529517105183), 'rouge2': np.float64(0.30747240973384526), 'rougeL': np.float64(0.4323955352478021), 'bleu': 0.10809094069972884}\n"
     ]
    }
   ],
   "source": [
    "chain_zero_shot_prompt = LLMChain(llm=chat, prompt=zero_shot_prompt)\n",
    "results_zero_shot_prompt = evaluate(chain_zero_shot_prompt, cot_used=False, ds=ds_sample)\n",
    "print(f\"Zero-shot Prompting Results: {results_zero_shot_prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phi4 + COT prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an expert extractive question-answering system.\n",
    "        When given a context and a question, you will:\n",
    "        1. Think through the relevant part of the context step by step.\n",
    "        2. Show your reasoning clearly (chain-of-thought).\n",
    "        3. Finally, output **only** the answer using the exact wording as it appears in the context.\n",
    "        If the answer is not contained in the context, your final answer must be 'Unsure about answer.'\n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Context:\n",
    "        {retrieved_SQuAD_passage}\n",
    "\n",
    "        Question:\n",
    "        {user_question}\n",
    "\n",
    "        Begin by reasoning step by step, then conclude with 'Answer: <your extractive answer>'.\"\"\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4480e4ac8914bbc9c777fac34036b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on SQuAD + BLEU/ROUGE:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-Thought Prompting Results: {'exact_match': 59.0, 'f1': 76.18329879976443, 'rouge1': np.float64(0.7103717761840456), 'rouge2': np.float64(0.5166486506070347), 'rougeL': np.float64(0.7098182819885526), 'bleu': 0.31843942324695707}\n"
     ]
    }
   ],
   "source": [
    "chain_cot_prompt = LLMChain(llm=chat, prompt=cot_prompt)\n",
    "results_cot_prompt = evaluate(chain_cot_prompt, cot_used=True, ds=ds_sample)\n",
    "print(f\"Chain-of-Thought Prompting Results: {results_cot_prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBert Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForQuestionAnswering, DistilBertTokenizerFast, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_valid_examples(examples, tokenizer, max_length=384, stride=128):\n",
    "    \"\"\"Process the validation split of the SQuAD dataset.\n",
    "\n",
    "    Process the training split of the SQuAD dataset to include the unique ID of each row,\n",
    "    the tokenized questions and context, as well as the start and end positions of the answer\n",
    "    within the context.\n",
    "\n",
    "    Args:\n",
    "        examples: A row from the dataset containing an example.\n",
    "        tokenizer: The BERT tokenizer to be used.\n",
    "        max_length: The maximum length of the input sequence. If exceeded, truncate the second\n",
    "            sentence of a pair (or a batch of pairs) to fit within the limit.\n",
    "        stride: The number of tokens to retain from the end of a truncated sequence, allowing\n",
    "            for overlap between truncated and overflowing sequences.\n",
    "\n",
    "    Returns:\n",
    "        The processed example.\n",
    "    \"\"\"\n",
    "    # Tokenize the questions and context sequences\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "      questions,\n",
    "      examples[\"context\"],\n",
    "      truncation=\"only_second\",\n",
    "      padding=\"max_length\",\n",
    "      stride=stride,\n",
    "      max_length=max_length,\n",
    "      return_offsets_mapping=True,\n",
    "      return_overflowing_tokens=True,\n",
    "    )\n",
    "\n",
    "    example_ids = []\n",
    "    answers = examples[\"answers\"]\n",
    "    offset_mapping = inputs[\"offset_mapping\"]\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # find the start and end positions of the answer within the context\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # if the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids  # keep the unique ID of the example\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def forward_distilbert(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    ds,\n",
    "    batch_size: int = 8,\n",
    "    max_length: int = 384,\n",
    "    stride: int = 128,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run DistilBERT over the SQuAD validation set in batches.\n",
    "\n",
    "    Returns:\n",
    "      start_logits: np.ndarray of shape (num_feature_rows, seq_len)\n",
    "      end_logits:   np.ndarray of shape (num_feature_rows, seq_len)\n",
    "      features:     HF Dataset with preprocessing columns (example_id, offset_mapping...)\n",
    "    \"\"\"\n",
    "    def wrapper(examples):\n",
    "        return preprocess_valid_examples(examples, tokenizer=tokenizer,\n",
    "                                         max_length=max_length, stride=stride)\n",
    "\n",
    "    features = ds.map(\n",
    "        wrapper,\n",
    "        batched=True,\n",
    "        remove_columns=ds.column_names,\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tensor_features = features.remove_columns(\n",
    "        [\"offset_mapping\", \"example_id\", \"start_positions\", \"end_positions\"]\n",
    "    ).with_format(\n",
    "        type=\"torch\",\n",
    "        columns=[\"input_ids\", \"attention_mask\"],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # 3) Allocate arrays to hold all logits\n",
    "    num_rows   = len(tensor_features)\n",
    "    seq_len    = tensor_features[\"input_ids\"].shape[1]\n",
    "    all_start  = np.zeros((num_rows, seq_len), dtype=np.float32)\n",
    "    all_end    = np.zeros((num_rows, seq_len), dtype=np.float32)\n",
    "\n",
    "    model.to(device).eval()\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, num_rows, batch_size), desc=\"DistilBERT inference\"):\n",
    "            batch_slice = slice(i, min(i + batch_size, num_rows))\n",
    "            batch_inputs = {\n",
    "                \"input_ids\":      tensor_features[\"input_ids\"][batch_slice],\n",
    "                \"attention_mask\": tensor_features[\"attention_mask\"][batch_slice],\n",
    "            }\n",
    "            outputs = model(**batch_inputs)\n",
    "            start_b = outputs.start_logits.detach().cpu().numpy()\n",
    "            end_b   = outputs.end_logits.detach().cpu().numpy()\n",
    "\n",
    "            all_start[batch_slice, :] = start_b\n",
    "            all_end[batch_slice, :]   = end_b\n",
    "\n",
    "    return all_start, all_end, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(\n",
    "    start_logits, end_logits, features, examples,\n",
    "    n_best=20, max_answer_length=50\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute Exact Match (EM), F1, BLEU and ROUGE for a Span-extraction model.\n",
    "\n",
    "    Args:\n",
    "        start_logits:      List of [num_tokens] arrays for start predictions\n",
    "        end_logits:        List of [num_tokens] arrays for end predictions\n",
    "        features:          The tokenized/offset-mapped validation features\n",
    "        examples:          The raw validation examples (with \"id\", \"context\", \"answers\")\n",
    "        n_best:            How many top start/end pairs to consider per example\n",
    "        max_answer_length: Maximum span length\n",
    "\n",
    "    Returns:\n",
    "        A dict with keys:\n",
    "          - exact_match, f1           (SQuAD)\n",
    "          - rouge1, rouge2, rougeL    (ROUGE)\n",
    "          - bleu                      (BLEU)\n",
    "    \"\"\"\n",
    "    # Load metrics\n",
    "    squad_metric = evaluate.load(\"squad\")\n",
    "    rouge_metric = evaluate.load(\"rouge\")\n",
    "    bleu_metric  = evaluate.load(\"bleu\")\n",
    "\n",
    "    # Map from example to its feature indices\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for i, feat in enumerate(features):\n",
    "        example_to_features[feat[\"example_id\"]].append(i)\n",
    "\n",
    "    # Build predictions\n",
    "    predicted = []\n",
    "    for ex in tqdm(examples, desc=\"Building predictions\"):\n",
    "        ex_id  = ex[\"id\"]\n",
    "        context = ex[\"context\"]\n",
    "        candidates = []\n",
    "\n",
    "        for fi in example_to_features[ex_id]:\n",
    "            starts = np.argsort(start_logits[fi])[-n_best:][::-1]\n",
    "            ends   = np.argsort(end_logits[fi])[-n_best:][::-1]\n",
    "            offsets = features[fi][\"offset_mapping\"]\n",
    "\n",
    "            for s in starts:\n",
    "                for e in ends:\n",
    "                    if offsets[s] is None or offsets[e] is None:\n",
    "                        continue\n",
    "                    if e < s or (e - s + 1) > max_answer_length:\n",
    "                        continue\n",
    "                    text = context[offsets[s][0] : offsets[e][1]]\n",
    "                    score = start_logits[fi][s] + end_logits[fi][e]\n",
    "                    candidates.append((text, score))\n",
    "\n",
    "        if candidates:\n",
    "            best_text = max(candidates, key=lambda x: x[1])[0]\n",
    "        else:\n",
    "            best_text = \"\"\n",
    "\n",
    "        predicted.append({\n",
    "            \"id\": ex_id,\n",
    "            \"prediction_text\": best_text\n",
    "        })\n",
    "\n",
    "    # Build references for SQuAD\n",
    "    references = [\n",
    "        {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]}\n",
    "        for ex in examples\n",
    "    ]\n",
    "\n",
    "    # 1) SQuAD EM/F1\n",
    "    squad_res = squad_metric.compute(\n",
    "        predictions=predicted,\n",
    "        references=references\n",
    "    )\n",
    "\n",
    "    # Prepare flat lists for BLEU/ROUGE\n",
    "    preds_texts = [p[\"prediction_text\"] for p in predicted]\n",
    "    # pick the first gold answer for each example\n",
    "    refs_texts  = [ex[\"answers\"][\"text\"][0] for ex in examples]\n",
    "\n",
    "    # 2) ROUGE\n",
    "    rouge_res = rouge_metric.compute(\n",
    "        predictions=preds_texts,\n",
    "        references=refs_texts\n",
    "    )\n",
    "\n",
    "    # 3) BLEU (expects list of lists of refs)\n",
    "    bleu_res = bleu_metric.compute(\n",
    "        predictions=preds_texts,\n",
    "        references=[[r] for r in refs_texts],\n",
    "        # tokenizer=\"none\"  # skip NLTK to avoid external deps\n",
    "    )\n",
    "\n",
    "    # Merge and return\n",
    "    return {\n",
    "        **squad_res,\n",
    "        \"rouge1\": rouge_res[\"rouge1\"],\n",
    "        \"rouge2\": rouge_res[\"rouge2\"],\n",
    "        \"rougeL\": rouge_res[\"rougeL\"],\n",
    "        \"bleu\":   bleu_res[\"bleu\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DistilBert without finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_path =  \"distilbert/distilbert-base-uncased\"\n",
    "model_not_finetuned = DistilBertForQuestionAnswering.from_pretrained(model_path)\n",
    "tokenizer_not_finetuned = DistilBertTokenizerFast.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581c47c4583e4161896914469e98ebb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7ba77443e542ee8c856b7f0e65bd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DistilBERT inference:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\001\\anaconda3\\envs\\nlp_env\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:402: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52830f354c34196b7c9a4314b572c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building predictions:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_logits, end_logits, features = forward_distilbert(model_not_finetuned, ds=ds_sample, tokenizer=tokenizer_not_finetuned)\n",
    "results_distilbert_not_finetuned = compute_metrics(\n",
    "    start_logits, end_logits, features, ds_sample,\n",
    "    n_best=20, max_answer_length=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.2,\n",
       " 'f1': 7.834462772607801,\n",
       " 'rouge1': np.float64(0.07191534459914353),\n",
       " 'rouge2': np.float64(0.03069607321407338),\n",
       " 'rougeL': np.float64(0.06955680376129332),\n",
       " 'bleu': 0.012541996200093062}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_distilbert_not_finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DistilBert with finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"../backend/distilbert-squad-finetuned_tokenizer\"\n",
    "model_path = \"../backend/distilbert-squad-finetuned_model\"\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(model_path)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1d2674b7404b4a9d750125da6f5c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac709b913ffd4851a1c0c38b39fb4139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DistilBERT inference:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e428c6e67d47b89d69460aee0c3760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building predictions:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_logits, end_logits, features = forward_distilbert(model, ds=ds_sample, tokenizer=tokenizer)\n",
    "results_distilbert_finetuned = compute_metrics(\n",
    "    start_logits, end_logits, features, ds_sample,\n",
    "    n_best=20, max_answer_length=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 74.6,\n",
       " 'f1': 83.40220257669176,\n",
       " 'rouge1': np.float64(0.7596087082942087),\n",
       " 'rouge2': np.float64(0.5054857359267266),\n",
       " 'rougeL': np.float64(0.7587980584781542),\n",
       " 'bleu': 0.45915352231519446}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_distilbert_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_kernel",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
