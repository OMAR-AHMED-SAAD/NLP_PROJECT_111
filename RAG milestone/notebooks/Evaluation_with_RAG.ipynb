{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large-instruct\")\n",
    "persist_directory = \"../backend/chroma_db_squad\"\n",
    "chroma_db = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "retriever = chroma_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_qa(qa_pipeline, query, k: int=2):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    docs_context = \"\\n\\n\".join([d.page_content for d in docs[:k]])\n",
    "    result = qa_pipeline(question=query, context=docs_context)\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_text_generation(chain, query, k: int=2, cot_used=False):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    docs_context = \"\\n\\n\".join([d.page_content for d in docs[:k]])\n",
    "    answer = chain.predict(\n",
    "        retrieved_SQuAD_passage=docs_context,\n",
    "        user_question=query\n",
    "    ).strip()\n",
    "    if cot_used:\n",
    "        answer = extract_answer(answer) or \"Unsure about answer.\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"squad\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_shuffled = ds.shuffle(seed=42)\n",
    "ds_sample = ds_shuffled.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "def extract_answer(cot_output: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Given a chain-of-thought LLM output ending with:\n",
    "      ... \n",
    "      Answer: <the extractive answer>\n",
    "    this returns the <the extractive answer> string.\n",
    "    If no “Answer:” line is found, returns None.\n",
    "    \"\"\"\n",
    "    # Look for a line that starts with “Answer:” (case-sensitive),\n",
    "    # optionally preceded by whitespace, and capture the rest of the line.\n",
    "    match = re.search(r'^[ \\t]*Answer:\\s*(.+)$', cot_output, flags=re.MULTILINE)\n",
    "    if not match:\n",
    "        return None\n",
    "    return match.group(1).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_metric = load(\"squad\")\n",
    "rouge_metric = load(\"rouge\")\n",
    "bleu_metric  = load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66827a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pipeline_or_chain, cot_used: bool=False, ds=ds_sample, is_distilbert: bool=False):\n",
    "    squad_preds, squad_refs = [], []\n",
    "    texts_pred, texts_ref = [], []  \n",
    "    \n",
    "    for ex in tqdm(ds, desc=\"Evaluating on SQuAD + BLEU/ROUGE\"):\n",
    "        if not is_distilbert:\n",
    "            raw = get_answer_text_generation(pipeline_or_chain, ex[\"question\"], k=3, cot_used=cot_used)\n",
    "        else:\n",
    "            raw = get_answer_qa(pipeline_or_chain, ex[\"question\"], k=3)\n",
    "\n",
    "        squad_preds.append({\n",
    "            \"id\": ex[\"id\"],\n",
    "            \"prediction_text\": raw,\n",
    "        })\n",
    "        squad_refs.append({\n",
    "            \"id\": ex[\"id\"],\n",
    "            \"answers\": {\n",
    "                \"text\": ex[\"answers\"][\"text\"], \n",
    "                \"answer_start\": ex[\"answers\"][\"answer_start\"]\n",
    "            }\n",
    "        })\n",
    "\n",
    "        texts_pred.append(raw)\n",
    "        texts_ref.append(ex[\"answers\"][\"text\"][0])\n",
    "\n",
    "    squad_results = squad_metric.compute(\n",
    "        predictions=squad_preds, \n",
    "        references=squad_refs\n",
    "    )\n",
    "\n",
    "    rouge_results = rouge_metric.compute(\n",
    "        predictions=texts_pred, \n",
    "        references=texts_ref\n",
    "    )\n",
    "\n",
    "    bleu_results = bleu_metric.compute(\n",
    "        predictions=texts_pred, \n",
    "        references=[[r] for r in texts_ref]  \n",
    "    )\n",
    "\n",
    "    return {\n",
    "        **squad_results,\n",
    "        \"rouge1\": rouge_results[\"rouge1\"],\n",
    "        \"rouge2\": rouge_results[\"rouge2\"],\n",
    "        \"rougeL\": rouge_results[\"rougeL\"],\n",
    "        \"bleu\":   bleu_results[\"bleu\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuned DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline_distilbert_finetuned = pipeline(\"question-answering\", \n",
    "                        model=\"../backend/distilbert-squad-finetuned_model\", \n",
    "                        tokenizer=\"../backend/distilbert-squad-finetuned_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the metric slug'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a very seldom used unit of mass in the metric system?\"\n",
    "get_answer_qa(qa_pipeline_distilbert_finetuned, query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb76899310ae41a9801eb890a4c22cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on SQuAD + BLEU/ROUGE:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_distilbert_finetuned = evaluate(qa_pipeline_distilbert_finetuned, ds=ds_sample, is_distilbert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 59.2,\n",
       " 'f1': 67.76800534219976,\n",
       " 'rouge1': np.float64(0.6175922348539327),\n",
       " 'rouge2': np.float64(0.398389768927323),\n",
       " 'rougeL': np.float64(0.6175378256159525),\n",
       " 'bleu': 0.408588369518375}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_distilbert_finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOT Finetuned DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5f1d62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline_distilbert_not_finetuned = pipeline(\"question-answering\", \n",
    "                        model=\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f54f690a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', with almost no weight variance from 1888 to about 1926.:292'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a very seldom used unit of mass in the metric system?\"\n",
    "get_answer_qa(qa_pipeline_distilbert_not_finetuned, query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba146ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c82c25fd744b2499f6bf8df9e9bce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on SQuAD + BLEU/ROUGE:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_distilbert_not_finetuned = evaluate(qa_pipeline_distilbert_not_finetuned, ds=ds_sample, is_distilbert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57475d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0,\n",
       " 'f1': 2.196700410541207,\n",
       " 'rouge1': np.float64(0.02536077853748131),\n",
       " 'rouge2': np.float64(0.0023636363636363638),\n",
       " 'rougeL': np.float64(0.02461819767550417),\n",
       " 'bleu': 0.0032469254814464802}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_distilbert_not_finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phi4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_ollama import ChatOllama\n",
    "import torch\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"microsoft/phi-4\",\n",
    "#     task=\"text-generation\",\n",
    "#     temperature=0.0,\n",
    "#     max_new_tokens=512,\n",
    "#     model_kwargs={\"device_map\": \"cuda\", \"torch_dtype\": torch.float16},\n",
    "# )\n",
    "# chat = ChatHuggingFace(\n",
    "#     llm=llm,\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "chat = ChatOllama(\n",
    "    model=\"phi4\",    \n",
    "    temperature=0.0,        \n",
    "    num_predict=512,        # max new tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "zero_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an expert extractive question-answering system.\n",
    "        Use only the provided context to answer the question.\n",
    "        Always output the answer using the exact wording and phrasing as it appears in the context.\n",
    "        If the answer is not contained in the context, reply “Unsure about answer.”\n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Context:\n",
    "        {retrieved_SQuAD_passage}\n",
    "\n",
    "        Question:\n",
    "        {user_question}\n",
    "\n",
    "        'Answer:'\n",
    "        \"\"\"\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "chain_zero_shot_prompt = LLMChain(llm=chat, prompt=zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ce0c9b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The metric slug (sometimes mug or hyl) is that mass that accelerates at 1 m·s−2 when subjected to a force of 1 kgf.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a very seldom used unit of mass in the metric system?\"\n",
    "get_answer_text_generation(chain_zero_shot_prompt, query, k=3, cot_used=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e4fe114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847ba515897a461fb67e67e80180f40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on SQuAD + BLEU/ROUGE:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_zero_shot = evaluate(chain_zero_shot_prompt, ds=ds_sample, is_distilbert=False, cot_used=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c15fd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0,\n",
       " 'f1': 14.719487795118047,\n",
       " 'rouge1': np.float64(0.11710526315789474),\n",
       " 'rouge2': np.float64(0.044582043343653247),\n",
       " 'rougeL': np.float64(0.11320050125313283),\n",
       " 'bleu': 0.0}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_zero_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COT Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an expert extractive question-answering system.\n",
    "        When given a context and a question, you will:\n",
    "        1. Think through the relevant part of the context step by step.\n",
    "        2. Show your reasoning clearly (chain-of-thought).\n",
    "        3. Finally, output **only** the answer using the exact wording as it appears in the context.\n",
    "        If the answer is not contained in the context, your final answer must be 'Unsure about answer.'\n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Context:\n",
    "        {retrieved_SQuAD_passage}\n",
    "\n",
    "        Question:\n",
    "        {user_question}\n",
    "\n",
    "        Begin by reasoning step by step, then conclude with 'Answer: <your extractive answer>'.\"\"\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_cot_prompt = LLMChain(llm=chat, prompt=cot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "553e6b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metric slug'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a very seldom used unit of mass in the metric system?\"\n",
    "get_answer_text_generation(chain_cot_prompt, query, k=3, cot_used=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "695dfa9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e4a917719543c499773f9177d70a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on SQuAD + BLEU/ROUGE:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_cot = evaluate(chain_cot_prompt, ds=ds_sample, is_distilbert=False, cot_used=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bb0fb967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 60.0,\n",
       " 'f1': 60.0,\n",
       " 'rouge1': np.float64(0.6),\n",
       " 'rouge2': np.float64(0.2),\n",
       " 'rougeL': np.float64(0.6),\n",
       " 'bleu': 0.0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_kernel",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
