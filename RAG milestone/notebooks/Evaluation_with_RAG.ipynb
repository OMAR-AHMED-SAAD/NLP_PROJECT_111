{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large-instruct\")\n",
    "persist_directory = \"../backend/chroma_db_squad\"\n",
    "chroma_db = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "retriever = chroma_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_qa(qa_pipeline, query, k: int=2):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    docs_context = \"\\n\\n\".join([d.page_content for d in docs[:k]])\n",
    "    result = qa_pipeline(question=query, context=docs_context)\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92275cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "def extract_answer(cot_output: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Given a chain-of-thought LLM output ending with:\n",
    "      ... \n",
    "      Answer: <the extractive answer>\n",
    "    this returns the <the extractive answer> string.\n",
    "    If no “Answer:” line is found, returns None.\n",
    "    \"\"\"\n",
    "    # Look for a line that starts with “Answer:” (case-sensitive),\n",
    "    # optionally preceded by whitespace, and capture the rest of the line.\n",
    "    match = re.search(r'^[ \\t]*Answer:\\s*(.+)$', cot_output, flags=re.MULTILINE)\n",
    "    if not match:\n",
    "        return None\n",
    "    return match.group(1).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_text_generation(chain, query, k: int=3, cot_used=False):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    docs_context = \"\\n\\n\".join([d.page_content for d in docs[:k]])\n",
    "    answer = chain.predict(\n",
    "        retrieved_SQuAD_passage=docs_context,\n",
    "        user_question=query\n",
    "    ).strip()\n",
    "    if cot_used:\n",
    "        answer = extract_answer(answer) or \"Unsure about answer.\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"squad\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_shuffled = ds.shuffle(seed=42)\n",
    "ds_sample = ds_shuffled.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_metric = load(\"squad\")\n",
    "rouge_metric = load(\"rouge\")\n",
    "bleu_metric  = load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66827a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pipeline_or_chain, cot_used: bool=False, ds=ds_sample, is_distilbert: bool=False):\n",
    "    squad_preds, squad_refs = [], []\n",
    "    texts_pred, texts_ref = [], []  \n",
    "    \n",
    "    for ex in tqdm(ds, desc=\"Evaluating on SQuAD + BLEU/ROUGE\"):\n",
    "        if not is_distilbert:\n",
    "            raw = get_answer_text_generation(pipeline_or_chain, ex[\"question\"], k=3, cot_used=cot_used)\n",
    "        else:\n",
    "            raw = get_answer_qa(pipeline_or_chain, ex[\"question\"], k=3)\n",
    "\n",
    "        squad_preds.append({\n",
    "            \"id\": ex[\"id\"],\n",
    "            \"prediction_text\": raw,\n",
    "        })\n",
    "        squad_refs.append({\n",
    "            \"id\": ex[\"id\"],\n",
    "            \"answers\": {\n",
    "                \"text\": ex[\"answers\"][\"text\"], \n",
    "                \"answer_start\": ex[\"answers\"][\"answer_start\"]\n",
    "            }\n",
    "        })\n",
    "\n",
    "        texts_pred.append(raw)\n",
    "        texts_ref.append(ex[\"answers\"][\"text\"][0])\n",
    "\n",
    "    squad_results = squad_metric.compute(\n",
    "        predictions=squad_preds, \n",
    "        references=squad_refs\n",
    "    )\n",
    "\n",
    "    rouge_results = rouge_metric.compute(\n",
    "        predictions=texts_pred, \n",
    "        references=texts_ref\n",
    "    )\n",
    "\n",
    "    bleu_results = bleu_metric.compute(\n",
    "        predictions=texts_pred, \n",
    "        references=[[r] for r in texts_ref]  \n",
    "    )\n",
    "\n",
    "    return {\n",
    "        **squad_results,\n",
    "        \"rouge1\": rouge_results[\"rouge1\"],\n",
    "        \"rouge2\": rouge_results[\"rouge2\"],\n",
    "        \"rougeL\": rouge_results[\"rougeL\"],\n",
    "        \"bleu\":   bleu_results[\"bleu\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuned DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline_distilbert_finetuned = pipeline(\"question-answering\", \n",
    "                        model=\"../backend/distilbert-squad-finetuned_model\", \n",
    "                        tokenizer=\"../backend/distilbert-squad-finetuned_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\001\\AppData\\Local\\Temp\\ipykernel_58608\\1342108450.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(query)\n",
      "c:\\Users\\001\\anaconda3\\envs\\nlp_env\\Lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:371: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the metric slug'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a very seldom used unit of mass in the metric system?\"\n",
    "get_answer_qa(qa_pipeline_distilbert_finetuned, query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dde87781194ddcbc76c9bf13ca5982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on SQuAD + BLEU/ROUGE:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "results_distilbert_finetuned = evaluate(qa_pipeline_distilbert_finetuned, ds=ds_sample, is_distilbert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 70.0,\n",
       " 'f1': 73.2813258636788,\n",
       " 'rouge1': np.float64(0.687505288828818),\n",
       " 'rouge2': np.float64(0.4449621723305933),\n",
       " 'rougeL': np.float64(0.6872597010832304),\n",
       " 'bleu': 0.5422825123791992}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_distilbert_finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOT Finetuned DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5f1d62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline_distilbert_not_finetuned = pipeline(\"question-answering\", \n",
    "                        model=\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f54f690a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of particles, there are no internal forces that are unbalanced. That'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a very seldom used unit of mass in the metric system?\"\n",
    "get_answer_qa(qa_pipeline_distilbert_not_finetuned, query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba146ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504ff0b671f540b19e1ad1425c563140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on SQuAD + BLEU/ROUGE:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_distilbert_not_finetuned = evaluate(qa_pipeline_distilbert_not_finetuned, ds=ds_sample, is_distilbert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57475d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0,\n",
       " 'f1': 1.735071301247772,\n",
       " 'rouge1': np.float64(0.014065934065934066),\n",
       " 'rouge2': np.float64(0.003636363636363636),\n",
       " 'rougeL': np.float64(0.014139194139194141),\n",
       " 'bleu': 0.0054419568831522705}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_distilbert_not_finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phi4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_ollama import ChatOllama\n",
    "import torch\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"microsoft/phi-4\",\n",
    "#     task=\"text-generation\",\n",
    "#     temperature=0.0,\n",
    "#     max_new_tokens=512,\n",
    "#     model_kwargs={\"device_map\": \"cuda\", \"torch_dtype\": torch.float16},\n",
    "# )\n",
    "# chat = ChatHuggingFace(\n",
    "#     llm=llm,\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "chat = ChatOllama(\n",
    "    model=\"phi4\",    \n",
    "    temperature=0.0,        \n",
    "    num_predict=512,        # max new tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "zero_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an expert extractive question-answering system.\n",
    "        Use only the provided context to answer the question.\n",
    "        Always output the answer using the exact wording and phrasing as it appears in the context.\n",
    "        If the answer is not contained in the context, reply “Unsure about answer.”\n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Context:\n",
    "        {retrieved_SQuAD_passage}\n",
    "\n",
    "        Question:\n",
    "        {user_question}\n",
    "\n",
    "        'Answer:'\n",
    "        \"\"\"\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\001\\AppData\\Local\\Temp\\ipykernel_58608\\308783713.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain_zero_shot_prompt = LLMChain(llm=chat, prompt=zero_shot_prompt)\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "chain_zero_shot_prompt = LLMChain(llm=chat, prompt=zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce0c9b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The metric slug (sometimes mug or hyl) is that mass that accelerates at 1 m·s−2 when subjected to a force of 1 kgf.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a very seldom used unit of mass in the metric system?\"\n",
    "get_answer_text_generation(chain_zero_shot_prompt, query, k=3, cot_used=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e4fe114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d587713d0f48bb9826f4738ff34a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on SQuAD + BLEU/ROUGE:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_zero_shot = evaluate(chain_zero_shot_prompt, ds=ds_sample, is_distilbert=False, cot_used=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c15fd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 9.0,\n",
       " 'f1': 35.40381629282565,\n",
       " 'rouge1': np.float64(0.32876703530083873),\n",
       " 'rouge2': np.float64(0.22962927894887022),\n",
       " 'rougeL': np.float64(0.32855611646718663),\n",
       " 'bleu': 0.06971672811429382}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_zero_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COT Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an expert extractive question-answering system.\n",
    "        When given a context and a question, you will:\n",
    "        1. Think through the relevant part of the context step by step.\n",
    "        2. Show your reasoning clearly (chain-of-thought).\n",
    "        3. Finally, output **only** the answer using the exact wording as it appears in the context.\n",
    "        If the answer is not contained in the context, your final answer must be 'Unsure about answer.'\n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Context:\n",
    "        {retrieved_SQuAD_passage}\n",
    "\n",
    "        Question:\n",
    "        {user_question}\n",
    "\n",
    "        Begin by reasoning step by step, then conclude with 'Answer: <your extractive answer>'.\"\"\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_cot_prompt = LLMChain(llm=chat, prompt=cot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "553e6b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metric slug'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a very seldom used unit of mass in the metric system?\"\n",
    "get_answer_text_generation(chain_cot_prompt, query, k=3, cot_used=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "695dfa9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12272e3fb25497391aeb7211187783d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on SQuAD + BLEU/ROUGE:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_cot = evaluate(chain_cot_prompt, ds=ds_sample, is_distilbert=False, cot_used=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb0fb967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 50.0,\n",
       " 'f1': 65.75330030867113,\n",
       " 'rouge1': np.float64(0.6316693562618112),\n",
       " 'rouge2': np.float64(0.44573261033398315),\n",
       " 'rougeL': np.float64(0.6297702009698172),\n",
       " 'bleu': 0.2572570101548084}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_kernel",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
