{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarahmed/miniconda3/envs/main/lib/python3.12/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/omarahmed/miniconda3/envs/main/lib/python3.12/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "class GloveModel(nn.Module):\n",
    "    def __init__(self, embed_dim = 200):\n",
    "        super(GloveModel, self).__init__()\n",
    "        global_vectors = GloVe(name='6B', dim=embed_dim)\n",
    "        glove_weights = torch.load(f\".vector_cache/glove.6B.{embed_dim}d.txt.pt\")\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove_weights[2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'world', '!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenizes a string into a list of words.\"\"\"\n",
    "    return tokenizer(text)\n",
    "\n",
    "\n",
    "def detokenize(tokens):\n",
    "    \"\"\"Detokenizes a list of words into a string.\"\"\"\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "tokenize(\"Hello, world!\")  # Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m glove = GloVe(name=\u001b[33m'\u001b[39m\u001b[33m6B\u001b[39m\u001b[33m'\u001b[39m, dim=\u001b[32m300\u001b[39m).get_vecs_by_tokens(\u001b[43mtokenize\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33m[sos] Hello, world []!\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(glove)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#  decoder the indices\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "glove = GloVe(name='6B', dim=300).get_vecs_by_tokens(tokenize(\"[sos] Hello, world []!\"))\n",
    "print(glove)\n",
    "\n",
    "#  decoder the indices\n",
    "def decode_indices(indices):\n",
    "    \"\"\"Decodes a list of indices into a string.\"\"\"\n",
    "    return ' '.join([glove.itos[i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['testing', 'the', 'glove', '[eos]', 'model', '.']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'stoi'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m tokens = tokenize(text)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTokens:\u001b[39m\u001b[33m\"\u001b[39m, tokens)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m indices = [\u001b[43mglove\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstoi\u001b[49m[token] \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens]\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIndices:\u001b[39m\u001b[33m\"\u001b[39m, indices)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Tensor' object has no attribute 'stoi'"
     ]
    }
   ],
   "source": [
    "text = \"Testing the GloVe [EOS] model.\"\n",
    "tokens = tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "indices = [glove.stoi[token] for token in tokens]\n",
    "print(\"Indices:\", indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 400001 is out of bounds for dimension 0 with size 400000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mglove\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m400001\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: index 400001 is out of bounds for dimension 0 with size 400000"
     ]
    }
   ],
   "source": [
    "glove.vectors[torch.tensor([400001])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe, vocab\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#define your model that accepts pretrained embeddings \n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_embeddings, num_class, freeze_embeddings = False):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag.from_pretrained(pretrained_embeddings, freeze = freeze_embeddings, sparse=True)\n",
    "        self.fc = nn.Linear(pretrained_embeddings.shape[1], num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "train_iter = AG_NEWS(split = 'train')\n",
    "num_class = len(set([label for (label, _) in train_iter]))\n",
    "unk_token = \"<unk>\"\n",
    "unk_index = 0\n",
    "glove_vectors = GloVe()\n",
    "glove_vocab = vocab(glove_vectors.stoi)\n",
    "glove_vocab.insert_token(\"<unk>\",unk_index)\n",
    "#this is necessary otherwise it will throw runtime error if OOV token is queried \n",
    "glove_vocab.set_default_index(unk_index)\n",
    "pretrained_embeddings = glove_vectors.vectors\n",
    "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
    "\n",
    "#instantiate model with pre-trained glove vectors\n",
    "glove_model = TextClassificationModel(pretrained_embeddings, num_class)\n",
    "\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "train_iter = AG_NEWS(split = 'train')\n",
    "example_text = next(train_iter)[1]\n",
    "tokens = tokenizer(example_text)\n",
    "indices = glove_vocab(tokens)\n",
    "text_input = torch.tensor(indices)\n",
    "offset_input = torch.tensor([0])\n",
    "\n",
    "model_output = glove_model(text_input, offset_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Embeddings Shape: torch.Size([400006, 300])\n",
      "Vocab Size: 400005\n",
      "[unk]: 0\n",
      "[pad]: 1\n",
      "[mask]: 2\n",
      "[sos]: 3\n",
      "[eos]: 4\n",
      "[sep]: 5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'detokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m tokens = tokenizer(text)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m#  decode the tokens\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m decoded_text = \u001b[43mdetokenize\u001b[49m(tokens)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDecoded Text:\u001b[39m\u001b[33m\"\u001b[39m, decoded_text)\n",
      "\u001b[31mNameError\u001b[39m: name 'detokenize' is not defined"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import GloVe, vocab\n",
    "glove = GloVe(name='6B', dim=300)\n",
    "glove_vocab = vocab(glove.stoi)\n",
    "special_tokens = [\"[unk]\", \"[pad]\", \"[mask]\", \"[sos]\", \"[eos]\", \"[sep]\"]\n",
    "for i, token in enumerate(special_tokens):\n",
    "    glove_vocab.insert_token(token, i)\n",
    "    glove_vocab.set_default_index(i)\n",
    "pretrained_embeddings = glove.vectors\n",
    "pretrained_embeddings = torch.cat(\n",
    "    (torch.zeros(len(special_tokens),\n",
    "                 pretrained_embeddings.shape[1]), pretrained_embeddings))\n",
    "\n",
    "#  test the vectors\n",
    "print(\"Pretrained Embeddings Shape:\", pretrained_embeddings.shape)\n",
    "#  test the vocab\n",
    "print(\"Vocab Size:\", len(glove_vocab))\n",
    "#  test the special tokens\n",
    "for token in special_tokens:\n",
    "    print(f\"{token}: {glove_vocab[token]}\")\n",
    "\n",
    "\n",
    "text = \"Testing the GloVe [EOS] model.\"\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens = tokenizer(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Output Shape: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
    "#  test the embedding layer with a sample input\n",
    "sample_input = torch.tensor([glove_vocab[\"[eos]\"], glove_vocab[\"[unk]\"]])\n",
    "embedded_output = embedding_layer(sample_input)\n",
    "print(\"Embedded Output Shape:\", embedded_output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import GloVe, vocab\n",
    "import torch\n",
    "torchtext.disable_torchtext_deprecation_warning()\n",
    "\n",
    "\n",
    "class gloveTokenizer:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ver: str = \"6B\",\n",
    "        dim: int = 300,\n",
    "        special_tokens: list[str] = [\n",
    "            \"[UNK]\", \"[PAD]\", \"[MASK]\", \"[SOS]\", \"[EOS]\", \"[SEP]\"\n",
    "        ],\n",
    "        max_length: int = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the GloVe tokenizer.\n",
    "\n",
    "        Args:\n",
    "            ver (str): The name of the GloVe model to use. Default is \"6B\".\n",
    "            dim (int): The dimensionality of the GloVe vectors. Default is 300.\n",
    "            special_tokens (list[str]): A list of special tokens to add to the vocabulary.\n",
    "            max_length (int): The maximum length for the tokenizer. Default is None.\n",
    "        \"\"\"\n",
    "\n",
    "        glove = GloVe(name=ver, dim=dim)\n",
    "        glove_vocab = vocab(glove.stoi)\n",
    "        for i, token in enumerate(special_tokens):\n",
    "            glove_vocab.insert_token(token, i)\n",
    "        glove_vocab.set_default_index(glove_vocab[\"[UNK]\"])\n",
    "        pretrained_embeddings = glove.vectors\n",
    "        pretrained_embeddings = torch.cat(\n",
    "            (torch.randn(len(special_tokens), pretrained_embeddings.shape[1]),\n",
    "             pretrained_embeddings))\n",
    "\n",
    "        self.special_tokens = special_tokens\n",
    "        self.pretrained_embeddings = pretrained_embeddings\n",
    "        self.tokenizer = get_tokenizer(\"basic_english\")\n",
    "        self.glove_vocab = glove_vocab\n",
    "        self.max_length = max_length\n",
    "        self.pad_idx = glove_vocab[\"[PAD]\"]\n",
    "\n",
    "    def set_max_length(self, max_length: int):\n",
    "        \"\"\"\n",
    "        Set the maximum length for the tokenizer.\n",
    "\n",
    "        Args:\n",
    "            max_length (int): The maximum length for the tokenizer.\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def tokenize(self, text1: str, text2: str = None) -> list[str]:\n",
    "        \"\"\"\n",
    "        Tokenize one or two input strings, add special tokens, and PAD to max_length if set.\n",
    "\n",
    "        Args:\n",
    "            text1 (str): The first input string.\n",
    "            text2 (str, optional): The second input string (for paired input).\n",
    "\n",
    "        Returns:\n",
    "            list[str]: The tokenized and padded list with special tokens.\n",
    "        \"\"\"\n",
    "        tokens = [\"[SOS]\"] + self.tokenizer(text1)\n",
    "\n",
    "        if text2:\n",
    "            tokens += [\"[SEP]\"] + self.tokenizer(text2)\n",
    "\n",
    "        tokens.append(\"[EOS]\")\n",
    "\n",
    "        if self.max_length:\n",
    "            tokens = tokens[:self.max_length]\n",
    "            tokens += [\"[PAD]\"] * max(0, self.max_length - len(tokens))\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def encode(self, text: str) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Encode a single text into tokens.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to encode.\n",
    "        \"\"\"\n",
    "        tokens = self.tokenize(text)\n",
    "        token_ids = [self.glove_vocab[token] for token in tokens]\n",
    "        attention_mask = [0 if token_id == self.pad_idx else 1 for token_id in token_ids]\n",
    "        return torch.tensor(token_ids), attention_mask\n",
    "\n",
    "    def decode(self, token_ids: torch.Tensor) -> str:\n",
    "        \"\"\"\n",
    "        Decode a list of token IDs into text.\n",
    "\n",
    "        Args:\n",
    "            token_ids (torch.Tensor): The list of token IDs to decode.\n",
    "        \"\"\"\n",
    "        # Convert token IDs to tokens using the vocab's lookup_tokens method\n",
    "        tokens = self.glove_vocab.lookup_tokens(token_ids.tolist())\n",
    "\n",
    "        # Remove special tokens\n",
    "        tokens = [token for token in tokens if token not in self.special_tokens]\n",
    "\n",
    "        return \" \".join(tokens)\n",
    "\n",
    "    def encode_batch(\n",
    "            self, texts: list[str]) -> tuple[list[list[int]], list[list[int]]]:\n",
    "        \"\"\"\n",
    "        Encode a batch of texts into token IDs and attention masks.\n",
    "\n",
    "        Args:\n",
    "            texts (list[str]): The list of texts to encode.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - token_ids: List of lists of token IDs.\n",
    "                - attention_masks: List of lists with 1s for real tokens and 0s for padding.\n",
    "        \"\"\"\n",
    "\n",
    "        token_lists = [self.tokenize(text) for text in texts]\n",
    "        token_ids = [[self.glove_vocab[token] for token in tokens]\n",
    "                     for tokens in token_lists]\n",
    "        attention_masks = [[0 if token_id == self.pad_idx else 1 for token_id in ids]\n",
    "                           for ids in token_ids]\n",
    "\n",
    "        return token_ids, attention_masks\n",
    "\n",
    "    def decode_batch(self, token_ids_batch: list[torch.Tensor]) -> list[str]:\n",
    "        \"\"\"\n",
    "        Decode a batch of token IDs into texts.\n",
    "\n",
    "        Args:\n",
    "            token_ids_batch (list[torch.Tensor]): A list of token ID tensors to decode.\n",
    "        \"\"\"\n",
    "        # Convert each batch of token IDs to tokens using the vocab's lookup_tokens method\n",
    "        texts = [\n",
    "            self.glove_vocab.lookup_tokens(token_ids) for token_ids in token_ids_batch\n",
    "        ]\n",
    "        \n",
    "        # Remove special tokens\n",
    "        texts = [\n",
    "            [token for token in text if token not in self.special_tokens] \n",
    "            for text in texts\n",
    "        ]\n",
    "        \n",
    "        # Join tokens into strings for each batch\n",
    "        return [\" \".join(text) for text in texts]\n",
    "       \n",
    "    def encode_two_texts(self, context: str,\n",
    "                         question: str) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Encode a single context and question into tokens.\n",
    "        Args:\n",
    "            context (str): The context to encode.\n",
    "            question (str): The question to encode.\n",
    "        \"\"\"\n",
    "        tokens = self.tokenize(context, question)\n",
    "        token_ids = [self.glove_vocab[token] for token in tokens]\n",
    "        attention_mask = [0 if token_id == self.pad_idx else 1 for token_id in token_ids]\n",
    "        return torch.tensor(token_ids), attention_mask\n",
    "\n",
    "    def encode_two_texts_batch(\n",
    "            self, contexts: list[str], questions: list[str]\n",
    "    ) -> tuple[list[torch.Tensor], list[list[int]]]:\n",
    "        \"\"\"\n",
    "        Encode a batch of contexts and questions into token IDs and attention masks.\n",
    "\n",
    "        Args:\n",
    "            contexts (list[str]): The list of contexts to encode.\n",
    "            questions (list[str]): The list of questions to encode.\n",
    "\n",
    "        Returns:\n",
    "            tuple: token IDs tensors list, attention masks list\n",
    "        \"\"\"\n",
    "        token_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for context, question in zip(contexts, questions):\n",
    "            tokens = self.tokenize(context, question)\n",
    "            ids = [self.glove_vocab[token] for token in tokens]\n",
    "            mask = [0 if token_id == self.pad_idx else 1 for token_id in ids]\n",
    "            token_ids.append(torch.tensor(ids))\n",
    "            attention_masks.append(mask)\n",
    "\n",
    "        return token_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: (tensor([    3, 13080,     6,    90,   810,     5,   202,    37,    86,   193,\n",
      "            4,     1,     1,     1,     1,     1,     1,     1]), [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "Encoded Batch: ([[3, 13080, 6, 90, 810, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 202, 37, 86, 193, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Encoded: (tensor([    3, 13080,     6,    90,   810,     4,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1]), [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Decoded: hello , world !\n",
      "Decoded Batch: ['hello , world !', 'how are you ?']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "glove_tokenizer = gloveTokenizer()\n",
    "glove_tokenizer.set_max_length(18)\n",
    "text1 = \"Hello, world!\"\n",
    "text2 = \"How are you?\"\n",
    "encodings = glove_tokenizer.encode_two_texts(text1, text2)\n",
    "print(\"Encoded:\", encodings)\n",
    "encodings_batch = glove_tokenizer.encode_batch(\n",
    "    [text1, text2])\n",
    "print(\"Encoded Batch:\", encodings_batch)\n",
    "\n",
    "encodings = glove_tokenizer.encode(text1)\n",
    "print(\"Encoded:\", encodings)\n",
    "decodings = glove_tokenizer.decode(encodings[0])\n",
    "print(\"Decoded:\", decodings)\n",
    "\n",
    "# Example usage\n",
    "decoded_text = glove_tokenizer.decode_batch(\n",
    "    encodings_batch[0]  # Assuming you want to decode the first batch\n",
    ")\n",
    "print(\"Decoded Batch:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
