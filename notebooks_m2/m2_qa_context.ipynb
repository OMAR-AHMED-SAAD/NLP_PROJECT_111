{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\001\\OneDrive\\Desktop\\GUC\\semester 10\\nlp\\NLP_PROJECT_111\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "# imports \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scripts_m2 import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['qas', 'context'])\n",
      "{\n",
      "  \"title\": \"Beyonc\\u00e9\",\n",
      "  \"paragraphs\": [\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"When did Beyonce start becoming popular?\",\n",
      "          \"id\": \"56be85543aeaaa14008c9063\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"in the late 1990s\",\n",
      "              \"answer_start\": 269\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What areas did Beyonce compete in when she was growing up?\",\n",
      "          \"id\": \"56be85543aeaaa14008c9065\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"singing and dancing\",\n",
      "              \"answer_start\": 207\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce leave Destiny's Child and become a solo singer?\",\n",
      "          \"id\": \"56be85543aeaaa14008c9066\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2003\",\n",
      "              \"answer_start\": 526\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In what city and state did Beyonce  grow up? \",\n",
      "          \"id\": \"56bf6b0f3aeaaa14008c9601\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Houston, Texas\",\n",
      "              \"answer_start\": 166\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In which decade did Beyonce become famous?\",\n",
      "          \"id\": \"56bf6b0f3aeaaa14008c9602\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"late 1990s\",\n",
      "              \"answer_start\": 276\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In what R&B group was she the lead singer?\",\n",
      "          \"id\": \"56bf6b0f3aeaaa14008c9603\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Destiny's Child\",\n",
      "              \"answer_start\": 320\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What album made her a worldwide known artist?\",\n",
      "          \"id\": \"56bf6b0f3aeaaa14008c9604\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dangerously in Love\",\n",
      "              \"answer_start\": 505\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who managed the Destiny's Child group?\",\n",
      "          \"id\": \"56bf6b0f3aeaaa14008c9605\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Mathew Knowles\",\n",
      "              \"answer_start\": 360\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 rise to fame?\",\n",
      "          \"id\": \"56d43c5f2ccc5a1400d830a9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"late 1990s\",\n",
      "              \"answer_start\": 276\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What role did Beyonc\\u00e9 have in Destiny's Child?\",\n",
      "          \"id\": \"56d43c5f2ccc5a1400d830aa\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"lead singer\",\n",
      "              \"answer_start\": 290\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the first album Beyonc\\u00e9 released as a solo artist?\",\n",
      "          \"id\": \"56d43c5f2ccc5a1400d830ab\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dangerously in Love\",\n",
      "              \"answer_start\": 505\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 release Dangerously in Love?\",\n",
      "          \"id\": \"56d43c5f2ccc5a1400d830ac\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2003\",\n",
      "              \"answer_start\": 526\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many Grammy awards did Beyonc\\u00e9 win for her first solo album?\",\n",
      "          \"id\": \"56d43c5f2ccc5a1400d830ad\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"five\",\n",
      "              \"answer_start\": 590\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was Beyonc\\u00e9's role in Destiny's Child?\",\n",
      "          \"id\": \"56d43ce42ccc5a1400d830b4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"lead singer\",\n",
      "              \"answer_start\": 290\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of Beyonc\\u00e9's first solo album?\",\n",
      "          \"id\": \"56d43ce42ccc5a1400d830b5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dangerously in Love\",\n",
      "              \"answer_start\": 505\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 Giselle Knowles-Carter (/bi\\u02d0\\u02c8j\\u0252nse\\u026a/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyonc\\u00e9's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \\\"Crazy in Love\\\" and \\\"Baby Boy\\\".\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"After her second solo album, what other entertainment venture did Beyonce explore?\",\n",
      "          \"id\": \"56be86cf3aeaaa14008c9076\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"acting\",\n",
      "              \"answer_start\": 207\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which artist did Beyonce marry?\",\n",
      "          \"id\": \"56be86cf3aeaaa14008c9078\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 369\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"To set the record for Grammys, how many did Beyonce win?\",\n",
      "          \"id\": \"56be86cf3aeaaa14008c9079\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"six\",\n",
      "              \"answer_start\": 565\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"For what movie did Beyonce receive  her first Golden Globe nomination?\",\n",
      "          \"id\": \"56bf6e823aeaaa14008c9627\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dreamgirls\",\n",
      "              \"answer_start\": 260\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce take a hiatus in her career and take control of her management?\",\n",
      "          \"id\": \"56bf6e823aeaaa14008c9629\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2010\",\n",
      "              \"answer_start\": 586\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which album was darker in tone from her previous work?\",\n",
      "          \"id\": \"56bf6e823aeaaa14008c962a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonc\\u00e9\",\n",
      "              \"answer_start\": 180\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"After what movie portraying Etta James, did Beyonce create Sasha Fierce?\",\n",
      "          \"id\": \"56bf6e823aeaaa14008c962b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Cadillac Records\",\n",
      "              \"answer_start\": 406\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Destiny's Child end their group act?\",\n",
      "          \"id\": \"56d43da72ccc5a1400d830bd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"June 2005\",\n",
      "              \"answer_start\": 48\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of Beyonc\\u00e9's second solo album?\",\n",
      "          \"id\": \"56d43da72ccc5a1400d830be\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"B'Day\",\n",
      "              \"answer_start\": 95\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was Beyonc\\u00e9's first acting job, in 2006?\",\n",
      "          \"id\": \"56d43da72ccc5a1400d830bf\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dreamgirls\",\n",
      "              \"answer_start\": 260\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who is Beyonc\\u00e9 married to?\",\n",
      "          \"id\": \"56d43da72ccc5a1400d830c0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 369\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of Beyonc\\u00e9's alter-ego?\",\n",
      "          \"id\": \"56d43da72ccc5a1400d830c1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sasha Fierce\",\n",
      "              \"answer_start\": 466\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Following the disbandment of Destiny's Child in June 2005, she released her second solo album, B'Day (2006), which contained hits \\\"D\\u00e9j\\u00e0 Vu\\\", \\\"Irreplaceable\\\", and \\\"Beautiful Liar\\\". Beyonc\\u00e9 also ventured into acting, with a Golden Globe-nominated performance in Dreamgirls (2006), and starring roles in The Pink Panther (2006) and Obsessed (2009). Her marriage to rapper Jay Z and portrayal of Etta James in Cadillac Records (2008) influenced her third album, I Am... Sasha Fierce (2008), which saw the birth of her alter-ego Sasha Fierce and earned a record-setting six Grammy Awards in 2010, including Song of the Year for \\\"Single Ladies (Put a Ring on It)\\\". Beyonc\\u00e9 took a hiatus from music in 2010 and took over management of her career; her fourth album 4 (2011) was subsequently mellower in tone, exploring 1970s funk, 1980s pop, and 1990s soul. Her critically acclaimed fifth studio album, Beyonc\\u00e9 (2013), was distinguished from previous releases by its experimental production and exploration of darker themes.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"In her music, what are some recurring elements in them?\",\n",
      "          \"id\": \"56be88473aeaaa14008c9080\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"love, relationships, and monogamy\",\n",
      "              \"answer_start\": 104\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Time magazine named her one of the most 100 what people of the century?\",\n",
      "          \"id\": \"56be88473aeaaa14008c9083\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"influential\",\n",
      "              \"answer_start\": 935\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which magazine declared her the most dominant woman musician?\",\n",
      "          \"id\": \"56be88473aeaaa14008c9084\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Forbes\",\n",
      "              \"answer_start\": 985\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In which decade did the Recording Industry Association of America recognize Beyonce as the The Top Certified Artist?\",\n",
      "          \"id\": \"56bf725c3aeaaa14008c9643\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2000s\",\n",
      "              \"answer_start\": 736\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What magazine rated Beyonce as the most powerful female musician in 2015?\",\n",
      "          \"id\": \"56bf725c3aeaaa14008c9644\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Forbes\",\n",
      "              \"answer_start\": 985\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How did Beyonce describe herself as a feminist?\",\n",
      "          \"id\": \"56bf725c3aeaaa14008c9645\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"modern-day feminist\",\n",
      "              \"answer_start\": 18\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In which years did Time rate Beyonce in the 100 most influential people in the world?\",\n",
      "          \"id\": \"56bf725c3aeaaa14008c9646\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2013 and 2014\",\n",
      "              \"answer_start\": 970\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many records has Beyonce sold in her 19 year career?\",\n",
      "          \"id\": \"56bf725c3aeaaa14008c9647\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"118 million\",\n",
      "              \"answer_start\": 393\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many records did Beyonc\\u00e9 sell as part of Destiny's Child?\",\n",
      "          \"id\": \"56d43f7e2ccc5a1400d830c7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"60 million\",\n",
      "              \"answer_start\": 445\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"After leaving Destiny's Child, how many records did Beyonc\\u00e9 release under her own name?\",\n",
      "          \"id\": \"56d43f7e2ccc5a1400d830c8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"118 million\",\n",
      "              \"answer_start\": 393\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many Grammy awards has Beyonc\\u00e9 won?\",\n",
      "          \"id\": \"56d43f7e2ccc5a1400d830c9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"20\",\n",
      "              \"answer_start\": 552\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What magazine named Beyonc\\u00e9 as the most powerful female musician for 2015?\",\n",
      "          \"id\": \"56d43f7e2ccc5a1400d830cb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Forbes\",\n",
      "              \"answer_start\": 985\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"A self-described \\\"modern-day feminist\\\", Beyonc\\u00e9 creates songs that are often characterized by themes of love, relationships, and monogamy, as well as female sexuality and empowerment. On stage, her dynamic, highly choreographed performances have led to critics hailing her as one of the best entertainers in contemporary popular music. Throughout a career spanning 19 years, she has sold over 118 million records as a solo artist, and a further 60 million with Destiny's Child, making her one of the best-selling music artists of all time. She has won 20 Grammy Awards and is the most nominated woman in the award's history. The Recording Industry Association of America recognized her as the Top Certified Artist in America during the 2000s decade. In 2009, Billboard named her the Top Radio Songs Artist of the Decade, the Top Female Artist of the 2000s and their Artist of the Millennium in 2011. Time listed her among the 100 most influential people in the world in 2013 and 2014. Forbes magazine also listed her as the most powerful female musician of 2015.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce's younger sibling also sang with her in what band?\",\n",
      "          \"id\": \"56be892d3aeaaa14008c908b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Destiny's Child\",\n",
      "              \"answer_start\": 303\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Beyonce get her name from?\",\n",
      "          \"id\": \"56be892d3aeaaa14008c908c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her mother's maiden name\",\n",
      "              \"answer_start\": 204\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What race was Beyonce's father?\",\n",
      "          \"id\": \"56be892d3aeaaa14008c908d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"African-American\",\n",
      "              \"answer_start\": 330\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's childhood home believed in what religion?\",\n",
      "          \"id\": \"56be892d3aeaaa14008c908e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Methodist\",\n",
      "              \"answer_start\": 578\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's father worked as a sales manager for what company?\",\n",
      "          \"id\": \"56bf74d53aeaaa14008c9659\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Xerox\",\n",
      "              \"answer_start\": 152\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's mother worked in what industry?\",\n",
      "          \"id\": \"56bf74d53aeaaa14008c965a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"hairdresser and salon owner\",\n",
      "              \"answer_start\": 101\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What younger sister of Beyonce also appeared in Destiny's Child?\",\n",
      "          \"id\": \"56bf74d53aeaaa14008c965b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Solange\",\n",
      "              \"answer_start\": 255\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce is a descendent of what Arcadian leader?\",\n",
      "          \"id\": \"56bf74d53aeaaa14008c965d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Joseph Broussard\",\n",
      "              \"answer_start\": 540\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What company did Beyonc\\u00e9's father work for when she was a child?\",\n",
      "          \"id\": \"56d440df2ccc5a1400d830d1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Xerox\",\n",
      "              \"answer_start\": 152\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonc\\u00e9's mother own when Beyonc\\u00e9 was a child?\",\n",
      "          \"id\": \"56d440df2ccc5a1400d830d2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"salon\",\n",
      "              \"answer_start\": 117\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of Beyonc\\u00e9's younger sister?\",\n",
      "          \"id\": \"56d440df2ccc5a1400d830d3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Solange\",\n",
      "              \"answer_start\": 255\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9 is a descendant of which Acadian leader?\",\n",
      "          \"id\": \"56d440df2ccc5a1400d830d4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Joseph Broussard.\",\n",
      "              \"answer_start\": 540\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9 was raised in what religion?\",\n",
      "          \"id\": \"56d440df2ccc5a1400d830d5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Methodist\",\n",
      "              \"answer_start\": 578\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 Giselle Knowles was born in Houston, Texas, to Celestine Ann \\\"Tina\\\" Knowles (n\\u00e9e Beyinc\\u00e9), a hairdresser and salon owner, and Mathew Knowles, a Xerox sales manager. Beyonc\\u00e9's name is a tribute to her mother's maiden name. Beyonc\\u00e9's younger sister Solange is also a singer and a former member of Destiny's Child. Mathew is African-American, while Tina is of Louisiana Creole descent (with African, Native American, French, Cajun, and distant Irish and Spanish ancestry). Through her mother, Beyonc\\u00e9 is a descendant of Acadian leader Joseph Broussard. She was raised in a Methodist household.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"What town did Beyonce go to school in?\",\n",
      "          \"id\": \"56be8a583aeaaa14008c9094\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Fredericksburg\",\n",
      "              \"answer_start\": 49\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was the first person to notice Beyonce's singing ability?\",\n",
      "          \"id\": \"56be8a583aeaaa14008c9095\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Darlette Johnson\",\n",
      "              \"answer_start\": 165\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce moved to which town after she left her first elementary school?\",\n",
      "          \"id\": \"56be8a583aeaaa14008c9097\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Houston\",\n",
      "              \"answer_start\": 507\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which of her teachers discovered Beyonce's musical talent?\",\n",
      "          \"id\": \"56bf76ef3aeaaa14008c9664\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"dance instructor Darlette Johnson\",\n",
      "              \"answer_start\": 148\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"I which church was Beyonce  a member and soloist  in the choir?\",\n",
      "          \"id\": \"56bf76ef3aeaaa14008c9665\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"St. John's United Methodist Church\",\n",
      "              \"answer_start\": 711\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What type of school was Parker Elementary School?\",\n",
      "          \"id\": \"56bf76ef3aeaaa14008c9666\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"music magnet school\",\n",
      "              \"answer_start\": 484\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which song did Beyonce sing to win a competition at age 7?\",\n",
      "          \"id\": \"56bf76ef3aeaaa14008c9667\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Imagine\",\n",
      "              \"answer_start\": 385\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What city was Beyonc\\u00e9's elementary school located in?\",\n",
      "          \"id\": \"56d443ef2ccc5a1400d830db\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Fredericksburg\",\n",
      "              \"answer_start\": 49\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of Beyonc\\u00e9's first dance instructor?\",\n",
      "          \"id\": \"56d443ef2ccc5a1400d830dc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Darlette Johnson\",\n",
      "              \"answer_start\": 165\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How old was Beyonc\\u00e9 when she won a school talent show?\",\n",
      "          \"id\": \"56d443ef2ccc5a1400d830dd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"seven\",\n",
      "              \"answer_start\": 355\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What choir did Beyonc\\u00e9 sing in for two years?\",\n",
      "          \"id\": \"56d443ef2ccc5a1400d830df\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"St. John's United Methodist Church\",\n",
      "              \"answer_start\": 711\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 attended St. Mary's Elementary School in Fredericksburg, Texas, where she enrolled in dance classes. Her singing talent was discovered when dance instructor Darlette Johnson began humming a song and she finished it, able to hit the high-pitched notes. Beyonc\\u00e9's interest in music and performing continued after winning a school talent show at age seven, singing John Lennon's \\\"Imagine\\\" to beat 15/16-year-olds. In fall of 1990, Beyonc\\u00e9 enrolled in Parker Elementary School, a music magnet school in Houston, where she would perform with the school's choir. She also attended the High School for the Performing and Visual Arts and later Alief Elsik High School. Beyonc\\u00e9 was also a member of the choir at St. John's United Methodist Church as a soloist for two years.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Who decided to place Beyonce's group in Star Search the talent show?\",\n",
      "          \"id\": \"56be8bab3aeaaa14008c909f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Arne Frager\",\n",
      "              \"answer_start\": 303\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In 1995, who decided to manage the girls singing group?\",\n",
      "          \"id\": \"56be8bab3aeaaa14008c90a0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonc\\u00e9's father\",\n",
      "              \"answer_start\": 542\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was the first record label to give the girls a record deal?\",\n",
      "          \"id\": \"56be8bab3aeaaa14008c90a1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Elektra Records\",\n",
      "              \"answer_start\": 918\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who brought Beyonce to California and enter her group in Star Search?\",\n",
      "          \"id\": \"56bf79c73aeaaa14008c966d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Arne Frager\",\n",
      "              \"answer_start\": 303\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In what year did Beyonce's father quit his job to manage her group?\",\n",
      "          \"id\": \"56bf79c73aeaaa14008c966e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1995\",\n",
      "              \"answer_start\": 537\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What large record company recorded Beyonce's group's first album?\",\n",
      "          \"id\": \"56bf79c73aeaaa14008c966f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sony Music\",\n",
      "              \"answer_start\": 1264\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What record company first signed Beyonce's group and later cut them?\",\n",
      "          \"id\": \"56bf79c73aeaaa14008c9670\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Elektra Records\",\n",
      "              \"answer_start\": 918\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"At what age did Beyonce meet LaTavia Robertson?\",\n",
      "          \"id\": \"56bf79c73aeaaa14008c9671\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"age eight\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How old was Beyonc\\u00e9 when she met LaTavia Roberson?\",\n",
      "          \"id\": \"56d45abf2ccc5a1400d830e5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"eight\",\n",
      "              \"answer_start\": 7\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the first group Beyonc\\u00e9 was a part of?\",\n",
      "          \"id\": \"56d45abf2ccc5a1400d830e6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Girl's Tyme\",\n",
      "              \"answer_start\": 192\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who placed Girl's Tyme in Star Search?\",\n",
      "          \"id\": \"56d45abf2ccc5a1400d830e7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Arne Frager\",\n",
      "              \"answer_start\": 303\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 begin to manage the girl group?\",\n",
      "          \"id\": \"56d45abf2ccc5a1400d830e8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1995\",\n",
      "              \"answer_start\": 537\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who signed the girl group on October 5, 1995?\",\n",
      "          \"id\": \"56d45abf2ccc5a1400d830e9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dwayne Wiggins's Grass Roots Entertainment\",\n",
      "              \"answer_start\": 1126\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"At age eight, Beyonc\\u00e9 and childhood friend Kelly Rowland met LaTavia Roberson while in an audition for an all-girl entertainment group. They were placed into a group with three other girls as Girl's Tyme, and rapped and danced on the talent show circuit in Houston. After seeing the group, R&B producer Arne Frager brought them to his Northern California studio and placed them in Star Search, the largest talent show on national TV at the time. Girl's Tyme failed to win, and Beyonc\\u00e9 later said the song they performed was not good. In 1995 Beyonc\\u00e9's father resigned from his job to manage the group. The move reduced Beyonc\\u00e9's family's income by half, and her parents were forced to move into separated apartments. Mathew cut the original line-up to four and the group continued performing as an opening act for other established R&B girl groups. The girls auditioned before record labels and were finally signed to Elektra Records, moving to Atlanta Records briefly to work on their first recording, only to be cut by the company. This put further strain on the family, and Beyonc\\u00e9's parents separated. On October 5, 1995, Dwayne Wiggins's Grass Roots Entertainment signed the group. In 1996, the girls began recording their debut album under an agreement with Sony Music, the Knowles family reunited, and shortly after, the group got a contract with Columbia Records.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Which film featured Destiny's Child's first major single?\",\n",
      "          \"id\": \"56be8c8a3aeaaa14008c90a9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Men in Black\",\n",
      "              \"answer_start\": 215\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"For which song, did Destiny's Child take home the grammy award for best R&B performance?\",\n",
      "          \"id\": \"56be8c8a3aeaaa14008c90ab\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"\\\"Say My Name\\\"\",\n",
      "              \"answer_start\": 848\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonce record with for the movie \\\"The Best Man?\\\"\",\n",
      "          \"id\": \"56be8c8a3aeaaa14008c90ac\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Marc Nelson\",\n",
      "              \"answer_start\": 1212\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's group changed their name to Destiny's Child in what year?\",\n",
      "          \"id\": \"56bf7cb63aeaaa14008c9677\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1996\",\n",
      "              \"answer_start\": 51\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The name Destiny's Child was based on a quote in which book of the Bible?\",\n",
      "          \"id\": \"56bf7cb63aeaaa14008c9678\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Book of Isaiah\",\n",
      "              \"answer_start\": 85\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Debut song, \\\"Killing Time\\\" was featured on what movie's sound track?\",\n",
      "          \"id\": \"56bf7cb63aeaaa14008c9679\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Men in Black\",\n",
      "              \"answer_start\": 215\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song won Best R&B Performance in the 43 Annual Grammy Awards?\",\n",
      "          \"id\": \"56bf7cb63aeaaa14008c967a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Say My Name\",\n",
      "              \"answer_start\": 849\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What singer did Beyonce record a song with for the movie, ''The Best Man\\\"?\",\n",
      "          \"id\": \"56bf7cb63aeaaa14008c967b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Marc Nelson\",\n",
      "              \"answer_start\": 1212\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Destiny's Child get their name from?\",\n",
      "          \"id\": \"56d45fcb2ccc5a1400d830f9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Book of Isaiah.\",\n",
      "              \"answer_start\": 85\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Destiny's Child song, Killing Time, was included in which film's soundtrack?\",\n",
      "          \"id\": \"56d45fcb2ccc5a1400d830fa\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Men in Black.\",\n",
      "              \"answer_start\": 215\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was Destiny's Child's first major song hit?\",\n",
      "          \"id\": \"56d45fcb2ccc5a1400d830fb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"No, No, No\",\n",
      "              \"answer_start\": 330\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Destiny's Child release their second album?\",\n",
      "          \"id\": \"56d45fcb2ccc5a1400d830fc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1999\",\n",
      "              \"answer_start\": 688\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 sing a duet with for \\\"The Best Man\\\" film?\",\n",
      "          \"id\": \"56d45fcb2ccc5a1400d830fd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Marc Nelson\",\n",
      "              \"answer_start\": 1212\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"The group changed their name to Destiny's Child in 1996, based upon a passage in the Book of Isaiah. In 1997, Destiny's Child released their major label debut song \\\"Killing Time\\\" on the soundtrack to the 1997 film, Men in Black. The following year, the group released their self-titled debut album, scoring their first major hit \\\"No, No, No\\\". The album established the group as a viable act in the music industry, with moderate sales and winning the group three Soul Train Lady of Soul Awards for Best R&B/Soul Album of the Year, Best R&B/Soul or Rap New Artist, and Best R&B/Soul Single for \\\"No, No, No\\\". The group released their multi-platinum second album The Writing's on the Wall in 1999. The record features some of the group's most widely known songs such as \\\"Bills, Bills, Bills\\\", the group's first number-one single, \\\"Jumpin' Jumpin'\\\" and \\\"Say My Name\\\", which became their most successful song at the time, and would remain one of their signature songs. \\\"Say My Name\\\" won the Best R&B Performance by a Duo or Group with Vocals and the Best R&B Song at the 43rd Annual Grammy Awards. The Writing's on the Wall sold more than eight million copies worldwide. During this time, Beyonc\\u00e9 recorded a duet with Marc Nelson, an original member of Boyz II Men, on the song \\\"After All Is Said and Done\\\" for the soundtrack to the 1999 film, The Best Man.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"What mental health issue did Beyonce go through?\",\n",
      "          \"id\": \"56be8d423aeaaa14008c90b2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"depression\",\n",
      "              \"answer_start\": 169\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What event occured after she was publicly criticized?\",\n",
      "          \"id\": \"56be8d423aeaaa14008c90b3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"boyfriend left her\",\n",
      "              \"answer_start\": 320\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who supported Beyonce through her depression?\",\n",
      "          \"id\": \"56be8d423aeaaa14008c90b6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her mother\",\n",
      "              \"answer_start\": 714\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What event caused Beyonce's depression?\",\n",
      "          \"id\": \"56bf7e603aeaaa14008c9681\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"split with Luckett and Rober\",\n",
      "              \"answer_start\": 194\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How long was Beyonce depressed?\",\n",
      "          \"id\": \"56bf7e603aeaaa14008c9682\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"a couple of years\",\n",
      "              \"answer_start\": 396\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who helped Beyonce fight her depression the most?\",\n",
      "          \"id\": \"56bf7e603aeaaa14008c9685\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her mother\",\n",
      "              \"answer_start\": 714\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who replaced Luckett and Roberson in Destiny's Child?\",\n",
      "          \"id\": \"56d462f82ccc5a1400d8311f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Farrah Franklin and Michelle Williams.\",\n",
      "              \"answer_start\": 110\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was blamed for Luckett and Roberson leaving Destiny's Child?\",\n",
      "          \"id\": \"56d462f82ccc5a1400d83120\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonc\\u00e9\",\n",
      "              \"answer_start\": 149\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who helped Beyonc\\u00e9 overcome her depression during the years following the Destiny's Child split?\",\n",
      "          \"id\": \"56d462f82ccc5a1400d83121\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her mother\",\n",
      "              \"answer_start\": 714\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which newest member was removed from Destiny's Child?\",\n",
      "          \"id\": \"56d462f82ccc5a1400d83123\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Farrah Franklin\",\n",
      "              \"answer_start\": 110\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"LeToya Luckett and Roberson became unhappy with Mathew's managing of the band and eventually were replaced by Farrah Franklin and Michelle Williams. Beyonc\\u00e9 experienced depression following the split with Luckett and Roberson after being publicly blamed by the media, critics, and blogs for its cause. Her long-standing boyfriend left her at this time. The depression was so severe it lasted for a couple of years, during which she occasionally kept herself in her bedroom for days and refused to eat anything. Beyonc\\u00e9 stated that she struggled to speak about her depression because Destiny's Child had just won their first Grammy Award and she feared no one would take her seriously. Beyonc\\u00e9 would later speak of her mother as the person who helped her fight it. Franklin was dismissed, leaving just Beyonc\\u00e9, Rowland, and Williams.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"\\\"Charlie's Angels\\\" featured which single from the band members?\",\n",
      "          \"id\": \"56be8e353aeaaa14008c90c6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Independent Women Part I\",\n",
      "              \"answer_start\": 37\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many weeks did their single \\\"Independent Women Part I\\\" stay on top?\",\n",
      "          \"id\": \"56be8e353aeaaa14008c90c7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"eleven\",\n",
      "              \"answer_start\": 216\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"For what network, did Beyonce land a major movie role in?\",\n",
      "          \"id\": \"56be8e353aeaaa14008c90c8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"MTV\",\n",
      "              \"answer_start\": 348\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Their third album, Survivor, sold how many during its first week?\",\n",
      "          \"id\": \"56be8e353aeaaa14008c90c9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"663,000 copies\",\n",
      "              \"answer_start\": 793\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What French composer wrote the original opera ''Carmen'' in the 19th century?\",\n",
      "          \"id\": \"56bf89cfa10cfb1400551162\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Georges Bizet\",\n",
      "              \"answer_start\": 557\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What album caused a lawsuit to be filed in 2001?\",\n",
      "          \"id\": \"56bf89cfa10cfb1400551163\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Survivor\",\n",
      "              \"answer_start\": 593\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Independent Women Part I was on which 2000 film's soundtrack?\",\n",
      "          \"id\": \"56d4831f2ccc5a1400d83154\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Charlie's Angels.\",\n",
      "              \"answer_start\": 115\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which film did Beyonc\\u00e9 star in 2001 with Mekhi Phifer?\",\n",
      "          \"id\": \"56d4831f2ccc5a1400d83155\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Carmen: A Hip Hopera\",\n",
      "              \"answer_start\": 378\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of Destiny Child's third album?\",\n",
      "          \"id\": \"56d4831f2ccc5a1400d83156\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Survivor\",\n",
      "              \"answer_start\": 593\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who filed a lawsuit over Survivor?\",\n",
      "          \"id\": \"56d4831f2ccc5a1400d83157\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Luckett and Roberson\",\n",
      "              \"answer_start\": 628\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Destiny's Child announce their hiatus?\",\n",
      "          \"id\": \"56d4831f2ccc5a1400d83158\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"October 2001\",\n",
      "              \"answer_start\": 1070\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"The remaining band members recorded \\\"Independent Women Part I\\\", which appeared on the soundtrack to the 2000 film, Charlie's Angels. It became their best-charting single, topping the U.S. Billboard Hot 100 chart for eleven consecutive weeks. In early 2001, while Destiny's Child was completing their third album, Beyonc\\u00e9 landed a major role in the MTV made-for-television film, Carmen: A Hip Hopera, starring alongside American actor Mekhi Phifer. Set in Philadelphia, the film is a modern interpretation of the 19th century opera Carmen by French composer Georges Bizet. When the third album Survivor was released in May 2001, Luckett and Roberson filed a lawsuit claiming that the songs were aimed at them. The album debuted at number one on the U.S. Billboard 200, with first-week sales of 663,000 copies sold. The album spawned other number-one hits, \\\"Bootylicious\\\" and the title track, \\\"Survivor\\\", the latter of which earned the group a Grammy Award for Best R&B Performance by a Duo or Group with Vocals. After releasing their holiday album 8 Days of Christmas in October 2001, the group announced a hiatus to further pursue solo careers.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Who did Beyonce star with in the movie, \\\"Austin Powers in Goldmember\\\"?\",\n",
      "          \"id\": \"56be8fdf3aeaaa14008c90da\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Mike Myers\",\n",
      "              \"answer_start\": 84\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which three countries did Beyonce's song \\\"Work It Out\\\" achieve top ten status?\",\n",
      "          \"id\": \"56be8fdf3aeaaa14008c90db\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"UK, Norway, and Belgium\",\n",
      "              \"answer_start\": 331\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce starred with Cuba Gooding Jr. in which film?\",\n",
      "          \"id\": \"56be8fdf3aeaaa14008c90dc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Fighting Temptations\",\n",
      "              \"answer_start\": 431\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonce record the lead single with in the movie \\\"The Fighting Temptations\\\"?\",\n",
      "          \"id\": \"56be8fdf3aeaaa14008c90dd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Missy Elliott\",\n",
      "              \"answer_start\": 705\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which other song from the soundtrack did better in the charts?\",\n",
      "          \"id\": \"56be8fdf3aeaaa14008c90de\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Summertime\",\n",
      "              \"answer_start\": 834\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What film did Beyonce appear in with Mike Myers?\",\n",
      "          \"id\": \"56bf8c8aa10cfb140055116b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Austin Powers in Goldmember\",\n",
      "              \"answer_start\": 115\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What large amount did the movie \\\"Goldmember\\\" gross?\",\n",
      "          \"id\": \"56bf8c8aa10cfb140055116c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"73 million\",\n",
      "              \"answer_start\": 210\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What genre of movie did Beyonce star in with Cuba Gooding, Jr?\",\n",
      "          \"id\": \"56bf8c8aa10cfb140055116d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"musical comedy\",\n",
      "              \"answer_start\": 416\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song was the lead single from the film's sound track?\",\n",
      "          \"id\": \"56bf8c8aa10cfb140055116e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Fighting Temptations\",\n",
      "              \"answer_start\": 435\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How did the critics view the movie, ''The Fighting Temptations''?\",\n",
      "          \"id\": \"56bf8c8aa10cfb140055116f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"mixed reviews\",\n",
      "              \"answer_start\": 545\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What film did Beyonc\\u00e9 star in with Mike Myers in 2002?\",\n",
      "          \"id\": \"56d484312ccc5a1400d8315e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Austin Powers in Goldmember\",\n",
      "              \"answer_start\": 115\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was Beyonc\\u00e9's character called in Austin Powers in Goldmember?\",\n",
      "          \"id\": \"56d484312ccc5a1400d8315f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Foxxy Cleopatra\",\n",
      "              \"answer_start\": 58\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which song did Beyonc\\u00e9 release as the lead single for Austin Powers in Goldmember's soundtrack?\",\n",
      "          \"id\": \"56d484312ccc5a1400d83160\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Work It Out\",\n",
      "              \"answer_start\": 240\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What musical comedy did Beyonc\\u00e9 star in along with Cuba Gooding, Jr. in 2003?\",\n",
      "          \"id\": \"56d484312ccc5a1400d83161\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Fighting Temptations\",\n",
      "              \"answer_start\": 431\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did Beyonc\\u00e9 release as the lead single from The Fighting Tempations?\",\n",
      "          \"id\": \"56d484312ccc5a1400d83162\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Fighting Temptations\",\n",
      "              \"answer_start\": 435\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In July 2002, Beyonc\\u00e9 continued her acting career playing Foxxy Cleopatra alongside Mike Myers in the comedy film, Austin Powers in Goldmember, which spent its first weekend atop the US box office and grossed $73 million. Beyonc\\u00e9 released \\\"Work It Out\\\" as the lead single from its soundtrack album which entered the top ten in the UK, Norway, and Belgium. In 2003, Beyonc\\u00e9 starred opposite Cuba Gooding, Jr., in the musical comedy The Fighting Temptations as Lilly, a single mother whom Gooding's character falls in love with. The film received mixed reviews from critics but grossed $30 million in the U.S. Beyonc\\u00e9 released \\\"Fighting Temptation\\\" as the lead single from the film's soundtrack album, with Missy Elliott, MC Lyte, and Free which was also used to promote the film. Another of Beyonc\\u00e9's contributions to the soundtrack, \\\"Summertime\\\", fared better on the US charts.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"What was the highest Beyonce's first solo recording achieved in the Billboard Hot 100?\",\n",
      "          \"id\": \"56be90ee3aeaaa14008c90e4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"number four\",\n",
      "              \"answer_start\": 123\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's first album by herself was called what?\",\n",
      "          \"id\": \"56be90ee3aeaaa14008c90e5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dangerously in Love\",\n",
      "              \"answer_start\": 193\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many has \\\"Dangerously in Love\\\" sould worldwide since its debut?\",\n",
      "          \"id\": \"56be90ee3aeaaa14008c90e6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"11 million\",\n",
      "              \"answer_start\": 419\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's first number one song was which song?\",\n",
      "          \"id\": \"56be90ee3aeaaa14008c90e7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Crazy in Love\",\n",
      "              \"answer_start\": 474\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many top five singles came from her first album?\",\n",
      "          \"id\": \"56be90ee3aeaaa14008c90e8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"four\",\n",
      "              \"answer_start\": 130\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's first solo album in the U.S. with what artist in the lead single?\",\n",
      "          \"id\": \"56bf8fc1a10cfb1400551175\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 48\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What solo album did Beyonce release in 2003?\",\n",
      "          \"id\": \"56bf8fc1a10cfb1400551176\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dangerously in Love\",\n",
      "              \"answer_start\": 193\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \" The album, Dangerously in Love  achieved what spot on the Billboard Top 100 chart?\",\n",
      "          \"id\": \"56bf8fc1a10cfb1400551177\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"number four\",\n",
      "              \"answer_start\": 123\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"\\\"The Closer I get to You\\\" was recorded with which artist?\",\n",
      "          \"id\": \"56bf8fc1a10cfb1400551178\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Luther Vandross\",\n",
      "              \"answer_start\": 1042\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which artist was associated with Beyonc\\u00e9's premiere solo recording?\",\n",
      "          \"id\": \"56d4b9702ccc5a1400d83172\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 48\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 release her first solo album?\",\n",
      "          \"id\": \"56d4b9702ccc5a1400d83173\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"June 24, 2003\",\n",
      "              \"answer_start\": 229\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the lead single on Beyonc\\u00e9's first album?\",\n",
      "          \"id\": \"56d4b9702ccc5a1400d83174\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Crazy in Love\",\n",
      "              \"answer_start\": 474\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who helped Beyonc\\u00e9 earn a Grammy award for Best R&B Performance by a Duo or Group at the 46th annual Grammy Awards?\",\n",
      "          \"id\": \"56d4b9702ccc5a1400d83175\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Luther Vandross.\",\n",
      "              \"answer_start\": 1042\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many awards did Beyonc\\u00e9 win at the 46th Grammy's Awards?\",\n",
      "          \"id\": \"56d4b9702ccc5a1400d83176\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"five.\",\n",
      "              \"answer_start\": 696\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9's first solo recording was a feature on Jay Z's \\\"'03 Bonnie & Clyde\\\" that was released in October 2002, peaking at number four on the U.S. Billboard Hot 100 chart. Her first solo album Dangerously in Love was released on June 24, 2003, after Michelle Williams and Kelly Rowland had released their solo efforts. The album sold 317,000 copies in its first week, debuted atop the Billboard 200, and has since sold 11 million copies worldwide. The album's lead single, \\\"Crazy in Love\\\", featuring Jay Z, became Beyonc\\u00e9's first number-one single as a solo artist in the US. The single \\\"Baby Boy\\\" also reached number one, and singles, \\\"Me, Myself and I\\\" and \\\"Naughty Girl\\\", both reached the top-five. The album earned Beyonc\\u00e9 a then record-tying five awards at the 46th Annual Grammy Awards; Best Contemporary R&B Album, Best Female R&B Vocal Performance for \\\"Dangerously in Love 2\\\", Best R&B Song and Best Rap/Sung Collaboration for \\\"Crazy in Love\\\", and Best R&B Performance by a Duo or Group with Vocals for \\\"The Closer I Get to You\\\" with Luther Vandross.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Destiny's Child's final album was named what?\",\n",
      "          \"id\": \"56be91b23aeaaa14008c90f0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Destiny Fulfilled\",\n",
      "              \"answer_start\": 513\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Destiny's Child got a star on the Hollywood Walk of Fame in what year?\",\n",
      "          \"id\": \"56be91b23aeaaa14008c90f2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2006\",\n",
      "              \"answer_start\": 1212\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In what year did Beyonce embark on her Dangerously in Love tour of Europe?\",\n",
      "          \"id\": \"56bf91c6a10cfb140055117f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"November 2003\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the final album of Destiny's Child?\",\n",
      "          \"id\": \"56bf91c6a10cfb1400551181\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Destiny Fulfilled\",\n",
      "              \"answer_start\": 664\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"It was announced that Destiny's Child would  disban in what European city?\",\n",
      "          \"id\": \"56bf91c6a10cfb1400551182\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Barcelona\",\n",
      "              \"answer_start\": 935\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Destiny's Child get their star on the Hollywood Walk of Fame?\",\n",
      "          \"id\": \"56bf91c6a10cfb1400551183\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"March 2006\",\n",
      "              \"answer_start\": 1206\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of Beyonc\\u00e9's European start that started in November 2003?\",\n",
      "          \"id\": \"56d4baf92ccc5a1400d8317c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dangerously in Love Tour\",\n",
      "              \"answer_start\": 38\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 tour with for the Verizon Lades First Tour?\",\n",
      "          \"id\": \"56d4baf92ccc5a1400d8317d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Missy Elliott and Alicia Keys\",\n",
      "              \"answer_start\": 100\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What major event did Beyonc\\u00e9 perform at on February 1, 2004?\",\n",
      "          \"id\": \"56d4baf92ccc5a1400d8317e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Super Bowl XXXVIII\",\n",
      "              \"answer_start\": 253\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of the final studio album from Destiny's Child?\",\n",
      "          \"id\": \"56d4baf92ccc5a1400d8317f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Destiny Fulfilled.\",\n",
      "              \"answer_start\": 848\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In November 2003, she embarked on the Dangerously in Love Tour in Europe and later toured alongside Missy Elliott and Alicia Keys for the Verizon Ladies First Tour in North America. On February 1, 2004, Beyonc\\u00e9 performed the American national anthem at Super Bowl XXXVIII, at the Reliant Stadium in Houston, Texas. After the release of Dangerously in Love, Beyonc\\u00e9 had planned to produce a follow-up album using several of the left-over tracks. However, this was put on hold so she could concentrate on recording Destiny Fulfilled, the final studio album by Destiny's Child. Released on November 15, 2004, in the US and peaking at number two on the Billboard 200, Destiny Fulfilled included the singles \\\"Lose My Breath\\\" and \\\"Soldier\\\", which reached the top five on the Billboard Hot 100 chart. Destiny's Child embarked on a worldwide concert tour, Destiny Fulfilled... and Lovin' It and during the last stop of their European tour, in Barcelona on June 11, 2005, Rowland announced that Destiny's Child would disband following the North American leg of the tour. The group released their first compilation album Number 1's on October 25, 2005, in the US and accepted a star on the Hollywood Walk of Fame in March 2006.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"How many albums did Beyonce sell in the first week when she released her second album?\",\n",
      "          \"id\": \"56be932e3aeaaa14008c90f9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"541,000\",\n",
      "              \"answer_start\": 132\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The lead single from the album was which song?\",\n",
      "          \"id\": \"56be932e3aeaaa14008c90fa\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"D\\u00e9j\\u00e0 Vu\",\n",
      "              \"answer_start\": 303\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many countries did her song \\\"Irreplaceable\\\" get number one status in?\",\n",
      "          \"id\": \"56be932e3aeaaa14008c90fb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"five\",\n",
      "              \"answer_start\": 346\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many singles did her second album produce?\",\n",
      "          \"id\": \"56be932e3aeaaa14008c90fc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"five\",\n",
      "              \"answer_start\": 346\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What birthday did Beyonce's album B'Day celebrate?\",\n",
      "          \"id\": \"56bf940da10cfb1400551189\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"twenty-fifth birthday\",\n",
      "              \"answer_start\": 101\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What artist did Beyonce duet with in the single, \\\"Deja Vu''?\",\n",
      "          \"id\": \"56bf940da10cfb140055118a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 323\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How high did ''Deja Vu'' climb on the Billboard chart?\",\n",
      "          \"id\": \"56bf940da10cfb140055118b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"top five\",\n",
      "              \"answer_start\": 342\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of Beyonc\\u00e9's second album?\",\n",
      "          \"id\": \"56d4bc642ccc5a1400d83190\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"B'Day\",\n",
      "              \"answer_start\": 28\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many copies did B'Day sell during the first week of its release?\",\n",
      "          \"id\": \"56d4bc642ccc5a1400d83191\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"541,000\",\n",
      "              \"answer_start\": 132\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who collaborated with Beyonc\\u00e9 on the single, Deja Vu?\",\n",
      "          \"id\": \"56d4bc642ccc5a1400d83192\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 323\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which single from B'Day was only released in the U.K.?\",\n",
      "          \"id\": \"56d4bc642ccc5a1400d83193\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Green Light\",\n",
      "              \"answer_start\": 635\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9's second solo album B'Day was released on September 5, 2006, in the US, to coincide with her twenty-fifth birthday. It sold 541,000 copies in its first week and debuted atop the Billboard 200, becoming Beyonc\\u00e9's second consecutive number-one album in the United States. The album's lead single \\\"D\\u00e9j\\u00e0 Vu\\\", featuring Jay Z, reached the top five on the Billboard Hot 100 chart. The second international single \\\"Irreplaceable\\\" was a commercial success worldwide, reaching number one in Australia, Hungary, Ireland, New Zealand and the United States. B'Day also produced three other singles; \\\"Ring the Alarm\\\", \\\"Get Me Bodied\\\", and \\\"Green Light\\\" (released in the United Kingdom only).\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"What movie did Beyonce act in 2006?\",\n",
      "          \"id\": \"56be94703aeaaa14008c9102\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Pink Panther\",\n",
      "              \"answer_start\": 53\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Her second movie Beyonce did was what film?\",\n",
      "          \"id\": \"56be94703aeaaa14008c9103\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dreamgirls\",\n",
      "              \"answer_start\": 171\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The single, \\\"Listen\\\" was featured in which movie?\",\n",
      "          \"id\": \"56be94703aeaaa14008c9104\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dreamgirls\",\n",
      "              \"answer_start\": 171\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's first world tour was when?\",\n",
      "          \"id\": \"56be94703aeaaa14008c9105\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2007\",\n",
      "              \"answer_start\": 550\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much money did Beyonce's tour make in 2007?\",\n",
      "          \"id\": \"56be94703aeaaa14008c9106\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"24 million\",\n",
      "              \"answer_start\": 671\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many millions of dollars did ''The Pink Panther'' gross world-wide?\",\n",
      "          \"id\": \"56bf95eaa10cfb1400551194\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"158.8 million\",\n",
      "              \"answer_start\": 112\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonce call her first concert tour?\",\n",
      "          \"id\": \"56bf95eaa10cfb1400551195\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Beyonc\\u00e9 Experience\",\n",
      "              \"answer_start\": 576\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was Beyonce's duet with in ''Beautiful Liar''?\",\n",
      "          \"id\": \"56bf95eaa10cfb1400551196\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Shakira\",\n",
      "              \"answer_start\": 932\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which film did Beyonc\\u00e9 star with Steve Martin in?\",\n",
      "          \"id\": \"56d4bd272ccc5a1400d831a0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Pink Panther\",\n",
      "              \"answer_start\": 53\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9's role in Dreamgirls was based on what pop singer?\",\n",
      "          \"id\": \"56d4bd272ccc5a1400d831a1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Diana Ross.\",\n",
      "              \"answer_start\": 436\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the lead single for the Dreamgirls soundtrack?\",\n",
      "          \"id\": \"56d4bd272ccc5a1400d831a2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Listen\",\n",
      "              \"answer_start\": 487\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of Beyonc\\u00e9's first international tour?\",\n",
      "          \"id\": \"56d4bd272ccc5a1400d831a3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Beyonc\\u00e9 Experience\",\n",
      "              \"answer_start\": 576\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What pop singer did a duet with Beyonc\\u00e9 on Beautiful Liar?\",\n",
      "          \"id\": \"56d4bd272ccc5a1400d831a4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Shakira\",\n",
      "              \"answer_start\": 932\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Her first acting role of 2006 was in the comedy film The Pink Panther starring opposite Steve Martin, grossing $158.8 million at the box office worldwide. Her second film Dreamgirls, the film version of the 1981 Broadway musical loosely based on The Supremes, received acclaim from critics and grossed $154 million internationally. In it, she starred opposite Jennifer Hudson, Jamie Foxx, and Eddie Murphy playing a pop singer based on Diana Ross. To promote the film, Beyonc\\u00e9 released \\\"Listen\\\" as the lead single from the soundtrack album. In April 2007, Beyonc\\u00e9 embarked on The Beyonc\\u00e9 Experience, her first worldwide concert tour, visiting 97 venues and grossed over $24 million.[note 1] Beyonc\\u00e9 conducted pre-concert food donation drives during six major stops in conjunction with her pastor at St. John's and America's Second Harvest. At the same time, B'Day was re-released with five additional songs, including her duet with Shakira \\\"Beautiful Liar\\\".\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce got married in 2008 to whom?\",\n",
      "          \"id\": \"56be95823aeaaa14008c910c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 34\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Her third album, \\\"I am...Sasha Fierce\\\" was released when?\",\n",
      "          \"id\": \"56be95823aeaaa14008c910d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"November 18, 2008\",\n",
      "              \"answer_start\": 253\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"For which decade, did Beyonce have more top ten songs than any other woman?\",\n",
      "          \"id\": \"56be95823aeaaa14008c910e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2000s\",\n",
      "              \"answer_start\": 897\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which singer beat out Beyonce for best video performance?\",\n",
      "          \"id\": \"56be95823aeaaa14008c910f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Taylor Swift\",\n",
      "              \"answer_start\": 1567\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In 2009, Beyonce started her second world tour and grossed how much money?\",\n",
      "          \"id\": \"56be95823aeaaa14008c9110\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"119.5 million\",\n",
      "              \"answer_start\": 1881\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How did she reveal the marriage?\",\n",
      "          \"id\": \"56bf97aba10cfb140055119e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"in a video montage\",\n",
      "              \"answer_start\": 78\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce begin her second world tour?\",\n",
      "          \"id\": \"56bf97aba10cfb140055119f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"March 2009\",\n",
      "              \"answer_start\": 1744\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who beat out Beyonce for Best Female Video ?\",\n",
      "          \"id\": \"56bf97aba10cfb14005511a0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Taylor Swift\",\n",
      "              \"answer_start\": 1567\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much did the second world tour make in dollars?\",\n",
      "          \"id\": \"56bf97aba10cfb14005511a1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"119.5 million\",\n",
      "              \"answer_start\": 1881\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 get married?\",\n",
      "          \"id\": \"56d4bf242ccc5a1400d831be\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"April 4, 2008\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 marry?\",\n",
      "          \"id\": \"56d4bf242ccc5a1400d831bf\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z.\",\n",
      "              \"answer_start\": 34\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who is Beyonc\\u00e9's alter ego?\",\n",
      "          \"id\": \"56d4bf242ccc5a1400d831c0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sasha Fierce\",\n",
      "              \"answer_start\": 156\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The video for what song won Beyonc\\u00e9 the 2009 MTV Video of the Year award?\",\n",
      "          \"id\": \"56d4bf242ccc5a1400d831c1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Single Ladies\",\n",
      "              \"answer_start\": 605\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which prominent star felt the 2009 Female Video of the Year award should have went to Beyonc\\u00e9 instead of Taylor Swift?\",\n",
      "          \"id\": \"56d4bf242ccc5a1400d831c2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Kanye West\",\n",
      "              \"answer_start\": 1611\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"On April 4, 2008, Beyonc\\u00e9 married Jay Z. She publicly revealed their marriage in a video montage at the listening party for her third studio album, I Am... Sasha Fierce, in Manhattan's Sony Club on October 22, 2008. I Am... Sasha Fierce was released on November 18, 2008 in the United States. The album formally introduces Beyonc\\u00e9's alter ego Sasha Fierce, conceived during the making of her 2003 single \\\"Crazy in Love\\\", selling 482,000 copies in its first week, debuting atop the Billboard 200, and giving Beyonc\\u00e9 her third consecutive number-one album in the US. The album featured the number-one song \\\"Single Ladies (Put a Ring on It)\\\" and the top-five songs \\\"If I Were a Boy\\\" and \\\"Halo\\\". Achieving the accomplishment of becoming her longest-running Hot 100 single in her career, \\\"Halo\\\"'s success in the US helped Beyonc\\u00e9 attain more top-ten singles on the list than any other woman during the 2000s. It also included the successful \\\"Sweet Dreams\\\", and singles \\\"Diva\\\", \\\"Ego\\\", \\\"Broken-Hearted Girl\\\" and \\\"Video Phone\\\". The music video for \\\"Single Ladies\\\" has been parodied and imitated around the world, spawning the \\\"first major dance craze\\\" of the Internet age according to the Toronto Star. The video has won several awards, including Best Video at the 2009 MTV Europe Music Awards, the 2009 Scottish MOBO Awards, and the 2009 BET Awards. At the 2009 MTV Video Music Awards, the video was nominated for nine awards, ultimately winning three including Video of the Year. Its failure to win the Best Female Video category, which went to American country pop singer Taylor Swift's \\\"You Belong with Me\\\", led to Kanye West interrupting the ceremony and Beyonc\\u00e9 improvising a re-presentation of Swift's award during her own acceptance speech. In March 2009, Beyonc\\u00e9 embarked on the I Am... World Tour, her second headlining worldwide concert tour, consisting of 108 shows, grossing $119.5 million.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce portrayed which character in the film, Cadillac Records?\",\n",
      "          \"id\": \"56be96653aeaaa14008c9116\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Etta James\",\n",
      "              \"answer_start\": 69\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce gave her entire salary from Cadillac Records to which organization?\",\n",
      "          \"id\": \"56be96653aeaaa14008c9117\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Phoenix House\",\n",
      "              \"answer_start\": 439\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which song did Beyonce sing at the first couple's inaugural ball? \",\n",
      "          \"id\": \"56be96653aeaaa14008c9118\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"At Last\",\n",
      "              \"answer_start\": 582\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What genre of film was the movie, Obsessed, in which Beyonce starred in?\",\n",
      "          \"id\": \"56be96653aeaaa14008c9119\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"thriller\",\n",
      "              \"answer_start\": 693\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"A fight scene from the movie, Obsessed, won which award for Beyonce?\",\n",
      "          \"id\": \"56be96653aeaaa14008c911a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"MTV Movie Award for Best Fight\",\n",
      "              \"answer_start\": 1101\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Beyonce donate her salary from the movie Cadillac Records?\",\n",
      "          \"id\": \"56bf99aca10cfb14005511a7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Phoenix House\",\n",
      "              \"answer_start\": 439\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What thriller film did Beyonce star in?\",\n",
      "          \"id\": \"56bf99aca10cfb14005511a9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Obsessed\",\n",
      "              \"answer_start\": 703\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the woman she played in Obsessed?\",\n",
      "          \"id\": \"56bf99aca10cfb14005511aa\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sharon Charles\",\n",
      "              \"answer_start\": 724\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much more that the buget did the film gross?\",\n",
      "          \"id\": \"56bf99aca10cfb14005511ab\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"60 million\",\n",
      "              \"answer_start\": 940\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which singer did Beyonc\\u00e9 portray in Cadillac Records?\",\n",
      "          \"id\": \"56d4c0452ccc5a1400d831c8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Etta James\",\n",
      "              \"answer_start\": 69\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which organization received Beyonc\\u00e9's entire Cadillac Records salary?\",\n",
      "          \"id\": \"56d4c0452ccc5a1400d831c9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Phoenix House\",\n",
      "              \"answer_start\": 439\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Beyonc\\u00e9 perform on January 20, 2009?\",\n",
      "          \"id\": \"56d4c0452ccc5a1400d831ca\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the First Couple's first inaugural ball.\",\n",
      "              \"answer_start\": 594\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which thriller film did Beyonc\\u00e9 star in with Ali Larter?\",\n",
      "          \"id\": \"56d4c0452ccc5a1400d831cb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Obsessed.\",\n",
      "              \"answer_start\": 703\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 further expanded her acting career, starring as blues singer Etta James in the 2008 musical biopic, Cadillac Records. Her performance in the film received praise from critics, and she garnered several nominations for her portrayal of James, including a Satellite Award nomination for Best Supporting Actress, and a NAACP Image Award nomination for Outstanding Supporting Actress. Beyonc\\u00e9 donated her entire salary from the film to Phoenix House, an organization of rehabilitation centers for heroin addicts around the country. On January 20, 2009, Beyonc\\u00e9 performed James' \\\"At Last\\\" at the First Couple's first inaugural ball. Beyonc\\u00e9 starred opposite Ali Larter and Idris Elba in the thriller, Obsessed. She played Sharon Charles, a mother and wife who learns of a woman's obsessive behavior over her husband. Although the film received negative reviews from critics, the movie did well at the US box office, grossing $68 million\\u2014$60 million more than Cadillac Records\\u2014on a budget of $20 million. The fight scene finale between Sharon and the character played by Ali Larter also won the 2010 MTV Movie Award for Best Fight.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"How many awards was Beyonce nominated for at the 52nd Grammy Awards?\",\n",
      "          \"id\": \"56be973d3aeaaa14008c9120\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"ten\",\n",
      "              \"answer_start\": 51\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce tied with which artist for most nominations by a female artist?\",\n",
      "          \"id\": \"56be973d3aeaaa14008c9121\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Lauryn Hill\",\n",
      "              \"answer_start\": 242\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In 2010, Beyonce worked with which other famous singer?\",\n",
      "          \"id\": \"56be973d3aeaaa14008c9122\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Lady Gaga\",\n",
      "              \"answer_start\": 352\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many number one singles did Beyonce now have after the song \\\"Telephone\\\"?\",\n",
      "          \"id\": \"56be973d3aeaaa14008c9123\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"six\",\n",
      "              \"answer_start\": 457\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce tied who for most number one singles by a female?\",\n",
      "          \"id\": \"56be973d3aeaaa14008c9124\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Mariah Carey\",\n",
      "              \"answer_start\": 517\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce received how many nominations at the 52nd Annual Grammy Awards?\",\n",
      "          \"id\": \"56bf9b57a10cfb14005511b1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"ten nominations\",\n",
      "              \"answer_start\": 51\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song was the sixth first place song for Beyonce?\",\n",
      "          \"id\": \"56bf9b57a10cfb14005511b2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Telephone\",\n",
      "              \"answer_start\": 372\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who else appeared with Beyonce in Telephone?\",\n",
      "          \"id\": \"56bf9b57a10cfb14005511b3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Lady Gaga\",\n",
      "              \"answer_start\": 352\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did they tie with for six top songs?\",\n",
      "          \"id\": \"56bf9b57a10cfb14005511b4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Mariah Carey\",\n",
      "              \"answer_start\": 517\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonce tie with for the most nominations in a year?\",\n",
      "          \"id\": \"56bf9b57a10cfb14005511b5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Lauryn Hill\",\n",
      "              \"answer_start\": 242\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many nominations did Beyonc\\u00e9 receive at the 52nd Grammy Awards ceremony?\",\n",
      "          \"id\": \"56d4c1452ccc5a1400d831dc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"ten\",\n",
      "              \"answer_start\": 51\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 tie with for the most Grammy nominations for female artists?\",\n",
      "          \"id\": \"56d4c1452ccc5a1400d831de\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Lauryn Hill\",\n",
      "              \"answer_start\": 242\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9 was a featured artist on which singer's hit, Telephone?\",\n",
      "          \"id\": \"56d4c1452ccc5a1400d831df\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Lady Gaga\",\n",
      "              \"answer_start\": 352\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 and Lady Gaga tie with for the most number one hits since 1992?\",\n",
      "          \"id\": \"56d4c1452ccc5a1400d831e0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Mariah Carey\",\n",
      "              \"answer_start\": 517\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"At the 52nd Annual Grammy Awards, Beyonc\\u00e9 received ten nominations, including Album of the Year for I Am... Sasha Fierce, Record of the Year for \\\"Halo\\\", and Song of the Year for \\\"Single Ladies (Put a Ring on It)\\\", among others. She tied with Lauryn Hill for most Grammy nominations in a single year by a female artist. In 2010, Beyonc\\u00e9 was featured on Lady Gaga's single \\\"Telephone\\\" and its music video. The song topped the US Pop Songs chart, becoming the sixth number-one for both Beyonc\\u00e9 and Gaga, tying them with Mariah Carey for most number-ones since the Nielsen Top 40 airplay chart launched in 1992. \\\"Telephone\\\" received a Grammy Award nomination for Best Pop Collaboration with Vocals.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce would take a break from music in which year?\",\n",
      "          \"id\": \"56be97c73aeaaa14008c912a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2010\",\n",
      "              \"answer_start\": 60\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which year did Beyonce and her father part business ways?\",\n",
      "          \"id\": \"56be97c73aeaaa14008c912b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2010\",\n",
      "              \"answer_start\": 60\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which famous landmark did Beyonce see in China?\",\n",
      "          \"id\": \"56be97c73aeaaa14008c912e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the Great Wall of China\",\n",
      "              \"answer_start\": 300\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In what year did Beyonce have her hiatus?\",\n",
      "          \"id\": \"56bf9c70a10cfb14005511bb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2010\",\n",
      "              \"answer_start\": 60\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who inspired this hiatus?\",\n",
      "          \"id\": \"56bf9c70a10cfb14005511bc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her mother\",\n",
      "              \"answer_start\": 74\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did she stop using her father as a manager?\",\n",
      "          \"id\": \"56bf9c70a10cfb14005511bd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"During the break\",\n",
      "              \"answer_start\": 143\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How long did the hiatus last?\",\n",
      "          \"id\": \"56bf9c70a10cfb14005511bf\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"nine months\",\n",
      "              \"answer_start\": 244\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonc\\u00e9 announce in January 2010?\",\n",
      "          \"id\": \"56d4c1c12ccc5a1400d831e6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"a hiatus\",\n",
      "              \"answer_start\": 18\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who suggested the hiatus for Beyonc\\u00e9?\",\n",
      "          \"id\": \"56d4c1c12ccc5a1400d831e7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her mother\",\n",
      "              \"answer_start\": 74\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 part ways with during her hiatus?\",\n",
      "          \"id\": \"56d4c1c12ccc5a1400d831e8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her father\",\n",
      "              \"answer_start\": 168\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How long did her hiatus last?\",\n",
      "          \"id\": \"56d4c1c12ccc5a1400d831e9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"nine months\",\n",
      "              \"answer_start\": 244\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 announced a hiatus from her music career in January 2010, heeding her mother's advice, \\\"to live life, to be inspired by things again\\\". During the break she and her father parted ways as business partners. Beyonc\\u00e9's musical break lasted nine months and saw her visit multiple European cities, the Great Wall of China, the Egyptian pyramids, Australia, English music festivals and various museums and ballet performances.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"In which year was reports about Beyonce performing for Muammar Gaddafi surface?\",\n",
      "          \"id\": \"56be99b53aeaaa14008c913e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2011\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonce donate the money to earned from her shows?\",\n",
      "          \"id\": \"56be99b53aeaaa14008c913f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Clinton Bush Haiti Fund\",\n",
      "              \"answer_start\": 367\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce became the first female artist to perform solo in 20 years at which stage?\",\n",
      "          \"id\": \"56be99b53aeaaa14008c9140\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the 2011 Glastonbury Festival\",\n",
      "              \"answer_start\": 486\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which organization did Beyonce's spokespeople confirm her donations to?\",\n",
      "          \"id\": \"56be99b53aeaaa14008c9141\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Huffington Post\",\n",
      "              \"answer_start\": 313\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce was listed in 2011 as the highest paid performer per what?\",\n",
      "          \"id\": \"56be99b53aeaaa14008c9142\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"minute\",\n",
      "              \"answer_start\": 596\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Hoe did everyone learn that Beyonce performed for Kaddafi?\",\n",
      "          \"id\": \"56bf9dbda10cfb14005511c5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"documents obtained by WikiLeaks\",\n",
      "              \"answer_start\": 9\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did this leak happen?\",\n",
      "          \"id\": \"56bf9dbda10cfb14005511c6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2011\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did she tell about the donation?\",\n",
      "          \"id\": \"56bf9dbda10cfb14005511c8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Huffington Post\",\n",
      "              \"answer_start\": 313\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Beyonce perform in 2011?\",\n",
      "          \"id\": \"56bf9dbda10cfb14005511c9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Glastonbury Festival\",\n",
      "              \"answer_start\": 495\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 perform privately for in 2011?\",\n",
      "          \"id\": \"56d4c2b22ccc5a1400d831f2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Muammar Gaddafi.\",\n",
      "              \"answer_start\": 137\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who released the information about Beyonc\\u00e9's performance for the Libyan ruler?\",\n",
      "          \"id\": \"56d4c2b22ccc5a1400d831f3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"WikiLeaks\",\n",
      "              \"answer_start\": 31\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which organization did Beyonc\\u00e9 donate her pay for the private performance to?\",\n",
      "          \"id\": \"56d4c2b22ccc5a1400d831f4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Clinton Bush Haiti Fund.\",\n",
      "              \"answer_start\": 367\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9 was the first female singer to headline what at the 2011 Glastonbury Festival?\",\n",
      "          \"id\": \"56d4c2b22ccc5a1400d831f5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Pyramid stage\",\n",
      "              \"answer_start\": 469\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In 2011, documents obtained by WikiLeaks revealed that Beyonc\\u00e9 was one of many entertainers who performed for the family of Libyan ruler Muammar Gaddafi. Rolling Stone reported that the music industry was urging them to return the money they earned for the concerts; a spokesperson for Beyonc\\u00e9 later confirmed to The Huffington Post that she donated the money to the Clinton Bush Haiti Fund. Later that year she became the first solo female artist to headline the main Pyramid stage at the 2011 Glastonbury Festival in over twenty years, and was named the highest-paid performer in the world per minute.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce's fourth album debuted in what year?\",\n",
      "          \"id\": \"56be9add3aeaaa14008c9152\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2011\",\n",
      "              \"answer_start\": 51\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which single had the most success from that album?\",\n",
      "          \"id\": \"56be9add3aeaaa14008c9153\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Love on Top\",\n",
      "              \"answer_start\": 371\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce won an award for which activity in 2011?\",\n",
      "          \"id\": \"56be9add3aeaaa14008c9155\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"writing\",\n",
      "              \"answer_start\": 617\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"in 2011, Beyonce performed for four nights where?\",\n",
      "          \"id\": \"56be9add3aeaaa14008c9156\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"New York's Roseland Ballroom\",\n",
      "              \"answer_start\": 719\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When was Beyonce's forth album released?\",\n",
      "          \"id\": \"56bf9f6aa10cfb14005511cf\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"June 28, 2011\",\n",
      "              \"answer_start\": 42\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many copies did the album sell in its first week?\",\n",
      "          \"id\": \"56bf9f6aa10cfb14005511d0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"310,000 copies\",\n",
      "              \"answer_start\": 74\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who awarded Beyonce and award for writing?\",\n",
      "          \"id\": \"56bf9f6aa10cfb14005511d2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"New York Association of Black Journalists\",\n",
      "              \"answer_start\": 640\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did she perform at the Roseland ballroom?\",\n",
      "          \"id\": \"56bf9f6aa10cfb14005511d3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2011\",\n",
      "              \"answer_start\": 51\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of Beyonc\\u00e9's fourth studio album?\",\n",
      "          \"id\": \"56d4c4532ccc5a1400d83204\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"4\",\n",
      "              \"answer_start\": 24\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When was 4 released?\",\n",
      "          \"id\": \"56d4c4532ccc5a1400d83205\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"June 28, 2011\",\n",
      "              \"answer_start\": 42\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many copies of 4 sold in the first week?\",\n",
      "          \"id\": \"56d4c4532ccc5a1400d83206\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"310,000\",\n",
      "              \"answer_start\": 74\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What magazine did Beyonc\\u00e9 write a story for about her earlier hiatus?\",\n",
      "          \"id\": \"56d4c4532ccc5a1400d83207\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Essence\",\n",
      "              \"answer_start\": 562\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Beyonc\\u00e9 perform for four nights of standing room only concerts in 2011?\",\n",
      "          \"id\": \"56d4c4532ccc5a1400d83208\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"New York's Roseland Ballroom\",\n",
      "              \"answer_start\": 719\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Her fourth studio album 4 was released on June 28, 2011 in the US. 4 sold 310,000 copies in its first week and debuted atop the Billboard 200 chart, giving Beyonc\\u00e9 her fourth consecutive number-one album in the US. The album was preceded by two of its singles \\\"Run the World (Girls)\\\" and \\\"Best Thing I Never Had\\\", which both attained moderate success. The fourth single \\\"Love on Top\\\" was a commercial success in the US. 4 also produced four other singles; \\\"Party\\\", \\\"Countdown\\\", \\\"I Care\\\" and \\\"End of Time\\\". \\\"Eat, Play, Love\\\", a cover story written by Beyonc\\u00e9 for Essence that detailed her 2010 career break, won her a writing award from the New York Association of Black Journalists. In late 2011, she took the stage at New York's Roseland Ballroom for four nights of special performances: the 4 Intimate Nights with Beyonc\\u00e9 concerts saw the performance of her 4 album to a standing room only.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"When did Beyonce have her first child?\",\n",
      "          \"id\": \"56be9bb83aeaaa14008c915c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"January 7, 2012\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Beyonce give birth to her first child?\",\n",
      "          \"id\": \"56be9bb83aeaaa14008c915d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Lenox Hill Hospital\",\n",
      "              \"answer_start\": 91\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's first child is named what?\",\n",
      "          \"id\": \"56be9bb83aeaaa14008c915e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Blue Ivy Carter\",\n",
      "              \"answer_start\": 71\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Her first appearance performing since giving birth was where?\",\n",
      "          \"id\": \"56be9bb83aeaaa14008c9160\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Revel Atlantic City's Ovation Hall\",\n",
      "              \"answer_start\": 176\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce have her first child?\",\n",
      "          \"id\": \"56bfa087a10cfb14005511d9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"January 7, 2012\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the child's name?\",\n",
      "          \"id\": \"56bfa087a10cfb14005511da\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Blue Ivy Carter\",\n",
      "              \"answer_start\": 71\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How long was it after the birth of her child before she performed again?\",\n",
      "          \"id\": \"56bfa087a10cfb14005511dc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Five months\",\n",
      "              \"answer_start\": 124\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many nights did she perform at Atlantic City?\",\n",
      "          \"id\": \"56bfa087a10cfb14005511dd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"four nights\",\n",
      "              \"answer_start\": 161\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 give birth to a daughter?\",\n",
      "          \"id\": \"56d4c4e72ccc5a1400d83218\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"January 7, 2012\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonc\\u00e9 name her daughter?\",\n",
      "          \"id\": \"56d4c4e72ccc5a1400d83219\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Blue Ivy Carter\",\n",
      "              \"answer_start\": 71\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where was Blue Ivy born?\",\n",
      "          \"id\": \"56d4c4e72ccc5a1400d8321a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Lenox Hill Hospital in New York.\",\n",
      "              \"answer_start\": 91\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where was Beyonc\\u00e9's first public performance after giving birth?\",\n",
      "          \"id\": \"56d4c4e72ccc5a1400d8321b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Revel Atlantic City's Ovation Hall\",\n",
      "              \"answer_start\": 176\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many nights did Beyonc\\u00e9 play at the resort?\",\n",
      "          \"id\": \"56d4c4e72ccc5a1400d8321c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"four\",\n",
      "              \"answer_start\": 161\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"On January 7, 2012, Beyonc\\u00e9 gave birth to her first child, a daughter, Blue Ivy Carter, at Lenox Hill Hospital in New York. Five months later, she performed for four nights at Revel Atlantic City's Ovation Hall to celebrate the resort's opening, her first performances since giving birth to Blue Ivy.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Destiny's Child released a compilation album about which topic?\",\n",
      "          \"id\": \"56be9c863aeaaa14008c9166\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"romance\",\n",
      "              \"answer_start\": 81\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's documentary movie was called what?\",\n",
      "          \"id\": \"56be9c863aeaaa14008c9169\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Life Is But a Dream\",\n",
      "              \"answer_start\": 689\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonce sign in 2013?\",\n",
      "          \"id\": \"56be9c863aeaaa14008c916a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"global publishing agreement\",\n",
      "              \"answer_start\": 1163\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Destiny's Child release its album \\\"Love Songs\\\"?\",\n",
      "          \"id\": \"56bfa24ea10cfb14005511e3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"January 2013\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the title of the added track in Love Songs?\",\n",
      "          \"id\": \"56bfa24ea10cfb14005511e4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Nuclear\",\n",
      "              \"answer_start\": 158\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"At whose inauguration did she perform the National Anthem?\",\n",
      "          \"id\": \"56bfa24ea10cfb14005511e5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"President Obama\",\n",
      "              \"answer_start\": 258\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many Tweets per minute did the half time show get?\",\n",
      "          \"id\": \"56bfa24ea10cfb14005511e7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"268,000 tweets per minute\",\n",
      "              \"answer_start\": 523\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Destiny's Child release Love Songs?\",\n",
      "          \"id\": \"56d4c6b02ccc5a1400d83222\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"January 2013\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the new track for Love Songs?\",\n",
      "          \"id\": \"56d4c6b02ccc5a1400d83223\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Nuclear\",\n",
      "              \"answer_start\": 158\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonc\\u00e9 sing at President Obama's second inauguration?\",\n",
      "          \"id\": \"56d4c6b02ccc5a1400d83224\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the American national anthem\",\n",
      "              \"answer_start\": 186\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What event did Beyonc\\u00e9 perform at one month after Obama's inauguration? \",\n",
      "          \"id\": \"56d4c6b02ccc5a1400d83225\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Super Bowl XLVII halftime show\",\n",
      "              \"answer_start\": 362\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of Beyonc\\u00e9's documentary film?\",\n",
      "          \"id\": \"56d4c6b02ccc5a1400d83226\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Life Is But a Dream\",\n",
      "              \"answer_start\": 689\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In January 2013, Destiny's Child released Love Songs, a compilation album of the romance-themed songs from their previous albums and a newly recorded track, \\\"Nuclear\\\". Beyonc\\u00e9 performed the American national anthem singing along with a pre-recorded track at President Obama's second inauguration in Washington, D.C. The following month, Beyonc\\u00e9 performed at the Super Bowl XLVII halftime show, held at the Mercedes-Benz Superdome in New Orleans. The performance stands as the second most tweeted about moment in history at 268,000 tweets per minute. At the 55th Annual Grammy Awards, Beyonc\\u00e9 won for Best Traditional R&B Performance for \\\"Love on Top\\\". Her feature-length documentary film, Life Is But a Dream, first aired on HBO on February 16, 2013. The film, which she directed and produced herself, featured footage from her childhood, her as a mother and businesswoman, recording, rehearsing for live performances, and her return to the spotlight following Blue Ivy's birth. Its DVD release in November 2013 was accompanied by footage from the Revel Presents: Beyonc\\u00e9 Live concerts and a new song, \\\"God Made You Beautiful\\\". In February 2013, Beyonc\\u00e9 signed a global publishing agreement with Warner/Chappell Music, which would cover her future songwriting and then-upcoming studio album.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"How many dates did Beyonce's \\\"The Mrs. Carter Show\\\" entail?\",\n",
      "          \"id\": \"56be9d3d3aeaaa14008c9170\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"132\",\n",
      "              \"answer_start\": 103\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"One of Beyonce's most successful tours yet was which one?\",\n",
      "          \"id\": \"56be9d3d3aeaaa14008c9172\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Mrs. Carter Show\",\n",
      "              \"answer_start\": 20\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce wrote which song for the movie \\\"Epic\\\"?\",\n",
      "          \"id\": \"56be9d3d3aeaaa14008c9173\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Rise Up\",\n",
      "              \"answer_start\": 560\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce voiced a character in which animated film?\",\n",
      "          \"id\": \"56be9d3d3aeaaa14008c9174\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Epic\",\n",
      "              \"answer_start\": 469\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did the tour begin?\",\n",
      "          \"id\": \"56bfa3cca10cfb14005511ee\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"April 15\",\n",
      "              \"answer_start\": 55\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Of what event was Beyonce honorary chair?\",\n",
      "          \"id\": \"56bfa3cca10cfb14005511ef\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2013 Met Gala\",\n",
      "              \"answer_start\": 399\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What part did she voice for the movie Epic?\",\n",
      "          \"id\": \"56bfa3cca10cfb14005511f0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Queen Tara\",\n",
      "              \"answer_start\": 429\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did Beyonce record for the film Epic?\",\n",
      "          \"id\": \"56bfa3cca10cfb14005511f1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Rise Up\",\n",
      "              \"answer_start\": 560\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of Beyonc\\u00e9's tour that she started on April 15?\",\n",
      "          \"id\": \"56d4c75a2ccc5a1400d8322c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Mrs. Carter Show World Tour\",\n",
      "              \"answer_start\": 20\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many dates did the Mrs. Carter Show World Tour have?\",\n",
      "          \"id\": \"56d4c75a2ccc5a1400d8322d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"132\",\n",
      "              \"answer_start\": 103\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which Amy Winehouse song did Beyonc\\u00e9 cover and release in May 2014?\",\n",
      "          \"id\": \"56d4c75a2ccc5a1400d8322e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Back to Black\",\n",
      "              \"answer_start\": 288\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9 was an honorary chair of the 2013 what?\",\n",
      "          \"id\": \"56d4c75a2ccc5a1400d8322f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Met Gala.\",\n",
      "              \"answer_start\": 404\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which character in the film, Epic, was voiced by Beyonc\\u00e9?\",\n",
      "          \"id\": \"56d4c75a2ccc5a1400d83230\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Queen Tara\",\n",
      "              \"answer_start\": 429\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 embarked on The Mrs. Carter Show World Tour on April 15 in Belgrade, Serbia; the tour included 132 dates that ran through to March 2014. It became the most successful tour of her career and one of the most-successful tours of all time. In May, Beyonc\\u00e9's cover of Amy Winehouse's \\\"Back to Black\\\" with Andr\\u00e9 3000 on The Great Gatsby soundtrack was released. She was also honorary chair of the 2013 Met Gala. Beyonc\\u00e9 voiced Queen Tara in the 3D CGI animated film, Epic, released by 20th Century Fox on May 24, and recorded an original song for the film, \\\"Rise Up\\\", co-written with Sia.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Where did Beyonce release her 5th album to a huge surprise?\",\n",
      "          \"id\": \"56be9e453aeaaa14008c917a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the iTunes Store\",\n",
      "              \"answer_start\": 88\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce get her fifth consecutive number one hit album?\",\n",
      "          \"id\": \"56bfa5b3a10cfb14005511f7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"December 13, 2013\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where was the album released? \",\n",
      "          \"id\": \"56bfa5b3a10cfb14005511f8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the iTunes Store\",\n",
      "              \"answer_start\": 88\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who joined Beyonce on her On The Run Tour?\",\n",
      "          \"id\": \"56bfa5b3a10cfb14005511f9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 810\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who reported Beyonce to e the top earning woman in music?\",\n",
      "          \"id\": \"56bfa5b3a10cfb14005511fa\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Forbes\",\n",
      "              \"answer_start\": 1344\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much more were her earnings that the year before?\",\n",
      "          \"id\": \"56bfa5b3a10cfb14005511fb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"more than double her earnings\",\n",
      "              \"answer_start\": 1471\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 release her fifth studio album?\",\n",
      "          \"id\": \"56d4cde92ccc5a1400d83236\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"December 13, 2013\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many digital copies of her fifth album did Beyonc\\u00e9 sell in six days?\",\n",
      "          \"id\": \"56d4cde92ccc5a1400d83237\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"one million\",\n",
      "              \"answer_start\": 440\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song on Beyonc\\u00e9's fifth studio album featured her husband?\",\n",
      "          \"id\": \"56d4cde92ccc5a1400d83238\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Drunk in Love\",\n",
      "              \"answer_start\": 784\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the tour featuring both Beyonc\\u00e9 and Jay Z?\",\n",
      "          \"id\": \"56d4cde92ccc5a1400d83239\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"On the Run Tour.\",\n",
      "              \"answer_start\": 974\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"On December 13, 2013, Beyonc\\u00e9 unexpectedly released her eponymous fifth studio album on the iTunes Store without any prior announcement or promotion. The album debuted atop the Billboard 200 chart, giving Beyonc\\u00e9 her fifth consecutive number-one album in the US. This made her the first woman in the chart's history to have her first five studio albums debut at number one. Beyonc\\u00e9 received critical acclaim and commercial success, selling one million digital copies worldwide in six days; The New York Times noted the album's unconventional, unexpected release as significant. Musically an electro-R&B album, it concerns darker themes previously unexplored in her work, such as \\\"bulimia, postnatal depression [and] the fears and insecurities of marriage and motherhood\\\". The single \\\"Drunk in Love\\\", featuring Jay Z, peaked at number two on the Billboard Hot 100 chart. In April 2014, after much speculation in the weeks before, Beyonc\\u00e9 and Jay Z officially announced their On the Run Tour. It served as the couple's first co-headlining stadium tour together. On August 24, 2014, she received the Video Vanguard Award at the 2014 MTV Video Music Awards. Knowles also took home three competitive awards: Best Video with a Social Message and Best Cinematography for \\\"Pretty Hurts\\\", as well as best collaboration for \\\"Drunk in Love\\\". In November, Forbes reported that Beyonc\\u00e9 was the top-earning woman in music for the second year in a row\\u2014earning $115 million in the year, more than double her earnings in 2013. Beyonc\\u00e9 was reissued with new material in three forms: as an extended play, a box set, as well as a full platinum edition.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"How many awards did Beyonce take home with her at the 57th Grammy Awards?\",\n",
      "          \"id\": \"56be9eea3aeaaa14008c9184\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"three\",\n",
      "              \"answer_start\": 108\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which artist beat Beyonce out for Album of the year?\",\n",
      "          \"id\": \"56be9eea3aeaaa14008c9185\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beck\",\n",
      "              \"answer_start\": 283\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which magazine did Beyonce pose on the cover for in August of 2015?\",\n",
      "          \"id\": \"56be9eea3aeaaa14008c9186\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Vogue\",\n",
      "              \"answer_start\": 364\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce would perform with who at Superbowl 50?\",\n",
      "          \"id\": \"56be9eea3aeaaa14008c9187\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Coldplay\",\n",
      "              \"answer_start\": 770\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce took home how many awards at the 57th Grammy Awards?\",\n",
      "          \"id\": \"56bea1f53aeaaa14008c918e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"three\",\n",
      "              \"answer_start\": 108\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce lost to which artist for Album of the year?\",\n",
      "          \"id\": \"56bea1f53aeaaa14008c918f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beck\",\n",
      "              \"answer_start\": 283\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonce perform next to during Superbowl 50?\",\n",
      "          \"id\": \"56bea1f53aeaaa14008c9191\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Coldplay\",\n",
      "              \"answer_start\": 770\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"If Beyonce won three Grammies in 2015, how many was she nominated for?\",\n",
      "          \"id\": \"56bfa761a10cfb1400551201\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"six awards\",\n",
      "              \"answer_start\": 77\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"On what magazine was she the cover model?\",\n",
      "          \"id\": \"56bfa761a10cfb1400551202\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Vogue\",\n",
      "              \"answer_start\": 364\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who would she perform with at Superbowl 50?\",\n",
      "          \"id\": \"56bfa761a10cfb1400551204\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Coldplay\",\n",
      "              \"answer_start\": 770\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"With what British band did Beyonce perform on their album?\",\n",
      "          \"id\": \"56bfa761a10cfb1400551205\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Coldplay\",\n",
      "              \"answer_start\": 770\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many awards was Beyonc\\u00e9 nominated for at the 57th annual Grammys?\",\n",
      "          \"id\": \"56d4ceac2ccc5a1400d83240\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"six\",\n",
      "              \"answer_start\": 77\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many awards did Beyonc\\u00e9 win at the 57th Annual Grammys?\",\n",
      "          \"id\": \"56d4ceac2ccc5a1400d83241\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"three\",\n",
      "              \"answer_start\": 108\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9 lost the Album of the Year award to which entertainer?\",\n",
      "          \"id\": \"56d4ceac2ccc5a1400d83242\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beck\",\n",
      "              \"answer_start\": 283\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which magazine did Beyonc\\u00e9 pose for the cover, making her the first black female artist to do so?\",\n",
      "          \"id\": \"56d4ceac2ccc5a1400d83243\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Vogue\",\n",
      "              \"answer_start\": 364\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonce perform with at Super Bowl 50?\",\n",
      "          \"id\": \"56d4ceac2ccc5a1400d83244\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Coldplay\",\n",
      "              \"answer_start\": 770\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"At the 57th Annual Grammy Awards in February 2015, Beyonc\\u00e9 was nominated for six awards, ultimately winning three: Best R&B Performance and Best R&B Song for \\\"Drunk in Love\\\", and Best Surround Sound Album for Beyonc\\u00e9. She was nominated for Album of the Year but the award was won by Beck for his Morning Phase album. In August, the cover of the September issue of Vogue magazine was unveiled online, Beyonc\\u00e9 as the cover star, becoming the first African-American artist and third African-American woman in general to cover the September issue. She headlined the 2015 Made in America festival in early September and also the Global Citizen Festival later that month. Beyonc\\u00e9 made an uncredited featured appearance on the track \\\"Hymn for the Weekend\\\" by British rock band Coldplay, on their seventh studio album A Head Full of Dreams (2015), which saw release in December. On January 7, 2016, Pepsi announced Beyonc\\u00e9 would perform alongside Coldplay at Super Bowl 50 in February. Knowles has previously performed at four Super Bowl shows throughout her career, serving as the main headliner of the 47th Super Bowl halftime show in 2013.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce released the song \\\"Formation\\\" on which online music service?\",\n",
      "          \"id\": \"56bea27b3aeaaa14008c9199\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tidal\",\n",
      "              \"answer_start\": 140\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's new single released before the super bowl was called what?\",\n",
      "          \"id\": \"56bea27b3aeaaa14008c919a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Formation\",\n",
      "              \"answer_start\": 154\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What day did Beyonce release her single, Formation?\",\n",
      "          \"id\": \"56bfa8bba10cfb140055120b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"February 6, 2016\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How was the single released?\",\n",
      "          \"id\": \"56bfa8bba10cfb140055120c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"exclusively\",\n",
      "              \"answer_start\": 101\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the streaming service?\",\n",
      "          \"id\": \"56bfa8bba10cfb140055120d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tidal\",\n",
      "              \"answer_start\": 140\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What kind of platform was the song released?\",\n",
      "          \"id\": \"56bfa8bba10cfb140055120f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"music streaming\",\n",
      "              \"answer_start\": 116\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 release Formation?\",\n",
      "          \"id\": \"56d4cee32ccc5a1400d8324a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"February 6, 2016\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Beyonc\\u00e9 exclusively release her single, Formation?\",\n",
      "          \"id\": \"56d4cee32ccc5a1400d8324b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tidal\",\n",
      "              \"answer_start\": 140\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"On February 6, 2016, one day before her performance at the Super Bowl, Beyonc\\u00e9 released a new single exclusively on music streaming service Tidal called \\\"Formation\\\".\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"As of April 2014, how many albums have Jay Z and Beyonce sold together?\",\n",
      "          \"id\": \"56bea5f23aeaaa14008c91a1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"300 million\",\n",
      "              \"answer_start\": 447\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Beyonce become pregnant?\",\n",
      "          \"id\": \"56bea5f23aeaaa14008c91a2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Paris\",\n",
      "              \"answer_start\": 825\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce described what as the \\\"hardest thing she had to endure\\\"?\",\n",
      "          \"id\": \"56bea5f23aeaaa14008c91a3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"miscarriage\",\n",
      "              \"answer_start\": 617\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonce have a relationship with?\",\n",
      "          \"id\": \"56bfaa11a10cfb1400551215\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 62\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When were Beyonce and Jay Z married?\",\n",
      "          \"id\": \"56bfaa11a10cfb1400551216\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"April 4, 2008\",\n",
      "              \"answer_start\": 332\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Together how records have they sold ?\",\n",
      "          \"id\": \"56bfaa11a10cfb1400551217\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"300 million\",\n",
      "              \"answer_start\": 447\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How did Beyonce deal with the miscarriage of her child?\",\n",
      "          \"id\": \"56bfaa11a10cfb1400551218\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"wrote music\",\n",
      "              \"answer_start\": 736\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where was Beyonce when she became pregnant?\",\n",
      "          \"id\": \"56bfaa11a10cfb1400551219\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Paris\",\n",
      "              \"answer_start\": 825\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In which music video did Beyonc\\u00e9 star as Jay Z's girlfriend, creating speculation about their relationship?\",\n",
      "          \"id\": \"56d4d0c32ccc5a1400d8324e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"'03 Bonnie & Clyde\",\n",
      "              \"answer_start\": 94\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When were Beyonc\\u00e9 and Jay Z married?\",\n",
      "          \"id\": \"56d4d0c32ccc5a1400d8324f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"April 4, 2008\",\n",
      "              \"answer_start\": 332\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many records combined have Beyonc\\u00e9 and Jay Z sold?\",\n",
      "          \"id\": \"56d4d0c32ccc5a1400d83250\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"300 million\",\n",
      "              \"answer_start\": 447\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonc\\u00e9 describe as the saddest thing in her life?\",\n",
      "          \"id\": \"56d4d0c32ccc5a1400d83251\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"miscarriage\",\n",
      "              \"answer_start\": 617\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Beyonc\\u00e9 get pregnant?\",\n",
      "          \"id\": \"56d4d0c32ccc5a1400d83252\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Paris.\",\n",
      "              \"answer_start\": 912\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 is believed to have first started a relationship with Jay Z after a collaboration on \\\"'03 Bonnie & Clyde\\\", which appeared on his seventh album The Blueprint 2: The Gift & The Curse (2002). Beyonc\\u00e9 appeared as Jay Z's girlfriend in the music video for the song, which would further fuel speculation of their relationship. On April 4, 2008, Beyonc\\u00e9 and Jay Z were married without publicity. As of April 2014, the couple have sold a combined 300 million records together. The couple are known for their private relationship, although they have appeared to become more relaxed in recent years. Beyonc\\u00e9 suffered a miscarriage in 2010 or 2011, describing it as \\\"the saddest thing\\\" she had ever endured. She returned to the studio and wrote music in order to cope with the loss. In April 2011, Beyonc\\u00e9 and Jay Z traveled to Paris in order to shoot the album cover for her 4, and unexpectedly became pregnant in Paris.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Jay Z and Beyonce attended which event together in August of 2011?\",\n",
      "          \"id\": \"56bea8463aeaaa14008c91a9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"MTV Video Music Awards\",\n",
      "              \"answer_start\": 40\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce confirmed what after performing one of her songs?\",\n",
      "          \"id\": \"56bea8463aeaaa14008c91aa\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her pregnancy\",\n",
      "              \"answer_start\": 360\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many people watched the 2011 MTV Music Awards?\",\n",
      "          \"id\": \"56bea8463aeaaa14008c91ac\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"12.4 million\",\n",
      "              \"answer_start\": 535\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did she announce her pregnancy?\",\n",
      "          \"id\": \"56bfab98a10cfb140055121f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2011 MTV Video Music Awards\",\n",
      "              \"answer_start\": 35\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Why was the broadcast the most-watched in history?\",\n",
      "          \"id\": \"56bfab98a10cfb1400551220\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Her appearance\",\n",
      "              \"answer_start\": 417\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What even was recorded in the Guinness World Records?\",\n",
      "          \"id\": \"56bfab98a10cfb1400551221\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"most tweets per second\",\n",
      "              \"answer_start\": 616\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the most searched term in week of Aug 29, 2011?\",\n",
      "          \"id\": \"56bfab98a10cfb1400551222\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonce pregnant\",\n",
      "              \"answer_start\": 719\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did she perform at the MTV Awards?\",\n",
      "          \"id\": \"56bfab98a10cfb1400551223\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Love on Top\",\n",
      "              \"answer_start\": 92\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Beyonc\\u00e9 announce her pregnancy?\",\n",
      "          \"id\": \"56d4d18d2ccc5a1400d83258\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2011 MTV Video Music Awards\",\n",
      "              \"answer_start\": 35\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did Beyonc\\u00e9 sing prior to announcing her pregnancy?\",\n",
      "          \"id\": \"56d4d18d2ccc5a1400d83259\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Love on Top\",\n",
      "              \"answer_start\": 92\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many people watched the 2011 MTV Video Music Awards?\",\n",
      "          \"id\": \"56d4d18d2ccc5a1400d8325a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"12.4 million\",\n",
      "              \"answer_start\": 535\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the most searched term on Google for the week of August 29, 2011?\",\n",
      "          \"id\": \"56d4d18d2ccc5a1400d8325c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonce pregnant\",\n",
      "              \"answer_start\": 719\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In August, the couple attended the 2011 MTV Video Music Awards, at which Beyonc\\u00e9 performed \\\"Love on Top\\\" and started the performance saying \\\"Tonight I want you to stand up on your feet, I want you to feel the love that's growing inside of me\\\". At the end of the performance, she dropped her microphone, unbuttoned her blazer and rubbed her stomach, confirming her pregnancy she had alluded to earlier in the evening. Her appearance helped that year's MTV Video Music Awards become the most-watched broadcast in MTV history, pulling in 12.4 million viewers; the announcement was listed in Guinness World Records for \\\"most tweets per second recorded for a single event\\\" on Twitter, receiving 8,868 tweets per second and \\\"Beyonce pregnant\\\" was the most Googled term the week of August 29, 2011.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Jay Z has a website called what?\",\n",
      "          \"id\": \"56bea9043aeaaa14008c91b1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Lifeandtimes.com\",\n",
      "              \"answer_start\": 216\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which song by Jay Z talked about the pregnancy struggles?\",\n",
      "          \"id\": \"56bea9043aeaaa14008c91b3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Glory\",\n",
      "              \"answer_start\": 160\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of Beyonce's daughter?\",\n",
      "          \"id\": \"56bfacdda10cfb1400551229\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Blue Ivy Carter\",\n",
      "              \"answer_start\": 54\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"At what hospital was the baby delivered?\",\n",
      "          \"id\": \"56bfacdda10cfb140055122a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Lenox Hill Hospital\",\n",
      "              \"answer_start\": 74\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the named of the song  dedicated to the child?\",\n",
      "          \"id\": \"56bfacdda10cfb140055122b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Glory\",\n",
      "              \"answer_start\": 160\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What does B.I.C. stand for?\",\n",
      "          \"id\": \"56bfacdda10cfb140055122c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Blue Ivy Carter\",\n",
      "              \"answer_start\": 54\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was credited for her cries on the song?\",\n",
      "          \"id\": \"56bfacdda10cfb140055122d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"B.I.C.\",\n",
      "              \"answer_start\": 457\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 give birth to her daughter?\",\n",
      "          \"id\": \"56d4d2232ccc5a1400d83262\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"January 7, 2012\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonc\\u00e9 and Jay Z name their daughter?\",\n",
      "          \"id\": \"56d4d2232ccc5a1400d83263\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Blue Ivy Carter\",\n",
      "              \"answer_start\": 54\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did Jay Z release two days after Blue Ivy was born?\",\n",
      "          \"id\": \"56d4d2232ccc5a1400d83264\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Glory\",\n",
      "              \"answer_start\": 160\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is included at the end of Glory?\",\n",
      "          \"id\": \"56d4d2232ccc5a1400d83265\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Blue Ivy's cries\",\n",
      "              \"answer_start\": 367\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How was Blue Ivy credited on Glory?\",\n",
      "          \"id\": \"56d4d2232ccc5a1400d83266\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"B.I.C.\",\n",
      "              \"answer_start\": 457\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"On January 7, 2012, Beyonc\\u00e9 gave birth to a daughter, Blue Ivy Carter, at Lenox Hill Hospital in New York under heavy security. Two days later, Jay Z released \\\"Glory\\\", a song dedicated to their child, on his website Lifeandtimes.com. The song detailed the couple's pregnancy struggles, including a miscarriage Beyonc\\u00e9 suffered before becoming pregnant with Blue Ivy. Blue Ivy's cries are included at the end of the song, and she was officially credited as \\\"B.I.C.\\\" on it. At two days old, she became the youngest person ever to appear on a Billboard chart when \\\"Glory\\\" debuted on the Hot R&B/Hip-Hop Songs chart.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce and Jay-Z went to a rally for the acquittal of whom?\",\n",
      "          \"id\": \"56beab283aeaaa14008c91cc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"George Zimmerman\",\n",
      "              \"answer_start\": 880\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce sang which song during the 2009 presidential inauguration?\",\n",
      "          \"id\": \"56beab283aeaaa14008c91cd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"America the Beautiful\",\n",
      "              \"answer_start\": 112\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much did Beyonce raise for Obama at the 40/40 Club?\",\n",
      "          \"id\": \"56bfae97a10cfb1400551234\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"4 million\",\n",
      "              \"answer_start\": 398\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did she endorse on March 26, 2013?\",\n",
      "          \"id\": \"56bfae97a10cfb1400551235\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"same sex marriage\",\n",
      "              \"answer_start\": 700\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did they attend in July 2013?\",\n",
      "          \"id\": \"56bfae97a10cfb1400551236\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"a rally\",\n",
      "              \"answer_start\": 840\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did she sing at the 2009 Presidential Inauguration?\",\n",
      "          \"id\": \"56bfae97a10cfb1400551237\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"America the Beautiful\",\n",
      "              \"answer_start\": 112\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did Beyonc\\u00e9 perform at the 2009 inauguration of Obama?\",\n",
      "          \"id\": \"56d4d2f12ccc5a1400d8326c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"America the Beautiful\",\n",
      "              \"answer_start\": 112\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did Beyonc\\u00e9 perform at the first inaugural dance for the Obamas.\",\n",
      "          \"id\": \"56d4d2f12ccc5a1400d8326d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"At Last\",\n",
      "              \"answer_start\": 186\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What social media platform did Beyonc\\u00e9 upload a picture of her paper ballot on?\",\n",
      "          \"id\": \"56d4d2f12ccc5a1400d8326f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tumblr\",\n",
      "              \"answer_start\": 458\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 endorse on March 26, 2013?\",\n",
      "          \"id\": \"56d4d2f12ccc5a1400d83270\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"same sex marriage\",\n",
      "              \"answer_start\": 700\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 and husband Jay Z are friends with President Barack Obama and First Lady Michelle Obama. She performed \\\"America the Beautiful\\\" at the 2009 presidential inauguration, as well as \\\"At Last\\\" during the first inaugural dance at the Neighborhood Ball two days later. Beyonc\\u00e9 and Jay Z held a fundraiser at the latter's 40/40 Club in Manhattan for Obama's 2012 presidential campaign which raised $4 million. Beyonc\\u00e9 uploaded pictures of her paper ballot on Tumblr, confirming she had voted in support for the Democratic Party and to encourage others to do so. She also performed the American national anthem at his second inauguration, singing along with a pre-recorded track. She publicly endorsed same sex marriage on March 26, 2013, after the Supreme Court debate on California's Proposition 8. In July 2013, Beyonc\\u00e9 and Jay-Z attended a rally in response to the acquittal of George Zimmerman for the shooting of Trayvon Martin.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce did an interview with which magazine and was asked about feminism?\",\n",
      "          \"id\": \"56beabab3aeaaa14008c91db\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Vogue\",\n",
      "              \"answer_start\": 29\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce supported which campaign that encourages leadership in girls?\",\n",
      "          \"id\": \"56beabab3aeaaa14008c91dc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Ban Bossy campaign\",\n",
      "              \"answer_start\": 514\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where was Beyonce quoted as saying that she is a modern-day feminist?\",\n",
      "          \"id\": \"56bfafdba10cfb140055123d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Vogue\",\n",
      "              \"answer_start\": 29\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did she say the she is a feminist?\",\n",
      "          \"id\": \"56bfafdba10cfb140055123e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"April 2013\",\n",
      "              \"answer_start\": 38\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What campaign did she contribute to?\",\n",
      "          \"id\": \"56bfafdba10cfb140055123f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Ban Bossy\",\n",
      "              \"answer_start\": 514\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did she release in 2013 in response to a speech?\",\n",
      "          \"id\": \"56bfafdba10cfb1400551240\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Flawless\",\n",
      "              \"answer_start\": 445\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What does Ban Bossy encourage?\",\n",
      "          \"id\": \"56bfafdba10cfb1400551241\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"leadership in girls\",\n",
      "              \"answer_start\": 586\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9 used words from which Nigerian author in her song, Flawless?\",\n",
      "          \"id\": \"56d4d3b12ccc5a1400d83277\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Chimamanda Ngozi Adichie\",\n",
      "              \"answer_start\": 365\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which campaign does Beyonc\\u00e9 contribute to that encourages leadership in females?\",\n",
      "          \"id\": \"56d4d3b12ccc5a1400d83278\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Ban Bossy\",\n",
      "              \"answer_start\": 514\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In an interview published by Vogue in April 2013, Beyonc\\u00e9 was asked if she considers herself a feminist, to which she said, \\\"that word can be very extreme... But I guess I am a modern-day feminist. I do believe in equality\\\". She would later align herself more publicly with the movement, sampling \\\"We should all be feminists\\\", a speech delivered by Nigerian author Chimamanda Ngozi Adichie at a TEDxEuston conference in April 2013, in her song \\\"Flawless\\\", released later that year. She has also contributed to the Ban Bossy campaign, which uses television and social media to encourage leadership in girls.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce signed a letter with who in 2015?\",\n",
      "          \"id\": \"56beb0683aeaaa14008c9211\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the ONE Campaign\",\n",
      "              \"answer_start\": 44\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"An important UN summit took place when?\",\n",
      "          \"id\": \"56beb0683aeaaa14008c9213\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"September 2015\",\n",
      "              \"answer_start\": 374\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The letter Beyonce signed focused on what issue?\",\n",
      "          \"id\": \"56beb0683aeaaa14008c9214\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"women\",\n",
      "              \"answer_start\": 191\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What had to be set in developing funding?\",\n",
      "          \"id\": \"56beb0683aeaaa14008c9215\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"priorities\",\n",
      "              \"answer_start\": 313\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce sign a letter for ONE Campaign?\",\n",
      "          \"id\": \"56bfb10da10cfb1400551247\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2015\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"To whom was the letter addressed?\",\n",
      "          \"id\": \"56bfb10da10cfb1400551248\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Angela Merkel and Nkosazana Dlamini-Zuma\",\n",
      "              \"answer_start\": 125\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who are these women?\",\n",
      "          \"id\": \"56bfb10da10cfb1400551249\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"head of the G7 in Germany\",\n",
      "              \"answer_start\": 218\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When will they meet?\",\n",
      "          \"id\": \"56bfb10da10cfb140055124b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"September 2015\",\n",
      "              \"answer_start\": 374\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 sign a letter for in 2015?\",\n",
      "          \"id\": \"56d4d5ef2ccc5a1400d83286\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the ONE Campaign\",\n",
      "              \"answer_start\": 44\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was the letter addressed to?\",\n",
      "          \"id\": \"56d4d5ef2ccc5a1400d83287\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Angela Merkel and Nkosazana Dlamini-Zuma\",\n",
      "              \"answer_start\": 125\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was Angela Merkel serving as in relation to the letter?\",\n",
      "          \"id\": \"56d4d5ef2ccc5a1400d83288\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the head of the G7 in Germany\",\n",
      "              \"answer_start\": 214\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did the letter want the two recipients to focus on?\",\n",
      "          \"id\": \"56d4d5ef2ccc5a1400d8328a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"women\",\n",
      "              \"answer_start\": 191\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In 2015 Beyonc\\u00e9 signed an open letter which the ONE Campaign had been collecting signatures for; the letter was addressed to Angela Merkel and Nkosazana Dlamini-Zuma, urging them to focus on women as they serve as the head of the G7 in Germany and the AU in South Africa respectively, which will start to set the priorities in development funding before a main UN summit in September 2015 that will establish new development goals for the generation.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce along with Jay Z met with whom's family after their death?\",\n",
      "          \"id\": \"56beb2a43aeaaa14008c9239\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Freddie Gray\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce with Jay Z gave lots of money to bail who out of prison?\",\n",
      "          \"id\": \"56beb2a43aeaaa14008c923a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"protesters\",\n",
      "              \"answer_start\": 132\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who's death caused this protest?\",\n",
      "          \"id\": \"56bfb1fca10cfb1400551253\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Freddie Gray\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much bail money did they spend?\",\n",
      "          \"id\": \"56bfb1fca10cfb1400551254\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"thousands of dollars\",\n",
      "              \"answer_start\": 186\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Following the death of Freddie Gray, Beyonc\\u00e9 and Jay-Z, among other notable figures, met with his family. After the imprisonment of protesters of Gray's death, Beyonc\\u00e9 and Jay-Z donated thousands of dollars to bail them out.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce beat out which musical artists for most paid between June 2007 and June 2008?\",\n",
      "          \"id\": \"56beb4023aeaaa14008c9252\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Madonna and Celine Dion\",\n",
      "              \"answer_start\": 248\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce and Jay Z got a Guinness World record for what in 2009?\",\n",
      "          \"id\": \"56beb4023aeaaa14008c9253\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"highest-earning power couple\",\n",
      "              \"answer_start\": 1013\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce became the highest-paid black musician in which year?\",\n",
      "          \"id\": \"56beb4023aeaaa14008c9254\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2014\",\n",
      "              \"answer_start\": 1460\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Up until May of 2015, how much is Beyonce's total worth?\",\n",
      "          \"id\": \"56beb4023aeaaa14008c9255\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"250 million\",\n",
      "              \"answer_start\": 1880\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Between 2008 and 2009, which entertainers did Beyonce beat in earnings?\",\n",
      "          \"id\": \"56bfb502a10cfb140055125b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Madonna and Celine Dion\",\n",
      "              \"answer_start\": 248\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In 2012 who placed Beyonce at 16 in the Celebrity List?\",\n",
      "          \"id\": \"56bfb502a10cfb140055125c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Forbes\",\n",
      "              \"answer_start\": 0\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did she and Jay Z become the highest paid black celebrity couple?\",\n",
      "          \"id\": \"56bfb502a10cfb140055125d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2011\",\n",
      "              \"answer_start\": 1112\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much did she earn in 2014?\",\n",
      "          \"id\": \"56bfb502a10cfb140055125e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"115 million\",\n",
      "              \"answer_start\": 1660\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is Beyonce's net worth in 2015?\",\n",
      "          \"id\": \"56bfb502a10cfb140055125f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"250 million\",\n",
      "              \"answer_start\": 1880\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who began reporting Beyonc\\u00e9's annual earnings, starting in 2008?\",\n",
      "          \"id\": \"56d4d8702ccc5a1400d83294\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Forbes\",\n",
      "              \"answer_start\": 0\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 become the highest paid black musician, ever?\",\n",
      "          \"id\": \"56d4d8702ccc5a1400d83296\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"April 2014.\",\n",
      "              \"answer_start\": 1557\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who predicted that Beyonc\\u00e9 would become the highest paid black entertainer?\",\n",
      "          \"id\": \"56d4d8702ccc5a1400d83297\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"MTV\",\n",
      "              \"answer_start\": 1427\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Jay Z and Beyonc\\u00e9 become the first music couple worth over a billion dollars?\",\n",
      "          \"id\": \"56d4d8702ccc5a1400d83298\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2013\",\n",
      "              \"answer_start\": 1204\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Forbes magazine began reporting on Beyonc\\u00e9's earnings in 2008, calculating that the $80 million earned between June 2007 to June 2008, for her music, tour, films and clothing line made her the world's best-paid music personality at the time, above Madonna and Celine Dion. They placed her fourth on the Celebrity 100 list in 2009 and ninth on the \\\"Most Powerful Women in the World\\\" list in 2010. The following year, Forbes placed her eighth on the \\\"Best-Paid Celebrities Under 30\\\" list, having earned $35 million in the past year for her clothing line and endorsement deals. In 2012, Forbes placed Beyonc\\u00e9 at number 16 on the Celebrity 100 list, twelve places lower than three years ago yet still having earned $40 million in the past year for her album 4, clothing line and endorsement deals. In the same year, Beyonc\\u00e9 and Jay Z placed at number one on the \\\"World's Highest-Paid Celebrity Couples\\\", for collectively earning $78 million. The couple made it into the previous year's Guinness World Records as the \\\"highest-earning power couple\\\" for collectively earning $122 million in 2009. For the years 2009 to 2011, Beyonc\\u00e9 earned an average of $70 million per year, and earned $40 million in 2012. In 2013, Beyonc\\u00e9's endorsements of Pepsi and H&M made her and Jay Z the world's first billion dollar couple in the music industry. That year, Beyonc\\u00e9 was published as the fourth most-powerful celebrity in the Forbes rankings. MTV estimated that by the end of 2014, Beyonc\\u00e9 would become the highest-paid black musician in history; she succeeded to do so in April 2014. In June 2014, Beyonc\\u00e9 ranked at #1 on the Forbes Celebrity 100 list, earning an estimated $115 million throughout June 2013 \\u2013 June 2014. This in turn was the first time she had topped the Celebrity 100 list as well as being her highest yearly earnings to date. As of May 2015, her net worth is estimated to be $250 million.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce's range in singing is how many octaves?\",\n",
      "          \"id\": \"56beb50f3aeaaa14008c926f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"four\",\n",
      "              \"answer_start\": 28\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"who talked about Beyonce's tone and timbre as distinctive?\",\n",
      "          \"id\": \"56beb50f3aeaaa14008c9270\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jody Rosen\",\n",
      "              \"answer_start\": 42\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which critic called Beyonce's voice \\\"versatile\\\"?\",\n",
      "          \"id\": \"56beb50f3aeaaa14008c9271\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Daily Mail\",\n",
      "              \"answer_start\": 415\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which era was credited to have influenced Beyonce's singing style by Jody Rosen?\",\n",
      "          \"id\": \"56beb50f3aeaaa14008c9272\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"hip hop\",\n",
      "              \"answer_start\": 546\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many octaves does Beyonce have?\",\n",
      "          \"id\": \"56bfb676a10cfb1400551265\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"four octaves\",\n",
      "              \"answer_start\": 28\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did the Daily Mail say about Beyonce's voice?\",\n",
      "          \"id\": \"56bfb676a10cfb1400551266\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"versatile\",\n",
      "              \"answer_start\": 453\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What does Rosen claim influenced Beyonce's style?\",\n",
      "          \"id\": \"56bfb676a10cfb1400551267\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"hip hop\",\n",
      "              \"answer_start\": 714\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What do other critics claim?\",\n",
      "          \"id\": \"56bfb676a10cfb1400551269\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"praise her range and power\",\n",
      "              \"answer_start\": 883\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many octaves does Beyonc\\u00e9's voice span?\",\n",
      "          \"id\": \"56d4d9392ccc5a1400d8329e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"four\",\n",
      "              \"answer_start\": 28\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Why is Beyonc\\u00e9 known as the centerpiece of Destiny's Child?\",\n",
      "          \"id\": \"56d4d9392ccc5a1400d8329f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Her vocal abilities\",\n",
      "              \"answer_start\": 333\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"New York Times' Jon Pareles calls Beyonc\\u00e9's voice velvety yet what?\",\n",
      "          \"id\": \"56d4d9392ccc5a1400d832a0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"tart\",\n",
      "              \"answer_start\": 630\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What does Jody Rosen say influenced Beyonc\\u00e9's vocal style?\",\n",
      "          \"id\": \"56d4d9392ccc5a1400d832a1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the hip hop era\",\n",
      "              \"answer_start\": 710\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9's vocal range spans four octaves. Jody Rosen highlights her tone and timbre as particularly distinctive, describing her voice as \\\"one of the most compelling instruments in popular music\\\". While another critic says she is a \\\"Vocal acrobat, being able to sing long and complex melismas and vocal runs effortlessly, and in key. Her vocal abilities mean she is identified as the centerpiece of Destiny's Child. The Daily Mail calls Beyonc\\u00e9's voice \\\"versatile\\\", capable of exploring power ballads, soul, rock belting, operatic flourishes, and hip hop. Jon Pareles of The New York Times commented that her voice is \\\"velvety yet tart, with an insistent flutter and reserves of soul belting\\\". Rosen notes that the hip hop era highly influenced Beyonc\\u00e9's strange rhythmic vocal style, but also finds her quite traditionalist in her use of balladry, gospel and falsetto. Other critics praise her range and power, with Chris Richards of The Washington Post saying she was \\\"capable of punctuating any beat with goose-bump-inducing whispers or full-bore diva-roars.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Music from Beyonce is generally categorized as what genre?\",\n",
      "          \"id\": \"56beb5b23aeaaa14008c9283\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"R&B\",\n",
      "              \"answer_start\": 29\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Besides R&B, which genres does Beyonce dabble in?\",\n",
      "          \"id\": \"56beb5b23aeaaa14008c9284\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"pop, soul and funk\",\n",
      "              \"answer_start\": 60\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce mostly releases English songs, but what other language did she release songs?\",\n",
      "          \"id\": \"56beb5b23aeaaa14008c9285\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Spanish\",\n",
      "              \"answer_start\": 307\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Spanish songs Beyonce released were for what?\",\n",
      "          \"id\": \"56beb5b23aeaaa14008c9286\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"re-release of B'Day\",\n",
      "              \"answer_start\": 417\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce was coached for her Spanish songs by which American?\",\n",
      "          \"id\": \"56beb5b23aeaaa14008c9287\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Rudy Perez\",\n",
      "              \"answer_start\": 516\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What kind of music does Beyonce do?\",\n",
      "          \"id\": \"56bfb789a10cfb140055126f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"R&B\",\n",
      "              \"answer_start\": 29\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What language does she mainly sing?\",\n",
      "          \"id\": \"56bfb789a10cfb1400551271\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"English\",\n",
      "              \"answer_start\": 267\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What other language has she sung?\",\n",
      "          \"id\": \"56bfb789a10cfb1400551272\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Spanish\",\n",
      "              \"answer_start\": 307\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What album did she re-release in Spanish?\",\n",
      "          \"id\": \"56bfb789a10cfb1400551273\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"B'Day\",\n",
      "              \"answer_start\": 369\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What style of music does Beyonc\\u00e9 usually perform?\",\n",
      "          \"id\": \"56d4d9a92ccc5a1400d832a6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"R&B\",\n",
      "              \"answer_start\": 29\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What language did Beyonc\\u00e9 release several songs in?\",\n",
      "          \"id\": \"56d4d9a92ccc5a1400d832a7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Spanish\",\n",
      "              \"answer_start\": 307\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who coached Beyonc\\u00e9 for her Spanish recordings?\",\n",
      "          \"id\": \"56d4d9a92ccc5a1400d832a8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Rudy Perez.\",\n",
      "              \"answer_start\": 516\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What album did the Spanish songs come from?\",\n",
      "          \"id\": \"56d4d9a92ccc5a1400d832a9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"B'Day.\",\n",
      "              \"answer_start\": 431\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9's music is generally R&B, but she also incorporates pop, soul and funk into her songs. 4 demonstrated Beyonc\\u00e9's exploration of 90s-style R&B, as well as further use of soul and hip hop than compared to previous releases. While she almost exclusively releases English songs, Beyonc\\u00e9 recorded several Spanish songs for Irreemplazable (re-recordings of songs from B'Day for a Spanish-language audience), and the re-release of B'Day. To record these, Beyonc\\u00e9 was coached phonetically by American record producer Rudy Perez.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce does not create which aspect of her music?\",\n",
      "          \"id\": \"56beb67d3aeaaa14008c929a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"beats\",\n",
      "              \"answer_start\": 521\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"An example of a song aimed towards a male audience is what?\",\n",
      "          \"id\": \"56beb67d3aeaaa14008c929b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Cater 2 U\",\n",
      "              \"answer_start\": 338\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What theme was Beyonce's early music?\",\n",
      "          \"id\": \"56bfb8dca10cfb1400551279\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"female-empowerment\",\n",
      "              \"answer_start\": 153\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"With Jay Z what were her new themes?\",\n",
      "          \"id\": \"56bfb8dca10cfb140055127b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"man-tending anthems\",\n",
      "              \"answer_start\": 309\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What does she get credits for in her music?\",\n",
      "          \"id\": \"56bfb8dca10cfb140055127c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"co-producing credits\",\n",
      "              \"answer_start\": 376\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What part of production does she do?\",\n",
      "          \"id\": \"56bfb8dca10cfb140055127d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"melodies\",\n",
      "              \"answer_start\": 564\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9's early recordings empowered who?\",\n",
      "          \"id\": \"56d4dd502ccc5a1400d832ae\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Women\",\n",
      "              \"answer_start\": 210\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In addition to co-writing credits, Beyonc\\u00e9 also got what credits for most of her albums?\",\n",
      "          \"id\": \"56d4dd502ccc5a1400d832b0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"co-producing\",\n",
      "              \"answer_start\": 376\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Rather than beats, what two things does Beyonc\\u00e9 usually come up with for producers?\",\n",
      "          \"id\": \"56d4dd502ccc5a1400d832b1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"melodies and ideas\",\n",
      "              \"answer_start\": 564\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"She has received co-writing credits for most of the songs recorded with Destiny's Child and her solo efforts. Her early songs were personally driven and female-empowerment themed compositions like \\\"Independent Women\\\" and \\\"Survivor\\\", but after the start of her relationship with Jay Z she transitioned to more man-tending anthems such as \\\"Cater 2 U\\\". Beyonc\\u00e9 has also received co-producing credits for most of the records in which she has been involved, especially during her solo efforts. However, she does not formulate beats herself, but typically comes up with melodies and ideas during production, sharing them with producers.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Pop Songwriter of the Year award in 2001 was awarded to whom?\",\n",
      "          \"id\": \"56beb9203aeaaa14008c92d1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonc\\u00e9\",\n",
      "              \"answer_start\": 205\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce received the Pop Songwriter of the Year award at which event?\",\n",
      "          \"id\": \"56beb9203aeaaa14008c92d2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"American Society of Composers, Authors, and Publishers Pop Music Awards\",\n",
      "              \"answer_start\": 132\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce has the same number of writing credits on number one singles as whom?\",\n",
      "          \"id\": \"56beb9203aeaaa14008c92d4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Diane Warren\",\n",
      "              \"answer_start\": 436\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce joined 2 other women on what list from Billboard magazine in 2011?\",\n",
      "          \"id\": \"56beb9203aeaaa14008c92d5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Top 20 Hot 100 Songwriters\",\n",
      "              \"answer_start\": 656\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce become the first African American woman to win Pop songwriter of the year?\",\n",
      "          \"id\": \"56bfbacaa10cfb1400551283\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2001\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What place is she tied for in songwriting credits?\",\n",
      "          \"id\": \"56bfbacaa10cfb1400551284\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"third\",\n",
      "              \"answer_start\": 221\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who listed her at number 17 in their list of  Top 20 hot 100 Songwriters?\",\n",
      "          \"id\": \"56bfbacaa10cfb1400551285\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Billboard magazine\",\n",
      "              \"answer_start\": 587\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where does she place in writing credits  for three number one songs?\",\n",
      "          \"id\": \"56bfbacaa10cfb1400551287\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"third woman\",\n",
      "              \"answer_start\": 221\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonc\\u00e9 win in 2001, making her the first black woman to do so?\",\n",
      "          \"id\": \"56d4df312ccc5a1400d832b6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Pop Songwriter of the Year award\",\n",
      "              \"answer_start\": 92\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who gave Beyonc\\u00e9 the Pop Songwriter of the Year award in 2001?\",\n",
      "          \"id\": \"56d4df312ccc5a1400d832b7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the American Society of Composers, Authors, and Publishers Pop Music Awards.\",\n",
      "              \"answer_start\": 128\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9 was one of how many women on Billboard magazine's 2011 \\\"Top 20 Hot 100 Songwriters\\\" list.\",\n",
      "          \"id\": \"56d4df312ccc5a1400d832b9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"three\",\n",
      "              \"answer_start\": 260\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What number was Beyonc\\u00e9 on the Top 20 Hot 100 Songwriters list?\",\n",
      "          \"id\": \"56d4df312ccc5a1400d832ba\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"17\",\n",
      "              \"answer_start\": 631\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In 2001, she became the first African-American woman and second woman songwriter to win the Pop Songwriter of the Year award at the American Society of Composers, Authors, and Publishers Pop Music Awards. Beyonc\\u00e9 was the third woman to have writing credits on three number one songs (\\\"Irreplaceable\\\", \\\"Grillz\\\" and \\\"Check on It\\\") in the same year, after Carole King in 1971 and Mariah Carey in 1991. She is tied with American songwriter Diane Warren at third with nine songwriting credits on number-one singles. (The latter wrote her 9/11-motivated song \\\"I Was Here\\\" for 4.) In May 2011, Billboard magazine listed Beyonc\\u00e9 at number 17 on their list of the \\\"Top 20 Hot 100 Songwriters\\\", for having co-written eight singles that hit number one on the Billboard Hot 100 chart. She was one of only three women on that list.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"To whom did Beyonce credit as her major influence on her music?\",\n",
      "          \"id\": \"56beba293aeaaa14008c92ef\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Michael Jackson\",\n",
      "              \"answer_start\": 14\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How old was Beyonce when she went to her first Michael Jackson concert as a kid?\",\n",
      "          \"id\": \"56beba293aeaaa14008c92f0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"five\",\n",
      "              \"answer_start\": 67\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce gave a tribute award to who in 2006?\",\n",
      "          \"id\": \"56beba293aeaaa14008c92f1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Michael Jackson\",\n",
      "              \"answer_start\": 14\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce cites Mariah Carey to making her want to start doing what?\",\n",
      "          \"id\": \"56beba293aeaaa14008c92f2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"vocal runs\",\n",
      "              \"answer_start\": 589\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who influenced Beyonce?\",\n",
      "          \"id\": \"56bfbc17a10cfb140055128d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Michael Jackson\",\n",
      "              \"answer_start\": 14\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song by Mariah Carey influenced her?\",\n",
      "          \"id\": \"56bfbc17a10cfb1400551290\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Vision of Love\",\n",
      "              \"answer_start\": 534\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who is Beyonc\\u00e9's biggest musical influence?\",\n",
      "          \"id\": \"56d4dfc82ccc5a1400d832ca\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Michael Jackson\",\n",
      "              \"answer_start\": 14\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was Beyonc\\u00e9's first concert?\",\n",
      "          \"id\": \"56d4dfc82ccc5a1400d832cb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Michael Jackson\",\n",
      "              \"answer_start\": 14\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who does Beyonc\\u00e9 feel is an all-around entertainer?\",\n",
      "          \"id\": \"56d4dfc82ccc5a1400d832cc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Diana Ross\",\n",
      "              \"answer_start\": 358\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who does she credit for the inspiration to \\\"get up there and do what she did\\\"?\",\n",
      "          \"id\": \"56d4dfc82ccc5a1400d832cd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Whitney Houston\",\n",
      "              \"answer_start\": 404\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song caused Beyonc\\u00e9 to practice runs as a child?\",\n",
      "          \"id\": \"56d4dfc82ccc5a1400d832ce\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Vision of Love\",\n",
      "              \"answer_start\": 534\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 names Michael Jackson as her major musical influence. Aged five, Beyonc\\u00e9 attended her first ever concert where Jackson performed and she claims to have realised her purpose. When she presented him with a tribute award at the World Music Awards in 2006, Beyonc\\u00e9 said, \\\"if it wasn't for Michael Jackson, I would never ever have performed.\\\" She admires Diana Ross as an \\\"all-around entertainer\\\" and Whitney Houston, who she said \\\"inspired me to get up there and do what she did.\\\" She credits Mariah Carey's singing and her song \\\"Vision of Love\\\" as influencing her to begin practicing vocal runs as a child. Her other musical influences include Aaliyah, Prince, Lauryn Hill, Sade Adu, Donna Summer, Mary J. Blige, Janet Jackson, Anita Baker and Rachelle Ferrell.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"What themes were influenced by her acting role in Dreamgirls?\",\n",
      "          \"id\": \"56bebba63aeaaa14008c930b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"feminism and female empowerment\",\n",
      "              \"answer_start\": 4\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which singer did Beyonce honor by entertaining with her song \\\"Deja Vu\\\"?\",\n",
      "          \"id\": \"56bebba63aeaaa14008c930c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Josephine Baker\",\n",
      "              \"answer_start\": 134\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who motivated Beyonce to explore other areas of music?\",\n",
      "          \"id\": \"56bebba63aeaaa14008c930e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Etta James\",\n",
      "              \"answer_start\": 399\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What movie influenced Beyonce towards empowerment themes? \",\n",
      "          \"id\": \"56bfbda3a10cfb1400551297\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dreamgirls\",\n",
      "              \"answer_start\": 109\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How did Etta James influence her?\",\n",
      "          \"id\": \"56bfbda3a10cfb140055129a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"boldness\",\n",
      "              \"answer_start\": 418\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did she perform wearing Baker's hula skirt?\",\n",
      "          \"id\": \"56bfbda3a10cfb140055129b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2006 Fashion Rocks concert\",\n",
      "              \"answer_start\": 211\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What singer inspired Beyonc\\u00e9's B'Day album?\",\n",
      "          \"id\": \"56d4e0532ccc5a1400d832d4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Josephine Baker.\",\n",
      "              \"answer_start\": 134\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did Beyonc\\u00e9 sing at a 2006 concert to honor Josephine Baker?\",\n",
      "          \"id\": \"56d4e0532ccc5a1400d832d5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"D\\u00e9j\\u00e0 Vu\",\n",
      "              \"answer_start\": 195\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"The feminism and female empowerment themes on Beyonc\\u00e9's second solo album B'Day were inspired by her role in Dreamgirls and by singer Josephine Baker. Beyonc\\u00e9 paid homage to Baker by performing \\\"D\\u00e9j\\u00e0 Vu\\\" at the 2006 Fashion Rocks concert wearing Baker's trademark mini-hula skirt embellished with fake bananas. Beyonc\\u00e9's third solo album I Am... Sasha Fierce was inspired by Jay Z and especially by Etta James, whose \\\"boldness\\\" inspired Beyonc\\u00e9 to explore other musical genres and styles. Her fourth solo album, 4, was inspired by Fela Kuti, 1990s R&B, Earth, Wind & Fire, DeBarge, Lionel Richie, Teena Marie with additional influences by The Jackson 5, New Edition, Adele, Florence and the Machine, and Prince.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce has noted which first lady with saying \\\"She proves you can do it all\\\"?\",\n",
      "          \"id\": \"56bec1c53aeaaa14008c936b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Michelle Obama\",\n",
      "              \"answer_start\": 68\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which month and year did Beyonce credit Madonna for inspiring her to take control of her career?\",\n",
      "          \"id\": \"56bec1c53aeaaa14008c936c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"February 2013\",\n",
      "              \"answer_start\": 588\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce has said that who embodies the \\\"definition of inspiration and a strong woman\\\"?\",\n",
      "          \"id\": \"56bec1c53aeaaa14008c936d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Oprah Winfrey\",\n",
      "              \"answer_start\": 144\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who personally influences Beyonce?\",\n",
      "          \"id\": \"56bfbf2fa10cfb14005512a1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Michelle Obama\",\n",
      "              \"answer_start\": 68\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Hoe does she describe Oprah Winfrey?\",\n",
      "          \"id\": \"56bfbf2fa10cfb14005512a2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"a strong woman\",\n",
      "              \"answer_start\": 196\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How does she describe Jean- Michel Basquiat?\",\n",
      "          \"id\": \"56bfbf2fa10cfb14005512a3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"lyrical and raw\",\n",
      "              \"answer_start\": 567\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How does Madonna influence her?\",\n",
      "          \"id\": \"56bfbf2fa10cfb14005512a4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"to take control of her own career\",\n",
      "              \"answer_start\": 642\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How does she describe Jay Z?\",\n",
      "          \"id\": \"56bfbf2fa10cfb14005512a5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"continuing inspiration\",\n",
      "              \"answer_start\": 251\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who inspires Beyonc\\u00e9 because \\\"she does it all?\\\"\",\n",
      "          \"id\": \"56d4e0e92ccc5a1400d832da\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"First Lady Michelle Obama\",\n",
      "              \"answer_start\": 57\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who does Beyonc\\u00e9 describe as the definition of inspiration?\",\n",
      "          \"id\": \"56d4e0e92ccc5a1400d832db\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Oprah Winfrey\",\n",
      "              \"answer_start\": 144\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who does Beyonc\\u00e9 describe as lyrical and raw?\",\n",
      "          \"id\": \"56d4e0e92ccc5a1400d832dc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jean-Michel Basquiat\",\n",
      "              \"answer_start\": 431\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who inspired Beyonc\\u00e9 to take control of her career?\",\n",
      "          \"id\": \"56d4e0e92ccc5a1400d832dd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Madonna\",\n",
      "              \"answer_start\": 621\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 has stated that she is personally inspired by US First Lady Michelle Obama, saying \\\"She proves you can do it all\\\" and she has described Oprah Winfrey as \\\"the definition of inspiration and a strong woman\\\". She has also discussed how Jay Z is a continuing inspiration to her, both with what she describes as his lyrical genius and in the obstacles he has overcome in his life. Beyonc\\u00e9 has expressed admiration for the artist Jean-Michel Basquiat, posting in a letter \\\"what I find in the work of Jean-Michel Basquiat, I search for in every day in music... he is lyrical and raw\\\". In February 2013, Beyonc\\u00e9 said that Madonna inspired her to take control of her own career. She commented: \\\"I think about Madonna and how she took all of the great things she achieved and started the label and developed other artists. But there are not enough of those women.\\\".\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce had an all-female tour band whose name was what?\",\n",
      "          \"id\": \"56bec29b3aeaaa14008c937f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Suga Mama\",\n",
      "              \"answer_start\": 53\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce had singers in the background known by the name as?\",\n",
      "          \"id\": \"56bec29b3aeaaa14008c9380\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Mamas\",\n",
      "              \"answer_start\": 216\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The Mamas members included which 3 musicians?\",\n",
      "          \"id\": \"56bec29b3aeaaa14008c9381\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Montina Cooper-Donnell, Crystal Collins and Tiffany Moniqu\\u00e9 Riddick\",\n",
      "              \"answer_start\": 238\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The Mamas first appearance was when?\",\n",
      "          \"id\": \"56bec29b3aeaaa14008c9382\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2006\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What band did Beyonce introduce in 2006?\",\n",
      "          \"id\": \"56bfc0a7a10cfb14005512ab\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Suga Mama\",\n",
      "              \"answer_start\": 53\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song name does the band Suga Mama  and a song on the B'Day album share?\",\n",
      "          \"id\": \"56bfc0a7a10cfb14005512ac\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Suga Mama\",\n",
      "              \"answer_start\": 53\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where did Suga Mama band make their first appearance?\",\n",
      "          \"id\": \"56bfc0a7a10cfb14005512ad\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2006 BET Awards\",\n",
      "              \"answer_start\": 347\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What band supports Beyonce in her tours?\",\n",
      "          \"id\": \"56bfc0a7a10cfb14005512af\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Suga Mama\",\n",
      "              \"answer_start\": 53\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of Beyonc\\u00e9's female tour band?\",\n",
      "          \"id\": \"56d4e17f2ccc5a1400d832e2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Suga Mama\",\n",
      "              \"answer_start\": 53\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Suga Mama is also a song on which Beyonc\\u00e9 album?\",\n",
      "          \"id\": \"56d4e17f2ccc5a1400d832e3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"B'Day\",\n",
      "              \"answer_start\": 91\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What are Beyonc\\u00e9's backup singers called?\",\n",
      "          \"id\": \"56d4e17f2ccc5a1400d832e4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Mamas\",\n",
      "              \"answer_start\": 216\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did The Mamas make their debut?\",\n",
      "          \"id\": \"56d4e17f2ccc5a1400d832e5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the 2006 BET Awards\",\n",
      "              \"answer_start\": 343\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In 2006, Beyonc\\u00e9 introduced her all-female tour band Suga Mama (also the name of a song in B'Day) which includes bassists, drummers, guitarists, horn players, keyboardists and percussionists. Her background singers, The Mamas, consist of Montina Cooper-Donnell, Crystal Collins and Tiffany Moniqu\\u00e9 Riddick. They made their debut appearance at the 2006 BET Awards and re-appeared in the music videos for \\\"Irreplaceable\\\" and \\\"Green Light\\\". The band have supported Beyonc\\u00e9 in most subsequent live performances, including her 2007 concert tour The Beyonc\\u00e9 Experience, 2009\\u20132010 I Am... World Tour and 2013\\u20132014 The Mrs. Carter Show World Tour.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"What characteristics has Beyonce received acclaim for?\",\n",
      "          \"id\": \"56bec3303aeaaa14008c9391\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"stage presence and voice\",\n",
      "              \"answer_start\": 36\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which former president of Def Jam called Beyonce the greatest entertainer alive?\",\n",
      "          \"id\": \"56bec3303aeaaa14008c9393\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"L.A. Reid\",\n",
      "              \"answer_start\": 445\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"For what does Beyonce receive praise?\",\n",
      "          \"id\": \"56bfc281a10cfb14005512b5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"stage presence\",\n",
      "              \"answer_start\": 36\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who chose her as number one on his list of Best singers/ Dancers?\",\n",
      "          \"id\": \"56bfc281a10cfb14005512b6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jarett Wieselman\",\n",
      "              \"answer_start\": 87\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How has L.A. Reid described her?\",\n",
      "          \"id\": \"56bfc281a10cfb14005512b8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"greatest entertainer alive\",\n",
      "              \"answer_start\": 484\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How does Alice Jones describe her?\",\n",
      "          \"id\": \"56bfc281a10cfb14005512b9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"she's almost too good\",\n",
      "              \"answer_start\": 393\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who has Beyonc\\u00e9 at number one on her Five Best Singer/Dancers?\",\n",
      "          \"id\": \"56d4e2142ccc5a1400d832ec\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jarett Wieselman\",\n",
      "              \"answer_start\": 87\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who has said that Beyonc\\u00e9 is the best entertainer alive?\",\n",
      "          \"id\": \"56d4e2142ccc5a1400d832ed\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"L.A. Reid\",\n",
      "              \"answer_start\": 445\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 has received praise for her stage presence and voice during live performances. Jarett Wieselman of the New York Post placed her at number one on her list of the Five Best Singer/Dancers. According to Barbara Ellen of The Guardian Beyonc\\u00e9 is the most in-charge female artist she's seen onstage, while Alice Jones of The Independent wrote she \\\"takes her role as entertainer so seriously she's almost too good.\\\" The ex-President of Def Jam L.A. Reid has described Beyonc\\u00e9 as the greatest entertainer alive. Jim Farber of the Daily News and Stephanie Classen of Star Phoenix both praised her strong voice and her stage presence.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce self proclaimed alter ego is named what?\",\n",
      "          \"id\": \"56bec3ea3aeaaa14008c939f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sasha Fierce\",\n",
      "              \"answer_start\": 139\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Her alter ego was born when according to Beyonce?\",\n",
      "          \"id\": \"56bec3ea3aeaaa14008c93a0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"making of \\\"Crazy in Love\\\"\",\n",
      "              \"answer_start\": 378\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What year did Beyonce do away with Sasha Fierce?\",\n",
      "          \"id\": \"56bec3ea3aeaaa14008c93a2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2010\",\n",
      "              \"answer_start\": 501\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce brought back Sasha Fierce during which event?\",\n",
      "          \"id\": \"56bec3ea3aeaaa14008c93a3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Revel Presents: Beyonc\\u00e9 Live\",\n",
      "              \"answer_start\": 712\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How does she describe Sasha?\",\n",
      "          \"id\": \"56bfc420a10cfb14005512c0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"too aggressive, too strong\",\n",
      "              \"answer_start\": 243\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Later what did she say about Sasha?\",\n",
      "          \"id\": \"56bfc420a10cfb14005512c2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"she would bring her back\",\n",
      "              \"answer_start\": 679\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of Beyonc\\u00e9's alter ego?\",\n",
      "          \"id\": \"56d4e2e12ccc5a1400d832f0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sasha Fierce.\",\n",
      "              \"answer_start\": 475\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 introduce Sasha Fierce?\",\n",
      "          \"id\": \"56d4e2e12ccc5a1400d832f1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2008\",\n",
      "              \"answer_start\": 456\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Sasha Fierce was created during the making of what song?\",\n",
      "          \"id\": \"56d4e2e12ccc5a1400d832f2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Crazy in Love\",\n",
      "              \"answer_start\": 389\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 tell in February 2010 that Sasha Fierce was no longer needed?\",\n",
      "          \"id\": \"56d4e2e12ccc5a1400d832f3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Allure magazine\",\n",
      "              \"answer_start\": 542\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Described as being \\\"sexy, seductive and provocative\\\" when performing on stage, Beyonc\\u00e9 has said that she originally created the alter ego \\\"Sasha Fierce\\\" to keep that stage persona separate from who she really is. She described Sasha as being \\\"too aggressive, too strong, too sassy [and] too sexy\\\", stating, \\\"I'm not like her in real life at all.\\\" Sasha was conceived during the making of \\\"Crazy in Love\\\", and Beyonc\\u00e9 introduced her with the release of her 2008 album I Am... Sasha Fierce. In February 2010, she announced in an interview with Allure magazine that she was comfortable enough with herself to no longer need Sasha Fierce. However, Beyonc\\u00e9 announced in May 2012 that she would bring her back for her Revel Presents: Beyonc\\u00e9 Live shows later that month.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce's sex appeal is characterized as what?\",\n",
      "          \"id\": \"56bec4de3aeaaa14008c93bb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"wide-ranging\",\n",
      "              \"answer_start\": 41\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which music journalist described Beyonce as a \\\"crossover sex symbol?\\\"\",\n",
      "          \"id\": \"56bec4de3aeaaa14008c93bc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tour\\u00e9\",\n",
      "              \"answer_start\": 88\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which word spawned from a term used to describe Beyonce in 2006?\",\n",
      "          \"id\": \"56bec4de3aeaaa14008c93bd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Bootylicious\",\n",
      "              \"answer_start\": 389\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Bootylicious was a song from which act that Beyonce performed with?\",\n",
      "          \"id\": \"56bec4de3aeaaa14008c93be\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Destiny's Child\",\n",
      "              \"answer_start\": 497\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Oxford Dictionary added which word from the 2000s dedicated to Beyonce?\",\n",
      "          \"id\": \"56bec4de3aeaaa14008c93bf\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Bootylicious\",\n",
      "              \"answer_start\": 389\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What word is often used to describe Beyonce/\",\n",
      "          \"id\": \"56bfc563a10cfb14005512ca\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Bootylicious\",\n",
      "              \"answer_start\": 389\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When was the term added to the dictionary?\",\n",
      "          \"id\": \"56bfc563a10cfb14005512cc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2006\",\n",
      "              \"answer_start\": 543\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What journalist wrote that Beyonc\\u00e9 was a \\\"sex symbol\\\"?\",\n",
      "          \"id\": \"56d4e5022ccc5a1400d832fa\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tour\\u00e9\",\n",
      "              \"answer_start\": 88\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Because of Beyonc\\u00e9's physical shape, what slang term has been used to describe her?\",\n",
      "          \"id\": \"56d4e5022ccc5a1400d832fb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Bootylicious\",\n",
      "              \"answer_start\": 389\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In what year was the slang term from a title of a Destiny's Child song that is also used to describe Beyonc\\u00e9 put in the dictionary?\",\n",
      "          \"id\": \"56d4e5022ccc5a1400d832fc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2006\",\n",
      "              \"answer_start\": 543\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How does Beyonc\\u00e9 say she likes to dress off-stage?\",\n",
      "          \"id\": \"56d4e5022ccc5a1400d832fd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"sexily\",\n",
      "              \"answer_start\": 242\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 has been described as a having a wide-ranging sex appeal, with music journalist Tour\\u00e9 writing that since the release of Dangerously in Love, she has \\\"become a crossover sex symbol\\\". Offstage Beyonc\\u00e9 says that while she likes to dress sexily, her onstage dress \\\"is absolutely for the stage.\\\" Due to her curves and the term's catchiness, in the 2000s, the media often used the term \\\"Bootylicious\\\" (a portmanteau of the words booty and delicious) to describe Beyonc\\u00e9, the term popularized by Destiny's Child's single of the same name. In 2006, it was added to the Oxford English Dictionary.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"in September 2010, what career area did Beyonce start exploring?\",\n",
      "          \"id\": \"56bec5d53aeaaa14008c93d9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"modelling\",\n",
      "              \"answer_start\": 43\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's first modelling event was at where?\",\n",
      "          \"id\": \"56bec5d53aeaaa14008c93da\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tom Ford's Spring/Summer 2011 fashion show\",\n",
      "              \"answer_start\": 62\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"\\\"World's Most Beautiful woman\\\" was declared to Beyonce by which national magazine?\",\n",
      "          \"id\": \"56bec5d53aeaaa14008c93db\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"People\",\n",
      "              \"answer_start\": 154\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which month and year did GQ feature Beyonce on its cover?\",\n",
      "          \"id\": \"56bec5d53aeaaa14008c93dc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"January 2013\",\n",
      "              \"answer_start\": 228\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What TV network listed Beyonce as number 1 on its 100 Sexiest Artists list?\",\n",
      "          \"id\": \"56bec5d53aeaaa14008c93dd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"VH1\",\n",
      "              \"answer_start\": 339\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who called Beyonce the World's most Beautiful Woman?\",\n",
      "          \"id\": \"56bfc6a6a10cfb14005512d3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"People\",\n",
      "              \"answer_start\": 154\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who called her Hottest Female Singer of all Time?\",\n",
      "          \"id\": \"56bfc6a6a10cfb14005512d4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Complex\",\n",
      "              \"answer_start\": 208\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did she appear on the cover of GQ?\",\n",
      "          \"id\": \"56bfc6a6a10cfb14005512d5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2013\",\n",
      "              \"answer_start\": 236\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"VH1 listed her at what number on their 100 Sexiest Artists list?\",\n",
      "          \"id\": \"56bfc6a6a10cfb14005512d6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"number 1\",\n",
      "              \"answer_start\": 357\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What year did Beyonc\\u00e9 first model for Tom Ford?\",\n",
      "          \"id\": \"56d4e5922ccc5a1400d83302\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2010\",\n",
      "              \"answer_start\": 13\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What magazine said Beyonc\\u00e9 was the \\\"World's Most Beautiful Woman\\\"?\",\n",
      "          \"id\": \"56d4e5922ccc5a1400d83303\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"People\",\n",
      "              \"answer_start\": 154\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What title did Complex award Beyonc\\u00e9?\",\n",
      "          \"id\": \"56d4e5922ccc5a1400d83304\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Hottest Female Singer of All Time\",\n",
      "              \"answer_start\": 170\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What museum has made several models of Beyonc\\u00e9 in wax?\",\n",
      "          \"id\": \"56d4e5922ccc5a1400d83306\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Madame Tussauds Wax Museums\",\n",
      "              \"answer_start\": 443\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In September 2010, Beyonc\\u00e9 made her runway modelling debut at Tom Ford's Spring/Summer 2011 fashion show. She was named \\\"World's Most Beautiful Woman\\\" by People and the \\\"Hottest Female Singer of All Time\\\" by Complex in 2012. In January 2013, GQ placed her on its cover, featuring her atop its \\\"100 Sexiest Women of the 21st Century\\\" list. VH1 listed her at number 1 on its 100 Sexiest Artists list. Several wax figures of Beyonc\\u00e9 are found at Madame Tussauds Wax Museums in major cities around the world, including New York, Washington, D.C., Amsterdam, Bangkok, Hollywood and Sydney.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Which parent of Beyonce's help co-write a book?\",\n",
      "          \"id\": \"56bec6763aeaaa14008c93f4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Her mother\",\n",
      "              \"answer_start\": 134\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which African-American woman before Beyonce had posed for SI Swimsuit issue?\",\n",
      "          \"id\": \"56bec6763aeaaa14008c93f7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tyra Banks\",\n",
      "              \"answer_start\": 535\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the title of Beyonce's mother's book?\",\n",
      "          \"id\": \"56bfc87ca10cfb14005512dd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Destiny's Style\",\n",
      "              \"answer_start\": 188\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When was she on the Sports Illustrated cover?\",\n",
      "          \"id\": \"56bfc87ca10cfb14005512e0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2007\",\n",
      "              \"answer_start\": 404\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was she the second  African American on the cover after?\",\n",
      "          \"id\": \"56bfc87ca10cfb14005512e1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tyra Banks\",\n",
      "              \"answer_start\": 535\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9 was the second African American woman featured as a swimsuit cover on the magazine, who was first?\",\n",
      "          \"id\": \"56d4e62e2ccc5a1400d8330f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tyra Banks\",\n",
      "              \"answer_start\": 535\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What magazine said Beyonc\\u00e9 was the \\\"best-dressed celebrity\\\"?\",\n",
      "          \"id\": \"56d4e62e2ccc5a1400d83310\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"People\",\n",
      "              \"answer_start\": 551\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"According to Italian fashion designer Roberto Cavalli, Beyonc\\u00e9 uses different fashion styles to work with her music while performing. Her mother co-wrote a book, published in 2002, titled Destiny's Style an account of how fashion had an impact on the trio's success. The B'Day Anthology Video Album showed many instances of fashion-oriented footage, depicting classic to contemporary wardrobe styles. In 2007, Beyonc\\u00e9 was featured on the cover of the Sports Illustrated Swimsuit Issue, becoming the second African American woman after Tyra Banks, and People magazine recognized Beyonc\\u00e9 as the best-dressed celebrity.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce has a fan base that is referred to as what?\",\n",
      "          \"id\": \"56bec6de3aeaaa14008c9407\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Bey Hive\",\n",
      "              \"answer_start\": 0\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Before the Bey Hive, fans of Beyonce were called what?\",\n",
      "          \"id\": \"56bec6de3aeaaa14008c9408\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Beyontourage\",\n",
      "              \"answer_start\": 83\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which social media company proclaimed Beyonce fans are know as the Bey Hive?\",\n",
      "          \"id\": \"56bec6de3aeaaa14008c9409\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Twitter\",\n",
      "              \"answer_start\": 321\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is Beyonce's fan base called?\",\n",
      "          \"id\": \"56bfcaf0a10cfb14005512e7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Bey Hive\",\n",
      "              \"answer_start\": 4\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did the fans used to be called?\",\n",
      "          \"id\": \"56bfcaf0a10cfb14005512e8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyontourage\",\n",
      "              \"answer_start\": 87\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the latest term used to describe Beyonc\\u00e9 fans?\",\n",
      "          \"id\": \"56d4e7eb2ccc5a1400d83316\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Bey Hive\",\n",
      "              \"answer_start\": 4\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the former word given to Beyonc\\u00e9 fans?\",\n",
      "          \"id\": \"56d4e7eb2ccc5a1400d83317\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyontourage\",\n",
      "              \"answer_start\": 87\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What word does \\\"Bey Hive\\\" derive from?\",\n",
      "          \"id\": \"56d4e7eb2ccc5a1400d83318\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"beehive\",\n",
      "              \"answer_start\": 184\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"The Bey Hive is the name given to Beyonc\\u00e9's fan base. Fans were previously titled \\\"The Beyontourage\\\", (a portmanteau of Beyonc\\u00e9 and entourage). The name Bey Hive derives from the word beehive, purposely misspelled to resemble her first name, and was penned by fans after petitions on the online social networking service Twitter and online news reports during competitions.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce has a clothing line known as what?\",\n",
      "          \"id\": \"56bec7b63aeaaa14008c9422\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"House of Der\\u00e9on\",\n",
      "              \"answer_start\": 158\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which French magazine did Beyonce show up on the cover of?\",\n",
      "          \"id\": \"56bec7b63aeaaa14008c9423\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"L'Officiel\",\n",
      "              \"answer_start\": 237\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce was seen wearing what on the french magazine that caused controversy?\",\n",
      "          \"id\": \"56bec7b63aeaaa14008c9424\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"blackface and tribal makeup\",\n",
      "              \"answer_start\": 252\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which year did PETA spark controversy with Beyonce?\",\n",
      "          \"id\": \"56bec7b63aeaaa14008c9425\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2006\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did PETA criticize Beyonce for in 2006?\",\n",
      "          \"id\": \"56bfcd33a10cfb14005512f1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"for wearing and using fur\",\n",
      "              \"answer_start\": 111\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What French Magazine cover did the media criticize?\",\n",
      "          \"id\": \"56bfcd33a10cfb14005512f2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"L'Officiel\",\n",
      "              \"answer_start\": 237\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How was she dressed on the cover of L'Officiel?\",\n",
      "          \"id\": \"56bfcd33a10cfb14005512f4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"in blackface and tribal makeup\",\n",
      "              \"answer_start\": 249\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What French magazine did Beyonc\\u00e9 appear in wearing blackface and tribal makeup?\",\n",
      "          \"id\": \"56d4e8472ccc5a1400d8331f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"L'Officiel\",\n",
      "              \"answer_start\": 237\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What clothing line of Beyonc\\u00e9 drew PETA criticism?\",\n",
      "          \"id\": \"56d4e8472ccc5a1400d83320\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"House of Der\\u00e9on.\",\n",
      "              \"answer_start\": 158\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What type of magazine is L'Officiel?\",\n",
      "          \"id\": \"56d4e8472ccc5a1400d83321\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"French fashion magazine\",\n",
      "              \"answer_start\": 213\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In 2006, the animal rights organization People for the Ethical Treatment of Animals (PETA), criticized Beyonc\\u00e9 for wearing and using fur in her clothing line House of Der\\u00e9on. In 2011, she appeared on the cover of French fashion magazine L'Officiel, in blackface and tribal makeup that drew criticism from the media. A statement released from a spokesperson for the magazine said that Beyonc\\u00e9's look was \\\"far from the glamorous Sasha Fierce\\\" and that it was \\\"a return to her African roots\\\".\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Which racial community gave criticism to Beyonce?\",\n",
      "          \"id\": \"56bec8a13aeaaa14008c943f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"African-American\",\n",
      "              \"answer_start\": 80\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which professor from Northeastern University wrote about how race correlates with these criticisms of Beyonce?\",\n",
      "          \"id\": \"56bec8a13aeaaa14008c9440\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Emmett Price\",\n",
      "              \"answer_start\": 108\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which company was accused of coloring Beyonce's hair?\",\n",
      "          \"id\": \"56bec8a13aeaaa14008c9441\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"L'Or\\u00e9al\",\n",
      "              \"answer_start\": 335\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Vogue request?\",\n",
      "          \"id\": \"56bfcf98a10cfb14005512fd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"natural pictures be used\",\n",
      "              \"answer_start\": 615\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How did L'Oreal respond to accusations of changing pictures?\",\n",
      "          \"id\": \"56bfcf98a10cfb14005512fe\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"it is categorically untrue\",\n",
      "              \"answer_start\": 436\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In addition to her light skin color, what else has made part of the African American community criticize Beyonc\\u00e9?\",\n",
      "          \"id\": \"56d4e8512ccc5a1400d83326\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"costuming\",\n",
      "              \"answer_start\": 33\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In 2007, which music professor said he believes this criticism does involve race as well?\",\n",
      "          \"id\": \"56d4e8512ccc5a1400d83327\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Emmett Price\",\n",
      "              \"answer_start\": 108\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was accused of lightening Beyonc\\u00e9's skin for an advertisement?\",\n",
      "          \"id\": \"56d4e8512ccc5a1400d83328\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"L'Or\\u00e9al\",\n",
      "              \"answer_start\": 335\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What advertisement was Beyonc\\u00e9's skin supposedly lightened in?\",\n",
      "          \"id\": \"56d4e8512ccc5a1400d83329\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Feria hair color advertisements\",\n",
      "              \"answer_start\": 386\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 tell in 2013 to only use natural pictures of her rather than retouched images?\",\n",
      "          \"id\": \"56d4e8512ccc5a1400d8332a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"H&M\",\n",
      "              \"answer_start\": 505\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9's lighter skin color and costuming has drawn criticism from some in the African-American community. Emmett Price, a professor of music at Northeastern University, wrote in 2007, that he thinks race plays a role in many of these criticisms, saying white celebrities who dress similarly do not attract as many comments. In 2008, L'Or\\u00e9al was accused of whitening her skin in their Feria hair color advertisements, responding that \\\"it is categorically untrue\\\", and in 2013, Beyonc\\u00e9 herself criticized H&M for their proposed \\\"retouching\\\" of promotional images of her, and according to Vogue requested that only \\\"natural pictures be used\\\".\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Artist of the Decade was bestowed upon Beyonce from which magazine?\",\n",
      "          \"id\": \"56bec94f3aeaaa14008c944f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Guardian\",\n",
      "              \"answer_start\": 215\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Whats the first year that Beyonce appear on the Time 100 list?\",\n",
      "          \"id\": \"56bec94f3aeaaa14008c9450\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2013\",\n",
      "              \"answer_start\": 700\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce than appeared again on the Time 100 list in what year?\",\n",
      "          \"id\": \"56bec94f3aeaaa14008c9451\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2014\",\n",
      "              \"answer_start\": 1078\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did the Guardian name her?\",\n",
      "          \"id\": \"56bfd14ba10cfb1400551306\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Artist of the Decade\",\n",
      "              \"answer_start\": 238\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce first make the Time 100 List?\",\n",
      "          \"id\": \"56bfd14ba10cfb1400551307\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2013\",\n",
      "              \"answer_start\": 700\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When was she again on the Time 100 List and on the cover?\",\n",
      "          \"id\": \"56bfd14ba10cfb1400551308\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2014\",\n",
      "              \"answer_start\": 1078\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who said that she is the reigning national voice?\",\n",
      "          \"id\": \"56bfd14ba10cfb1400551309\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Baz Luhrmann\",\n",
      "              \"answer_start\": 738\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who stated that Beyonc\\u00e9 is the most important musician of the 21st century?\",\n",
      "          \"id\": \"56d4e91b2ccc5a1400d83330\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jody Rosen\",\n",
      "              \"answer_start\": 31\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which publication named Beyonc\\u00e9 the Artist of the Decade?\",\n",
      "          \"id\": \"56d4e91b2ccc5a1400d83331\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Guardian\",\n",
      "              \"answer_start\": 215\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What list did Beyonc\\u00e9 make in 2013?\",\n",
      "          \"id\": \"56d4e91b2ccc5a1400d83332\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Time 100 list\",\n",
      "              \"answer_start\": 723\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who said Beyonc\\u00e9 is the heir-apparent diva of the United States?\",\n",
      "          \"id\": \"56d4e91b2ccc5a1400d83333\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Baz Luhrmann\",\n",
      "              \"answer_start\": 738\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What year was Beyonc\\u00e9 featured both on the Time 100 list as well as the cover of the issue?\",\n",
      "          \"id\": \"56d4e91b2ccc5a1400d83334\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2014\",\n",
      "              \"answer_start\": 1078\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In The New Yorker music critic Jody Rosen described Beyonc\\u00e9 as \\\"the most important and compelling popular musician of the twenty-first century..... the result, the logical end point, of a century-plus of pop.\\\" When The Guardian named her Artist of the Decade, Llewyn-Smith wrote, \\\"Why Beyonc\\u00e9? [...] Because she made not one but two of the decade's greatest singles, with Crazy in Love and Single Ladies (Put a Ring on It), not to mention her hits with Destiny's Child; and this was the decade when singles \\u2013 particularly R&B singles \\u2013 regained their status as pop's favourite medium. [...] [She] and not any superannuated rock star was arguably the greatest live performer of the past 10 years.\\\" In 2013, Beyonc\\u00e9 made the Time 100 list, Baz Luhrmann writing \\\"no one has that voice, no one moves the way she moves, no one can hold an audience the way she does... When Beyonc\\u00e9 does an album, when Beyonc\\u00e9 sings a song, when Beyonc\\u00e9 does anything, it's an event, and it's broadly influential. Right now, she is the heir-apparent diva of the USA \\u2014 the reigning national voice.\\\" In 2014, Beyonc\\u00e9 was listed again on the Time 100 and also featured on the cover of the issue.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Which rock band cited Beyonce on their third album?\",\n",
      "          \"id\": \"56bec9f13aeaaa14008c9467\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"White Rabbits\",\n",
      "              \"answer_start\": 292\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which friend learned from Beyonce while preparing for the film, \\\"Country Strong?\\\"\",\n",
      "          \"id\": \"56bec9f13aeaaa14008c9468\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Gwyneth Paltrow\",\n",
      "              \"answer_start\": 385\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Nicky Minaj became a spokesperson for which brand of soda after seeing Beyonce involved with it?\",\n",
      "          \"id\": \"56bec9f13aeaaa14008c9469\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Pepsi\",\n",
      "              \"answer_start\": 562\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What influenced Nicki Minaj to join the Pepsi global campaign?\",\n",
      "          \"id\": \"56bfd351a10cfb1400551310\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonc\\u00e9's Pepsi commercial\",\n",
      "              \"answer_start\": 552\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which band listed Beyonce as an inspiration on their latest album?\",\n",
      "          \"id\": \"56bfd351a10cfb1400551311\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"White Rabbits\",\n",
      "              \"answer_start\": 292\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What about Beyonce has influenced many entertainers?\",\n",
      "          \"id\": \"56bfd351a10cfb1400551312\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"work\",\n",
      "              \"answer_start\": 10\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"For what film was Paltrow studying Beyonce ?\",\n",
      "          \"id\": \"56bfd351a10cfb1400551313\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Country Strong\",\n",
      "              \"answer_start\": 501\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which Indie band said Beyonc\\u00e9 was an inspiration for one of hteir albums?\",\n",
      "          \"id\": \"56d4e9d12ccc5a1400d8333a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"White Rabbits\",\n",
      "              \"answer_start\": 292\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the White Rabbits' album?\",\n",
      "          \"id\": \"56d4e9d12ccc5a1400d8333b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Milk Famous\",\n",
      "              \"answer_start\": 358\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who studied Beyonc\\u00e9 during live concerts for research for a film's music role?\",\n",
      "          \"id\": \"56d4e9d12ccc5a1400d8333c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Gwyneth Paltrow\",\n",
      "              \"answer_start\": 385\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the film that Gwyneth Paltrow starred in as a musician?\",\n",
      "          \"id\": \"56d4e9d12ccc5a1400d8333d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Country Strong.\",\n",
      "              \"answer_start\": 501\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonc\\u00e9's Pepsi commercial inspired which star to join Pepsi's global campaign in 2012?\",\n",
      "          \"id\": \"56d4e9d12ccc5a1400d8333e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Nicki Minaj\",\n",
      "              \"answer_start\": 517\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9's work has influenced numerous artists including Adele, Ariana Grande, Lady Gaga, Bridgit Mendler, Rihanna, Kelly Rowland, Sam Smith, Meghan Trainor, Nicole Scherzinger, Rita Ora, Zendaya, Cheryl Cole, JoJo, Alexis Jordan, Jessica Sanchez, and Azealia Banks. American indie rock band White Rabbits also cited her an inspiration for their third album Milk Famous (2012), friend Gwyneth Paltrow studied Beyonc\\u00e9 at her live concerts while learning to become a musical performer for the 2010 film Country Strong. Nicki Minaj has stated that seeing Beyonc\\u00e9's Pepsi commercial influenced her decision to appear in the company's 2012 global campaign.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"VH1 declared what song the \\\"Greatest song of the 2000s?\\\"\",\n",
      "          \"id\": \"56beca973aeaaa14008c9477\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Crazy in Love\",\n",
      "              \"answer_start\": 19\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many Grammy awards did \\\"Crazy in Love\\\" win?\",\n",
      "          \"id\": \"56beca973aeaaa14008c9478\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"two\",\n",
      "              \"answer_start\": 225\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many did Crazy in Love sell to become one of the greatest selling singles in history?\",\n",
      "          \"id\": \"56beca973aeaaa14008c9479\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"8 million\",\n",
      "              \"answer_start\": 304\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What type of organism was named after Beyonce in 2012?\",\n",
      "          \"id\": \"56beca973aeaaa14008c947a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"fly\",\n",
      "              \"answer_start\": 959\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"A place for Beyonce in the Rock and Roll Hall of fame was awarded when?\",\n",
      "          \"id\": \"56beca973aeaaa14008c947b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"July 2014\",\n",
      "              \"answer_start\": 1073\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which of Beyonce's songs was called Greatest Song of the 2000s?\",\n",
      "          \"id\": \"56bfd565a10cfb1400551319\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Crazy in Love\",\n",
      "              \"answer_start\": 19\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many Grammy awards did Crazy in Love get?\",\n",
      "          \"id\": \"56bfd565a10cfb140055131a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"earned two Grammy Awards\",\n",
      "              \"answer_start\": 218\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many copies did Crazy in Love sell?\",\n",
      "          \"id\": \"56bfd565a10cfb140055131b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"around 8 million copies\",\n",
      "              \"answer_start\": 297\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who released the single Girls Love Beyonce?\",\n",
      "          \"id\": \"56bfd565a10cfb140055131c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Drake\",\n",
      "              \"answer_start\": 702\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which publication considers Crazy in Love to be one of the top 500 songs of all time?\",\n",
      "          \"id\": \"56d4eaca2ccc5a1400d83345\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Rolling Stone\",\n",
      "              \"answer_start\": 155\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who sang \\\"Girls Love Beyonc\\u00e9\\\" in 2013?\",\n",
      "          \"id\": \"56d4eaca2ccc5a1400d83347\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Drake\",\n",
      "              \"answer_start\": 702\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Bryan Lessard name after Beyonc\\u00e9?\",\n",
      "          \"id\": \"56d4eaca2ccc5a1400d83348\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"a species of horse fly\",\n",
      "              \"answer_start\": 940\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Her debut single, \\\"Crazy in Love\\\" was named VH1's \\\"Greatest Song of the 2000s\\\", NME's \\\"Best Track of the 00s\\\" and \\\"Pop Song of the Century\\\", considered by Rolling Stone to be one of the 500 greatest songs of all time, earned two Grammy Awards and is one of the best-selling singles of all time at around 8 million copies. The music video for \\\"Single Ladies (Put a Ring on It)\\\", which achieved fame for its intricate choreography and its deployment of jazz hands, was credited by the Toronto Star as having started the \\\"first major dance craze of both the new millennium and the Internet\\\", triggering a number of parodies of the dance choreography and a legion of amateur imitators on YouTube. In 2013, Drake released a single titled \\\"Girls Love Beyonc\\u00e9\\\", which featured an interpolation from Destiny Child's \\\"Say My Name\\\" and discussed his relationship with women. In January 2012, research scientist Bryan Lessard named Scaptia beyonceae, a species of horse fly found in Northern Queensland, Australia after Beyonc\\u00e9 due to the fly's unique golden hairs on its abdomen. In July 2014, a Beyonc\\u00e9 exhibit was introduced into the \\\"Legends of Rock\\\" section of the Rock and Roll Hall of Fame. The black leotard from the \\\"Single Ladies\\\" video and her outfit from the Super Bowl half time performance are among several pieces housed at the museum.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"How many copies of her albums as Beyonce sold in the US?\",\n",
      "          \"id\": \"56becb8d3aeaaa14008c9495\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"15 million\",\n",
      "              \"answer_start\": 73\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Totaling worldwide, how many records as Beyonce sold?\",\n",
      "          \"id\": \"56becb8d3aeaaa14008c9496\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"118 million\",\n",
      "              \"answer_start\": 111\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many certifications was Beyonce awarded by the RIAA?\",\n",
      "          \"id\": \"56becb8d3aeaaa14008c9497\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"64\",\n",
      "              \"answer_start\": 387\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When Beyonce was with Destiny's Child, how many albums did she manage to sell?\",\n",
      "          \"id\": \"56becb8d3aeaaa14008c9498\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"60 million\",\n",
      "              \"answer_start\": 152\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was the first female to achieve the International Artist Award at the American Music Awards?\",\n",
      "          \"id\": \"56becb8d3aeaaa14008c9499\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonc\\u00e9\",\n",
      "              \"answer_start\": 0\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many albums has Beyonce as a solo artist sold in the U.S?\",\n",
      "          \"id\": \"56bfd6f7a10cfb1400551323\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"15 million\",\n",
      "              \"answer_start\": 73\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many has she sold worldwide?\",\n",
      "          \"id\": \"56bfd6f7a10cfb1400551324\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"118 million\",\n",
      "              \"answer_start\": 111\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many records has she sold with Destiny's Child?\",\n",
      "          \"id\": \"56bfd6f7a10cfb1400551325\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"60 million\",\n",
      "              \"answer_start\": 152\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did she receive the Legend Award?\",\n",
      "          \"id\": \"56bfd6f7a10cfb1400551326\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2008 World Music Awards\",\n",
      "              \"answer_start\": 1052\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many music certifications has she received in the 2000s?\",\n",
      "          \"id\": \"56bfd6f7a10cfb1400551327\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"64 certifications\",\n",
      "              \"answer_start\": 387\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many records has Beyonc\\u00e9 sold in the United States?\",\n",
      "          \"id\": \"56d4eb762ccc5a1400d8334e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"over 15 million\",\n",
      "              \"answer_start\": 68\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many records has Beyonc\\u00e9 sold throughout the world?\",\n",
      "          \"id\": \"56d4eb762ccc5a1400d8334f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"over 118 million\",\n",
      "              \"answer_start\": 106\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who cited Beyonc\\u00e9 as being the top certified artist of the 2000s?\",\n",
      "          \"id\": \"56d4eb762ccc5a1400d83350\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Recording Industry Association of America\",\n",
      "              \"answer_start\": 261\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many certifications did RIAA give Beyonc\\u00e9?\",\n",
      "          \"id\": \"56d4eb762ccc5a1400d83351\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"64\",\n",
      "              \"answer_start\": 387\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonc\\u00e9 receive the Legend Award?\",\n",
      "          \"id\": \"56d4eb762ccc5a1400d83352\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the 2008 World Music Awards\",\n",
      "              \"answer_start\": 1048\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 has received numerous awards. As a solo artist she has sold over 15 million albums in the US, and over 118 million records worldwide (a further 60 million additionally with Destiny's Child), making her one of the best-selling music artists of all time. The Recording Industry Association of America (RIAA) listed Beyonc\\u00e9 as the top certified artist of the 2000s, with a total of 64 certifications. Her songs \\\"Crazy in Love\\\", \\\"Single Ladies (Put a Ring on It)\\\", \\\"Halo\\\", and \\\"Irreplaceable\\\" are some of the best-selling singles of all time worldwide. In 2009, The Observer named her the Artist of the Decade and Billboard named her the Top Female Artist and Top Radio Songs Artist of the Decade. In 2010, Billboard named her in their \\\"Top 50 R&B/Hip-Hop Artists of the Past 25 Years\\\" list at number 15. In 2012 VH1 ranked her third on their list of the \\\"100 Greatest Women in Music\\\". Beyonc\\u00e9 was the first female artist to be honored with the International Artist Award at the American Music Awards. She has also received the Legend Award at the 2008 World Music Awards and the Billboard Millennium Award at the 2011 Billboard Music Awards.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"How many Grammys has Beyonce won total with and without Destiny's Child?\",\n",
      "          \"id\": \"56becc903aeaaa14008c949f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"20\",\n",
      "              \"answer_start\": 16\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who is the only other woman with more Grammy awards than Beyonce?\",\n",
      "          \"id\": \"56becc903aeaaa14008c94a0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Alison Krauss\",\n",
      "              \"answer_start\": 159\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce has been awarded how many Grammy nominations?\",\n",
      "          \"id\": \"56becc903aeaaa14008c94a1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"52\",\n",
      "              \"answer_start\": 231\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce holds the record for how many wins in one night by a female?\",\n",
      "          \"id\": \"56becc903aeaaa14008c94a2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"six\",\n",
      "              \"answer_start\": 586\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many awards at the Broadcast Film Critics Association Awards in 2006 did Beyonce bring home?\",\n",
      "          \"id\": \"56becc903aeaaa14008c94a3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"two\",\n",
      "              \"answer_start\": 949\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many Grammies has Beyonce won?\",\n",
      "          \"id\": \"56bfd8bda10cfb140055132d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"20 Grammy Awards\",\n",
      "              \"answer_start\": 16\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many Grammy nominations does Beyonce have?\",\n",
      "          \"id\": \"56bfd8bda10cfb140055132e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"52 nominations\",\n",
      "              \"answer_start\": 231\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did she set the record for most Grammy awards won in one night?\",\n",
      "          \"id\": \"56bfd8bda10cfb140055132f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2010\",\n",
      "              \"answer_start\": 306\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who tied her record for most Grammies won in one night in 2012?\",\n",
      "          \"id\": \"56bfd8bda10cfb1400551330\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Adele\",\n",
      "              \"answer_start\": 705\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many Grammys has Beyonc\\u00e9 won?\",\n",
      "          \"id\": \"56d4ebea2ccc5a1400d83358\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"20\",\n",
      "              \"answer_start\": 16\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many Grammy nominations has Beyonc\\u00e9 had?\",\n",
      "          \"id\": \"56d4ebea2ccc5a1400d8335a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"52\",\n",
      "              \"answer_start\": 231\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What Beyonc\\u00e9 song was song of the year on 2010?\",\n",
      "          \"id\": \"56d4ebea2ccc5a1400d8335b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"\\\"Single Ladies (Put a Ring on It)\\\"\",\n",
      "              \"answer_start\": 247\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What movie had Beyonc\\u00e9 nominated as Best Actress for Golden Globe Awards?\",\n",
      "          \"id\": \"56d4ebea2ccc5a1400d8335c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dreamgirls\",\n",
      "              \"answer_start\": 756\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 has won 20 Grammy Awards, both as a solo artist and member of Destiny's Child, making her the second most honored female artist by the Grammys, behind Alison Krauss and the most nominated woman in Grammy Award history with 52 nominations. \\\"Single Ladies (Put a Ring on It)\\\" won Song of the Year in 2010 while \\\"Say My Name\\\" and \\\"Crazy in Love\\\" had previously won Best R&B Song. Dangerously in Love, B'Day and I Am... Sasha Fierce have all won Best Contemporary R&B Album. Beyonc\\u00e9 set the record for the most Grammy awards won by a female artist in one night in 2010 when she won six awards, breaking the tie she previously held with Alicia Keys, Norah Jones, Alison Krauss, and Amy Winehouse, with Adele equaling this in 2012. Following her role in Dreamgirls she was nominated for Best Original Song for \\\"Listen\\\" and Best Actress at the Golden Globe Awards, and Outstanding Actress in a Motion Picture at the NAACP Image Awards. Beyonc\\u00e9 won two awards at the Broadcast Film Critics Association Awards 2006; Best Song for \\\"Listen\\\" and Best Original Soundtrack for Dreamgirls: Music from the Motion Picture.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Which soda company has Beyonce partnered with since 2002?\",\n",
      "          \"id\": \"56bed07e3aeaaa14008c94a9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Pepsi\",\n",
      "              \"answer_start\": 24\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Pepsi paid Beyonce how much in 2012 for her endorsement?\",\n",
      "          \"id\": \"56bed07e3aeaaa14008c94aa\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"50 million\",\n",
      "              \"answer_start\": 172\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which organization wrote a letter to Beyonce after her Pepsi endorsement deal?\",\n",
      "          \"id\": \"56bed07e3aeaaa14008c94ab\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Center for Science in the Public Interest (CSPINET)\",\n",
      "              \"answer_start\": 206\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What percentage of people were positive about Beyonce's endorsement of Pepsi?\",\n",
      "          \"id\": \"56bed07e3aeaaa14008c94ad\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"70\",\n",
      "              \"answer_start\": 535\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce begin doing Pepsi advetisments?\",\n",
      "          \"id\": \"56bfda91a10cfb1400551337\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2002\",\n",
      "              \"answer_start\": 36\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was in the commercial with Beyonce in 2004?\",\n",
      "          \"id\": \"56bfda91a10cfb1400551338\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Britney Spears, Pink, and Enrique Iglesias\",\n",
      "              \"answer_start\": 101\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did she agree to do for 50 million dollars in 2012?\",\n",
      "          \"id\": \"56bfda91a10cfb1400551339\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"endorse Pepsi\",\n",
      "              \"answer_start\": 191\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who sent her a letter asking that she reconsider the Pepsi deal?\",\n",
      "          \"id\": \"56bfda91a10cfb140055133a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Center for Science in the Public Interest\",\n",
      "              \"answer_start\": 210\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What soft drink company has Beyonc\\u00e9 worked with since 2002?\",\n",
      "          \"id\": \"56d4ec422ccc5a1400d83362\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Pepsi\",\n",
      "              \"answer_start\": 24\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much did Beyonc\\u00e9 get for a deal with a soft drink company in 2012?\",\n",
      "          \"id\": \"56d4ec422ccc5a1400d83363\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"$50 million\",\n",
      "              \"answer_start\": 171\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who asked her to change her mind about the soft drink deal due to the nature of the product?\",\n",
      "          \"id\": \"56d4ec422ccc5a1400d83364\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"The Center for Science in the Public Interest (CSPINET)\",\n",
      "              \"answer_start\": 206\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What organization discovered that the advertisements Beyonc\\u00e9 did for the soft drink company were 70% positive?\",\n",
      "          \"id\": \"56d4ec422ccc5a1400d83365\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"NetBase\",\n",
      "              \"answer_start\": 437\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 has worked with Pepsi since 2002, and in 2004 appeared in a Gladiator-themed commercial with Britney Spears, Pink, and Enrique Iglesias. In 2012, Beyonc\\u00e9 signed a $50 million deal to endorse Pepsi. The Center for Science in the Public Interest (CSPINET) wrote Beyonc\\u00e9 an open letter asking her to reconsider the deal because of the unhealthiness of the product and to donate the proceeds to a medical organisation. Nevertheless, NetBase found that Beyonc\\u00e9's campaign was the most talked about endorsement in April 2013, with a 70 per cent positive audience response to the commercial and print ads.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce worked with who on her perfumes, True Star and True Star Gold?\",\n",
      "          \"id\": \"56bed1243aeaaa14008c94b3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tommy Hilfiger\",\n",
      "              \"answer_start\": 24\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The world's best selling celebrity perfume line belongs to whom?\",\n",
      "          \"id\": \"56bed1243aeaaa14008c94b4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonc\\u00e9\",\n",
      "              \"answer_start\": 0\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's first fragrance had what name?\",\n",
      "          \"id\": \"56bed1243aeaaa14008c94b5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Heat\",\n",
      "              \"answer_start\": 247\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The Mrs. Carter Show Limited Edition was released in what year?\",\n",
      "          \"id\": \"56bed1243aeaaa14008c94b6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2013\",\n",
      "              \"answer_start\": 577\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much money did The Mrs. Carter Show Limited Edition fragrance make?\",\n",
      "          \"id\": \"56bed1243aeaaa14008c94b7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"400 million\",\n",
      "              \"answer_start\": 750\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was Beyonce's 2010  perfume called?\",\n",
      "          \"id\": \"56bfdbf2a10cfb1400551341\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Heat\",\n",
      "              \"answer_start\": 247\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When was her second perfume, Heat Rush, released?\",\n",
      "          \"id\": \"56bfdbf2a10cfb1400551342\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2011\",\n",
      "              \"answer_start\": 452\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was Beyonce's third perfume named?\",\n",
      "          \"id\": \"56bfdbf2a10cfb1400551343\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Pulse\",\n",
      "              \"answer_start\": 535\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many editions of Heat have been launched?\",\n",
      "          \"id\": \"56bfdbf2a10cfb1400551344\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"six editions\",\n",
      "              \"answer_start\": 654\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which Emporio Armani fragrance did Beyonc\\u00e9 promote in 2007?\",\n",
      "          \"id\": \"56d4ee342ccc5a1400d8336d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Diamonds\",\n",
      "              \"answer_start\": 172\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What year did Beyonc\\u00e9 introduce her first fragrance?\",\n",
      "          \"id\": \"56d4ee342ccc5a1400d8336e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2010.\",\n",
      "              \"answer_start\": 255\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was Beyonc\\u00e9's first fragrance called?\",\n",
      "          \"id\": \"56d4ee342ccc5a1400d8336f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Heat\",\n",
      "              \"answer_start\": 247\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many editions of Heat exist?\",\n",
      "          \"id\": \"56d4ee342ccc5a1400d83370\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"six\",\n",
      "              \"answer_start\": 654\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 has worked with Tommy Hilfiger for the fragrances True Star (singing a cover version of \\\"Wishing on a Star\\\") and True Star Gold; she also promoted Emporio Armani's Diamonds fragrance in 2007. Beyonc\\u00e9 launched her first official fragrance, Heat in 2010. The commercial, which featured the 1956 song \\\"Fever\\\", was shown after the water shed in the United Kingdom as it begins with an image of Beyonc\\u00e9 appearing to lie naked in a room. In February 2011, Beyonc\\u00e9 launched her second fragrance, Heat Rush. Beyonc\\u00e9's third fragrance, Pulse, was launched in September 2011. In 2013, The Mrs. Carter Show Limited Edition version of Heat was released. The six editions of Heat are the world's best-selling celebrity fragrance line, with sales of over $400 million.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"How young was Beyonce when she acquired deals from American Express and L'Oreal?\",\n",
      "          \"id\": \"56bed17a3aeaaa14008c94bd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"18\",\n",
      "              \"answer_start\": 450\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the video game that was cancelled for Beyonce?\",\n",
      "          \"id\": \"56bed17a3aeaaa14008c94be\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Starpower: Beyonc\\u00e9\",\n",
      "              \"answer_start\": 28\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce begin her deals with name brands?\",\n",
      "          \"id\": \"56bfdd3fa10cfb140055134b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"since the age of 18\",\n",
      "              \"answer_start\": 433\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many people lost jobs when Beyonce left the video game deal?\",\n",
      "          \"id\": \"56bfdd3fa10cfb140055134d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"70 staff\",\n",
      "              \"answer_start\": 168\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How was the suit settled?\",\n",
      "          \"id\": \"56bfdd3fa10cfb140055134e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"out of court\",\n",
      "              \"answer_start\": 236\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the video game?\",\n",
      "          \"id\": \"56bfdd3fa10cfb140055134f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Starpower: Beyonc\\u00e9\",\n",
      "              \"answer_start\": 28\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What video game did Beyonc\\u00e9 back out of?\",\n",
      "          \"id\": \"56d4efd92ccc5a1400d83376\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Starpower: Beyonc\\u00e9\",\n",
      "              \"answer_start\": 28\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What company was producing the video game?\",\n",
      "          \"id\": \"56d4efd92ccc5a1400d83377\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"GateFive\",\n",
      "              \"answer_start\": 109\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How many people lost their jobs over Beyonc\\u00e9 backing out of the deal?\",\n",
      "          \"id\": \"56d4efd92ccc5a1400d83378\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"70\",\n",
      "              \"answer_start\": 168\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When was the disagreement settled out of court?\",\n",
      "          \"id\": \"56d4efd92ccc5a1400d83379\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"June 2013\",\n",
      "              \"answer_start\": 267\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"The release of a video-game Starpower: Beyonc\\u00e9 was cancelled after Beyonc\\u00e9 pulled out of a $100 million with GateFive who alleged the cancellation meant the sacking of 70 staff and millions of pounds lost in development. It was settled out of court by her lawyers in June 2013 who said that they had cancelled because GateFive had lost its financial backers. Beyonc\\u00e9 also has had deals with American Express, Nintendo DS and L'Or\\u00e9al since the age of 18.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Who did Bayonce's management go into business with in 2014?\",\n",
      "          \"id\": \"56bed22d3aeaaa14008c94c1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"fashion retailer Topshop\",\n",
      "              \"answer_start\": 136\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"After their agreement together, Beyonce's and Topshop\\\" new business was called what?\",\n",
      "          \"id\": \"56bed22d3aeaaa14008c94c2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Parkwood Topshop Athletic Ltd\",\n",
      "              \"answer_start\": 209\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What type of clothing does Parkwood Topshop Athletic Ltd produce?\",\n",
      "          \"id\": \"56bed22d3aeaaa14008c94c3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"activewear\",\n",
      "              \"answer_start\": 299\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The company and products were set to be in stores when?\",\n",
      "          \"id\": \"56bed22d3aeaaa14008c94c4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"fall of 2015\",\n",
      "              \"answer_start\": 698\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonce partner with in London?\",\n",
      "          \"id\": \"56bfdecca10cfb1400551355\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Topshop\",\n",
      "              \"answer_start\": 153\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When will the new line launch?\",\n",
      "          \"id\": \"56bfdecca10cfb1400551359\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2015\",\n",
      "              \"answer_start\": 706\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of Beyonc\\u00e9's management company?\",\n",
      "          \"id\": \"56d4f5d32ccc5a1400d83380\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Parkwood Entertainment\",\n",
      "              \"answer_start\": 75\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 and Parkwood Entertainment partner with in October 2014?\",\n",
      "          \"id\": \"56d4f5d32ccc5a1400d83381\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Topshop\",\n",
      "              \"answer_start\": 153\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where is Topshop located?\",\n",
      "          \"id\": \"56d4f5d32ccc5a1400d83382\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"London\",\n",
      "              \"answer_start\": 123\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the new division of Topshop because of the partnership?\",\n",
      "          \"id\": \"56d4f5d32ccc5a1400d83383\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"activewear\",\n",
      "              \"answer_start\": 299\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In October 2014, it was announced that Beyonc\\u00e9 with her management company Parkwood Entertainment would be partnering with London-based fashion retailer Topshop, in a new 50/50 split subsidiary business named Parkwood Topshop Athletic Ltd. The new division was created for Topshop to break into the activewear market, with an athletic, street wear brand being produced. \\\"Creating a partnership with Beyonc\\u00e9, one of the most hard-working and talented people in the world, who spends many hours of her life dancing, rehearsing and training is a unique opportunity to develop this category\\\" stated Sir Philip Green on the partnership. The company and collection is set to launch and hit stores in the fall of 2015.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"When was it discovered Beyonce was a co-owner of the music service, Tidal?\",\n",
      "          \"id\": \"56bed2993aeaaa14008c94c9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"March 30, 2015\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The parent company of Tidal became under the ownership of whom in 2015?\",\n",
      "          \"id\": \"56bed2993aeaaa14008c94cb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 230\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When was it announced that Beyonce was  a co-owner in Tidal?\",\n",
      "          \"id\": \"56bfe0a9a10cfb140055135f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"March 30, 2015\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What kind of service is Tidal?\",\n",
      "          \"id\": \"56bfe0a9a10cfb1400551361\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"music streaming service\",\n",
      "              \"answer_start\": 105\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is a criticism of other streaming services?\",\n",
      "          \"id\": \"56bfe0a9a10cfb1400551363\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"low payout of royalties\",\n",
      "              \"answer_start\": 763\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What music streaming system is Beyonc\\u00e9 part owner of?\",\n",
      "          \"id\": \"56d4f63e2ccc5a1400d8338a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Tidal.\",\n",
      "              \"answer_start\": 129\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the parent company of the music service Beyonc\\u00e9 owns part of?\",\n",
      "          \"id\": \"56d4f63e2ccc5a1400d8338c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Aspiro\",\n",
      "              \"answer_start\": 274\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who acquired the parent company of the music service Beyonc\\u00e9 owns part of?\",\n",
      "          \"id\": \"56d4f63e2ccc5a1400d8338d\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Jay Z\",\n",
      "              \"answer_start\": 230\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What music service is accused of providing low royalty amounts?\",\n",
      "          \"id\": \"56d4f63e2ccc5a1400d8338e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Spotify\",\n",
      "              \"answer_start\": 717\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"On March 30, 2015, it was announced that Beyonc\\u00e9 is a co-owner, with various other music artists, in the music streaming service Tidal. The service specialises in lossless audio and high definition music videos. Beyonc\\u00e9's husband Jay Z acquired the parent company of Tidal, Aspiro, in the first quarter of 2015. Including Beyonc\\u00e9 and Jay-Z, sixteen artist stakeholders (such as Kanye West, Rihanna, Madonna, Chris Martin, Nicki Minaj and more) co-own Tidal, with the majority owning a 3% equity stake. The idea of having an all artist owned streaming service was created by those involved to adapt to the increased demand for streaming within the current music industry, and to rival other streaming services such as Spotify, which have been criticised for their low payout of royalties. \\\"The challenge is to get everyone to respect music again, to recognize its value\\\", stated Jay-Z on the release of Tidal.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"House of Dereon became known through Beyonce and which of Beyonce's relatives?\",\n",
      "          \"id\": \"56bed32f3aeaaa14008c94cf\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her mother\",\n",
      "              \"answer_start\": 12\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's grandma's name was?\",\n",
      "          \"id\": \"56bed32f3aeaaa14008c94d0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Agn\\u00e8z Der\\u00e9on\",\n",
      "              \"answer_start\": 218\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce's family's company name is what?\",\n",
      "          \"id\": \"56bed32f3aeaaa14008c94d1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyond Productions\",\n",
      "              \"answer_start\": 408\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What types of garments are sold by Beyonce's clothing line?\",\n",
      "          \"id\": \"56bed32f3aeaaa14008c94d2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"sportswear, denim offerings with fur, outerwear and accessories that include handbags and footwear\",\n",
      "              \"answer_start\": 670\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which two countries can you purchase Beyonce's clothing line?\",\n",
      "          \"id\": \"56bed32f3aeaaa14008c94d3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"US and Canada\",\n",
      "              \"answer_start\": 834\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who partnered with Beyonce to start the clothing line, Dereon?\",\n",
      "          \"id\": \"56bfe2a2a10cfb1400551369\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her mother\",\n",
      "              \"answer_start\": 12\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce and her mother start Dereon?\",\n",
      "          \"id\": \"56bfe2a2a10cfb140055136a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2005\",\n",
      "              \"answer_start\": 91\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who was the business named for in Beyonce's family?\",\n",
      "          \"id\": \"56bfe2a2a10cfb140055136b\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"grandmother, Agn\\u00e8z Der\\u00e9on\",\n",
      "              \"answer_start\": 205\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Where were items from the clothing line displayed?\",\n",
      "          \"id\": \"56bfe2a2a10cfb140055136c\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"in Destiny's Child's shows and tours\",\n",
      "              \"answer_start\": 572\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who shares in the House of Der\\u00e9on fashion line introduction with Beyonc\\u00e9?\",\n",
      "          \"id\": \"56d4f6922ccc5a1400d83394\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her mother\",\n",
      "              \"answer_start\": 12\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of the House of Der\\u00e9on junior collection?\",\n",
      "          \"id\": \"56d4f6922ccc5a1400d83397\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Der\\u00e9on.\",\n",
      "              \"answer_start\": 526\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 and her mother introduced House of Der\\u00e9on, a contemporary women's fashion line, in 2005. The concept is inspired by three generations of women in their family, the name paying tribute to Beyonc\\u00e9's grandmother, Agn\\u00e8z Der\\u00e9on, a respected seamstress. According to Tina, the overall style of the line best reflects her and Beyonc\\u00e9's taste and style. Beyonc\\u00e9 and her mother founded their family's company Beyond Productions, which provides the licensing and brand management for House of Der\\u00e9on, and its junior collection, Der\\u00e9on. House of Der\\u00e9on pieces were exhibited in Destiny's Child's shows and tours, during their Destiny Fulfilled era. The collection features sportswear, denim offerings with fur, outerwear and accessories that include handbags and footwear, and are available at department and specialty stores across the US and Canada.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"What type of accessory company did Beyonce partner with in 2005?\",\n",
      "          \"id\": \"56bed38e3aeaaa14008c94d9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"shoe\",\n",
      "              \"answer_start\": 51\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"In 2010, Beyonce released Dereon to what country?\",\n",
      "          \"id\": \"56bed38e3aeaaa14008c94da\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Brazil\",\n",
      "              \"answer_start\": 741\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Back-to-school shopping was introduced in what year of Beyonce's clothing line?\",\n",
      "          \"id\": \"56bed38e3aeaaa14008c94db\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"2009\",\n",
      "              \"answer_start\": 294\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonce's Fashion Diva  feature?\",\n",
      "          \"id\": \"56bfe4dfa10cfb1400551374\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"House of Der\\u00e9on collection\",\n",
      "              \"answer_start\": 258\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What new idea did Beyonce and her mother launch in 2009?\",\n",
      "          \"id\": \"56bfe4dfa10cfb1400551375\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sasha Fierce for Der\\u00e9on\",\n",
      "              \"answer_start\": 360\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When did Beyonce partner with C&A to sell fashion in Brazil?\",\n",
      "          \"id\": \"56bfe4dfa10cfb1400551377\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"May 27, 2010\",\n",
      "              \"answer_start\": 638\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What company did Beyonc\\u00e9 get together with in 2005 to add shoes to her fashions?\",\n",
      "          \"id\": \"56d4f6e02ccc5a1400d8339e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"House of Brands\",\n",
      "              \"answer_start\": 32\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the game put out by Starwave Mobile in 2008 that featured Beyonc\\u00e9 fashions?\",\n",
      "          \"id\": \"56d4f6e02ccc5a1400d8339f\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonc\\u00e9 Fashion Diva\",\n",
      "              \"answer_start\": 159\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the name of the junior fashions launched in 2009 by Beyonc\\u00e9 and her mother?\",\n",
      "          \"id\": \"56d4f6e02ccc5a1400d833a0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sasha Fierce for Der\\u00e9on\",\n",
      "              \"answer_start\": 360\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 team up with in 2010 to get her fashions into Brazil?\",\n",
      "          \"id\": \"56d4f6e02ccc5a1400d833a1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"C&A\",\n",
      "              \"answer_start\": 690\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Sasha Fierce for Der\\u00e9on fashions were sold at stores that included Macy's and what other store?\",\n",
      "          \"id\": \"56d4f6e02ccc5a1400d833a2\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Dillard's\",\n",
      "              \"answer_start\": 570\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In 2005, Beyonc\\u00e9 teamed up with House of Brands, a shoe company, to produce a range of footwear for House of Der\\u00e9on. In January 2008, Starwave Mobile launched Beyonc\\u00e9 Fashion Diva, a \\\"high-style\\\" mobile game with a social networking component, featuring the House of Der\\u00e9on collection. In July 2009, Beyonc\\u00e9 and her mother launched a new junior apparel label, Sasha Fierce for Der\\u00e9on, for back-to-school selling. The collection included sportswear, outerwear, handbags, footwear, eyewear, lingerie and jewelry. It was available at department stores including Macy's and Dillard's, and specialty stores Jimmy Jazz and Against All Odds. On May 27, 2010, Beyonc\\u00e9 teamed up with clothing store C&A to launch Der\\u00e9on by Beyonc\\u00e9 at their stores in Brazil. The collection included tailored blazers with padded shoulders, little black dresses, embroidered tops and shirts and bandage dresses.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Beyonce, during October 2014, partnered with whom to produce an outdoor line of clothing?\",\n",
      "          \"id\": \"56bed3e63aeaaa14008c94e0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Topshop\",\n",
      "              \"answer_start\": 110\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce and Topshops first products were to be sold in stores when?\",\n",
      "          \"id\": \"56bed3e63aeaaa14008c94e1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"autumn 2015\",\n",
      "              \"answer_start\": 250\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the new business called?\",\n",
      "          \"id\": \"56bfe66ea10cfb140055137e\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Parkwood Topshop Athletic Ltd\",\n",
      "              \"answer_start\": 147\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is Beyonce's percentage of ownership in the new venture?\",\n",
      "          \"id\": \"56bfe66ea10cfb1400551380\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"50\",\n",
      "              \"answer_start\": 126\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"When will the full line appear?\",\n",
      "          \"id\": \"56bfe66ea10cfb1400551381\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"April 2016\",\n",
      "              \"answer_start\": 287\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What company did Beyonc\\u00e9 contract with to sell clothing in England?\",\n",
      "          \"id\": \"56d4f71e2ccc5a1400d833a8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Topshop\",\n",
      "              \"answer_start\": 110\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of the equal partnership's fashion line between Beyonc\\u00e9 and the British company to come out in 2016?\",\n",
      "          \"id\": \"56d4f71e2ccc5a1400d833a9\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Parkwood Topshop Athletic Ltd\",\n",
      "              \"answer_start\": 147\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What type of clothing does the British partnership with Beyonc\\u00e9 sell?\",\n",
      "          \"id\": \"56d4f71e2ccc5a1400d833aa\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"activewear\",\n",
      "              \"answer_start\": 52\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In October 2014, Beyonc\\u00e9 signed a deal to launch an activewear line of clothing with British fashion retailer Topshop. The 50-50 venture is called Parkwood Topshop Athletic Ltd and is scheduled to launch its first dance, fitness and sports ranges in autumn 2015. The line will launch in April 2016.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"What national disaster caused Beyonce to create the Survivor Foundation?\",\n",
      "          \"id\": \"56bed4553aeaaa14008c94e5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Hurricane Katrina\",\n",
      "              \"answer_start\": 6\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much cash did Beyonce put into the venture, the Survivor Foundation at startup?\",\n",
      "          \"id\": \"56bed4553aeaaa14008c94e7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"250,000\",\n",
      "              \"answer_start\": 191\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What hurricane years later after Katrina did the organization provide support for?\",\n",
      "          \"id\": \"56bed4553aeaaa14008c94e8\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Ike\",\n",
      "              \"answer_start\": 321\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonce and Rowland found in 2005?\",\n",
      "          \"id\": \"56bfe7eaa10cfb1400551387\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"the Survivor Foundation\",\n",
      "              \"answer_start\": 61\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much did Beyonce initially contribute to the foundation?\",\n",
      "          \"id\": \"56bfe7eaa10cfb1400551389\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"$250,000\",\n",
      "              \"answer_start\": 190\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How has this foundation changed in recent years?\",\n",
      "          \"id\": \"56bfe7eaa10cfb140055138a\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"expanded to work with other charities\",\n",
      "              \"answer_start\": 225\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What foundation did Beyonc\\u00e9 start after Hurricane Katrina?\",\n",
      "          \"id\": \"56d4f7a22ccc5a1400d833ae\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Survivor Foundation\",\n",
      "              \"answer_start\": 65\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much money did Beyonc\\u00e9 contribute at the beginning of her Hurricane Katrina foundation?\",\n",
      "          \"id\": \"56d4f7a22ccc5a1400d833b0\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"$250,000.\",\n",
      "              \"answer_start\": 190\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What other hurricane did Beyonc\\u00e9's foundation help with?\",\n",
      "          \"id\": \"56d4f7a22ccc5a1400d833b1\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Hurricane Ike\",\n",
      "              \"answer_start\": 311\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"After Hurricane Katrina in 2005, Beyonc\\u00e9 and Rowland founded the Survivor Foundation to provide transitional housing for victims in the Houston area, to which Beyonc\\u00e9 contributed an initial $250,000. The foundation has since expanded to work with other charities in the city, and also provided relief following Hurricane Ike three years later.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Who did Beyonce participate with in the Hope for Haiti Now: A Global Benefit?\",\n",
      "          \"id\": \"56bed4c23aeaaa14008c94ed\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"George Clooney and Wyclef Jean\",\n",
      "              \"answer_start\": 24\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce opened a cosmetology center in what location?\",\n",
      "          \"id\": \"56bed4c23aeaaa14008c94ee\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Brooklyn Phoenix House\",\n",
      "              \"answer_start\": 356\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"After Osama Bin Laden's death, what single did Beyonce cover?\",\n",
      "          \"id\": \"56bed4c23aeaaa14008c94ef\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"God Bless the USA\",\n",
      "              \"answer_start\": 781\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"How much did the T-shirt with Beyonce's image on it make? \",\n",
      "          \"id\": \"56bfeb09a10cfb1400551391\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"$1 million\",\n",
      "              \"answer_start\": 253\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What enterprise did Beyonce and her mother start on March 5, 2010?\",\n",
      "          \"id\": \"56bfeb09a10cfb1400551392\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonc\\u00e9 Cosmetology Center at the Brooklyn Phoenix House\",\n",
      "              \"answer_start\": 322\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What charity benefited from  the release of the song, God Bless the USA?\",\n",
      "          \"id\": \"56bfeb09a10cfb1400551394\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"New York Police and Fire Widows' and Children's Benefit Fund\",\n",
      "              \"answer_start\": 849\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did she participate in with George Clooney?\",\n",
      "          \"id\": \"56bfeb09a10cfb1400551395\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Hope for Haiti Now: A Global Benefit\",\n",
      "              \"answer_start\": 57\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Which two stars did Beyonc\\u00e9 help with their Haiti Earthquake organization?\",\n",
      "          \"id\": \"56d4f9112ccc5a1400d833b6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"George Clooney and Wyclef Jean\",\n",
      "              \"answer_start\": 24\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What did Beyonc\\u00e9 open at the Brooklyn Phoenix House in 2010?\",\n",
      "          \"id\": \"56d4f9112ccc5a1400d833b7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Beyonc\\u00e9 Cosmetology Center\",\n",
      "              \"answer_start\": 322\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What Lee Greenwood song did Beyonc\\u00e9 cover after Osama bin Laden was killed?\",\n",
      "          \"id\": \"56d4f9112ccc5a1400d833ba\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"God Bless the USA\",\n",
      "              \"answer_start\": 781\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"Beyonc\\u00e9 participated in George Clooney and Wyclef Jean's Hope for Haiti Now: A Global Benefit for Earthquake Relief telethon and was named the official face of the limited edition CFDA \\\"Fashion For Haiti\\\" T-shirt, made by Theory which raised a total of $1 million. On March 5, 2010, Beyonc\\u00e9 and her mother Tina opened the Beyonc\\u00e9 Cosmetology Center at the Brooklyn Phoenix House, offering a seven-month cosmetology training course for men and women. In April 2011, Beyonc\\u00e9 joined forces with US First Lady Michelle Obama and the National Association of Broadcasters Education Foundation, to help boost the latter's campaign against child obesity by reworking her single \\\"Get Me Bodied\\\". Following the death of Osama bin Laden, Beyonc\\u00e9 released her cover of the Lee Greenwood song \\\"God Bless the USA\\\", as a charity single to help raise funds for the New York Police and Fire Widows' and Children's Benefit Fund.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"question\": \"Which national event caused Beyonce to produce \\\"Demand a Plan?\\\"\",\n",
      "          \"id\": \"56bed5983aeaaa14008c94f3\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sandy Hook Elementary School shooting\",\n",
      "              \"answer_start\": 280\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did Beyonce contribute to the campaign?\",\n",
      "          \"id\": \"56bed5983aeaaa14008c94f4\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"I Was Here\",\n",
      "              \"answer_start\": 412\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce is contributing to which food-donation campaign?\",\n",
      "          \"id\": \"56bed5983aeaaa14008c94f5\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Miss a Meal\",\n",
      "              \"answer_start\": 1553\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"On June 1 , 2013 where was the concert held for \\\"a Chime for Change\\\"?\",\n",
      "          \"id\": \"56bed5983aeaaa14008c94f6\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"London\",\n",
      "              \"answer_start\": 765\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Beyonce was speaking about whom when she said her gift was \\\"finding the best qualities in every human being.\\\"?\",\n",
      "          \"id\": \"56bed5983aeaaa14008c94f7\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"her mother\",\n",
      "              \"answer_start\": 1277\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"The Demand a Plan video campaign followed what tragic event?\",\n",
      "          \"id\": \"56bfed855a85de14001c7864\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sandy Hook Elementary School shooting.\",\n",
      "              \"answer_start\": 280\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What was the focus of the Gucci Chime for Change campaign?\",\n",
      "          \"id\": \"56bfed855a85de14001c7866\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"spread female empowerment\",\n",
      "              \"answer_start\": 616\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What crowdfunding platform was used in the concert?\",\n",
      "          \"id\": \"56bfed855a85de14001c7868\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Catapult\",\n",
      "              \"answer_start\": 1409\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What is the name of the campaign that Beyonc\\u00e9 and others are involved in that deals with gun control?\",\n",
      "          \"id\": \"56d4fa2e2ccc5a1400d833ca\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Demand A Plan\",\n",
      "              \"answer_start\": 108\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What school shooting prompted the creation of Demand A Plan?\",\n",
      "          \"id\": \"56d4fa2e2ccc5a1400d833cb\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Sandy Hook Elementary School\",\n",
      "              \"answer_start\": 280\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"What song did Beyonc\\u00e9 donate to the 2012 World Humanitarian Day campaign?\",\n",
      "          \"id\": \"56d4fa2e2ccc5a1400d833cc\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"I Was Here\",\n",
      "              \"answer_start\": 412\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        },\n",
      "        {\n",
      "          \"question\": \"Who did Beyonc\\u00e9 work with in 2013 on the Chime for Change campaign?\",\n",
      "          \"id\": \"56d4fa2e2ccc5a1400d833cd\",\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"Salma Hayek and Frida Giannini\",\n",
      "              \"answer_start\": 533\n",
      "            }\n",
      "          ],\n",
      "          \"is_impossible\": false\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"In December, Beyonc\\u00e9 along with a variety of other celebrities teamed up and produced a video campaign for \\\"Demand A Plan\\\", a bipartisan effort by a group of 950 US mayors and others designed to influence the federal government into rethinking its gun control laws, following the Sandy Hook Elementary School shooting. Beyonc\\u00e9 became an ambassador for the 2012 World Humanitarian Day campaign donating her song \\\"I Was Here\\\" and its music video, shot in the UN, to the campaign. In 2013, it was announced that Beyonc\\u00e9 would work with Salma Hayek and Frida Giannini on a Gucci \\\"Chime for Change\\\" campaign that aims to spread female empowerment. The campaign, which aired on February 28, was set to her new music. A concert for the cause took place on June 1, 2013 in London and included other acts like Ellie Goulding, Florence and the Machine, and Rita Ora. In advance of the concert, she appeared in a campaign video released on 15 May 2013, where she, along with Cameron Diaz, John Legend and Kylie Minogue, described inspiration from their mothers, while a number of other artists celebrated personal inspiration from other women, leading to a call for submission of photos of women of viewers' inspiration from which a selection was shown at the concert. Beyonc\\u00e9 said about her mother Tina Knowles that her gift was \\\"finding the best qualities in every human being.\\\" With help of the crowdfunding platform Catapult, visitors of the concert could choose between several projects promoting education of women and girls. Beyonc\\u00e9 is also taking part in \\\"Miss a Meal\\\", a food-donation campaign, and supporting Goodwill charity through online charity auctions at Charitybuzz that support job creation throughout Europe and the U.S.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Loading the training data\n",
    "import json \n",
    "\n",
    "with open('data/m2_train.json', 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "print(squad_data['data'][0]['paragraphs'][0].keys())\n",
    "\n",
    "print(json.dumps(squad_data['data'][0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of answerable questions:  86821\n",
      "Number of unanswerable questions:  43498\n",
      "Number of QA pairs:  130319\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of answerable and unanswerable questions\n",
    "num_answerable = 0\n",
    "num_unanswerable = 0\n",
    "\n",
    "for article in squad_data[\"data\"]:\n",
    "    for paragraph in article[\"paragraphs\"]:\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            if qa[\"is_impossible\"]:\n",
    "                num_unanswerable += 1\n",
    "            else:\n",
    "                num_answerable += 1\n",
    "\n",
    "print(\"Number of answerable questions: \", num_answerable)\n",
    "print(\"Number of unanswerable questions: \", num_unanswerable)\n",
    "print(\"Number of QA pairs: \", num_answerable + num_unanswerable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answerable vs. Unanswerable Questions in SQuAD 2.0\n",
    "\n",
    "- **Answerable Questions:** The correct answer exists within the given passage, and the model must extract the exact span.\n",
    "- **Unanswerable Questions:** The passage does not contain the answer, and the model should predict \"No Answer.\"\n",
    "\n",
    "SQuAD 2.0 introduces unanswerable questions to make the task more challenging, requiring models to distinguish between when an answer is present and when it is not.\n",
    "\n",
    "In this notebook, we will use answerable questions only in the subset we will be training our neural networks on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:    This is a \n",
      "\n",
      "\t sample    text.    \n",
      "Cleaned text:    this is a \n",
      "\n",
      "\t sample    text.    \n"
     ]
    }
   ],
   "source": [
    "# Clean text function\n",
    "import re\n",
    "\n",
    "def clean_text(text: str, is_question: bool=False):\n",
    "    \"\"\"\n",
    "    Cleans text by removing extra spaces, newline characters, and special symbols.\n",
    "    \"\"\"\n",
    "    if is_question:\n",
    "        text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")  # Remove newlines & tabs\n",
    "        text = re.sub(r\"\\s+\", \" \", text)  # Remove extra spaces\n",
    "        text = text.strip()  # Trim leading/trailing spaces\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Testing the clean_text function on a sample text\n",
    "sample_text = \"   This is a \\n\\n\\t sample    text.    \"\n",
    "print(\"Original text:\", sample_text)\n",
    "print(\"Cleaned text:\", clean_text(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QA pairs in train data: 86821\n",
      "Training sample: dict_keys(['context', 'question', 'answer', 'answer_start', 'answer_end'])\n",
      "\n",
      "\n",
      "Number of QA pairs in test data: 2000\n",
      "Dev sample: dict_keys(['context', 'question', 'answer', 'answer_start', 'answer_end'])\n"
     ]
    }
   ],
   "source": [
    "# Load and process the SQuAD dataset using the clean_text function\n",
    "import json\n",
    "\n",
    "def load_and_process_squad(filepath, max_samples=20000):\n",
    "    \"\"\"\n",
    "    Loads, cleans, and extracts answerable questions from the SQuAD dataset.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the SQuAD JSON file.\n",
    "        max_samples (int): Maximum number of answerable questions to load.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of cleaned question-answer pairs.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as f:\n",
    "        squad_data = json.load(f)\n",
    "\n",
    "    data = []\n",
    "    for article in squad_data[\"data\"]:\n",
    "        for paragraph in article[\"paragraphs\"]:\n",
    "            context = clean_text(paragraph[\"context\"]) \n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                if qa[\"is_impossible\"]:  \n",
    "                    continue\n",
    "                \n",
    "                question = clean_text(qa[\"question\"], is_question=True) \n",
    "                answer_text = clean_text(qa[\"answers\"][0][\"text\"])  \n",
    "                answer_start = qa[\"answers\"][0][\"answer_start\"]\n",
    "                \n",
    "                data.append({\n",
    "                    \"context\": context, \n",
    "                    \"question\": question, \n",
    "                    \"answer\": answer_text, \n",
    "                    \"answer_start\": answer_start, \n",
    "                    \"answer_end\": answer_start + len(answer_text)})\n",
    "\n",
    "\n",
    "    data.sort(key=lambda x: (len(x[\"context\"]), len(x[\"question\"])))\n",
    "    # Limit the number of samples if specified\n",
    "    if max_samples > 0:\n",
    "        data = data[:max_samples]\n",
    "    return data\n",
    "\n",
    "# Load and process the SQuAD dataset\n",
    "train_dataset = load_and_process_squad(\"data/m2_train.json\", max_samples=-1)\n",
    "dev_samples = load_and_process_squad(\"data/m2_dev.json\", max_samples=2000)\n",
    "\n",
    "print(\"Number of QA pairs in train data:\", len(train_dataset))\n",
    "print(\"Training sample:\", train_dataset[0].keys())\n",
    "print(\"\\n\")\n",
    "print(\"Number of QA pairs in test data:\", len(dev_samples))\n",
    "print(\"Dev sample:\", dev_samples[0].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the training set: 82597\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "\n",
    "for sample in train_dataset:\n",
    "    context = sample[\"context\"]\n",
    "    question = sample[\"question\"]\n",
    "    answer = sample[\"answer\"]\n",
    "\n",
    "    unique_words.update(set(re.findall(r\"\\w+\", context)))\n",
    "    unique_words.update(set(re.findall(r\"\\w+\", question)))\n",
    "    unique_words.update(set(re.findall(r\"\\w+\", answer)))\n",
    "\n",
    "                \n",
    "# Print the number of unique words\n",
    "print(\"Number of unique words in the training set:\", len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = []\n",
    "for sample in train_dataset:\n",
    "    combined_text.append(sample[\"context\"])\n",
    "    combined_text.append(sample[\"question\"])\n",
    "    combined_text.append(sample[\"answer\"])\n",
    "\n",
    "# Join all text samples into one corpus (you can also use '\\n'.join for a more distinct separation)\n",
    "combined_text = \"\\n\".join(combined_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from ./tokenizers/tokenizer.json...\n",
      "Tokenizer already exists at ./tokenizers/tokenizer.json. Skipping training.\n"
     ]
    }
   ],
   "source": [
    "# Training the tokenizer\n",
    "from scripts_m2 import *\n",
    "\n",
    "# Creating / Loading the tokenizer\n",
    "tokenizer = BPETokenizer()\n",
    "\n",
    "# Training the tokenizer if not already trained\n",
    "tokenizer.train(combined_text=combined_text.split(\"/n\"), vocab_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Question: [3, 2441, 1997, 1966, 4721, 2776, 1974, 3539, 1978, 7873, 3120, 1390, 4]\n",
      "Length of Tokenized Question: 13\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Decoded Question: where is the oklahoma school of science and mathematics located ?\n"
     ]
    }
   ],
   "source": [
    "# Encoding a Question\n",
    "example_question = train_dataset[4][\"question\"]\n",
    "tokenized_output, attention_mask = tokenizer.encode(example_question)\n",
    "print(\"Tokenized Question:\", tokenized_output)\n",
    "print(\"Length of Tokenized Question:\", len(tokenized_output))\n",
    "print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "# Decoding the tokenized output\n",
    "decoded_output = tokenizer.decode(tokenized_output)\n",
    "print(\"Decoded Question:\", decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the max tokenizer length\n",
    "tokenizer.set_max_length(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Answer: [3, 4721, 2251, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Length of Tokenized Answer: 25\n",
      "Attention Mask: [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded Answer: oklahoma city\n"
     ]
    }
   ],
   "source": [
    "# Encoding an answer\n",
    "example_answer = train_dataset[4][\"answer\"]\n",
    "tokenized_answer, attention_mask = tokenizer.encode(example_answer)\n",
    "print(\"Tokenized Answer:\", tokenized_answer)\n",
    "print(\"Length of Tokenized Answer:\", len(tokenized_answer))\n",
    "print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "# Decoding the tokenized answer\n",
    "decoded_answer = tokenizer.decode(tokenized_answer)\n",
    "print(\"Decoded Answer:\", decoded_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dataset & Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 20000\n",
      "Number of dev samples: 2000\n"
     ]
    }
   ],
   "source": [
    "# Getting the dataset\n",
    "train_dataset = load_and_process_squad(\"data/m2_train.json\", max_samples=20000)\n",
    "dev_dataset = load_and_process_squad(\"data/m2_dev.json\", max_samples=2000)\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of dev samples:\", len(dev_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from ./tokenizers/tokenizer.json...\n",
      "Tokenizer already exists at ./tokenizers/tokenizer.json. Skipping training.\n"
     ]
    }
   ],
   "source": [
    "# Create the tokenizer\n",
    "tokenizer = BPETokenizer()\n",
    "# Train the tokenizer\n",
    "tokenizer.train(combined_text=combined_text.split(\"\\n\"), vocab_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['context', 'question', 'answer', 'answer_start', 'answer_end'])\n",
      "Training data sample:\n",
      "it is not only the proportion of latewood, but also its quality, that counts. in specimens that show a very large proportion of latewood it may be noticeably more porous and weigh considerably less than the latewood in pieces that contain but little. one can judge comparative density, and therefore to some extent strength, by visual inspection.\n",
      "what can we judge in wood just by looking at it?\n",
      "comparative density\n",
      "Answer start: 265\n",
      "Answer end: 284\n",
      "Length of the training examples: 20000\n"
     ]
    }
   ],
   "source": [
    "# View the training data\n",
    "random_idx = np.random.randint(0, len(train_dataset))\n",
    "\n",
    "# Print the random sample\n",
    "print(train_dataset[random_idx].keys())\n",
    "print(\"Training data sample:\")\n",
    "print(train_dataset[random_idx][\"context\"])\n",
    "print(train_dataset[random_idx][\"question\"])\n",
    "print(train_dataset[random_idx][\"answer\"])\n",
    "print(\"Answer start:\", train_dataset[random_idx][\"answer_start\"])\n",
    "print(\"Answer end:\", train_dataset[random_idx][\"answer_end\"])\n",
    "print(\"Length of the training examples:\", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'where is the oklahoma school of science and mathematics located ?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = tokenizer.encode(train_dataset[4][\"question\"])[0]\n",
    "tokenizer.decode(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max context length: 205\n",
      "Max question length: 64\n",
      "Max answer length: 75\n"
     ]
    }
   ],
   "source": [
    "# Viewing the length of the longest question, context, and answer\n",
    "max_context_length = max(len(tokenizer.encode(sample[\"context\"])[0]) for sample in train_dataset)\n",
    "max_question_length = max(len(tokenizer.encode(sample[\"question\"])[0]) for sample in train_dataset)\n",
    "max_answer_length = max(len(tokenizer.encode(sample[\"answer\"])[0]) for sample in train_dataset)\n",
    "\n",
    "print(\"Max context length:\", max_context_length)\n",
    "print(\"Max question length:\", max_question_length)\n",
    "print(\"Max answer length:\", max_answer_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Context Lengths:\n",
      "Number of questions: 20000\n",
      "Number of outliers: 18\n",
      "Minimum: 29\n",
      "Q1 (25%): 83.0\n",
      "Median: 110.0\n",
      "Q3 (75%): 124.0\n",
      "Maximum: 205\n",
      "Interquartile Range (IQR): 41.0\n",
      "95th Percentile: 143.0\n",
      "97th Percentile: 149.0\n",
      "99th Percentile: 160.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the distribution of tokenized question lengths\n",
    "context_lengths = [len(tokenizer.encode(sample[\"context\"])[0]) for sample in train_dataset]\n",
    "plt.figure(figsize=(10, 6))\n",
    "boxplot = plt.boxplot(context_lengths, vert=True, patch_artist=True)\n",
    "plt.title(\"Distribution of Tokenized Context Lengths\")\n",
    "plt.ylabel(\"Tokenized Context Length\")\n",
    "\n",
    "# Calculate and display quartiles\n",
    "quartiles = np.percentile(context_lengths, [25, 50, 75, 95, 97, 99])\n",
    "min_val = np.min(context_lengths)\n",
    "max_val = np.max(context_lengths)\n",
    "\n",
    "plt.text(1.15, quartiles[0], f'Q1: {quartiles[0]:.1f}', \n",
    "         verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, quartiles[1], f'Q2 (Median): {quartiles[1]:.1f}', \n",
    "         verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, quartiles[2], f'Q3: {quartiles[2]:.1f}', \n",
    "         verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, min_val, f'Min: {min_val}', \n",
    "         verticalalignment='bottom', fontweight='bold')\n",
    "plt.text(1.15, max_val, f'Max: {max_val}', \n",
    "         verticalalignment='top', fontweight='bold')\n",
    "\n",
    "print(f\"Summary Statistics for Context Lengths:\")\n",
    "print(\"Number of questions:\", len(context_lengths))\n",
    "print(\"Number of outliers:\", len([x for x in context_lengths if x > quartiles[2] + 1.5 * (quartiles[2] - quartiles[0])]) + len([x for x in context_lengths if x < quartiles[0] - 1.5 * (quartiles[2] - quartiles[0])]))\n",
    "print(f\"Minimum: {min_val}\")\n",
    "print(f\"Q1 (25%): {quartiles[0]:.1f}\")\n",
    "print(f\"Median: {quartiles[1]:.1f}\")\n",
    "print(f\"Q3 (75%): {quartiles[2]:.1f}\")\n",
    "print(f\"Maximum: {max_val}\")\n",
    "print(f\"Interquartile Range (IQR): {quartiles[2] - quartiles[0]:.1f}\")\n",
    "print(\"95th Percentile:\", quartiles[3])\n",
    "print(\"97th Percentile:\", quartiles[4])\n",
    "print(\"99th Percentile:\", quartiles[5])\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Question Lengths:\n",
      "Number of questions: 20000\n",
      "Number of outliers: 407\n",
      "Minimum: 6\n",
      "Q1 (25%): 12.0\n",
      "Median: 15.0\n",
      "Q3 (75%): 18.0\n",
      "Maximum: 64\n",
      "Interquartile Range (IQR): 6.0\n",
      "95th Percentile: 24.0\n",
      "97th Percentile: 26.0\n",
      "99th Percentile: 30.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the distribution of tokenized question lengths\n",
    "question_lengths = [len(tokenizer.encode(sample[\"question\"])[0]) for sample in train_dataset]\n",
    "plt.figure(figsize=(10, 6))\n",
    "boxplot = plt.boxplot(question_lengths, vert=True, patch_artist=True)\n",
    "plt.title(\"Distribution of Tokenized Question Lengths\")\n",
    "plt.ylabel(\"Tokenized Question Length\")\n",
    "\n",
    "# Calculate and display quartiles\n",
    "quartiles = np.percentile(question_lengths, [25, 50, 75, 95, 97, 99])\n",
    "min_val = np.min(question_lengths)\n",
    "max_val = np.max(question_lengths)\n",
    "\n",
    "plt.text(1.15, quartiles[0], f'Q1: {quartiles[0]:.1f}', \n",
    "         verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, quartiles[1], f'Q2 (Median): {quartiles[1]:.1f}', \n",
    "         verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, quartiles[2], f'Q3: {quartiles[2]:.1f}', \n",
    "         verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, min_val, f'Min: {min_val}', \n",
    "         verticalalignment='bottom', fontweight='bold')\n",
    "plt.text(1.15, max_val, f'Max: {max_val}', \n",
    "         verticalalignment='top', fontweight='bold')\n",
    "\n",
    "print(f\"Summary Statistics for Question Lengths:\")\n",
    "print(\"Number of questions:\", len(question_lengths))\n",
    "print(\"Number of outliers:\", len([x for x in question_lengths if x > quartiles[2] + 1.5 * (quartiles[2] - quartiles[0])]) + len([x for x in question_lengths if x < quartiles[0] - 1.5 * (quartiles[2] - quartiles[0])]))\n",
    "print(f\"Minimum: {min_val}\")\n",
    "print(f\"Q1 (25%): {quartiles[0]:.1f}\")\n",
    "print(f\"Median: {quartiles[1]:.1f}\")\n",
    "print(f\"Q3 (75%): {quartiles[2]:.1f}\")\n",
    "print(f\"Maximum: {max_val}\")\n",
    "print(f\"Interquartile Range (IQR): {quartiles[2] - quartiles[0]:.1f}\")\n",
    "print(\"95th Percentile:\", quartiles[3])\n",
    "print(\"97th Percentile:\", quartiles[4])\n",
    "print(\"99th Percentile:\", quartiles[5])\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Answer Lengths:\n",
      "Number of answers:  20000\n",
      "Number of outliers:  1705\n",
      "Minimum: 3\n",
      "Q1 (25%): 4.0\n",
      "Median: 5.0\n",
      "Q3 (75%): 7.0\n",
      "Maximum: 75\n",
      "Interquartile Range (IQR): 3.0\n",
      "95th Percentile: 14.0\n",
      "97th Percentile: 18.0\n",
      "99th Percentile: 25.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the distribution of tokenized answer lengths\n",
    "answer_lengths = [len(tokenizer.encode(sample[\"answer\"])[0]) for sample in train_dataset]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "boxplot = plt.boxplot(answer_lengths, vert=True, patch_artist=True)\n",
    "plt.title(\"Distribution of Tokenized Answer Lengths\")\n",
    "plt.ylabel(\"Tokenized Answer Length\")\n",
    "# Calculate and display quartiles\n",
    "quartiles = np.percentile(answer_lengths, [25, 50, 75, 95, 97, 99])\n",
    "min_val = np.min(answer_lengths)\n",
    "max_val = np.max(answer_lengths)\n",
    "\n",
    "print(f\"Summary Statistics for Answer Lengths:\")\n",
    "print(\"Number of answers: \", len(answer_lengths))\n",
    "print(\"Number of outliers: \", len([x for x in answer_lengths if x > quartiles[2] + 1.5 * (quartiles[2] - quartiles[0])]) + len([x for x in answer_lengths if x < quartiles[0] - 1.5 * (quartiles[2] - quartiles[0])]))\n",
    "print(f\"Minimum: {min_val}\")\n",
    "print(f\"Q1 (25%): {quartiles[0]:.1f}\")\n",
    "print(f\"Median: {quartiles[1]:.1f}\")\n",
    "print(f\"Q3 (75%): {quartiles[2]:.1f}\")\n",
    "print(f\"Maximum: {max_val}\")\n",
    "print(f\"Interquartile Range (IQR): {quartiles[2] - quartiles[0]:.1f}\")\n",
    "print(\"95th Percentile:\", quartiles[3])\n",
    "print(\"97th Percentile:\", quartiles[4])\n",
    "print(\"99th Percentile:\", quartiles[5])\n",
    "\n",
    "plt.text(1.15, quartiles[0], f'Q1: {quartiles[0]:.1f}',\n",
    "            verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, quartiles[1], f'Q2 (Median): {quartiles[1]:.1f}',\n",
    "            verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, quartiles[2], f'Q3: {quartiles[2]:.1f}',\n",
    "            verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, min_val, f'Min: {min_val}',\n",
    "            verticalalignment='bottom', fontweight='bold')\n",
    "plt.text(1.15, max_val, f'Max: {max_val}',\n",
    "            verticalalignment='top', fontweight='bold')\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for context + question Lengths:\n",
      "Number of context + question:  20000\n",
      "Number of outliers:  10\n",
      "Minimum: 39\n",
      "Q1 (25%): 97.0\n",
      "Median: 124.0\n",
      "Q3 (75%): 139.0\n",
      "Maximum: 224\n",
      "Interquartile Range (IQR): 42.0\n",
      "95th Percentile: 159.0\n",
      "97th Percentile: 164.0\n",
      "99th Percentile: 175.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the distribution of tokenized answer lengths\n",
    "context_question_lengths = [len(tokenizer.encode_two_texts(sample[\"context\"], sample[\"question\"])[0]) for sample in train_dataset]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "boxplot = plt.boxplot(context_question_lengths, vert=True, patch_artist=True)\n",
    "plt.title(\"Distribution of Tokenized Context + Question Lengths\")\n",
    "plt.ylabel(\"Tokenized Context + Question Length\")\n",
    "# Calculate and display quartiles\n",
    "quartiles = np.percentile(context_question_lengths, [25, 50, 75, 95, 97, 99])\n",
    "min_val = np.min(context_question_lengths)\n",
    "max_val = np.max(context_question_lengths)\n",
    "\n",
    "print(f\"Summary Statistics for context + question Lengths:\")\n",
    "print(\"Number of context + question: \", len(context_question_lengths))\n",
    "print(\"Number of outliers: \", len([x for x in context_question_lengths if x > quartiles[2] + 1.5 * (quartiles[2] - quartiles[0])]) + len([x for x in context_question_lengths if x < quartiles[0] - 1.5 * (quartiles[2] - quartiles[0])]))\n",
    "print(f\"Minimum: {min_val}\")\n",
    "print(f\"Q1 (25%): {quartiles[0]:.1f}\")\n",
    "print(f\"Median: {quartiles[1]:.1f}\")\n",
    "print(f\"Q3 (75%): {quartiles[2]:.1f}\")\n",
    "print(f\"Maximum: {max_val}\")\n",
    "print(f\"Interquartile Range (IQR): {quartiles[2] - quartiles[0]:.1f}\")\n",
    "print(\"95th Percentile:\", quartiles[3])\n",
    "print(\"97th Percentile:\", quartiles[4])\n",
    "print(\"99th Percentile:\", quartiles[5])\n",
    "\n",
    "plt.text(1.15, quartiles[0], f'Q1: {quartiles[0]:.1f}',\n",
    "            verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, quartiles[1], f'Q2 (Median): {quartiles[1]:.1f}',\n",
    "            verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, quartiles[2], f'Q3: {quartiles[2]:.1f}',\n",
    "            verticalalignment='center', fontweight='bold')\n",
    "plt.text(1.15, min_val, f'Min: {min_val}',\n",
    "            verticalalignment='bottom', fontweight='bold')\n",
    "plt.text(1.15, max_val, f'Max: {max_val}',\n",
    "            verticalalignment='top', fontweight='bold')\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the transformer based models we can use the max length of the question and answer as follows:\n",
    "1. `Answers Max Length`: 25 tokens\n",
    "2. `Question Max Length`: 30 tokens\n",
    "3. `Context Max Length`: 160 tokens\n",
    "4. `Context + Question Length`: 160+30+1 (+1 for [SEP]) We could have used 175 as it is the 99th percentile but we will use 191 instead\n",
    "\n",
    "\n",
    "This would give us a good tradeoff between the length of the sequence without using a lot of padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from ./tokenizers/tokenizer.json...\n",
      "Filtered dataset size: 19993 out of original 20000\n",
      "Filtered dataset size: 1996 out of original 2000\n",
      "Number of training samples: 19993\n",
      "Number of dev samples: 1996\n",
      "Sample from the dataset:\n",
      "Question encoded: tensor([   3, 2087, 1997, 1966, 2996, 4428, 2273, 1989, 6508, 1966, 3985, 2065,\n",
      "        1979, 1966, 3263, 2405, 1974, 2996, 3299, 1390,    4,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1])\n",
      "Question decoded:  what is the main material used to build the cellar in the basement of main building ?\n",
      "Answer encoded: tensor([   3, 2247, 4043,    4,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1])\n",
      "Answer decoded:  brick\n",
      "Context encoded: tensor([   3, 4831, 2079, 2835, 1359, 1266, 8295, 3985, 2065, 1996, 1966, 4440,\n",
      "        1974, 5397, 4517, 1283, 3253, 1979, 3241, 3355, 1381, 3241, 3410, 2038,\n",
      "        7705, 6287, 6187, 1283, 1997, 1979, 1966, 3263, 2405, 1974, 2996, 3299,\n",
      "        1283, 1978, 1997, 2273, 2038, 6033, 1321, 1966, 4925, 6663, 2040, 2091,\n",
      "        2247, 4043, 4050, 1974, 1966, 3985, 2065, 2022, 2532, 2367, 1979, 8079,\n",
      "        1978, 2021, 7951, 1978, 1975, 3120, 5158, 6342, 1989, 1966, 2582, 1978,\n",
      "        4421, 3845, 6342, 1528, 1294, 1321, 1296, 1288, 1300, 2028,   47, 2564,\n",
      "        1979, 7392, 1283, 2276, 4027, 2022, 1975, 2716, 1971, 1996, 1966, 3931,\n",
      "        2301, 2360, 2403, 2835, 1321, 2156, 2022, 5689, 2191, 3314, 2729, 3534,\n",
      "        6056, 1989, 1966, 4050, 1321,    4,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1])\n",
      "Context decoded:  henry viii ' s wine cellar at the palace of whitehall , built in 1514  1516 for cardinal wolsey , is in the basement of main building , and is used for entertainment . the entire vaulted brick structure of the cellar was encased in steel and concrete and relocated nine feet to the west and nearly 19 feet ( 5 . 8 m ) deeper in 1949 , when construction was resumed at the site after world war ii . this was carried out without any significant damage to the structure .\n",
      "\n",
      "\n",
      "\n",
      "Sample from the dev dataset:\n",
      "Context encoded: tensor([   3, 2745, 2068, 2572, 1986, 1978,   45,   56, 2131, 1973, 3303, 1283,\n",
      "          45, 2257, 2043, 2624, 2326, 2166, 2334, 2996, 9572, 1974, 5405, 2050,\n",
      "        7560,   65, 2093, 1267, 3272, 8306, 1974,   52, 2000, 2015, 1330, 2745,\n",
      "        4428, 1283, 2097, 1997, 2566, 1966, 6096, 2179, 2045, 1267, 1979,   45,\n",
      "          56, 2131, 1973, 3303, 1978,   45, 2257, 2043, 2624, 2326, 1407, 2283,\n",
      "        4604, 4530, 2166, 2604, 2996, 5724, 9572, 1978, 2579, 9661, 2078,   52,\n",
      "        2000, 2015, 1330, 2745, 8306, 1321, 8262,   45, 2257, 2043, 2624, 2326,\n",
      "        1978,   45,   56, 2131, 1973, 3303, 2166, 5964, 2290, 3199, 5464, 2012,\n",
      "        2897, 2196, 5517, 1283, 3000, 2051, 2068, 2572, 1986, 1321, 2560,   45,\n",
      "        2257, 2043, 2624, 2326, 1978,   45,   56, 2131, 1973, 3303, 2166, 1267,\n",
      "        3203, 1974, 2485, 4901, 2050, 1283, 1979, 2283, 4604, 4530, 1283, 1973,\n",
      "        7238, 2075, 1966, 3272, 5724, 8306, 1283, 1978, 1990, 1267, 3459, 2314,\n",
      "        4316, 5111, 5141, 4379, 4695,   45, 2257, 2043, 2624, 2326, 1990, 2295,\n",
      "        2897, 2196, 5517,    4])\n",
      "Context decoded:  like sponges and cnidarians , ctenophores have two main layers of cells that sandwich a middle layer of jelly - like material , which is called the mesoglea in cnidarians and ctenophores ; more complex animals have three main cell layers and no intermediate jelly - like layer . hence ctenophores and cnidarians have traditionally been labelled diploblastic , along with sponges . both ctenophores and cnidarians have a type of muscle that , in more complex animals , arises from the middle cell layer , and as a result some recent text books classify ctenophores as triploblastic\n",
      "Question encoded: tensor([   3, 2097, 2807, 2170, 2334, 9572, 1974, 5405, 2051, 1267, 3272, 8306,\n",
      "        1974, 6096, 2179, 2045, 1267, 1390,    4,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1])\n",
      "Question decoded:  which group has two layers of cells with a middle layer of mesoglea ?\n",
      "Answer encoded: tensor([   3, 2068, 2572, 1986, 1978,   45,   56, 2131, 1973, 3303, 1283,   45,\n",
      "        2257, 2043, 2624, 2326,    4,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1])\n",
      "Answer decoded:  sponges and cnidarians , ctenophores\n",
      "Context Question encoded: tensor([   3, 2745, 2068, 2572, 1986, 1978,   45,   56, 2131, 1973, 3303, 1283,\n",
      "          45, 2257, 2043, 2624, 2326, 2166, 2334, 2996, 9572, 1974, 5405, 2050,\n",
      "        7560,   65, 2093, 1267, 3272, 8306, 1974,   52, 2000, 2015, 1330, 2745,\n",
      "        4428, 1283, 2097, 1997, 2566, 1966, 6096, 2179, 2045, 1267, 1979,   45,\n",
      "          56, 2131, 1973, 3303, 1978,   45, 2257, 2043, 2624, 2326, 1407, 2283,\n",
      "        4604, 4530, 2166, 2604, 2996, 5724, 9572, 1978, 2579, 9661, 2078,   52,\n",
      "        2000, 2015, 1330, 2745, 8306, 1321, 8262,   45, 2257, 2043, 2624, 2326,\n",
      "        1978,   45,   56, 2131, 1973, 3303, 2166, 5964, 2290, 3199, 5464, 2012,\n",
      "        2897, 2196, 5517, 1283, 3000, 2051, 2068, 2572, 1986, 1321, 2560,   45,\n",
      "        2257, 2043, 2624, 2326, 1978,   45,   56, 2131, 1973, 3303, 2166, 1267,\n",
      "        3203, 1974, 2485, 4901, 2050, 1283, 1979, 2283, 4604, 4530, 1283, 1973,\n",
      "        7238, 2075, 1966, 3272, 5724, 8306, 1283, 1978, 1990, 1267, 3459, 2314,\n",
      "        4316, 5111, 5141, 4379, 4695,   45, 2257, 2043, 2624, 2326, 1990, 2295,\n",
      "        2897, 2196, 5517, 1283, 2459, 3403, 3066, 8756, 2694, 1990, 2012, 2897,\n",
      "        2196, 5517, 1321,    5, 2097, 2807, 2170, 2334, 9572, 1974, 5405, 2051,\n",
      "        1267, 3272, 8306, 1974, 6096, 2179, 2045, 1267, 1390,    4,    1])\n",
      "Context Question decoded:  like sponges and cnidarians , ctenophores have two main layers of cells that sandwich a middle layer of jelly - like material , which is called the mesoglea in cnidarians and ctenophores ; more complex animals have three main cell layers and no intermediate jelly - like layer . hence ctenophores and cnidarians have traditionally been labelled diploblastic , along with sponges . both ctenophores and cnidarians have a type of muscle that , in more complex animals , arises from the middle cell layer , and as a result some recent text books classify ctenophores as triploblastic , while others still regard them as diploblastic . which group has two layers of cells with a middle layer of mesoglea ?\n",
      "Answer Start: tensor(2)\n",
      "Answer End: tensor(16)\n",
      "Answer Start: End decoded: sponges and cnidarians , ctenophores\n"
     ]
    }
   ],
   "source": [
    "# Creating dataset\n",
    "tokenizer = BPETokenizer()\n",
    "train_data = load_and_process_squad(\"data/m2_train.json\", max_samples=20000)\n",
    "dev_data = load_and_process_squad(\"data/m2_dev.json\", max_samples=2000)\n",
    "\n",
    "context_max_length = 160\n",
    "question_max_length = 30\n",
    "answer_max_length = 25\n",
    "train_dataset = QADataset(train_data, tokenizer, context_max_length=context_max_length, question_max_length=question_max_length, answer_max_length=answer_max_length, include_context=True)\n",
    "dev_dataset = QADataset(dev_data, tokenizer, context_max_length=context_max_length, question_max_length=question_max_length, answer_max_length=answer_max_length, include_context=True)\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of dev samples:\", len(dev_dataset))\n",
    "\n",
    "# View a sample from the dataset\n",
    "random_idx = np.random.randint(0, len(train_dataset))\n",
    "print(\"Sample from the dataset:\")\n",
    "print(\"Question encoded:\", train_dataset[random_idx][\"question\"])\n",
    "print(\"Question decoded: \", tokenizer.decode(train_dataset[random_idx][\"question\"].tolist()))\n",
    "print(\"Answer encoded:\", train_dataset[random_idx][\"answer\"])\n",
    "print(\"Answer decoded: \", tokenizer.decode(train_dataset[random_idx][\"answer\"].tolist()))\n",
    "print(\"Context encoded:\", train_dataset[random_idx][\"context\"])\n",
    "print(\"Context decoded: \", tokenizer.decode(train_dataset[random_idx][\"context\"].tolist()))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# View a sample from the dev dataset\n",
    "random_idx = np.random.randint(0, len(dev_dataset))\n",
    "print(\"Sample from the dev dataset:\")\n",
    "print(\"Context encoded:\", dev_dataset[random_idx][\"context\"])\n",
    "print(\"Context decoded: \", tokenizer.decode(dev_dataset[random_idx][\"context\"].tolist()))\n",
    "print(\"Question encoded:\", dev_dataset[random_idx][\"question\"])\n",
    "print(\"Question decoded: \", tokenizer.decode(dev_dataset[random_idx][\"question\"].tolist()))\n",
    "print(\"Answer encoded:\", dev_dataset[random_idx][\"answer\"])\n",
    "print(\"Answer decoded: \", tokenizer.decode(dev_dataset[random_idx][\"answer\"].tolist()))\n",
    "print(\"Context Question encoded:\", dev_dataset[random_idx][\"context_question\"])\n",
    "print(\"Context Question decoded: \", tokenizer.decode(dev_dataset[random_idx][\"context_question\"].tolist()))\n",
    "print(\"Answer Start:\", dev_dataset[random_idx][\"answer_start\"])\n",
    "print(\"Answer End:\", dev_dataset[random_idx][\"answer_end\"])\n",
    "print(\"Answer Start: End decoded:\", tokenizer.decode(dev_dataset[random_idx][\"context\"][dev_dataset[random_idx][\"answer_start\"]:dev_dataset[random_idx][\"answer_end\"]+1].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 90,  12,  16,  61,  22,  23,  19,  27,  10,  17, 100,  32, 103,  57,\n",
      "         46,   0,  11,  23,  15,  58,   8,  50,  24,  52,  29,  37,  55,   0,\n",
      "         47,  46,  29,  21]) tensor([ 91,  18,  20,  61,  25,  29,  25,  31,  13,  22, 107,  33, 112,  58,\n",
      "         60,   4,  11,  23,  16,  70,  12,  51,  38,  52,  32,  39,  58,  17,\n",
      "         47,  49,  31,  24])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,   2,  11,  35,   9,  16,  35,  74,  46,  51,  68,  55,  83,  17,\n",
      "         17,   2,  23, 112,  59,  25,  74,  40,  59,  60,  69, 100,  63,  48,\n",
      "          7,  14,  77,  70]) tensor([  7,   5,  22,  38,  13,  21,  38,  75,  50,  52,  78,  56,  84,  22,\n",
      "         18,   5,  25, 113,  68,  27,  82,  41,  60,  64,  82, 101,  65,  61,\n",
      "         13,  19,  79,  81])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 25,  96,   3,  52,   2,  34,  83,   9,  24,  16, 103,  12,  64,  56,\n",
      "          9,  63,  47,  24,   3,  15,  40,   3,  67,  23,   8,  48,  13, 103,\n",
      "         58,  92,  90,  56]) tensor([ 27, 100,   3,  58,   5,  34,  84,  12,  25,  18, 105,  15,  72,  61,\n",
      "         12,  63,  48,  25,   5,  15,  41,   6,  76,  30,   9,  48,  15, 110,\n",
      "         59,  92,  90,  56])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 51,   7,   0, 110,  34,  99,   7, 124,   0,  72,  26,  51,  23,  41,\n",
      "         45,  37,  13,  19,  62,  11,  25,  18,  23,  38,   6, 122,  74,  68,\n",
      "         56,  11,  46, 116]) tensor([ 52,   8,   2, 112,  35, 106,   7, 130,   3,  72,  27,  52,  36,  43,\n",
      "         46,  63,  16,  20,  64,  19,  28,  28,  29,  42,  10, 122,  74,  73,\n",
      "         57,  21,  48, 118])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 87,  61,   0,  75,   3,  91,   2,  44, 130,  16, 115,  11,   7,  73,\n",
      "         17,  40,  49,  30,  35,  47, 112,   4, 108,  45,  86,  20,  88,  32,\n",
      "          5,  85,  45,  15]) tensor([ 87,  63,   1,  78,  10,  94,   2,  47, 131,  21, 125,  13,  16,  75,\n",
      "         22,  41,  58,  45,  37,  48, 112,   9, 109,  51,  88,  22,  94,  36,\n",
      "         13,  86,  48,  19])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 44,  21,  75,   0,   8,   9,  74,  31,  13,  84,  48,  54, 104,  42,\n",
      "         57,   2,  47,  21,  68,  75,  15,  22,  23,  34,  44,  22,  49,  56,\n",
      "         40,  20,   8,  30]) tensor([ 46,  23,  78,  12,  12,  14,  74,  33,  13,  86,  56,  55, 104,  45,\n",
      "         59,   2,  53,  46,  73,  75,  16,  27,  25,  37,  45,  24,  53,  63,\n",
      "         45,  20,   8,  33])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([151,  84,  45,  14,   3,  63,  35,  27,  88,  14,  59,  34,   8, 119,\n",
      "         37,  90, 110,  85, 119,  35, 134,   2,  27,  66,  13,  31,  43,  64,\n",
      "         43,   2,  11,  34]) tensor([157,  86,  47,  14,   5,  66,  37,  28,  88,  14,  59,  37,   9, 119,\n",
      "         39, 102, 110,  85, 119,  44, 136,   5,  29,  68,  14,  35,  43,  66,\n",
      "         48,   2,  11,  38])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 21,  91,  84, 120,  22,   9,   6, 110,  49,  52,  73,  68,  85,  75,\n",
      "         53,  89, 119,  10,  32,  20, 119,  44,  50,  34,  11,  50,  98,  63,\n",
      "        119,  61,  39,  57]) tensor([ 23,  95,  85, 123,  24,  15,  11, 114,  50,  88,  94,  77,  87,  77,\n",
      "         54,  91, 119,  12,  37,  30, 123,  46,  51,  40,  17,  53, 107,  65,\n",
      "        120,  61,  40,  65])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 62,   9,  15,  20,  24,  45,  33,  63,  17,   9,   0,   2,   9, 103,\n",
      "         44, 108, 128,  33,  20,  51,  71,  34,   2,  12,  85,  13,  36,   7,\n",
      "         12,  18,  87,  62]) tensor([ 62,  17,  16,  21,  27,  47,  35,  68,  17,   9,   1,   3,  11, 107,\n",
      "         48, 113, 131,  40,  22,  54,  75,  36,   3,  16,  87,  18,  39,  11,\n",
      "         12,  22,  87,  65])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 17,  21,  43,  10,   0,  70,  69, 104,  80,  90,  27,  31,  49,  24,\n",
      "         22,  59,  62,  13,  33,  40,  52,  94,  17,   8, 102,  62, 111,  14,\n",
      "         25,  26,  82,   3]) tensor([ 27,  27,  49,  12,   3,  71,  73, 107,  83, 118,  31,  32,  54,  28,\n",
      "         22,  59,  67,  19,  47,  46,  52,  94,  21,  13, 107,  65, 112,  15,\n",
      "         27,  29,  87,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([101,  46,   9,  31, 121,  13,  20,   0,  13,  60, 133,   4,  26,  34,\n",
      "         38, 111,  23,  65,  23,  44,  45,  26,  28,  32,  36, 102,  19,  35,\n",
      "         38,  66, 100, 124]) tensor([102,  53,  10,  36, 124,  18,  21,   4,  15,  64, 135,  13,  30,  34,\n",
      "         40, 116,  25,  67,  28,  49,  47,  29,  28,  34,  37, 104,  19,  40,\n",
      "         42,  70, 105, 125])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 28,   0,  71,  41,  12,  33,  11,  92,  86,  24,   0,  24,  96,   5,\n",
      "         18,  44,  68,  13,  85, 102,  67,  17,  83,  65,  55,   7,   4, 147,\n",
      "         71,  16,  25,   9]) tensor([ 28,   3,  74,  44,  15,  36,  12,  94,  88,  29,   9,  29,  99,   7,\n",
      "         22,  54,  68,  14,  86, 106,  70,  20,  99,  74,  55,   9,   5, 156,\n",
      "         76,  26,  29,   9])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([14, 68, 90, 78, 85, 86, 74, 19, 16, 93, 22,  0, 28, 46, 74, 85, 55, 76,\n",
      "        51, 45, 29, 35, 35, 21, 97, 67, 33,  5, 22, 17, 90, 20]) tensor([18, 69, 95, 80, 87, 94, 78, 19, 17, 95, 25,  5, 31, 48, 83, 85, 59, 76,\n",
      "        55, 46, 33, 39, 35, 21, 97, 67, 37, 10, 22, 21, 92, 22])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 62,  55,  26,   6,  14,  21,  58,  50,  63, 120,  75,  39,  75,   4,\n",
      "         50,  76,  20,  65,  85,  93,  39,   0,   0,  40,  43,  43,  22,  59,\n",
      "         69,   0,  19,  20]) tensor([ 66,  58,  28,  19,  14,  22,  61,  58,  65, 126,  78,  41,  75,   5,\n",
      "         55,  78,  21,  66, 102,  97,  39,   2,   1,  42,  45,  45,  25,  59,\n",
      "         72,   1,  22,  21])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8,  11,  57,  63,   4, 118,  16,   4,  38, 116,   2,  76,   7,  22,\n",
      "         33,  23,  63,  57,   3,  36,  86,  11,  46,  86,  13,  99,  16, 103,\n",
      "         34, 100,  64,  47]) tensor([ 13,  15,  62,  67,   4, 122,  19,   6,  47, 117,   5, 101,  10,  22,\n",
      "         38,  24,  70,  60,   5,  37,  86,  14,  49,  94,  18, 109,  30, 107,\n",
      "         36, 103,  72,  49])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([134,   9,   0,  36,  99,  62,  77,  11,  22,  18,  70, 107,  84,  52,\n",
      "         18,  56,  51,  38,   8,  34,  30, 115,  12,  12, 121,  12, 106,  29,\n",
      "         13,  23,  30,  68]) tensor([138,  17,   2,  36, 103,  68,  82,  12,  22,  23,  71, 117,  88,  57,\n",
      "         23,  56,  51,  44,  10,  36,  30, 123,  18,  14, 123,  13, 109,  32,\n",
      "         16,  24,  31,  69])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 84,  59,  38, 107,  35,  70,  13, 106,  33,  15,  56,  24,  12,  27,\n",
      "          0,  17,   9,  32,  54,  68,  11,  83, 104,  61,  46,  75, 105,  80,\n",
      "         75,   0,  13,  45]) tensor([ 86,  61,  44, 111,  39,  85,  18, 107,  35,  18,  58,  26,  14,  27,\n",
      "          4,  22,  15,  37,  56,  70,  14, 106, 111,  61,  56,  78, 107,  80,\n",
      "         94,   1,  19,  52])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8,  17,  58,  47,  77,  75,  66,   2,  67,  44,  27,  85, 107,  26,\n",
      "          9,   0,  10,  48,  22,  21,  82,  50,   0,  23,   9,  50,  17, 103,\n",
      "         69,  63,  72,  64]) tensor([  8,  19,  59,  51,  77,  77,  67,   2,  69,  47,  32, 109, 109,  28,\n",
      "         10,   4,  11,  53,  22,  21,  99,  55,   2,  26,  13,  53,  17, 104,\n",
      "         72,  69,  76,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([110,  13,   0,   5,  69,  59,  30,   4,  14,  41,  25,  66,  39,  19,\n",
      "          2,  52,  76,  78,  54,  25,  23,  21,   7,  39,  69,   5,  85,  54,\n",
      "         78,  64,  20,  17]) tensor([111,  15,   5,  14,  70,  61,  34,  14,  28,  42,  26,  73,  39,  23,\n",
      "          5,  52,  93,  78,  62,  28,  26,  28,  10,  40,  73,   9,  87,  56,\n",
      "        109,  66,  26,  20])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 71,   0,  54, 151,   7,   4,  82,  76,  10,  30, 122,  48,  16,  13,\n",
      "         12,  91,  40,  77,  19, 105,  85,  22,   6,  54,  20,  82,  50,  54,\n",
      "          6,  82,  19,  53]) tensor([ 71,   6,  56, 153,  15,   4,  85,  78,  11,  30, 124,  53,  19,  22,\n",
      "         18,  94,  51,  89,  20, 114,  85,  26,   8,  76,  20,  86,  55,  58,\n",
      "          9,  83,  21,  53])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 47,  75,   0,  94,  60,  54,  53,   0,  22, 118,  95,  26,   7,   7,\n",
      "         45,  14,  73,  70,   2,  33,   6,  91,   2,  15,  42,  19,  31,  36,\n",
      "         81,   9,  71,  34]) tensor([ 48,  88,   4, 130,  61,  57,  56,   6,  24, 119,  99,  28,   7,   7,\n",
      "         52,  32,  73,  78,   3,  37,  12,  91,   5,  18,  49,  20,  36,  36,\n",
      "         89,  11,  71,  37])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 61,  42,  99, 109,   6,   9, 123, 116,   4,  80,  34,  54,  25,  47,\n",
      "         29, 105,  61,  30,  19,  67,  27,   5,   6,  98,  70,  31,  16,  76,\n",
      "        126,   9,  48, 101]) tensor([ 61,  47, 102, 111,   6,  10, 141, 116,   6,  81,  37,  61,  25,  50,\n",
      "         29, 110,  61,  36,  26,  69,  27,   5,  15,  98,  73,  34,  22,  77,\n",
      "        129,  12,  48, 107])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  6,   8,  41,  58,  48,  26,  80,   7, 102,  73,  66,  51,  61,  16,\n",
      "         45,  21,  61,  25, 126,  87,  72, 100,  40,   6,  18,  80,  59, 102,\n",
      "         52,  69,  15, 101]) tensor([  7,   8,  43,  59,  54,  29,  83,  10, 106,  75,  67,  63,  80,  18,\n",
      "         45,  22,  61,  27, 133,  87,  74, 106,  41,   9,  20,  85,  60, 104,\n",
      "         54,  72,  17, 101])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 15,  33, 107,  55,  78,  27,  25,   5,  32,  94,  14,  84, 109,  36,\n",
      "         30,  10,  15,  39,  22,  90,  50,   0,   6,  51,  21,  41,  76,  54,\n",
      "          2,   2,   0,  46]) tensor([ 18,  38, 109,  57,  80,  28,  28,   5,  33,  98,  14,  85, 110,  36,\n",
      "         34,  18,  18,  42,  26,  92,  52,   3,   7,  57,  25,  44,  80,  55,\n",
      "          5,   3,   4,  51])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 75,  15,  46,  72,  63,  13,  61,  31,  62,  70,  14,  65,   2,  45,\n",
      "          7,  26,  10,  74,  42, 102,  35,   2,  16,  91,  22,  96,  54,  21,\n",
      "         63,  35,  40,   0]) tensor([ 89,  16,  51,  76,  64,  16,  65,  33,  65,  75,  18,  72,   2,  49,\n",
      "         12,  28,  13,  77,  42, 105,  39,   3,  17,  96,  25, 102,  60,  24,\n",
      "         64,  43,  43,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 32,  41,  22,  80, 108,  20,  30,  56,   9,  13, 100,  32,  14,  38,\n",
      "         24,  18,  28,  70,   6,  14,  35, 105,   3,  72, 103,  65, 119,  58,\n",
      "         33,  48,   8, 104]) tensor([ 38,  41,  23,  82, 117,  20,  34,  61,  10,  13, 107,  33,  16,  39,\n",
      "         26,  22,  32,  87,   7,  14,  39, 106,   3,  72, 107,  68, 121,  62,\n",
      "         34,  51,   9, 106])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,  32,  42,  65, 105,  59,  46,  53,  25,  19,   9,  35,   3,   3,\n",
      "         18,  90,  22,  78,  61,  10,  10,   2,  39,  42,  52,  28, 123,  54,\n",
      "         37,  48, 105,  25]) tensor([ 39,  35,  42,  65, 107,  60,  49,  58,  25,  21,  26,  39,   5,   3,\n",
      "         20, 118,  24,  83,  63,  17,  11,   5,  49,  47,  52,  29, 124,  56,\n",
      "         52,  50, 107,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 21,  24,  65,  36,  18, 131,  13,   8,  16,  18,  40,  11,   0,  22,\n",
      "         74,  63,  26,   7,  54,  62,  28,   0,  65,  49,  36,  13,   7,   3,\n",
      "         24, 111,  43,  30]) tensor([ 23,  35,  67,  38,  20, 135,  16,  10,  27,  41,  56,  13,   4,  22,\n",
      "         77,  63,  27,  12,  57,  63,  32,   4,  66,  49,  41,  15,   7,  14,\n",
      "         25, 112,  44,  30])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 48,  49,  63, 102,  32,  53,  15,  11,   0, 108,  99,  23, 124,  42,\n",
      "         43,   9, 100, 107,   5,  61,  57,  55,  76,  96,  95,  54,  60,  31,\n",
      "         53,  16,  16,  73]) tensor([ 53,  53,  63, 102,  38,  57,  17,  12,  13, 111, 107,  24, 130,  42,\n",
      "         44,  12, 100, 108,  10,  63,  61,  59,  79,  97,  95,  56,  71,  31,\n",
      "         58,  19,  22,  84])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13,  16,  51,  13,  27,  16,  29,  47,  66,  21,  45,  17,  58,  42,\n",
      "          7,   4,  14,   6,  10,  42,  57,  17,  36,  12,  46, 124,   0,  34,\n",
      "          0,  95,  66,  12]) tensor([ 14,  27,  58,  16,  28,  17,  31,  51,  66,  21,  49,  17,  62,  43,\n",
      "         12,   5,  14,  10,  12,  55,  59,  33,  38,  16,  51, 128,   5,  34,\n",
      "          7,  97,  67,  15])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 52, 118,  93, 119,  45,  63, 107,  12,  69,  45,   2,  30,  76,  23,\n",
      "         48,  33,   5,  79,  30, 103,  56,  72,  94,  34,  62,  12,   2,   6,\n",
      "         30,  43,  73,  68]) tensor([ 59, 120,  94, 121,  49,  69, 120,  14,  78,  52,   2,  32,  79,  29,\n",
      "         52,  33,   6,  82,  33, 106,  59,  77, 101,  35,  65,  12,   5,  12,\n",
      "         32,  45,  80,  68])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 68,  39,  42,  35,  64,  19,   0,   5,  47,  70,  12,  12,  16,  61,\n",
      "         45,  60,  77,  82,   2, 101,  63,   7,  63,  52,  17,  91,  84,  26,\n",
      "         28,  14,  73,  32]) tensor([ 87,  41,  44,  35,  70,  25,   2,   6,  48,  87,  13,  12,  16,  65,\n",
      "         48,  68,  80,  84,   4, 113,  64,   8,  65,  53,  17,  92,  95,  29,\n",
      "         29,  16,  75,  33])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 19, 133,  15,  61,  46,   2,  48,  93,  46,  18,   2,  51, 126,  93,\n",
      "          2,  46,  29,  77,  81,   0,  48,  14,  39,  35,  39,   8,  30,  75,\n",
      "         11,  68,  25,  70]) tensor([ 22, 134,  18,  65,  61,   3,  49, 126,  64,  21,   2,  52, 128,  94,\n",
      "          2,  67,  32,  91,  81,   5,  48,  15,  42,  40,  39,  11,  38,  82,\n",
      "         16,  87,  26,  79])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 14,  91,  16,  67,  36,  47,  65,  63,  38,  24,   5,  18,  71,  23,\n",
      "         53,   4,  44,  27,   8,  41, 105,  10,  68,  10,  20,  56,  10, 124,\n",
      "          9,  36,  14,  59]) tensor([ 15, 103,  18,  73,  38,  49,  68,  66,  38,  27,   5,  20,  77,  24,\n",
      "         57,   5,  49,  27,  13,  42, 107,  17,  76,  12,  38,  58,  13, 127,\n",
      "         23,  38,  15,  59])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 75,  73,  74,  30,  20,  71,  52,  81,  28,  43,  52,  71,  46,  15,\n",
      "         97, 108,   2,  59,  13,   8,  77,  12, 118,  53,   7, 114,  27,  28,\n",
      "         51,  16,  17,  11]) tensor([ 75,  78,  74,  47,  20,  82,  52,  81,  28,  44,  72,  78,  46,  17,\n",
      "        103, 109,   4,  61,  17,  10,  86,  16, 123,  56,  10, 132,  37,  29,\n",
      "         54,  18,  19,  13])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 20,  56,  18,  65,  67,  45, 115, 126,   8,  79,  83,   2,  82,  76,\n",
      "         18,  27,  70,  38,  66,  43,   9,  23,  17,  82,   9,   8,   7,  10,\n",
      "         14,  77,  97,  53]) tensor([ 20,  76,  19,  71,  75,  49, 118, 128,   9,  79,  84,   3,  96,  76,\n",
      "         21,  32,  75,  39,  67,  44,  11,  26,  18,  86,  11,   8,   8,  11,\n",
      "         14,  80, 125,  55])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 19,  80,   0,  31,  27,  54,  94,  19,  44, 104,  61,  42,   3,   2,\n",
      "         67,  26,  45, 121,  15,   3,  12,  47,  54,  74,  92,  39,  79,  52,\n",
      "         50,  80,  55,  19]) tensor([ 20,  82,   5,  35,  41,  56,  94,  22,  49, 104,  63,  44,   7,   5,\n",
      "         72,  30,  55, 126,  18,   7,  16,  50,  58,  75, 102,  64,  88,  52,\n",
      "         59,  82,  55,  22])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([104,  71,   5,  83,  26,  72,  38, 108,  93,  20,  76,  16,  22, 102,\n",
      "         36,   6,  99, 120,  12,  92,  53,  89,  67,  78,  23,   6,  25,  21,\n",
      "        121,   9,   9,  56]) tensor([115,  75,   5,  85,  34,  94,  38, 117,  94,  23,  76,  19,  24, 112,\n",
      "         38,   8, 100, 128,  19,  95,  54,  90,  73,  82,  26,   9,  26,  22,\n",
      "        126,  12,  10,  61])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 48,  82, 115,   7,  15,  33,  44,  55,  10,  58,  86,  30,  47,  12,\n",
      "         60, 110,  19,  16, 103,  84,  30,  61,  10,  23,   7, 110,  61,  61,\n",
      "         29,  92,  50,  76]) tensor([ 48,  88, 116,  20,  24,  33,  50,  56,  15,  59,  88,  30,  48,  16,\n",
      "         65, 111,  22,  18, 112,  88,  36,  61,  16,  24,   7, 110,  61,  65,\n",
      "         29, 116,  53,  96])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 53,  54,  15,  12,  21,  40,   9,   2,  40,  22,  29,  21,  45,  57,\n",
      "          0,  40,  31, 111,  17,  28,  16,  55,  21,  57,  23,  62,  83,  87,\n",
      "         79, 115, 122,   5]) tensor([ 56,  57,  19,  13,  22,  41,  10,   3,  45,  27,  34,  21,  48,  62,\n",
      "          4,  47,  35, 118,  24,  35,  21,  60,  23,  57,  37,  62,  83,  93,\n",
      "         81, 120, 125,   9])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 12,   0,  10,  24,   0, 115,   0,  53,   0,  59,   0,  97,  13,  67,\n",
      "        105,  60,  38,  92,  74,  13,  15,  86,  46,  17,  67,   0, 125,  33,\n",
      "         65,  31,  91,  60]) tensor([ 20,   3,  12,  25,   4, 121,   4,  56,   2,  65,   7, 100,  16,  73,\n",
      "        111,  61,  41,  95,  74,  14,  33,  88,  47,  19,  67,   4, 126,  34,\n",
      "         65,  37,  95,  61])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 27,  59,  49,  45,  69, 122,  62,  18,   2,  76,  34,   0,  30,  11,\n",
      "        110,   4,  22,  27,  77,  20,  19,  40,  44,  18,  29,  39,  21,  81,\n",
      "         10,  19,   8,  14]) tensor([ 29,  60,  50,  51,  96, 126,  70,  23,   3,  78,  42,   8,  30,  15,\n",
      "        110,   8,  34,  28,  83,  22,  21,  40,  59,  23,  32,  41,  23,  85,\n",
      "         16,  22,   9,  23])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 26,  26,  14,  24,   0,  72,  18,  60,  36,  27,  57,  94,   0,   2,\n",
      "         19,  53,  46,  64,  89,  66,  53,  59,  52, 111,  69,   0,  23,  52,\n",
      "         76,  29,   2,  67]) tensor([ 26,  30,  17,  25,   2,  74,  23,  61,  36,  30,  61,  97,   3,   2,\n",
      "         19,  54,  48,  68,  94,  66,  53,  61,  55, 113,  79,   2,  25,  55,\n",
      "         82,  34,   2,  69])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,  48,   9,  30,  85,  21,  67,   6,   0,  19,  75,  45,  26,  29,\n",
      "         58, 101,   2,  62,  20,  89,  38, 102,  82,  62,  64,  55,  93,   2,\n",
      "         20,  32,   9,   5]) tensor([  5,  58,   9,  32,  87,  23,  67,   8,   2,  27,  82,  45,  27,  30,\n",
      "         61, 103,   4,  73,  26,  92,  40, 104,  85,  63,  67,  57,  97,   8,\n",
      "         24,  45,  12,   9])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  3, 128,   8,   9,  34,  55,  12,  61,   8,   6,   2,   6,  24,  32,\n",
      "         86,  39,  61,  27,  18,  20,  43,   9,  64,  86, 120,  26,  46,  49,\n",
      "         65,  42,  69,  28]) tensor([  3, 130,  21,  16,  36,  59,  12,  62,  11,   7,   2,  10,  27,  44,\n",
      "         88,  40,  64,  30,  19,  25,  46,  11,  65,  88, 121,  28,  50,  49,\n",
      "         70,  58,  72,  30])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  9,   8,  54,  76,  44,  13,  44, 121,  51,  18,  99, 112,  33,   3,\n",
      "         35,   4,  86,   4,  42,  22,   3, 123, 105, 100,   0,  22, 113, 110,\n",
      "          0,  27,  49,  45]) tensor([ 11,  33,  60,  76,  44,  14,  47, 121,  51,  20, 103, 113,  43,   3,\n",
      "         35,   5,  87,   4,  43,  27,   3, 123, 106, 101,   2,  26, 113, 110,\n",
      "          4,  28,  52,  49])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 24,   6, 113,  33,   6,  20,  70,  16,  85,  75,   7,  29,  72, 116,\n",
      "         91,  61,  82,  71,  58, 126,  82,  33,   3,  27,  19,   9,  53,   0,\n",
      "         65, 108,  10, 105]) tensor([ 25,  12, 118,  33,   7,  22,  71,  22,  88,  83,   8,  29,  78, 117,\n",
      "         92,  61,  82,  72,  61, 132,  82,  36,   6,  30,  23,  11,  53,   6,\n",
      "         69, 108,  15, 107])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 12,  29,  78,  33,  39,  46,  28,  25,  38,  55,  33,   3,  36,   5,\n",
      "         37, 139,  32, 108,   2,  43,  18,  41,  92,  72,  33,  84,  48,   2,\n",
      "        104,  55,  61,  50]) tensor([ 14,  32,  80,  35,  42,  48,  33,  26,  41,  56,  35,   6,  39,   5,\n",
      "         39, 141,  35, 110,   6,  46,  20,  41,  97,  73,  33,  87,  50,   2,\n",
      "        106,  56,  69,  51])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 28,  78,   9,  21, 112,  65,  22,  18, 104,  23,  16,   5,  57,  11,\n",
      "         35,  31,   5,  29,  92,   7,  69,  58,  30, 131,   5,  16,  24,  60,\n",
      "         48, 114,  82,  74]) tensor([ 30,  81,  13,  21, 115,  68,  24,  18, 110,  26,  18,   6,  66,  11,\n",
      "         38,  36,   5,  34,  96,  11,  69,  59,  31, 133,  11,  20,  26,  63,\n",
      "         50, 118,  89,  85])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 40,  51,   0,  23,  31,  54,  13,  34,  79,  19,  97,  52,  91,  30,\n",
      "         11,  68,  27,  91,  25,  54,  21,  74,  94,  41,  41,   2,  29,  33,\n",
      "         63,  48, 127,  31]) tensor([ 40,  59,   6,  28,  37,  56,  18,  34,  82,  24,  99,  53,  95,  30,\n",
      "         14,  70,  34, 114,  34,  60,  24,  76, 100,  42,  43,   4,  33,  41,\n",
      "         64,  51, 130,  41])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 50,  51,  99,  27,   2,  37,   7, 105,  52,  86,  41,  37,  20,   5,\n",
      "         16,  74,  68,  62,  33,  66,  20,  69, 105,  94, 103,   0,  35,  96,\n",
      "         14, 102,  22,  64]) tensor([ 54,  51, 100,  33,   2,  37,   7, 108,  56,  96,  41,  39,  23,   6,\n",
      "         21,  74,  69,  67,  36,  69,  21,  80, 121,  98, 104,   8,  36,  98,\n",
      "         20, 102,  25,  70])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 24,  52, 106,   0,  27,  61,   3,   0,  60,   9,   5,   2,  14,  27,\n",
      "        102,  29,  26,  60,  15,   5,  38,  25,  19,  30,   2,  92,  53,  78,\n",
      "          7,  11,  47,   2]) tensor([ 48,  54, 109,   2,  27,  62,   6,   1,  62,  13,   8,   5,  24,  39,\n",
      "        102,  33,  29,  67,  15,   8,  45,  31,  21,  41,   4,  95,  54,  81,\n",
      "         16,  11,  49,   7])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 32,  19,  28,  46,  19,  10,  25,   2,  13,  49,  77,  13,  98,  17,\n",
      "          2,  19,   7,   3,  49,  68, 108,  67,  11,  75,  14,  97,  48,  43,\n",
      "         87,  96, 100,  64]) tensor([ 33,  36,  29,  53,  25,  12,  26,   2,  15,  50,  79,  14,  98,  20,\n",
      "          2,  21,  12,   6,  50,  69, 115,  70,  13,  89,  29,  97,  51,  47,\n",
      "         88, 102, 101,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 38,  76,  31, 126,  47,  50,  20,  35,  29,  11,  42,  79,  48,  57,\n",
      "         25,  25,  63,  95,  37,  27,   6,   7,  26,   0,  36,  38,   7,  41,\n",
      "         82,  26,  28,  39]) tensor([ 40,  77,  42, 134,  49,  55,  21,  36,  30,  15,  42,  79,  49,  58,\n",
      "         25,  25,  64, 102,  43,  28,   6,   7,  27,   3,  38,  49,  48,  42,\n",
      "         82,  27,  29,  40])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 96,  98, 137,  78,  65,   7, 147,  88,  91,  61,   0,  82,  24,  23,\n",
      "         68,   0,  47,  10,  74,  46,  81, 129,  43,  30,   0, 100,  89,  12,\n",
      "         47,  70,  61,  39]) tensor([ 97,  98, 140,  84,  72,  27, 157,  93,  94,  61,   4,  84,  34,  28,\n",
      "         72,   9,  48,  13,  82,  47,  85, 135,  44,  33,   3, 101,  92,  13,\n",
      "         47,  74,  66,  43])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 58, 104,  55, 113,  60,  48,  67,   9,  17,  80,   8,  28,   9,  53,\n",
      "         14, 142,  87,  81,  22,  48,   0,  41,  38,  45,   8,  25,  78,  35,\n",
      "         50,   2,   5,  68]) tensor([ 59, 114,  56, 113,  61,  49,  68,   9,  28,  88,  19,  32,   9,  53,\n",
      "         14, 143, 116,  85,  23,  53,   4,  43,  43,  49,  21,  34,  79,  38,\n",
      "         57,   7,   6,  71])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 47,  44,  74,  23,   4,   0,  28, 129,  64,  29, 106, 100,   0,  86,\n",
      "         20,  40,  20,  37, 101,  13,  50,  45,   8, 154,   7,  75,  43,  24,\n",
      "         30,   4,  96, 122]) tensor([ 57,  48,  75,  25,   4,   2,  32, 129,  73,  44, 108, 101,   3,  89,\n",
      "         26,  40,  23,  41, 101,  14,  53,  48,   9, 155,  11,  78,  45,  27,\n",
      "         30,   8,  99, 124])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 43,  79,  27,  19,  50,  43,  53,  15,  42,   0,   4,  61,  74, 114,\n",
      "         42,   9,  30,  95,  70,  84,  46,  17,  31,  15,  98,  78,  81,  10,\n",
      "         69,  22,  67,  67]) tensor([ 44,  80,  29,  24,  50,  53,  66,  19,  45,  15,   5,  72,  79, 127,\n",
      "         43,   9,  33,  96,  71,  87,  50,  21,  34,  15, 102,  81,  82,  12,\n",
      "         75,  23,  73,  69])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,   2, 105,  38,  74,  17,  31,  38,  75,  57,  58,  40,  55,   6,\n",
      "        105,   4,  87,   0,  30,  54,   6,  27,   8,   7,  85,  36,  15,  36,\n",
      "         42,  37,  99,  69]) tensor([ 58,   5, 107,  39,  75,  23,  33,  42,  80,  75,  58,  40,  82,   8,\n",
      "        106,   7,  87,   7,  34,  56,   7,  27,   8,  10,  86,  36,  25,  41,\n",
      "         46,  38, 106,  71])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 42,  82,   2,  92,  46, 144,   0,  23,  68,  37,  11,  85,  84,  53,\n",
      "         29, 118,  50,  77,   0, 106,  36,  63,  24,   8,  58,  94,  26,   0,\n",
      "         26,  70,  21,  14]) tensor([ 49,  82,   2,  92,  47, 146,   2,  25,  69,  57,  15,  85,  86,  55,\n",
      "         30, 121,  51,  77,   7, 107,  39,  71,  26,  16,  60, 101,  32,   1,\n",
      "         27,  70,  23,  31])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 19,   3, 102,  42,  79,  36,  22, 110,  12,  27,  22,  41,  45,  56,\n",
      "         40,  53,  88,  71,  21,  31,  51,  39,  30, 125,  28,   7,  15,  59,\n",
      "         52,  19,  37,  51]) tensor([ 20,   6, 106,  44,  83,  41,  23, 113,  13,  28,  23,  43,  46,  61,\n",
      "         40,  61,  90,  84,  22,  32,  51,  41,  30, 126,  35,  12,  25,  68,\n",
      "         55,  19,  47,  60])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 73,  16,  22,  11, 113,  23,  74,  15,   2,  15,  47,  61,  20,  57,\n",
      "         38,   0,  40,   0,  80, 107,  77,  16,   2,  32,  33,   8,  26, 104,\n",
      "         80,   2, 109,  55]) tensor([ 73,  17,  26,  13, 113,  23,  75,  24,   8,  17,  52,  72,  23,  66,\n",
      "         39,   3,  41,   3,  80, 115,  77,  26,   3,  35,  34,  11,  28, 104,\n",
      "         82,   2, 109,  55])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 21,  21,  47,  37,  32,  66,  93,   4,  51, 115,  15,  60,  76,  14,\n",
      "        112,  65,  76,  68,  53,  34,  42,   8,  62,   3,  18,  25,   8,  80,\n",
      "          2,  28,  79,  75]) tensor([ 25,  22,  48,  40,  34,  70, 101,   6,  51, 115,  16,  64,  78,  21,\n",
      "        121,  69,  78,  86,  57,  35,  45,  12,  64,   3,  20,  26,  11,  84,\n",
      "          6,  38,  88,  80])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 16,  12,  75,  22,  72,  40,  40,  19,   9,  13,  48,  23,  61,  29,\n",
      "         48,  66,   4,  66, 104,  97,  12,  24,  28,  87,  76,  82,  31,  69,\n",
      "         51,  63,  37,  94]) tensor([ 17,  13,  75,  24,  72,  42,  45,  24,  15,  15,  48,  24,  67,  38,\n",
      "         50,  69,   4,  67, 107,  99,  13,  25,  30,  88,  77,  85,  35,  70,\n",
      "         56,  63,  40,  95])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 42,  61, 100,  27,  11, 103,   8,  53,  32, 100,  32,  11,  71,  26,\n",
      "         30,  74,  45,  62,   7,  80,   8,  68, 123,  71,   2,  25,  13,  34,\n",
      "        123, 135,  68,  30]) tensor([ 46,  63, 103,  27,  33, 103,  10,  54,  37, 103,  34,  14,  74,  28,\n",
      "         32,  75,  45,  67,   8,  81,  10,  71, 124,  73,   4,  28,  14,  40,\n",
      "        123, 138,  79,  32])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 82,  16,  62,  33,   0,  53,  59,  18,  76,   9,  10,   8,  49,  19,\n",
      "          0, 109,  40,  24,  21,  51,   4,  93,  32,  13,   0,   5,  24, 106,\n",
      "         52,  35,  22,  56]) tensor([ 85,  20,  64,  37,   4,  54,  62,  21,  77,  10,  14,   9,  58,  19,\n",
      "          1, 114,  43,  27,  23,  52,  14,  98,  41,  15,   4,   8,  27, 108,\n",
      "         58,  40,  24,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 39,  71,  63,  34,  92,   2,  10,  38,  54,  59, 125,  27,  36,   2,\n",
      "          6, 101,  52,  76,   8,  47,  11,   0,  32,  28,  78,  84, 106,   2,\n",
      "        122,   9,  78,  49]) tensor([ 40,  71,  65,  36,  93,   7,  13,  38,  54,  68, 129,  31,  48,   2,\n",
      "         11, 103,  53,  79,  13,  50,  11,   9,  37,  32,  85,  86, 108,   2,\n",
      "        125,  14,  79,  50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 19,  15,  61,  75,  92,  84,  32,  59, 156,  37,  39,   6,   3,  11,\n",
      "         43,  43,   5,   8,  91,  22,  53,  53,   9, 102,   8,  15, 100,  17,\n",
      "          7,  29,  84,  15]) tensor([ 24,  18,  62,  82,  93,  87,  33,  63, 158,  43,  46,   6,   5,  14,\n",
      "         47,  44,   7,   8, 100,  26,  55,  66,  15, 103,   9,  16, 112,  20,\n",
      "          7,  30,  86,  17])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([114,  47,  12,  20,  90, 113, 135,  76,  31,  66,   2,  30,   9,  18,\n",
      "         80, 125,  90,  17,  14, 114,  46,  59,  14,   7,  59,  99,  12,  37,\n",
      "         66,  52,  23,  90]) tensor([116,  51,  15,  22,  92, 116, 138,  80,  33,  67,   5,  34,  10,  19,\n",
      "         81, 130,  92,  17,  14, 114,  47,  62,  20,  12,  63, 105,  13,  39,\n",
      "         68,  57,  28,  91])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13,  57, 152,  23,   2,   8, 118,  68,  69, 116, 100,  10,  57,  10,\n",
      "         49,  18,  73,  10,  54,  62,  40, 113,  61,  47,  39,  40,   0, 105,\n",
      "         83,  18,  76,  52]) tensor([ 13,  58, 154,  24,   8,  13, 124,  70,  71, 126, 103,  12,  60,  10,\n",
      "         49,  18,  78,  20,  58,  63,  41, 119,  61,  49,  44,  48,   4, 106,\n",
      "         88,  20,  78,  53])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 75,  99,  95,  56,   0,  35,   6,  99,  38,  54,  85,  19, 110,  54,\n",
      "         28,  93,   6,  71,  47,  20,  67,  26,  12,  57,  52,  19,  12,  87,\n",
      "         70,  83,  23,   2]) tensor([ 77, 101,  98,  57,   6,  38,  12, 100,  44,  60,  85,  19, 115,  56,\n",
      "         29, 100,   6,  74,  49,  21,  68,  28,  17,  58,  59,  20,  12,  92,\n",
      "         73,  84,  30,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 29, 107,  36,  39,  85,  42,  30, 106, 107,   8,  91,   7,  21,  13,\n",
      "         16,  54,   0,  22,  43,  63,  16,  22,  19,   6,  28,  21,  91,   5,\n",
      "          9,  65,  78,  15]) tensor([ 31, 110,  37,  39,  86,  43,  37, 111, 111,   8,  93,   8,  36,  16,\n",
      "         18,  58,   2,  30,  46,  67,  18,  25,  22,   8,  34,  23,  91,   8,\n",
      "         12,  65,  81,  15])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 30, 113,  62,  84, 127,  36,  63,  79,  16,  44,  40,   0,  39,  12,\n",
      "         38,  32, 108, 123,  17,  60,  18,  52,  23, 122,   7,  79,  32,   6,\n",
      "         31,  74,   2,  23]) tensor([ 31, 116,  71,  84, 129,  37,  66,  79,  19,  53,  42,   3,  44,  15,\n",
      "         43,  36, 111, 129,  21,  62,  20,  59,  27, 123,   8,  81,  34,   8,\n",
      "         39,  76,   2,  23])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 90,  34,  32,   3,  22,  31,   8,  40, 114,  37,  87,  55,  96,   2,\n",
      "         92,  91,  33,  43,  44,  56,  17, 118,  28,  32,  91,  31,  21,   4,\n",
      "         17,  17,   0,  36]) tensor([ 94,  41,  37,   7,  27,  32,  12,  41, 122,  41,  90,  56, 101,   3,\n",
      "         93, 107,  35,  49,  45,  57,  18, 120,  30,  32,  95,  31,  23,  16,\n",
      "         21,  17,   1,  50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 71,  67,  13,  11,  38,  37,  13,  53,   4,  21,   8,  78,  57,  52,\n",
      "         44,  61,   9,  24,  69,   3,  33,  28, 117,  42,  80,   0,  42,  26,\n",
      "         62, 132,  56,  16]) tensor([ 72,  70,  17,  12,  40,  37,  16,  54,   5,  26,  10,  78,  58,  52,\n",
      "         45,  62,  11,  33,  73,   5,  35,  30, 118,  45,  80,  13,  44,  28,\n",
      "         90, 137,  66,  17])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 87,  70,  22,   2,   9,  29,  62,   9,   7,   3,  55,  42,  43,  28,\n",
      "         37,  97,  50,   3,  56,  49,   2,  47,   4,  56,  26,  19,  87, 113,\n",
      "          0,  71,  19,  34]) tensor([ 88,  79,  22,   3,  10,  29,  66,  11,   7,   3,  56,  44,  45,  29,\n",
      "         38, 104,  52,   6,  56,  50,   4,  49,   6,  68,  43,  20,  94, 117,\n",
      "          1,  73,  33,  37])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 44,  83,  24,  51,  93, 130,  84,  95,  41,  12,  11, 115,   5, 122,\n",
      "         47,  74,  16,   7,  18,  93,  88,  42,  73,  23,  49,   2,  85,  38,\n",
      "          6,  60,   7,  91]) tensor([ 49,  85,  33,  51,  95, 133,  89, 105,  42,  12,  12, 118,   5, 122,\n",
      "         49,  76,  21,   7,  18,  97,  92,  45,  74,  23,  52,   2,  96,  39,\n",
      "          7,  62,   9,  93])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([78,  0, 36, 18, 63, 59, 27, 72, 98, 15, 55,  0,  7,  8, 51, 64, 53, 60,\n",
      "        39, 41, 15, 67, 96, 18, 67, 68, 67,  0, 55, 55, 84,  9]) tensor([93,  6, 44, 46, 65, 63, 29, 76, 98, 19, 58,  2, 11, 11, 53, 74, 55, 70,\n",
      "        43, 41, 17, 68, 98, 20, 69, 74, 69,  2, 57, 58, 95, 11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 61,  83,  65,   2,   5,  40,  67,  71,  35,  38,  53,  64,  83,   8,\n",
      "         11,  87,  75,  21, 115,   0,  30,  12,   0,  31,  58, 103,   7,  36,\n",
      "         40,  25,  67,  40]) tensor([ 65,  83,  68,   5,   7,  51,  70,  77,  38,  42,  56,  70,  88,  11,\n",
      "         13,  94,  76,  22, 123,   6,  32,  12,   4,  33,  60, 120,   9,  38,\n",
      "         45,  25,  68,  43])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 72,  13, 117,  39,  49,  12,  52,  39,  45,  38,   3, 109,  73,  30,\n",
      "         94,  22,  66,  28,  68,  85,  36,  65,  96,  32,  58,  13,  84,  81,\n",
      "          3,   2,  20,  32]) tensor([ 75,  13, 124,  42,  53,  21,  52,  45,  48,  38,   4, 113,  75,  39,\n",
      "         95,  22,  66,  30,  80,  89,  37,  68, 105,  58,  60,  18,  85,  83,\n",
      "          3,   2,  27,  40])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 26, 125,  46,  52,  22,   9,   4,  10,  59,  72,   3,   5,   8, 129,\n",
      "         78,  93,  75,  38,  35, 100,  51,  36,  42,  37,  31,  29,   0, 103,\n",
      "          5,  19,  34,  52]) tensor([ 26, 125,  49,  53,  26,  13,  17,  14,  61,  73,   3,  20,   8, 129,\n",
      "         79,  95,  77,  38,  37, 102,  51,  38,  53,  40,  43,  33,   6, 107,\n",
      "          7,  19,  35,  53])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 38,  67,  24,  33,   0, 118, 117,  51,  89,  89,   9,  58,   2,  85,\n",
      "         19,  44,   6,   8,  33,  97,  15,  10,  15,   8,  48,  20,  52,  15,\n",
      "         83,  60,  52,   9]) tensor([ 43,  76,  25,  58,   6, 120, 117,  64, 107, 113,  15,  59,   2,  90,\n",
      "         24,  50,   7,  11,  35, 101,  16,  11,  15,  10,  48,  21,  53,  17,\n",
      "         98,  76,  55,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 18,   4,   6,   0,  17,  30,  30,  94,  75,  74,  77,   0,   9,  13,\n",
      "         22,  24,  60,  17,  33,  16,  39,  16,  22,  77,  53,  14, 139,   2,\n",
      "          5,  14,  22,  66]) tensor([ 27,  11,   6,   3,  20,  34,  30,  98,  86,  74,  80,   4,  10,  16,\n",
      "         31,  30,  61,  41,  37,  18,  44,  21,  25,  78,  56,  15, 140,   3,\n",
      "         10,  16,  23,  75])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 55,   4,  42,  12,   7,  73, 101,   8,  50,  19,   8,  14,  15,   9,\n",
      "         43,  32,   5,  80,  16,  77,  47, 107,  38,  38,  48,  58,  56,  35,\n",
      "         49, 116,  29,  62]) tensor([ 56,   4,  42,  15,  12,  75, 104,   8,  52,  20,  10,  19,  15,  10,\n",
      "         57,  36,   8,  82,  17,  79,  50, 107,  67,  42,  48,  61,  57,  35,\n",
      "         52, 121,  34,  66])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 60,  71,  15,  94,  56,  11,  81,  13,  45,  69, 120,  43,  46,  90,\n",
      "          3, 106,  44,  36,  24,  16,  16,  19,  39,  36, 144,  62,  34,  38,\n",
      "         70, 130,  24,  16]) tensor([ 71,  74,  25,  95,  59,  15,  84,  14,  48,  72, 120,  48,  50,  94,\n",
      "          3, 107,  47,  41,  26,  20,  18,  21,  44,  56, 146,  62,  35,  39,\n",
      "         71, 137,  24,  19])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([115,  63,  50,   0,  41,  20,  10,  50,  15,  42,  29,  84,  77,  43,\n",
      "         31,  93,  69,   9,  68,  40,  20,  60,   8,  19,  26,  16,   8, 105,\n",
      "        109,  35,  11,  27]) tensor([117,  64,  51,   4,  44,  26,  12,  52,  23,  58,  35,  86,  84,  47,\n",
      "         34,  94,  79,  10,  69,  42,  20,  64,   9,  25,  29,  19,  10, 114,\n",
      "        111,  46,  14,  30])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 48, 115,  68,  77,  95,  24,   0,  15,  40,  86,  31,  33,   2,  79,\n",
      "         22,  90,  90,  83,  49,  74,  30,  55, 103,  86,  10,   4,   2,  56,\n",
      "         25,  57, 119,  32]) tensor([ 49, 117,  75,  81, 103,  28,   5,  23,  42,  90,  31,  34,   2,  99,\n",
      "         26, 112,  97,  85,  55,  76,  34,  56, 119,  86,  19,   8,   4,  57,\n",
      "         27,  60, 122,  32])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 35,  55,  95,  85,  68,  89,  22,  15,  95,  52,   0,  32, 103,  64,\n",
      "         15,  43,  54,   9,  83,   4,  42,  14,  69, 116,  19,  31,  53,  63,\n",
      "         53,   8,  52,   0]) tensor([ 35,  55,  97,  90,  73,  91,  28,  17,  99,  78,   1,  34, 105,  65,\n",
      "         15,  49,  55,  12,  91,   4,  43,  15,  70, 121,  19,  38,  54,  65,\n",
      "         55,  12,  57,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  2,   3,   5, 106,  60,  54,  24,  76,   5,   7,   2,  63,  60,   3,\n",
      "        126,   6,  61,  53,  20,   9,  20,  15,  34,  35, 102,  15,  56,  41,\n",
      "         41,  73,  96,   3]) tensor([  2,   6,   8, 115,  64,  54,  28,  80,   7,  10,   2,  64,  65,   3,\n",
      "        128,  10,  67,  54,  26,  14,  22,  18,  45,  38, 104,  15,  57,  41,\n",
      "         43,  73, 107,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8,  59,   3,  64,   9,  87,  72,  10,  95,   0,   0,  72,  37,   2,\n",
      "         72,  10,  44,  56,  26,  25,  33,  66,  44,  56,  70,  57,   2,  77,\n",
      "         98, 136,  10,  76]) tensor([ 10,  62,   4,  64,  14,  90,  76,  15, 104,   2,   7,  73,  51,   4,\n",
      "         75,  11,  47,  57,  31,  26,  40,  83,  45,  59,  70,  59,   2,  79,\n",
      "        101, 137,  13,  80])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 10,  64,  21,  40,  21,   0,  45,  62,  86,   3,  73,  16,  49,  20,\n",
      "         72,  40,  67,  34,  54,  94,  11,  17,   6,   5,  47,  69, 121,   2,\n",
      "         52,  53,  40, 120]) tensor([ 11,  64,  24,  50,  25,   3,  64,  63,  86,   6,  75,  16,  52,  20,\n",
      "         79,  40,  94,  36,  65,  95,  19,  17,   6,   7,  60,  71, 121,   3,\n",
      "         53,  56,  41, 120])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 20,  13,   6,  21,   0,  42,  57,  99,   0,  89, 120,   7,  25,  25,\n",
      "         56,  28,  61,  26,   9,  88,  69,   0,   0,   9,   4,  10,  38,  15,\n",
      "         86,  70,  65,  25]) tensor([ 27,  16,  17,  24,   3,  43,  61, 101,   4,  94, 122,   8,  27,  36,\n",
      "         63,  31,  66,  28,  17, 101,  69,  22,   7,  11,   7,  10,  43,  21,\n",
      "        105,  70,  68,  25])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 83, 100,  70,  82,   7,  66,  43, 120, 121,   0,  58,  43,  70,  74,\n",
      "         35,  44,   2,  14,   0,  14,  96,   3,   0,  59,  51,  38,  13,  15,\n",
      "         67,  98,  41,  30]) tensor([ 92, 104,  70,  88,  14,  71,  52, 129, 125,   5,  58,  44,  72,  76,\n",
      "         39,  44,   2,  15,   1,  15, 111,   7,   4,  64,  52,  39,  14,  16,\n",
      "         70, 101,  46,  33])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  3,  58,   8,  79,  47,  64,  74, 128,  76,  21,   9,   0,  82,   0,\n",
      "         23,  98,  83,  51, 133, 102,  20,  61,   6,  62,  62,  45,  13,  13,\n",
      "         59, 104,   3,  94]) tensor([  7,  60,  12,  82,  49,  67,  76, 129,  78,  22,  23,   3,  85,   1,\n",
      "         26, 102,  87,  52, 135, 105,  22,  91,   7,  65,  66,  49,  18,  22,\n",
      "         61, 112,   4, 101])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  2,  69,  47,  48,  70,  46,  20, 105,  24,  62,  13,  11,  76,  29,\n",
      "         93,  18,  12,  91,  80,  49,  82,  25,   6,  22,  66,   3, 122, 115,\n",
      "         13,  73,  20,  13]) tensor([  7,  72,  47,  50,  71,  57,  24, 107,  26,  62,  14,  16,  76,  35,\n",
      "        101,  21,  12,  91,  83,  50,  82,  26,   9,  26,  66,   4, 126, 118,\n",
      "         15,  79,  22,  16])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13,  13,  25,  78, 101,   6,  23,  57,  89,  59, 108,   2,  45,  31,\n",
      "         38,  60,  20,  30,   3,  79,  76,  47,   8,  62,  62,   3,  33,  47,\n",
      "         67,  63,  51,  36]) tensor([ 23,  14,  28,  80, 105,   9,  25,  57,  93,  60, 111,   2,  45,  34,\n",
      "         38,  62,  22,  40,   6,  81,  80,  61,  15,  62,  69,   4,  33,  48,\n",
      "         68,  66,  54,  40])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 36,  61,  34, 105,  70,  36,   7,  94,  13,  95,  17,  33,  77,  38,\n",
      "         71,  69,  11,  60,  41,  49,  31, 103, 101,   4,  72,  12,  32,  77,\n",
      "         65,  40,  32,  30]) tensor([ 48,  67,  37, 105,  70,  55,  14,  96,  15, 104,  20,  33,  77,  45,\n",
      "         74,  73,  13,  62,  43,  57,  38, 105, 102,   6,  77,  13,  34,  78,\n",
      "         66,  42,  37,  32])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([13,  5, 94, 45,  4, 98,  6, 32, 30, 32, 12, 65, 85,  2, 68,  0,  6, 78,\n",
      "         9,  6, 39, 50,  4, 77, 16, 76, 36,  3, 98, 20, 36, 81]) tensor([ 13,   5,  94,  47,   5, 102,   7,  32,  30,  33,  16,  70,  88,   3,\n",
      "         88,   7,   7,  80,   9,   6,  40,  52,   4,  83,  17,  78,  39,  15,\n",
      "        101,  25,  39,  82])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 98,  37,  14,   7, 123,  14,  88,  42,  10,  67, 106,  45,   9,  62,\n",
      "         73,  36,   2,  31,  59,  65,  35,  23,   3,  14,  76,  23,  52,  66,\n",
      "         25,   8,  83,  69]) tensor([111,  48,  19,  12, 125,  17,  91,  46,  14,  70, 106,  51,  12,  69,\n",
      "         77,  42,   3,  31,  76,  66,  38,  29,   5,  16,  83,  26,  54,  66,\n",
      "         26,   9,  90,  82])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 68,  72,  39,  45,  90,  15,   7,  30,  11,  17,  96, 102,   2,  95,\n",
      "         80,  65,  31,  29, 116,   5,  88, 113,   0,  55, 117,  22,  72,  38,\n",
      "         19,  43,  11,  36]) tensor([ 70,  73,  47,  46,  93,  19,   9,  32,  11,  19, 101, 104,   8, 102,\n",
      "         85,  69,  35,  29, 117,  19,  95, 116,   6,  57, 120,  22,  77,  42,\n",
      "         20,  46,  12,  42])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 65, 104,   0,  21,   0,  16,  38, 129,   8,  16,  35,  37,   9,  78,\n",
      "         26,  89,  15,  75,  82,  59,  59, 101,  35,   2,  77,  47,  62,  21,\n",
      "         19,  67,  53,  50]) tensor([ 70, 105,   3,  30,   4,  19,  42, 132,   8,  17,  39,  38,  12,  78,\n",
      "         29,  97,  16,  76,  87,  60,  62, 101,  37,   3,  81,  47,  63,  22,\n",
      "         24,  67,  67,  52])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 72, 118,   8,   0,   6, 117,  71,  39,   2,  89,  98,  11,   6,  21,\n",
      "          5,   7,  86,  71,  16,  40,  70,   0,  45,  32,  78,   2,  33,  73,\n",
      "         93,  27,  37,  64]) tensor([ 72, 121,  16,   2,   9, 117,  72,  42,   2,  92, 101,  16,   6,  21,\n",
      "          7,  10,  97,  74,  19,  53,  71,   4,  47,  36,  86,   4,  35,  83,\n",
      "         96,  35,  40,  67])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13,  45,   0,  26, 106,  17,  92,   6,  89,  91,  28,  36, 116,  13,\n",
      "         36,  78,   2,  11,  54,  50,   9,   3,  26,  41,  94,  42,   0,  63,\n",
      "         19,   0,  52,  38]) tensor([ 14,  51,   6,  28, 107,  20, 117,  11, 134,  91,  34,  38, 119,  27,\n",
      "         37,  79,   4,  13,  54,  51,  12,   7,  46,  41,  96,  46,   5,  66,\n",
      "         22,   2,  58,  40])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  7,   8,  20,  34,   7,  56,  41,  55,  52,   0,  70,  82,  12,  28,\n",
      "         12,  21,   4,   7,  41,  67,  65,  39,  14,  43, 119,  14,   2,  42,\n",
      "         49,  38,  50,  59]) tensor([  9,  11,  29,  35,  10,  59,  43,  58,  57,   2,  73,  82,  33,  30,\n",
      "         12,  25,   5,   8,  44,  71,  66,  46,  14,  48, 119,  17,   3,  45,\n",
      "         50,  41,  59,  59])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 51,  16,  37,  20,  81,  44, 103,  80,  66,  87,  44,  10, 118,  37,\n",
      "         75,  58,  59,   6,  33,   4,  47,  57,  30,  70,  35,  18,  95,  16,\n",
      "         39,  25,  52,  43]) tensor([ 52,  18,  44,  25,  85,  48, 107,  80,  70,  90,  45,  16, 121,  37,\n",
      "         81,  61,  60,  15,  38,   4,  51,  57,  31,  75,  41,  19,  99,  17,\n",
      "         50,  27,  54,  44])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 57,   0,  22, 119,  12,  63,  19,  28,   0,  95,  53,   0, 108,   2,\n",
      "        105,  30, 108,  90,  10,  53,  18,  30, 113,  63, 136,  42,  16,  42,\n",
      "         49,   9,  51,  65]) tensor([ 59,  10,  24, 124,  13,  64,  21,  32,   4,  95,  57,   3, 116,   2,\n",
      "        116,  31, 109,  95,  12,  54,  18,  31, 114,  67, 139,  46,  17,  47,\n",
      "         51,  15,  65,  71])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 41,  41,  55,  71,  31,  86,  82,  99,  19,  12,  23,  24, 103,   0,\n",
      "         56,  79,  13,  40,  84,  20,   7,   0,  96,  15,  51, 104,  28,  59,\n",
      "         16,  27,  32,  19]) tensor([ 60,  42,  56,  73,  59,  91,  83, 101,  21,  16,  24,  25, 103,   7,\n",
      "         59,  84,  14,  42,  87,  20,  15,   1,  99,  19,  53, 106,  32,  60,\n",
      "         23,  27,  35,  20])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 45,  31,  36,  34,  21,  78,   8,  63,  95,  34,  13,  97,   0,  68,\n",
      "         28,  22,  87,  84,  82,   0, 108,   0,  59,  16,  76,  38,  31,  53,\n",
      "        112,  91,  69,  26]) tensor([ 52,  33,  41,  46,  22,  79,   8,  66,  95,  35,  14,  97,   6,  72,\n",
      "         29,  27,  92,  88,  84,   6, 109,   1,  62,  17,  76,  38,  31,  61,\n",
      "        120,  95,  70,  27])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 59,  63,  26,  83,   8,  47,  17,  10,  29,  60, 101, 128,  23,  25,\n",
      "         99,  55,  15,  28,  27,  22, 110, 114,  94,  35,  69,  66,  20,  43,\n",
      "         64,  45,  55,  11]) tensor([ 64,  68,  32,  86,  22,  48,  20,  14,  32,  61, 101, 128,  23,  26,\n",
      "        103,  58,  17,  32,  29,  28, 113, 120,  97,  41,  73,  67,  23,  47,\n",
      "         67,  45,  57,  23])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 56,  15,   2,  35,  84,  78,  80,  17,  21,  14,   0,   0,   2,  19,\n",
      "         19,  26,  21,  46,  32,  39,  10,  33,  59,   7,  18,  42,  49,  52,\n",
      "         60,   9, 114,   0]) tensor([ 67,  17,   5,  36,  86,  81,  80,  22,  24,  16,   6,   5,   4,  26,\n",
      "         22,  26,  25,  51,  41,  42,  12,  34,  61,   8,  20,  47,  52,  57,\n",
      "         61,   9, 121,   5])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 77,  32,  20,  35,  24, 135,  46,  24,  62,  67,  92,  24,  59,  21,\n",
      "         34,  16,  33,  53,  62,  39,  45,  39,   4,  82,  32,  42,  77,  23,\n",
      "          5,  18,  33,   7]) tensor([ 78,  33,  25,  37,  25, 135,  46,  25,  62,  68,  93,  27,  61,  23,\n",
      "         40,  39,  37,  54,  63,  40,  47,  47,   5,  84,  33,  51,  80,  26,\n",
      "          9,  21,  36,   8])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 21,  41,   2,  75,  30,   4,  53,  81,  41,  47,  47,  50, 122,  10,\n",
      "         37,   0,  66,  44,  49,   0,  23,  61,  83,  39,  30,  77,  70,   3,\n",
      "         54,  42,  12,  63]) tensor([ 32,  43,   5,  77,  30,  13,  54,  82,  41,  49,  48,  53, 154,  12,\n",
      "         38,   7,  70,  46,  53,   3,  30,  61, 106,  41,  33,  78,  76,   6,\n",
      "         55,  43,  13,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([62, 66, 51, 23, 15, 37, 22, 60, 16, 99, 73, 16, 18, 36, 88, 80, 77, 15,\n",
      "        75,  3,  7, 58, 86,  4, 12, 17, 59, 23, 47, 38, 82, 22]) tensor([ 63,  75,  53,  25,  15,  40,  25,  64,  18, 101,  76,  19,  22,  40,\n",
      "         91,  80,  79,  15,  84,   3,   8,  63,  98,   5,  14,  18,  59,  27,\n",
      "         48,  46,  83,  25])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 23,  29,  76,  19,   0,   0,  88,   8,   2,  58,  49,  67, 106,  96,\n",
      "         62,  83,  58,  59,  42, 120, 107,  64,  23,  11,  56,  14,  74,  15,\n",
      "         29,  40,   9,   0]) tensor([ 26,  32,  80,  22,   5,   1, 107,  11,   2,  59,  51,  69, 114,  98,\n",
      "         63,  83,  62,  59,  46, 120, 115,  72,  24,  11,  57,  18,  78,  22,\n",
      "         38,  45,  12,   4])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,  68,  34,  69,  41,  27,  83,  17,   1, 123,  54,  58,   8,  97,\n",
      "         41,  50, 114, 133,  14,  70,  35,  73,  50,   3,   5, 112,  27,   9,\n",
      "         85,  17,  42,   0]) tensor([ 13,  69,  35,  71,  44,  31,  86,  19,   1, 123,  57,  61,  10, 100,\n",
      "         46,  66, 114, 135,  17,  74,  37, 104,  53,   3,   6, 114,  27,  11,\n",
      "         87,  19,  52,   1])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 12,  84,  52,  40,  87,  93,  30,  19,  67,  19,  31,   2,   4,   6,\n",
      "          3,  60,  26,  54,  84,  69,  75,  89, 121,  81,   8,  22,  11,  18,\n",
      "         89,  84,  58,  27]) tensor([ 19, 105,  56,  49,  90,  99,  47,  19,  78,  25,  32,   3,   4,   9,\n",
      "          8,  72,  32,  54,  84,  71,  75,  92, 122,  82,  11,  22,  13,  18,\n",
      "         93,  96,  68,  27])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 69,  57, 101,   0,  99,  55,  95, 103, 111,  15,  23,  54,  15, 105,\n",
      "         62, 105,  30,  24,  30,  53,  73, 118,  49,  39,  29, 104,   8,  51,\n",
      "         12,  31,   5,   7]) tensor([ 71,  65, 102,   1, 100,  59,  99, 107, 117,  17,  26,  55,  16, 110,\n",
      "         69, 110,  34,  32,  31,  53,  77, 118,  49,  44,  44, 108,   8,  58,\n",
      "         18,  32,   5,   9])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 21, 108,  79,  65,  15,  36,  10,  26,   5,  21,  96, 100,  53,  83,\n",
      "         20,  46,  23, 104,  31, 137, 103,  77, 122,  83,  88,  66,  34,  71,\n",
      "         24,  43,  34,  73]) tensor([ 24, 110,  84,  74,  17,  37,  12,  28,  14,  21,  99, 102,  55,  86,\n",
      "         21,  51,  25, 108,  36, 144, 106,  78, 123,  85,  90,  71,  39,  75,\n",
      "         27,  43,  40,  79])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 53,   9,  65,  39,  59,  68,   0,  46,  14,  25,  32,  45, 127,  99,\n",
      "         13,  74,  10,  50,  11,  50,  28,  59,  29,   2, 127,  73,  34,   0,\n",
      "         33,  89,  13,  40]) tensor([ 55,   9,  69,  42,  59,  70,   3,  52,  14,  28,  39,  48, 129, 108,\n",
      "         13,  76,  17,  52,  12,  70,  29,  60,  31,   2, 132,  76,  39,   3,\n",
      "         33,  93,  16,  41])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8,  14,   8,  29,  57,  17,  98,  75, 104, 118,  34,   2,  15,  18,\n",
      "         82,  51,  43,  85,   2,  14,   0,   8,  51,  20,  57,  34,  49,  10,\n",
      "        158,  76,  97,  19]) tensor([ 11,  17,  10,  32,  59,  22, 101,  77, 121, 119,  40,   2,  15,  18,\n",
      "         92,  55,  46,  86,   4,  15,  22,  11,  54,  22,  59,  35,  52,  13,\n",
      "        159,  77, 101,  20])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  2,  98,  24,   7,  87,  46,  20, 145,  84,  48,   0,   2,  55,  31,\n",
      "         69,  47,   4, 106,  45,  44,   0,  25,  88,  25,   9,  38,  59,  29,\n",
      "         59,  24,  31,  52]) tensor([  2,  99,  29,   7,  88,  50,  22, 147,  85,  50,   1,   3,  57,  31,\n",
      "         78,  48,   7, 114,  46,  48,   1,  27,  88,  29,  14,  43,  59,  32,\n",
      "         64,  34,  35,  66])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 25,  48,  94,  50,  32,   8,  83, 104,   0,  82,  36,   0,   9,   2,\n",
      "         77,  23,  19,   0, 124, 108, 105,  59,  18,  44,   9,   2,  38,  19,\n",
      "         56,   5,  57,  61]) tensor([ 30,  50,  98,  53,  35,   9,  86, 115,   6,  91,  38,   3,  13,  11,\n",
      "         79,  46,  37,   4, 130, 118, 107,  63,  20,  46,  17,   2,  41,  21,\n",
      "         59,  14,  65,  67])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 29,   4,  44,  20,  85,  79, 113,  66,   6,  91,  99, 107,  60,  90,\n",
      "         73,   8,  74,  95,  73,  25,  76,  34,  57,  23,   3,  12, 105,  79,\n",
      "         25,   8,  25,  26]) tensor([ 37,   9,  46,  20,  86,  81, 117,  71,   9,  93, 100, 107,  64,  97,\n",
      "         75,  18,  81,  95,  75,  31,  78,  41,  63,  24,   3,  13, 106,  80,\n",
      "         28,   9,  27,  35])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,  34,  44,  49,  47,  57,  52,   4,  11,  58,  95,  69,  82,  11,\n",
      "         29,  67,  79,  55,  55,  89,  30,  46,  19,  41, 117,  70,  26,  12,\n",
      "         61,  26,  25,  85]) tensor([ 22,  35,  52,  53,  50,  77,  59,   4,  15,  62,  95,  70,  85,  13,\n",
      "         31,  73,  80,  56,  59,  91,  34,  49,  28,  42, 117,  74,  27,  16,\n",
      "         64,  31,  26,  88])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 40,  83,   2,  96, 127,  24,  10,  77,  48,  76,  28,   7,  97,  21,\n",
      "         75,  29,   9,  58,  10,  13,  25,  40,  71,  40,  78,  54,  38,   7,\n",
      "         19,  42,  61,  36]) tensor([ 41, 106,   6, 122, 128,  30,  11,  78,  51,  80,  38,   9, 115,  24,\n",
      "         75,  34,  10,  62,  13,  14,  25,  48,  72,  49,  90,  57,  38,  12,\n",
      "         21,  47,  63,  46])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  9,   5,  93,   9,  66,  50,  29,  13,   9,   2,  22,  24,  26,  13,\n",
      "         11,  16,  54,  13,  37, 105,  59, 107, 112,  16,  73,  48,  86,  28,\n",
      "          0,  87,  84,  41]) tensor([ 18,   7,  94,  11,  67,  51,  31,  13,  15,   4,  23,  27,  27,  16,\n",
      "         12,  17,  61,  16,  39, 113,  59, 110, 122,  21,  73,  49,  87,  40,\n",
      "          4,  89,  86,  49])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  3,  36,  27,   8,  57,  11, 108,   4,  46,  56,   3,   8,  21,  89,\n",
      "         19,  24,  92,  17,  75,  35,  62,  39,  98,  27,   6,  62,  21,  85,\n",
      "         41,  42,  90,   6]) tensor([  7,  39,  29,   8,  58,  13, 111,   5,  48,  61,   6,   9,  37,  93,\n",
      "         22,  26,  93,  17,  89,  38,  64,  42,  98,  32,   6,  64,  38,  86,\n",
      "         44,  43,  92,   7])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 72,  30,   0,  59,  68,  85,  33,  80,  27,  17,  23,   0,  91,  27,\n",
      "         86,  67,  20,  26,  23,   9,  87,  10,  46,  44, 109,  93,  33,  12,\n",
      "        118,  30,  27,  37]) tensor([ 74,  32,   6,  62,  71,  85,  34,  82,  29,  17,  25,   4,  95,  28,\n",
      "         89,  68,  23,  28,  24,  16,  90,  11,  46,  47, 116,  93,  47,  12,\n",
      "        123,  34,  27,  38])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 38,  21,  60,  20,  69,  53, 121,  24, 109,  21,  11,  20,  14,  87,\n",
      "          0,  23,  51,  98,  54,  14,  94,   2,  46,  76,  22,  10,  59,  31,\n",
      "         22,  30,  65,  36]) tensor([ 38,  28,  62,  22,  72,  58, 122,  30, 115,  22,  13,  23,  14,  88,\n",
      "          2,  25,  63, 103,  55,  20,  96,   8,  57,  81,  26,  15,  60,  34,\n",
      "         24,  36,  65,  38])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 15,  14,  77,   2,  21,  91,  19,  53,  30, 109,  34,  11,  23,  60,\n",
      "         23,  72,  40,  50, 118,  71,  63,  79,  82,  12, 104,  54,  25,  28,\n",
      "         23,  38,   4,  62]) tensor([ 18,  16,  80,   2,  28,  91,  19,  54,  34, 114,  46,  13,  27,  65,\n",
      "         34,  75,  40,  56, 119,  72,  64,  83,  85,  16, 107,  60,  26,  35,\n",
      "         25,  41,   6,  72])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,   7,   4,   0,  87,   6,  24,   4,  47, 109,  12,  89,  37,  38,\n",
      "        109,   9,  63,  55,  45,  35,  20,  38,  45,  39,  11,  53,  20,  16,\n",
      "         61,  32,   7,  11]) tensor([  4,  13,   4,   2,  88,  12,  27,   7,  49, 113,  12,  89,  38,  39,\n",
      "        110,  12,  84,  58,  49,  36,  35,  38,  45,  41,  14,  54,  25,  21,\n",
      "         62,  33,  10,  14])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 84, 112,  88,  45,  13,  60,  94,   2,  26, 100,  97,  34,  85,  44,\n",
      "         26,  36,  46,  76,   0,  68,  12,  12,  34,  18,   8,   5,  50,  88,\n",
      "         67,   0,  44,   2]) tensor([ 87, 112,  90,  47,  14,  60,  95,   6,  29, 102,  99,  37,  85,  48,\n",
      "         48,  36,  47,  77,   8,  72,  15,  16,  36,  21,  14,   6,  52,  90,\n",
      "         69,   5,  45,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([108,  11,  45,  66,  31, 112,  46,  45,  41,  60,   6,  45,  40,  18,\n",
      "         79,  75,  65,  51,  14,  19,  38,  56,  73,  35,  17,  36,  55,  10,\n",
      "         17,   0, 100,  38]) tensor([110,  12,  58,  67,  33, 114,  49,  47,  57,  63,   9,  45,  41,  19,\n",
      "         81,  77,  65,  53,  15,  22,  38,  61,  74,  37,  21,  36,  65,  11,\n",
      "         22,   8, 106,  38])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([92, 18, 24, 33,  4, 11, 51, 32, 39, 14, 77, 66, 81, 71, 68, 43, 42, 87,\n",
      "        18, 35, 38, 16, 43, 40, 23, 59, 22, 32, 14, 15, 56, 17]) tensor([95, 19, 25, 36, 11, 12, 51, 37, 41, 18, 90, 74, 82, 76, 71, 46, 45, 90,\n",
      "        18, 38, 39, 21, 44, 42, 53, 60, 25, 35, 16, 25, 70, 23])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,  41,  42,  11,  40, 106,  64,  62,  88,  63,  89,   4,  14,  31,\n",
      "          0, 111,  19,  19,  16,  51,   7, 104,  61,  83, 114,  97,  25,  86,\n",
      "         21,  58,  33,  24]) tensor([  6,  45,  44,  15,  40, 107,  64,  66,  91,  66,  91,   9,  15,  31,\n",
      "          2, 113,  20,  24,  19,  58,  13, 106,  65,  87, 116,  98,  25,  88,\n",
      "         21,  60,  34,  26])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 27,  10, 104,  91,  22,  84,  81,   7,  69,  30,   8,  75,  19,  20,\n",
      "        113,  25,  96,  55,   0,   7,  56,  64,  44,  91,  74,  64,  93,  16,\n",
      "        122,  13,  85,  41]) tensor([ 27,  11, 105, 107,  24,  86,  83,   9,  74,  32,  22,  81,  21,  30,\n",
      "        118,  46, 105,  57,   1,   9,  60,  87,  46,  92,  74,  66,  98,  34,\n",
      "        123,  16, 110,  42])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 14,  91,  34,   4,  78,  91,  64,  49,  49,  37,  93,  71, 103,   9,\n",
      "         95,  29,   4,  57,  26,  57,  34,  94,   5,  10,  51,  37, 104,  89,\n",
      "         85,  20,  34,  67]) tensor([ 17,  92,  39,   5,  83,  93,  69,  55,  58,  38,  96,  74, 115,  11,\n",
      "         98,  33,   8,  59,  28,  68,  38,  96,   8,  15,  51,  40, 105,  90,\n",
      "         94,  24,  36,  80])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([100,  16,  58,  28,   3, 100,  31, 100,  11,  70,  75,  87,  21,  27,\n",
      "         41,  40, 118,  87,   2, 116,  38,  32,  18,  26,  89,  51,  36,  26,\n",
      "         59,  29,  11,  23]) tensor([101,  18,  60,  30,   3, 102,  31, 105,  11,  72,  77,  88,  25,  38,\n",
      "         44,  41, 122,  93,   5, 118,  39,  40,  19,  31,  92,  54,  37,  26,\n",
      "         63,  33,  17,  26])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 47, 105,   2,   0,  70,  28,  49,  63,  26,  39,   8,  95,  61,  40,\n",
      "         13,  16,  44,  13, 103,  36,  91,  22,  76,  44,   5, 106,   6,  86,\n",
      "         92,  17,  30, 109]) tensor([ 47, 108,   7,  21,  71,  29,  54,  67,  26,  41,   9, 110,  61,  41,\n",
      "         15,  21,  49,  15, 106,  36,  93,  24,  80,  47,   7, 112,   8,  93,\n",
      "         97,  20,  32, 109])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 54,  51,  36,   0,  30,  90,  25,  41,  95, 106,   6,  41,  52,  74,\n",
      "         26,  58,  24,  67,  10,  10,   7,  16,  18,  86,  48, 150,  53,  46,\n",
      "          2,  41,  48,   7]) tensor([ 56,  52,  51,   1,  38,  95,  42,  44,  97, 114,  15,  43,  57,  74,\n",
      "         26,  62,  26,  73,  11,  13,   9,  21,  20,  89,  48, 153,  60,  56,\n",
      "          2,  49,  49,  10])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 67,  39,  74,  39,  38,   6, 114,  18,  44,  18, 108,  13,   7,  34,\n",
      "         71,  20,  10,   0,  14,  30,  71,  86,  20,   7, 104,  32,  31,   9,\n",
      "        108,   2, 114,  55]) tensor([ 71,  43,  76,  40,  39,   6, 117,  26,  45,  20, 110,  18,  40,  40,\n",
      "         71,  23,  10,   2,  23,  31,  71,  86,  28,  10, 106,  34,  35,  10,\n",
      "        110,   4, 115,  57])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  3,  34,   0,  12,  58, 125,  92,  50,  95,  14, 120,  19,  28,  51,\n",
      "         73,   2,  39,  40,  91,  28,  54,  35,  16,  56,  18,  35, 120,   3,\n",
      "         25,  28,  63,  21]) tensor([  5,  37,   5,  13,  62, 127, 115,  54,  96,  21, 123,  22,  31,  51,\n",
      "         73,   4,  39,  40, 101,  29,  59,  36,  29,  56,  18,  36, 125,   3,\n",
      "         27,  30,  63,  29])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,  84,  13,   0,  84,  85,  50,   0,  21, 124,  21,  83,  87,  90,\n",
      "         21,  86,   0,  44,  18,  91,   8,  56,   5,  26,  30,   0,  33,  42,\n",
      "          2,  54,   9,   3]) tensor([  4,  85,  13,   2,  85,  87,  50,   1,  30, 126,  25,  85,  92,  90,\n",
      "         23,  87,  35,  47,  32,  97,   9,  56,   7,  26,  32,   2,  37,  42,\n",
      "          7,  81,  14,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([54, 22, 68,  4, 74, 41, 69, 23, 24, 27, 12, 87, 22, 69, 67, 20, 99,  0,\n",
      "        27, 33, 11,  5, 38, 99, 67, 24,  4, 24, 50, 15,  0,  9]) tensor([ 60,  23,  71,   7,  75,  49,  70,  36,  25,  36,  19,  88,  22,  69,\n",
      "         67,  27, 101,   4,  40,  34,  15,   5,  39, 101,  74,  24,   7,  27,\n",
      "         66,  16,   4,   9])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 68,   4,  26,  86,  96, 122,  63,   0,  44,   4,  64,  49,   0,  57,\n",
      "         13,  10,  46,  85,  40,  49,  86,  88,  73,   8, 104, 126,  82,  75,\n",
      "         40,  66,  58,  64]) tensor([ 71,   6,  28,  86,  97, 123,  68,  15,  47,   9,  65,  52,   1,  60,\n",
      "         14,  16,  47,  92,  41,  51,  90,  91,  74,  14, 104, 127,  85,  79,\n",
      "         56,  68,  62,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 36,  14,  18,  56,   8,   7,  90,  83,  46,  27,  32,  43,  18,  91,\n",
      "         30,  41,  20,  49,   3, 147,  80, 105,  82,  25,  81,   6,  48,   2,\n",
      "         11,  76,  50,   8]) tensor([ 38,  17,  31,  56,  16,   8,  90,  86,  49,  27,  33,  45,  21, 102,\n",
      "         33,  43,  21,  50,   4, 148,  81, 105,  83,  33,  83,  10,  53,   3,\n",
      "         12,  78,  52,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 43,  34,  87,  84,  35,   2,  67,  37, 116,   9,  39,  18, 104,  43,\n",
      "         24,  59,  47,  55,  30,  97,  19,  99,  34,  60,  16,  33,  19,  76,\n",
      "         60,  27,  73,  60]) tensor([ 47,  37, 100, 106,  37,   5,  68,  40, 120,  10,  39,  20, 108,  53,\n",
      "         37,  65,  50,  64,  32,  97,  19, 103,  35,  60,  21,  36,  22,  76,\n",
      "         61,  42,  89,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 92,  38, 127,  10,  45, 101, 118, 126,  30,  21,  61,  33,  55,  24,\n",
      "         11,  62,  31,  60,  27,  24,  15,  15,  71,  43,  11,  92,  65,   8,\n",
      "         23,  53,  36,  93]) tensor([ 95,  41, 128,  11,  55, 102, 119, 134,  33,  26,  62,  35,  59,  24,\n",
      "         14,  78,  35,  65,  27,  29,  20,  16,  77,  45,  13,  93,  68,  10,\n",
      "         25,  53,  38,  95])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 54,   0,  31,  80,  23,  58,  79, 120, 106, 100, 108,  26,  40,   5,\n",
      "          0,  86,  91,  13,  40,  43,  59,   0,  12,  46,  80,  16,   3,  53,\n",
      "         22,  73,  14,  13]) tensor([ 60,   4,  35,  84,  25,  58,  79, 123, 106, 103, 124,  36,  42,   5,\n",
      "          2,  89,  98,  25,  43,  45,  59,   5,  17,  46,  98,  17,   5,  58,\n",
      "         22,  76,  15,  13])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 78,  32,  22,  32,  27,  24,  19,  19,  24,  55,  36,  47,  44,  12,\n",
      "         21, 101,  63,  68,  33,  28,  76,  64,  30,   2,  42,  42,  37,   9,\n",
      "         30,  31,  38,  12]) tensor([ 87,  32,  23,  33,  27,  27,  31,  42,  25,  58,  40,  51,  45,  18,\n",
      "         21, 103,  64,  71,  34,  29,  77,  69,  40,   9,  51,  44,  57,  12,\n",
      "         36,  45,  38,  18])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 52,   3, 101,  48,  79,  55, 108,  61,  56,  24,  60,  68,  38,  78,\n",
      "         73, 127,  24,   2,  58,  24, 112,  91,  74,  62,   5,  27,   5,  42,\n",
      "         36,   0,  73,   0]) tensor([ 57,   4, 105,  51,  82,  62, 115,  65,  59,  27,  64,  80,  44,  84,\n",
      "         76, 129,  27,   5,  60,  24, 113, 102,  77,  63,   6,  27,  11,  44,\n",
      "         37,   1,  76,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8,  96,  11,  65,  67,  88,  64, 107,  52,   7,  68,  97,  42,  55,\n",
      "        100,  23,   2,   0,  14,  48,  93,  39,  39,  51,  34,  12,  42,  81,\n",
      "         21,  23,  28,  58]) tensor([  8, 100,  13,  65,  69,  89,  76, 109,  58,  18,  71, 105,  44,  57,\n",
      "        101,  36,   3,   5,  15,  50,  94,  43,  43,  52,  41,  13,  44,  83,\n",
      "         25,  25,  30,  66])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 58,  11,  79,   7,   4,  27, 101,  25,  35,   4,   5, 121, 115,  32,\n",
      "          2,   6,  30,  24,  27,  28,  54,   8,  88,  30,  45,  38,  24,  16,\n",
      "        120,  99,  38,  45]) tensor([ 58,  14,  79,   7,  10,  29, 101,  29,  37,   7,   9, 125, 117,  33,\n",
      "          2,   7,  39,  26,  28,  30,  65,  13,  89,  31,  57,  41,  27,  20,\n",
      "        123, 113,  40,  56])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 38,  35,  22,  47,   5,  15,  33,  86,  53,   2,  46,  22,  61,  31,\n",
      "         23,  48,  48, 100,  91,   0,  34,   3,   9, 106,  40,  22, 104,  12,\n",
      "         14,  10,   9,  15]) tensor([ 39,  36,  25,  48,   5,  19,  33,  89,  54,   2,  51,  24,  61,  38,\n",
      "         28,  72,  50, 105, 139,   9,  38,   5,  14, 119,  41,  22, 105,  12,\n",
      "         15,  12,   9,  16])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 53,  59,  71,  26,  34,  26,  31,  43,  14,  28,  15,  45,   0,   0,\n",
      "         90,  24, 115,  44,  10,  40,  84,   0,  44,   5,  37,  97,  25,  37,\n",
      "         89,  35,  15,  40]) tensor([ 57,  64,  75,  32,  34,  28,  32,  47,  15,  39,  19,  51,   6,   3,\n",
      "         93,  30, 118,  46,  15,  41,  84,   4,  48,  33,  43,  99,  25,  40,\n",
      "         92,  37,  20,  43])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  76,  18,  55, 119,   9,  95,   4,  13,  13,   9,  60,  28,  29,\n",
      "          0,  69,  62,  75,   0,  11,  93,  30,  18,  43,  34,  15,  22,   2,\n",
      "         14,  50,  29,  60]) tensor([ 19,  78,  25,  56, 128,  11,  96,   9,  13,  16,  11,  67,  32,  31,\n",
      "          1,  72,  64,  77,   3,  14,  98,  33,  18,  45,  50,  16,  22,   4,\n",
      "         16,  56,  32,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([103,  76,   7,  80,  30,  25,  94, 101,   0,  71, 118,  39,  84,  21,\n",
      "          9,  98,   3,  34,  17,  76,   2,  17,  63,  44,  84,  11,   8,  24,\n",
      "         40,  11,  19,  56]) tensor([103,  82,   7,  83,  33,  26, 100, 105,   1,  72, 120,  39,  98,  23,\n",
      "         15, 101,   5,  35,  17,  79,   4,  29,  65,  47,  85,  18,  12,  26,\n",
      "         41,  17,  29,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 77,  16,  83,   0,  93,  79,  75,  37,  66, 104,  54,  78,  44,   5,\n",
      "         22,  31, 138, 111,  23,  32,  94,  33,  46,  12,  12,  12,  90, 118,\n",
      "         70,   2,  48,  86]) tensor([ 79,  22,  83,   3,  93,  84,  77,  46,  71, 109,  54,  81,  45,   7,\n",
      "         24,  32, 142, 114,  37,  32,  97,  36,  46,  14,  14,  13,  92, 122,\n",
      "         72,   3,  48,  96])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 29,  47,  34,  18,  16,   6,   0,  65, 106, 117,  28,  83,  80,   0,\n",
      "         38,  45,  10,   8, 131,  66,  12,   2,  57,  73,   2,  20,  94,  16,\n",
      "        111,  84,  44,   0]) tensor([ 32,  50,  46,  20,  19,   7,   2,  69, 114, 121,  32, 103,  85,   6,\n",
      "         39,  49,  10,  12, 132,  72,  15,   2,  57,  73,   3,  22,  95,  16,\n",
      "        122,  89,  44,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 58,  17,  63,  36,  30,   2, 148,  28,  59,   0,   8,  69,  74,  73,\n",
      "         79,  29,  33,  31, 125,  22,  99, 119,   2,  99,  22,  29,  10,   0,\n",
      "         29,  79,  30, 109]) tensor([ 59,  17,  65,  45,  33,   2, 149,  30,  65,   6,  11,  74,  74,  76,\n",
      "         85,  30,  35,  34, 128,  37, 100, 125,   4,  99,  23,  33,  12,   2,\n",
      "         31,  93,  32, 113])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,   5,  57,  11,  49, 131,  64,  75,   7,  10, 121,  90,  28,  52,\n",
      "         60,  44,  15,  80,  42,   6,   0,  19,  13,  54,   8,  73,  16,  57,\n",
      "         27,  23,  16,  79]) tensor([ 24,   7,  58,  13,  51, 131,  66,  76,   8,  43, 121,  91,  31,  54,\n",
      "         64,  45,  16,  82,  46,   6,   2,  22,  17,  55,   9,  81,  18,  62,\n",
      "         28,  31,  22,  80])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  9,  51,  64,  58,  65,  41,  22,  46, 104,   0,  20,  49, 103,  41,\n",
      "         66,   0,  26,  53,   6,  45,   0,  79,  73,  21,  35,   9,  46,   2,\n",
      "         33,   4, 134,  39]) tensor([  9,  52,  73,  64,  69,  41,  26,  46, 106,   1,  20,  52, 104,  41,\n",
      "         90,   3,  30,  56,   9,  49,   1,  85,  78,  24,  37,  11,  51,   4,\n",
      "         35,  27, 138,  42])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 48,  86,  32,  39,  29,  25,  66,  33,  57,  16,  64,  52,  26,  16,\n",
      "         84,  13,  16,   6,  31,  79,  40,  75,  39, 103, 105,  16,  18,  90,\n",
      "         68,   9,  19,  21]) tensor([ 49,  91,  36,  42,  32,  25,  79,  37,  57,  18,  71,  52,  28,  17,\n",
      "         87,  16,  19,   8,  37,  85,  40,  75,  39, 106, 106,  23,  18,  91,\n",
      "         69,  13,  22,  21])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([28,  0,  0, 69, 54,  2, 21,  8, 45, 65,  9, 68, 30, 23,  7, 10, 98, 27,\n",
      "        20, 40, 53,  2, 17, 85,  8, 16, 10, 24, 88, 24, 99,  4]) tensor([ 32,   5,   2,  69,  62,   5,  21,   9,  48,  67,   9,  73,  35,  25,\n",
      "         10,  13,  98,  31,  21,  41,  57,   6,  20,  98,  10,  22,  16,  25,\n",
      "         98,  27, 103,   5])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 49,  20,  51,   6,  56,  95,  46,  50,  39,  19,  55,  16, 122,   0,\n",
      "         94,  19,  46,  25,  23,   0,  40,   5,   0,  53, 103,  13,   2,  16,\n",
      "         45,  44,  60,   5]) tensor([ 51,  23,  55,   9,  59,  95,  48,  57,  46,  25,  59,  28, 125,  16,\n",
      "         94,  22,  47,  29,  24,  11,  43,  15,   6,  56, 105,  17,   2,  16,\n",
      "         47,  44,  60,  14])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 88,  17,  93,  21,  52,  94,  34,  48,  11,  46,  35,  37,   8,  84,\n",
      "         49,  82,  58,  71,  46,  57,  89, 101,  80, 113,   9,  41,  67,   8,\n",
      "         19, 119,  14,  16]) tensor([ 91,  39, 101,  23,  53,  98,  35,  52,  16,  48,  38,  38,  13,  89,\n",
      "         50,  98,  60,  72,  49,  59,  91, 104,  81, 113,  11,  43,  69,   9,\n",
      "         20, 121,  15,  21])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 84,  19,  86, 103, 123,  16, 101,  60, 119,  93,   2,  22,   0, 104,\n",
      "         17,  85,   6,  55,  28,  55,  48,  68,  56,  36,  35,  45,  44,  78,\n",
      "         61,  17,  38,   2]) tensor([ 86,  21,  92, 104, 123,  22, 101,  71, 125, 101,   3,  22,   2, 118,\n",
      "         23,  85,   6,  58,  32,  55,  48,  69,  57,  38,  39,  48,  48,  82,\n",
      "         66,  21,  41,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 78, 106,   8,  42,  65,   0,  56,   2, 109,  61,  33, 104,   4,  48,\n",
      "          2,  18,  44,   3,  11,  50,  29,   9, 102,  34,  49,  20,  62,  54,\n",
      "         40,  60,  63,  63]) tensor([ 93, 111,  15,  44,  68,   3,  56,  15, 112,  66,  37, 107,   8,  48,\n",
      "          3,  19,  46,   3,  16,  51,  34,   9, 103,  36,  56,  25,  63,  58,\n",
      "         44,  61,  71,  63])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 30,  43,  33,  13,  39,   3,  45, 137,  83,  91,  15,  12,  47,  47,\n",
      "          3,  38, 102,  26,   2,  55,  60,  15,   0,  20,  61,  18,  30,  23,\n",
      "         33,  33,  52,  41]) tensor([ 31,  53,  35,  14,  68,   3,  46, 141,  86, 112,  18,  12,  48,  49,\n",
      "          4,  42, 112,  27,  27,  58,  60,  16,   3,  23,  61,  20,  32,  24,\n",
      "         33,  40,  64,  42])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 35,  11,   6,  47,  35,  23,   2, 104,  39,  19,  94,  68,  47,  64,\n",
      "         25,  53,   5,  61,   6,   4,  42,  67, 119,   7,   0,  30,  43,  25,\n",
      "         25,  57,  53,  68]) tensor([ 35,  15,   6,  49,  35,  24,   7, 104,  40,  19,  96,  70,  47,  72,\n",
      "         32,  57,   7,  66,   8,   4,  44,  68, 126,   7,   9,  33,  45,  25,\n",
      "         28,  59,  63,  70])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 10,  10, 102,  16,  12,  27,  39, 109,  41,  56,  46,  93,  39,   6,\n",
      "        107,  25, 117,  92,   8, 113,  30,  23,  35,  57,   9,  11,  13,  11,\n",
      "         78,   2,  68,  42]) tensor([ 13,  11, 107,  18,  13,  41,  42, 110,  43,  56,  52,  95,  52,  10,\n",
      "        112,  29, 119,  93,   8, 117,  32,  28,  40,  61,  11,  17,  14,  15,\n",
      "         83,   6,  69,  46])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 26,  28,   4,  26,  15,  46,  23,  64,  13,  91,  86,  30,  94,   0,\n",
      "         20,   2,  47,  80,  43,  38,  27,  31,  69,  22,  21,  63,  26,  14,\n",
      "          0,  17,  89, 104]) tensor([ 30,  28,   9,  39,  32,  46,  24,  64,  29, 107,  92,  30,  99,   3,\n",
      "         34,   2,  48,  84,  43,  38,  39,  33,  71,  25,  22,  78,  30,  15,\n",
      "          4,  17,  90, 104])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([104,  37,   2,  49,  65,  41,  84,  11,  72, 125,  66,  42,  71,  73,\n",
      "         78,  21,  15,   0,  63, 104,   9,   8,  67,   2,  10,   9,  67,  35,\n",
      "         12, 120,  70,   2]) tensor([104,  38,   2,  51,  75,  45, 101,  12,  77, 126,  68,  44,  80,  75,\n",
      "         81,  30,  20,   8,  64, 105,  12,  10,  73,   5,  11,  14,  67,  39,\n",
      "         12, 121,  71,   5])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  10, 101,  76,   8,  19,  30,  54,  73,  63,   0, 117,  37,  89,\n",
      "         73,  37,  95,  37,   2,  36,  62,  20,   8, 121,   4,  86,  11,   0,\n",
      "         48,  23, 100,   9]) tensor([  8,  23, 101,  79,  10,  19,  48,  57,  74,  72,  10, 119,  45,  89,\n",
      "         75,  41, 100,  39,   6,  38,  64,  22,  11, 124,  14,  89,  11,  34,\n",
      "         48,  25, 101,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 24,  66,  35,  93,  54,  88,  47,  38,  59,  70,  77,   2,  36,  27,\n",
      "         15,  67, 118,  86,  63,  11,  36,  33,  50,  45,  27,  44,  47,   6,\n",
      "         32,   7,  47,  76]) tensor([ 26,  79,  37,  96,  54,  90,  47,  41,  65,  72,  80,   2,  38,  28,\n",
      "         18,  70, 132,  89,  69,  13,  39,  35,  54,  46,  30,  47,  47,   6,\n",
      "         40,  14,  51,  76])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([13, 52, 51, 38, 67, 79, 75, 68, 79, 55, 80, 23,  2, 80, 42, 65, 81, 45,\n",
      "        50, 26, 56, 95, 14, 40, 53,  6, 93, 38,  0, 13, 92, 94]) tensor([14, 54, 57, 39, 70, 79, 79, 69, 88, 59, 82, 24,  2, 84, 43, 65, 82, 45,\n",
      "        61, 29, 61, 96, 31, 44, 55,  8, 98, 40,  2, 13, 99, 95])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,  59,  16,  25,  51,  20,  62,  67,  58,  29,  73,  77,  22,  56,\n",
      "          2,  74,  10,  11, 100,  62,  95,  57,  71,   7,  40,  19,  31,  22,\n",
      "         28, 105,   0,  55]) tensor([ 14,  79,  16,  25,  54,  24,  69,  68,  59,  33,  74,  86,  24,  56,\n",
      "          2,  81,  12,  11, 104,  62,  99,  61,  71,   9,  42,  19,  36,  41,\n",
      "         34, 110,   4,  56])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  6,  60,  19,   6,   3,  13,   4,   6,  81,  88,  49,  24,   0,  49,\n",
      "          8,  51,  23,  62,  29,  28,  63,  88,  65, 102,   0,  98,  59,  10,\n",
      "        137,   0,   6,   6]) tensor([  8,  71,  23,   6,   5,  21,   6,   6,  81,  94,  72,  24,   4,  51,\n",
      "         12,  54,  29,  66,  29,  28,  63,  95,  68, 108,   4, 106,  64,  10,\n",
      "        144,   1,   9,   6])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  22,  75,  62,   0,  32,  22,  22,  68,  11, 107,  19,  32, 119,\n",
      "         42,  75,  57,   6,  30,  16,  37,  15,  15,  91,  27,  72, 100, 116,\n",
      "         66,  23, 109,  47]) tensor([  7,  23,  75,  63,   2,  35,  26,  30,  68,  13, 108,  20,  32, 120,\n",
      "         44,  77,  63,  12,  32,  16,  38,  22,  17,  94,  35,  88, 102, 121,\n",
      "         83,  29, 116,  47])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([109,  70,  26,   6,  40,  73,  48,  44,  46,   4,  30,  28,  50,  10,\n",
      "         40,   5,   5,  74,  89,   0,  38,  44,  28,   2,  45,  80,  52,  18,\n",
      "         54,  45,  54,  46]) tensor([114,  73,  33,   7,  42,  76,  49,  45,  47,   4,  36,  28,  54,  15,\n",
      "         41,   7,   6,  75,  90,   4,  40,  62,  29,   2,  49,  83,  55,  20,\n",
      "         56,  47,  55,  48])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([100, 118, 118,  16,  37,  16,  59,  42,  42,  45,  34,  34,  97,   0,\n",
      "         36,  17,  14,  20,  16,  24,  55,  69,  60,  91, 101,  46,  42, 120,\n",
      "         41,  51,  87,  96]) tensor([101, 132, 119,  20,  39,  19,  59,  43,  44,  45,  37,  41, 111,  26,\n",
      "         42,  27,  18,  23,  16,  29,  56,  76,  78,  92, 119,  47,  42, 120,\n",
      "         43,  62,  90, 101])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 15,  78,  13,  22,   7,  67, 115,  66,  32,   4,  45, 146,  31,  74,\n",
      "         31,  46,  72,  89,  34,  63,  16,  34,  98,  62,  84,  29,   0,  15,\n",
      "         49,  10,  48,  73]) tensor([ 16,  82,  17,  23,  10,  68, 125,  72,  36,   4,  50, 147,  32,  74,\n",
      "         32,  53,  72,  90,  37,  66,  27,  36,  99,  62,  84,  29,   4,  24,\n",
      "         50,  10,  50,  76])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 68,  52,  74,  23,  65,  10,  79,  62, 108,  35,  39,  33,  80,  11,\n",
      "          0,  28,  63,  90,  31,  35,  20,  79,   3,  33,  25,  45,  52,  45,\n",
      "         63,  11,  89, 109]) tensor([ 73,  52,  74,  26,  67,  12,  81,  63, 111,  37,  39,  34,  80,  17,\n",
      "          4,  28,  68,  93,  34,  38,  24,  80,   8,  36,  27,  46,  56,  45,\n",
      "         67,  12,  96, 110])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8,  70,  29,  77,  29, 110,  36,  36,  28,  13,  72,  12,  32,  56,\n",
      "          6,  35,  22,  21, 102,  65,  20,   9,  34,  21,   5,  69,  20,  31,\n",
      "         45,   7,  36,  74]) tensor([ 15,  73,  31,  79,  41, 112,  50,  49,  43,  15,  73,  12,  32,  60,\n",
      "         17,  38,  27,  22, 103,  71,  20,  12,  34,  22,   5,  74,  21,  34,\n",
      "         69,   7,  36,  90])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13,  38,  39,   0, 110,  29,  14,  29,  53,  64, 111,  84,  45,   4,\n",
      "          8,   0,   0,  13, 121,  60,  81,  12,  12,  25,  54,  25,  81,  12,\n",
      "          4,  17,   0,  61]) tensor([ 19,  42,  44,   5, 110,  31,  15,  29,  64,  65, 113,  88,  45,   8,\n",
      "          8,   8,   1,  13, 126,  64,  85,  15,  19,  32,  56,  29,  81,  18,\n",
      "          5,  18,   3,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 95,  32,  21,  28,  11,  13,  23,  67, 102,  96,  34,  99, 114,  87,\n",
      "         78, 107,   0,  59,  26,  30,  30,  56,   6,  67,  68,  37,  37,  46,\n",
      "         60,   4,  74,  18]) tensor([ 96,  36,  23,  29,  26,  31,  24,  71, 105,  97,  36,  99, 116,  92,\n",
      "         80, 110,   2,  60,  27,  31,  31,  58,  22,  79,  82,  38,  38,  49,\n",
      "         71,   5,  75,  20])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 34,  22,  64,  45,  66,  64, 112,  24,  53,  30,   2,  74,  11,  85,\n",
      "         59,   4, 115,  32,  37,  81,   0,  29,   0,   8,  56,  93,  15,  31,\n",
      "         31, 103,  26,  60]) tensor([ 39,  23,  66,  51,  66,  68, 119,  26,  53,  33,   2,  77,  12,  89,\n",
      "         80,   8, 128,  35,  40,  81,   4,  30,  18,  10,  65, 111,  24,  32,\n",
      "         32, 135,  30,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  65,  58,  52, 111,  47,  20,   9,   0,  12,  70,  19,   9,  22,\n",
      "          6,  14,   0,  28,   5,  14,  15,  37,   6,   5,  53,  70,  43,   2,\n",
      "         23,  33,  64,   9]) tensor([  4,  65,  60,  53, 113,  48,  24,  11,   3,  18,  71,  19,   9,  26,\n",
      "          9,  17,  10,  35,  10,  17,  15,  40,  13,   9,  57,  73,  49,   5,\n",
      "         32,  36,  65,   9])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 55, 112,  88,  13,  22,   8,  36,  56,  37,  51,  46,  10,  15,  45,\n",
      "         39,  14,  44,  80, 115,  64,   8,  33,  33,  28,   2,  10,  43,  70,\n",
      "         29,   5,  97,  79]) tensor([ 55, 119,  89,  22,  24,  15,  39,  57,  40,  53,  46,  11,  18,  48,\n",
      "         41,  15,  49,  82, 120,  66,   9,  34,  40,  31,   6,  10,  46,  79,\n",
      "         36,  10,  98,  96])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 38,  24,  45,   0,  14, 128, 126,  41,  39,  94,  46,  29,  22,  45,\n",
      "         69,  50,  76,  60,  17,  71,   6,  12,   2,   2,  23,  33,  76,  79,\n",
      "         25,  33,  19, 111]) tensor([ 46,  30,  49,   4,  16, 130, 132,  41,  43,  95,  49,  32,  26,  45,\n",
      "         71,  52,  80,  64,  18,  80,  21,  12,  31,   2,  27,  34,  79,  85,\n",
      "         39,  36,  29, 114])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 41,  63,  35,  53,   3,  54,   0,  25,  53,  65, 120,  90, 125,  55,\n",
      "         46,  40, 107, 117,  10,   0, 106,  66,  88,  83,  34,  57,  29,   0,\n",
      "         13, 103,  98,  99]) tensor([ 41,  88,  36,  54,   7,  60,   1,  27,  55,  74, 121,  98, 132,  58,\n",
      "         49,  41, 110, 127,  10,   3, 106,  66,  91,  91,  45,  67,  31,   3,\n",
      "         18, 106,  98,  99])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 55,   7,   8,   7,  60,   3,   5,  24,  18,  87,  57, 150,   9, 107,\n",
      "         54,  44, 107,  67,  77,  32,  66, 104,  26,  81,  36,  97,  51,  15,\n",
      "          2,  10,  46,  45]) tensor([ 56,   9,  11,   8,  62,   8,   6,  34,  51, 102,  57, 150,  14, 109,\n",
      "         55,  45, 108,  68,  87,  32,  78, 104,  29,  89,  39, 107,  58,  18,\n",
      "          3,  12,  49,  45])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 50,  80,  16, 105,   5,  26,   2,  13,  96,   4,   2,  88,  69,  17,\n",
      "         77,  30,  51,   2,  56,   0,  72,  34, 110,  60,  25,  21,  37,  59,\n",
      "         50,  40,  43,  53]) tensor([ 56,  82,  19, 109,   7,  27,   3,  16,  96,   4,   6,  90,  73,  18,\n",
      "         82,  32,  55,   6,  56,   2,  74,  35, 114,  62,  31,  21,  37,  60,\n",
      "         54,  43,  46,  54])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([114,  54,  29,  16,  21,  82,  76,  33,  36,  77,  29,  35,  59,  51,\n",
      "         28,  25,  63,  48,  10,   5,  71,  24,  20, 106,  62,  26,  23,  15,\n",
      "         85,  40,  26,  27]) tensor([120,  56,  29,  17,  22,  85,  79,  38,  36,  78,  30,  49,  59,  51,\n",
      "         29,  27,  73,  49,  10,   7,  75,  28,  20, 115,  62,  26,  30,  17,\n",
      "         93,  41,  29,  33])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 27,  27, 130,  60,  52,   2,  14,  25,  18,  84,  28,  29,  15,  66,\n",
      "        104,   0,  87,  24,  19,  32,  15,  68,  18,   7,  83,  81,  53,  28,\n",
      "          9,  17,  27,  90]) tensor([ 27,  28, 131,  62,  55,   3,  20,  28,  22,  87,  28,  32,  18,  73,\n",
      "        105,   2,  94,  26,  20,  39,  18,  69,  20,  11,  88,  87,  53,  30,\n",
      "         14,  17,  32,  98])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 34,  32,  72,  87,  11,  96, 115,  64,  44,  65,  21,  99,  57,   2,\n",
      "         54,  10,  65,  27,  46,  41,  34,   3,  37,  31,  23,   6,  47,  79,\n",
      "         21,  15,  67, 115]) tensor([ 35,  33,  75,  87,  13,  96, 117,  65,  48,  71,  26, 113,  61,   4,\n",
      "         57,  13,  66,  33,  46,  41,  39,   5,  41,  33,  25,   9,  52,  79,\n",
      "         21,  19, 103, 119])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([102, 102,   6,  61, 133,  41,   7, 132,  21,  57,   8,  43,  41,  85,\n",
      "          2,  86,  94,   9, 118,  19,  43,  29,  25,  63,  15,  34,  45,  28,\n",
      "         50,  54,  24,  57]) tensor([105, 105,   6,  62, 136,  41,   7, 135,  28,  58,  10,  44,  41,  85,\n",
      "          3,  86,  97,  11, 122,  19,  46,  52,  32,  64,  20,  34,  47,  32,\n",
      "         54,  56,  27,  61])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 65,  59,  69,  73,  54,  44,  51,  38, 108,  52,  35,  39,   3,  36,\n",
      "         35, 130, 119,  20,  21,  44,   0,  36,   2,  41,  52,  61,  18, 104,\n",
      "         24,   7,  70,  31]) tensor([ 66,  63,  71,  81,  57,  54,  52,  43, 111,  52,  36,  45,   4,  49,\n",
      "         40, 133, 122,  22,  22,  46,   3,  36,   4,  43,  54,  63,  23, 108,\n",
      "         29,   7,  71,  38])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 68,  75,   0,  69,  58,  65, 110,   6,  24,  48,   7,  30,  33,  41,\n",
      "         29,  37,  47,  56,  89,  52,  51,  64,   5,  62,  57,  96,  11,  20,\n",
      "         18,  63,  25,  62]) tensor([ 70,  75,   2,  70,  61,  65, 112,   7,  25,  59,  14,  31,  37,  43,\n",
      "         35,  38,  50,  64,  91,  52,  51,  66,   7,  72,  59, 102,  12,  22,\n",
      "         21, 103,  28,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13, 106,  33, 112,   3,  61,  30,  19, 106,  48,   4,  50,   7,  70,\n",
      "         32,  25, 124, 102,   0,  36,  38,  91, 107,  39,  51,  62,   7,  30,\n",
      "         33,  20,  70,  65]) tensor([ 15, 108,  33, 113,   5,  64,  31,  19, 109,  56,   6,  50,   8,  74,\n",
      "         39,  25, 126, 103,   1,  40,  43,  91, 110,  41,  53,  64,   7,  30,\n",
      "         34,  20,  73,  69])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  87,  26,  12,  57,  77,   0,   0,  21, 114,  36,  84,  32,  42,\n",
      "          2,  78,  31,  64,  85,  52,  13,  41,  14,  88,  79,  39,   0,  97,\n",
      "         70,  21,  77,  36]) tensor([  9,  93,  29,  13,  58,  80,   2,   3,  23, 119,  50,  86,  35,  43,\n",
      "          5,  79,  39,  68,  85,  55,  14,  48,  18,  89,  79,  41,   6, 107,\n",
      "         83,  22,  84,  40])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([139,   0,  95,  86,   3,  64,  54,  18,  85,  45,  37, 138,  87,  63,\n",
      "          4, 127,  46,  44,  87,  24,  26,   3,  39,  53,  51,  37,  21,  14,\n",
      "         23,  55,  37,  50]) tensor([142,   6,  96,  92,   3,  65,  60,  19,  87,  47,  37, 141,  98,  64,\n",
      "          4, 128,  52,  45,  87,  27,  27,   6,  46,  55,  51,  39,  22,  18,\n",
      "         24,  60,  38,  58])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([100,  70,  99, 107,  26,  69,   0,  84,  75,  34,  34,  70,   2,  85,\n",
      "         23,  94,   7,  34,   0,  38,  28,   0,  33,  33,   0,  29,  84,  47,\n",
      "         46,  17,  96,  29]) tensor([104,  73, 105, 110,  41,  70,   5,  85,  81,  38,  44,  72,   3,  89,\n",
      "         24, 107,  10,  36,   4,  41,  30,   1,  38,  33,   4,  29,  87,  49,\n",
      "         46,  42, 116,  29])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 6, 68,  7, 75, 52, 33,  2, 69,  0, 70, 35, 56,  0, 16, 45, 35, 53, 73,\n",
      "        89, 68, 19, 20, 30, 34,  8, 47, 81, 42,  0, 18, 68, 55]) tensor([ 6, 71, 58, 82, 53, 36,  6, 71,  3, 74, 37, 58,  3, 17, 69, 35, 54, 77,\n",
      "        91, 71, 22, 23, 31, 36, 14, 51, 83, 43,  1, 19, 69, 59])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 25,  41,   4,  14,  42,  30,  23, 146,  81,  30,   5,   7,  12,  83,\n",
      "         58,  89,  32,  78,  81,  72,  79,  52,  68,  96,  16,  58,   3,  36,\n",
      "         25,  90,  52,  15]) tensor([ 27,  41,   5,  15,  42,  32,  32, 149,  84,  35,   6,   8,  20,  84,\n",
      "         66,  90,  34,  78,  81,  77,  81,  56,  71, 103,  19,  60,   3,  37,\n",
      "         28,  93,  54,  17])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([94, 14,  2, 28, 37, 28, 15, 22, 85, 24, 85, 95, 21, 67, 63, 31, 53,  4,\n",
      "        19, 78,  7, 80, 83, 23, 18, 18,  8, 53, 34, 50, 35, 47]) tensor([ 96,  16,   2,  35,  38,  33,  18,  22,  90,  25,  88, 100,  22,  69,\n",
      "         65,  32,  53,   4,  19,  86,   8,  90,  83,  26,  21,  20,   8,  60,\n",
      "         35,  54,  39,  50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([30,  0, 48, 53,  6, 11, 34, 54, 81, 91, 73, 70,  4, 28, 32, 28, 43, 55,\n",
      "         7, 60, 34, 67, 55, 11, 83, 39, 18, 67, 11,  2,  8, 94]) tensor([38,  1, 56, 59, 12, 15, 34, 59, 82, 93, 74, 76, 10, 29, 34, 31, 46, 55,\n",
      "         7, 62, 36, 73, 55, 15, 86, 42, 38, 70, 14,  8, 11, 95])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  3, 104,  12,  29,  51,  25,  36,  99,  27,  15,  44,  74,  50,  49,\n",
      "         30,  13,  83,   9,  26,   7,   5,  76,   8,  15,  60,  30, 105,  49,\n",
      "        115,  52,  57,  88]) tensor([  3, 106,  34,  34,  52,  25,  37, 104,  31,  23,  45,  74,  54,  77,\n",
      "         31,  18,  86,   9,  29,   7,  14,  76,  11,  17,  61,  30, 107,  53,\n",
      "        119,  56,  58,  88])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 24,  49,  54,  41, 122,  15,  37,  22,  36,  96,  25,  18,  48,   2,\n",
      "         42,   5,  78,  78, 124,  61,  28,   7,  25,  67,  31,  57,  50,  46,\n",
      "         99,   4,   0,  61]) tensor([ 24,  52,  60,  41, 125,  20,  38,  23,  40, 105,  28,  22,  48,   2,\n",
      "         43,   7,  82,  84, 124,  62,  29,   7,  41,  69,  42,  63,  57,  50,\n",
      "        111,   7,   2,  65])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 39,  76,  15, 104,  66,  23,  75,  23,  15,   2,   0,  32,  28,  23,\n",
      "         52,  76,   2, 101,  39,  19,   2,  78,  39,  84, 115,  92,  28,  65,\n",
      "         13,   7,   0,  80]) tensor([ 41,  79,  15, 119,  71,  25,  81,  24,  22,   3,   2,  51,  34,  26,\n",
      "         52,  79,   5, 103,  39,  27,   8,  79,  40,  91, 117,  95,  29,  71,\n",
      "         13,   8,   4,  84])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 29,  92,  82,  31,  14,  28,  58,  20,  86,  53,   0,  42,  28,  28,\n",
      "         16,  95,   8,  82,  77,  44, 110,  23,  56, 109,  22,  34,  76,   0,\n",
      "         49,  38,  92,  29]) tensor([ 32, 104,  86,  39,  16,  30,  61,  21,  86,  54,   6,  45,  30,  29,\n",
      "         21,  96,  11,  87,  80,  46, 111,  23,  58, 110,  29,  39, 100,   1,\n",
      "         50,  41, 114,  39])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 88,  18,  62,  39,  27,  80,  51,  37,  26,  34,  41,  51,  18,  44,\n",
      "         40,  42,  83,  47, 104,  10,  41,  83,  41,  28,  41, 121,  38, 128,\n",
      "         30,  18,  30,  27]) tensor([ 98,  47,  64,  45,  30,  80,  56,  39,  27,  35,  43,  55,  20,  46,\n",
      "         40,  43,  83,  49, 107,  16,  42,  92,  43,  32,  49, 122,  42, 128,\n",
      "         32,  20,  33,  31])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  7,  53,  90,  30,  41, 113,  51,   5,  41,  40,  60,  59,   8,   2,\n",
      "          9,  59,  35,   4,  78,  44,   0,  66,  80,  71, 100,  67,  22,   5,\n",
      "         36,  19,  26,  86]) tensor([  7,  56,  95,  32,  42, 117,  56,   8,  43,  45,  65,  62,  12,   2,\n",
      "         20,  65,  36,   4, 102,  48,   2,  70,  84,  74, 102,  68,  23,   5,\n",
      "         37,  20,  27,  95])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 94,  43,  36,   8,  40,  31,  11,  34,  28,  98,  18,  36,  34, 141,\n",
      "        108,  35,  39,  47,  63,  82,  30,   9,   0,  76,  60,  37,  75,  21,\n",
      "        114, 146, 118,  66]) tensor([ 98,  44,  36,   9,  41,  33,  12,  44,  32, 100,  21,  36,  37, 143,\n",
      "        112,  40,  47,  55,  64,  86,  30,  16,   3,  88,  65,  40,  76,  27,\n",
      "        117, 146, 123,  66])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  9,  67,  96,  69,   7,  37,  90,  33,  84,  36, 112,   5,  33,  41,\n",
      "         54,   9,  41, 109,  20,   7,  23,  19,  39, 123,  15,  93,  56,  62,\n",
      "         81,  18,  74,  74]) tensor([  9,  68, 102,  80,  10,  38,  94,  36,  88,  38, 113,   9,  33,  44,\n",
      "         61,  13,  43, 114,  22,   8,  23,  19,  42, 124,  24, 100,  61,  63,\n",
      "         83,  23,  74,  75])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 14,  40,   0,  32,  48,  97,  87,  15,  78,  38,   2, 141,  66,  46,\n",
      "         57,  51,  31,   9,  76,  25,  37,  47,   0,   7,  94,  97,  31,  16,\n",
      "        125,  44,  39,  56]) tensor([ 15,  42,   2,  33,  50,  99,  88,  23,  83,  43,   3, 147,  66,  50,\n",
      "         61,  53,  44,  17,  81,  31,  39,  47,   2,   7,  99, 105,  31,  19,\n",
      "        126,  59,  44,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 81,  57,  24,  80,  92,  31,  20, 119,  29,   7,  24,  29,  37,  21,\n",
      "         75,  56,  74,  27,  61,  18, 100,  71,  12,  28,  91, 101,  66,  22,\n",
      "          2,  46,  24,   2]) tensor([ 88,  58,  27,  87,  94,  32,  23, 120,  36,   8,  32,  32,  43,  28,\n",
      "         77,  56,  80,  27,  61,  18, 105,  77,  15,  34, 105, 104,  69,  25,\n",
      "          8,  48,  25,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 34,  21,  90,  54,  87,  18,  25,  16,  82,  35, 102,  36,  29,  10,\n",
      "         92,  24,  25,  28,  77,  40, 122, 120,  32,  10,  57,  60,  48,   4,\n",
      "         24,  17, 110,  46]) tensor([ 38,  22, 107,  58,  88,  20,  26,  18,  82,  35, 105,  38,  29,  11,\n",
      "         95,  25,  26,  29,  77,  71, 125, 132,  33,  12,  58,  60,  49,   7,\n",
      "         24,  17, 113,  49])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,  65,  32, 131,  20,  17,  31, 101, 127,  29,  60,  62,  57,  89,\n",
      "         76,  60,  13,  14,   4,   0,  16,  23,   3,  14,  46,  25,   2,  53,\n",
      "        107,  34,  49,   0]) tensor([  8,  69,  33, 131,  25,  20,  33, 102, 129,  30,  60,  63,  57,  93,\n",
      "         76,  78,  16,  14,  10,   4,  23,  27,   5,  17,  51,  29,   2,  54,\n",
      "        110,  37,  62,  14])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 40,  48,   2,  31,  15,  56,  17,  63,   6,  77,  42, 100,   2,  83,\n",
      "         23,  50,  25,  88,  19,  49,  43,  68,  48,  50,   0,  85,  14,   3,\n",
      "         34,  63,  30,  17]) tensor([ 46,  50,   3,  32,  17,  58,  20,  66,   8,  80,  43, 105,   5,  83,\n",
      "         24,  52,  28,  93,  21,  53,  45,  68,  52,  52,   6,  85,  16,   5,\n",
      "         36,  79,  34,  20])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,   4,  91,  31,  35,  85,  30,  14,  16,  94,   4,  56,   4,  87,\n",
      "          2,  99,  80,  38, 100,  22,  30,  13,  36,  64,  33,  18,  50, 110,\n",
      "         29,  84,  20, 113]) tensor([  1,   5,  97,  36,  38, 104,  34,  21,  17,  99,   5,  57,   4, 107,\n",
      "          5, 100,  81,  39, 109,  24,  36,  13,  36,  67,  35,  24,  55, 115,\n",
      "         34,  86,  21, 115])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 69,  25,  10,  76,  70,  44,  82,  40,  91,  65,  57,  69,  73, 103,\n",
      "          8,  86, 118,   7,  83,  25,  88,  34,  54, 120, 116,  58,  96,  44,\n",
      "         52, 118,  25,   9]) tensor([ 71,  36,  13,  81,  72,  47,  84,  40,  93,  76,  64,  69,  74, 105,\n",
      "         19,  90, 119,   9,  90,  26,  89,  45,  90, 122, 116,  59, 101,  46,\n",
      "         57, 119,  26,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 72,  77,   5,  38,  85,  61,  47,  73,  23,  99,  14,  15,  46,  28,\n",
      "         74,  59,  18,  74,  42,  49,  34,   3,  84, 119,   7,  89,  11,  10,\n",
      "          5,  26, 115,  90]) tensor([ 72,  79,   8,  40,  85,  67,  51,  74,  27, 100,  15,  16,  47,  30,\n",
      "         75,  60,  19,  78,  45,  53,  38,   4,  87, 120,   8,  89,  13,  16,\n",
      "         13,  30, 120,  90])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  66,  45,  57,  85, 117,  34,   0,  34,  77,  98,  21,  44,  68,\n",
      "         24,  36,   2,  63,  41,  65,  50,  29,   0,   2,  36,  29,  66,  76,\n",
      "         22,  99,  69,  13]) tensor([  7,  66,  47,  63,  99, 118,  35,   2,  36,  81, 100,  31,  44,  72,\n",
      "         24,  36,   9,  64,  46,  66,  51,  38,   2,   3,  39,  30,  70,  77,\n",
      "         24, 102,  70,  18])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([112,  46, 112,  63,   5,  18,  75,   0,  40,  99,  84,  44,   9,   0,\n",
      "         30,   9,   6,  46,  11,   9,  23,  39,   7, 103,   8,  40,  83,   0,\n",
      "         58,  15,  25,  37]) tensor([113,  48, 118,  63,  13,  20,  79,   8,  40, 100,  86,  45,  16,   3,\n",
      "         32,   9,   9,  47,  13,  38,  24,  40,  10, 106,  10,  45,  96,   5,\n",
      "         62,  15,  30,  40])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 25,  42,   0,  17,  60,  39,   4,  21,  12,  45,  25,   3,  91,  52,\n",
      "         15,  82,   0,  11, 126,  30,  29,   9,  62, 121,  13,  94,  12,  20,\n",
      "         80,  25,  48,  32]) tensor([ 28,  43,   1,  18,  69,  40,   6,  24,  20,  52,  28,   6,  95,  52,\n",
      "         46,  84,   5,  39, 130,  32,  37,  12,  64, 135,  20,  98,  17,  21,\n",
      "         86,  28,  49,  39])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  16,  44,  69,  75,  24,  87,  27,  78,  17,  97,  15,  43,  38,\n",
      "          6,  69,  32,  24,  22,  10, 111,  17,  62,  32,  43,  85,  80,  10,\n",
      "         43,  82,  23,  78]) tensor([  2,  18,  50,  89,  77,  28,  95,  33,  82,  21,  99,  18,  47,  38,\n",
      "          8,  81,  34,  29,  22,  12, 115,  17,  68,  33,  54,  86,  81,  13,\n",
      "         46,  84,  23,  79])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  6,  73,  89,  38,  63,  34,  11,  19,   2,  93,  36,  82,  85,  35,\n",
      "         63,  85, 103,  15,   9,  79,  11,  24,  60,  76,  37,   2,   7, 128,\n",
      "        102,  40,  35,   5]) tensor([  8,  81,  89,  45,  64,  34,  14,  29,   2,  97,  36,  87,  86,  43,\n",
      "         68,  85, 104,  15,   9,  80,  18,  27,  63,  80,  39,  12,   8, 129,\n",
      "        103,  41,  39,  13])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 32, 109,   7,  13,  34,  48,  39,  98,  21,  10,  14,  93,  52,  47,\n",
      "         70,   4,  19,   2,  83,  21,   8,  51,  95,  46,  10,  47,  33,  97,\n",
      "         14,  73,   5,  14]) tensor([ 37, 111,  10,  16,  34,  51,  39, 104,  24,  16,  17, 101,  53,  47,\n",
      "         71,  10,  21,   5,  88,  27,  11,  54,  97,  48,  15,  53,  35,  99,\n",
      "         18,  73,   8,  14])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 47,  73,  62,  80,  29,  61,  79,   0,  37,   2,   9,  12,  22,  28,\n",
      "         58, 128,   2,  53,  76,   5, 105,  81,  43,  60,  68,  16,  46, 112,\n",
      "        108, 120,  33,  10]) tensor([ 50,  73,  63,  84,  29,  61,  87,   3,  40,  12,  14,  13,  24,  29,\n",
      "         59, 138,   6,  56,  78,   5, 110,  85,  45,  65,  69,  25,  46, 113,\n",
      "        110, 121,  35,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 43,  30, 109,  19,  60,  76,  93, 140,  28,  42,  45, 107,  52,  35,\n",
      "         76,   0,  61, 104,  10,  26,  55,   5,  65,  72,  23,  28,   8,  81,\n",
      "         29, 103,  32,   2]) tensor([ 45,  34, 115,  25,  62,  80,  94, 142,  32,  44,  53, 110,  61,  45,\n",
      "         80,   3,  64, 105,  11,  28,  59,   5,  66,  79,  28,  30,   9,  84,\n",
      "         30, 106,  36,   4])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  6,  41,  57,   3,   9,   9,  15,  50,   0,   8,  54,   2,   8,   0,\n",
      "         33,  38,  10,   8,  19,  89,  13, 115,  84,  65,  39,  20,  16,  69,\n",
      "         79,   0,  43,  43]) tensor([  6,  46,  60,   3,  20,  10,  16,  52,   5,   9,  55,   2,  12,   2,\n",
      "         35,  42,  13,  12,  20, 110,  16, 115,  87,  71,  41,  22,  19,  69,\n",
      "         79,   2,  50,  53])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 87,  91,  20,  44,  37,  12,   0, 129,  32,  34,  37,   5, 124,  40,\n",
      "         32, 106,  59,  40,  51,  67,   2,  21,  50, 121,  40,   6,  12,  14,\n",
      "         32,  12,  16,  97]) tensor([ 89,  97,  27,  44,  37,  22,   2, 132,  34,  39,  38,   7, 125,  41,\n",
      "         36, 110,  62,  42,  51,  70,   4,  23,  52, 121,  44,   6,  23,  15,\n",
      "         32,  13,  18, 117])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4, 103,   2,  86,  29,  94,   0, 132,  71,  37,  33,  11,  62,  65,\n",
      "         77,  13,  65,   9,  96,   6,  25,  42,  79,  82,  71,   3,  34,  61,\n",
      "         33, 115,  65,   2]) tensor([  4, 104,  12,  90,  29,  94,   1, 133,  73,  37,  35,  19,  92,  67,\n",
      "         77,  13,  72,  22,  97,  26,  25,  46,  85,  85,  90,  10,  42,  64,\n",
      "         33, 117,  82,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 78,  33,   2,  70,  50,  73, 113,  18,   4,  26,   8,   3,  10,  31,\n",
      "         20,  38,  86,  17,  90, 106,   0,  80,  23,  76,  36,   2,  43,  44,\n",
      "         33,  59,   9, 102]) tensor([ 79,  41,   3,  78,  51,  73, 116,  20,   6,  28,  12,   7,  14,  32,\n",
      "         22,  42,  87,  23,  92, 108,   1,  84,  24,  89,  37,   5,  46,  50,\n",
      "         38,  59,  12, 103])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 49,  23,  81,   5,  72,  59,  83,  13,  59,  61,   6,   6,  35,   8,\n",
      "         37,   2,  66,  22,   0,  57, 101, 104,  30,  97,  56,  53,  35,  34,\n",
      "         28,  21,  62,  55]) tensor([ 50,  26,  84,   6,  78,  63, 109,  22,  61,  64,   8,  11,  37,   9,\n",
      "         37,   4,  68,  25,   1,  58, 102, 107,  32, 102,  57,  58,  48,  36,\n",
      "         28,  22,  65,  59])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 27,  84,  86,  11,  74,  41,  70,  19,  88,  42,  48,  96, 103,  66,\n",
      "         39,  29,   9,  27,  84,  61,  22, 123,   2,  96,  31,  86,  65,  72,\n",
      "         88,  38,  13,  67]) tensor([ 41,  95,  86,  11,  75,  49, 103,  25,  90,  54,  48, 101, 103,  69,\n",
      "         44,  41,   9,  29,  87,  62,  24, 123,   2, 105,  35,  91,  66,  75,\n",
      "         88,  39,  16,  69])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,  66,  76,  13,  17, 108,  11,  83,  24,  58,   8,  47,  54,  89,\n",
      "         83,  41,   6,  15,  46,   2,   6,  58,  15,  44,  64,  70,  72,  67,\n",
      "          8,  20, 122,  38]) tensor([ 33,  66,  78,  14,  20, 109,  13,  89,  27,  77,   8,  51,  58,  89,\n",
      "         87,  45,   6,  17,  50,   4,   8,  73,  18,  46,  73,  74,  77,  69,\n",
      "          8,  20, 128,  40])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([66,  6,  8, 61,  9, 20,  9, 47, 65, 18, 56,  9,  0, 38, 84, 95, 32, 85,\n",
      "        15, 12, 42, 31, 28, 50, 52, 56, 44,  0, 17, 74, 68, 87]) tensor([69,  8,  9, 62, 11, 21, 11, 52, 66, 18, 75, 10,  2, 39, 93, 97, 33, 87,\n",
      "        19, 13, 46, 32, 33, 52, 52, 65, 54,  3, 20, 77, 70, 92])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 31,  35,  48,  69,  17,  72,   7,  20,  45,  94,  22,  33,  66,  34,\n",
      "         34,  68,   0,  40,  41,  27,  40, 104,  19,  16, 132,  11, 104,  41,\n",
      "         78,  37,  17,   0]) tensor([ 36,  54,  49,  87,  17,  72,   9,  20,  46,  96,  24,  36,  68,  38,\n",
      "         34,  71,  13,  42,  41,  27,  41, 105,  20,  19, 135,  12, 107,  45,\n",
      "         81,  37,  19,   6])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 24,  29, 116,  18,  19,  22,  32,  69, 135,  70,  42,  86,  71,  64,\n",
      "         87,  58,  36,  24,  51,  55,  10,  17,  35,   5,  43, 110,  57,  86,\n",
      "          8,  31,  97,   4]) tensor([ 34,  41, 119,  21,  21,  28,  36,  74, 138,  73,  42,  87,  72,  70,\n",
      "         88,  63,  41,  33,  51,  61,  12,  19,  42,   5,  51, 112,  58,  87,\n",
      "          8,  33,  98,   4])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 29,   0, 124,  37,  20,  26,  54,  39, 116,  56,  77,  59,  61,  33,\n",
      "         79,   5,  13,  70,  17,  93,  83,  58,  88,  13,  31,   8,  16,  16,\n",
      "        135,  44,  87,  10]) tensor([ 40,   3, 125,  40,  27,  27,  54,  41, 120,  56,  79,  62,  65,  34,\n",
      "         81,   8,  15,  71,  18,  96,  84,  60,  93,  14,  31,  11,  21,  18,\n",
      "        137,  47,  92,  14])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8, 117, 100,  71,  77,  44,  29,  72,  19,  20,   4,  10,  27,   8,\n",
      "         59,  73,  76,  22,   2,  56, 107,  60,  64,  82,  35,  46,  24,  39,\n",
      "          4, 110,  91,  27]) tensor([ 15, 117, 101,  79,  79,  48,  34,  74,  20,  21,   4,  17,  28,  11,\n",
      "         63,  75,  77,  23,   3,  57, 113,  64,  69,  84,  40,  47,  30,  42,\n",
      "          8, 114,  93,  29])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 18,   6,  77,  24,   0,  22,  44,  26,   0,  36,  35,  33,  45,   0,\n",
      "          7,  64,   8,  29,  28,  37,  10,   4,  74,  29,  84,  63,  42, 144,\n",
      "         40,  28,  69, 130]) tensor([ 18,  10,  94,  28,   5,  30,  46,  28,   2,  38,  36,  33,  45,   3,\n",
      "         17,  64,   8,  39,  44,  44,  17,  17,  76,  33,  88,  65,  43, 146,\n",
      "         48,  30,  70, 131])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 20,  60,  21,   2,  10,   0,  16,  58,  37,  30,  98,  46,  19,   3,\n",
      "        102,   7,  33,  60,  40,   6,  78,  91,  30,  54,   5, 129,   5,  87,\n",
      "          8,  92,  39,  18]) tensor([ 22,  63,  22,   5,  12,   1,  19,  63,  40,  30, 103,  47,  21,   3,\n",
      "        103,   7,  42,  60,  45,   6,  79,  93,  35,  55,  19, 135,   5,  91,\n",
      "          9, 102,  42,  25])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 60,  86,  99,  66,  23,  64,  66,  75,  42,  30,  11,  41,  69,   6,\n",
      "          2,   0,  39,  16,  21,  37,  95,  53,   0,  99,  68,  64, 116,  23,\n",
      "         83,   5,  88, 113]) tensor([ 60,  92,  99,  72,  30,  65,  67,  79,  49,  30,  11,  53,  71,   6,\n",
      "          2,   6,  39,  18,  25,  37,  98,  54,   4, 100,  69,  69, 120,  24,\n",
      "         92,   7,  91, 119])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 37,  34,   2,  70,   0,  26,   5,   5,  20,  54,  11,   0,  71,  61,\n",
      "         40,  42,  75,  55,  16,  40,  15,  47,  23,  51,  38,  66, 128,   0,\n",
      "         48,  24,  60,   3]) tensor([ 43,  35,   5,  95,  12,  31,   6,   5,  22,  58,  11,   1,  75,  62,\n",
      "         47,  43,  80,  56,  18, 103,  19,  49,  23,  53,  41,  69, 129,   1,\n",
      "         49,  25,  60,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([26, 36, 66,  9, 42, 78, 64, 62, 22, 50, 21,  0, 28, 81, 40, 61, 40, 64,\n",
      "        90,  8, 53, 50, 71, 80, 89, 14, 40, 61, 51,  9, 13, 44]) tensor([ 29,  40,  67,  11,  43,  83,  65,  63,  24,  55,  25,   2,  32,  86,\n",
      "         56,  65,  42,  65, 100,  13,  53,  54,  71,  83,  89,  22,  46,  62,\n",
      "         54,  15,  14,  50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,  28,  13,  28,  23,  97,  32,  16,   2,  24,  20,  18,  12,  30,\n",
      "         78,  61,  49,  47,  20,  48,  43,  52,  10,  73,   6,  77,  23,  45,\n",
      "         31,  57, 114,   3]) tensor([ 24,  34,  13,  28,  26, 101,  37,  18,   4,  24,  22,  20,  15,  32,\n",
      "         78,  65,  52,  51,  22,  49,  46,  53,  11,  74,  27,  79,  24,  47,\n",
      "         38,  57, 117,   4])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([135,   8,  54, 116,  13,  45,  56,  79,  29, 138,  11,  11,  95,  80,\n",
      "         56,  50,   9,  53,  71,  43,  68,  25,  34,   9,  40,   6,   0, 123,\n",
      "         92, 117,  68,  30]) tensor([141,  18,  57, 122,  31,  49,  60,  85,  29, 142,  17,  15,  95,  88,\n",
      "         56,  52,  11,  57,  73,  49,  70,  25,  35,  13,  44,   6,   6, 128,\n",
      "         95, 120,  73,  33])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 33,   8,  47,  86,   4,  98,  84,  54,   3,  48, 139, 110,  56,  32,\n",
      "         93,  17,  32,  10,  23,  26,  64,  67,  32,  24,   8,  18, 109,  79,\n",
      "          2,   0,  27,  44]) tensor([ 40,  11,  52,  88,   4,  99,  88,  56,   3,  53, 142, 114,  59,  34,\n",
      "         93,  18,  48,  10,  26,  28,  66,  68,  34,  27,  18,  18, 117,  79,\n",
      "          5,   6,  28,  47])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 98,   5,  98,   0,  58, 101,  58,  69,  31,  74, 147,   0,  34,   9,\n",
      "         10,  66,  53,  20,  54,  12, 135,   6, 122,  10,  64,  62,  33,  31,\n",
      "         47,  76,  30,   0]) tensor([100,   8, 119,   6,  58, 126,  63,  76,  36,  77, 150,   4,  38,  12,\n",
      "         17,  70,  57,  21,  55,  18, 138,  13, 124,  10,  66,  62,  39,  31,\n",
      "         48,  78,  31,   1])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 39,  19,  49,  72,   8,   7,  21,   0,  18,  77,  55,  14,  23,  59,\n",
      "         77,  83,  11,   3,  11,  40,   0,  44,  84,  30,   5,  10,  65, 102,\n",
      "         15,  48,  88,  50]) tensor([ 62,  21,  67,  77,  10,  11,  24,   2,  22,  86,  67,  15,  25,  63,\n",
      "         81,  86,  14,   4,  11,  44,   6,  48,  84,  31,   8,  14,  67, 114,\n",
      "         19,  53,  91,  53])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 49,  89,  90,  88,   3, 102,  13, 106,   9,   5,  80,   0,  60,  15,\n",
      "          6,  44,  10, 101,  95, 140,  91,   0,  23,  99,  15,  12,  58,  12,\n",
      "         17,  99,   0,   4]) tensor([ 50,  90,  93,  90,   4, 110,  14, 109,  12,  11,  85,   1,  64,  16,\n",
      "         12,  45,  11, 104, 100, 140,  93,   7,  24, 100,  16,  13,  60,  12,\n",
      "         33, 102,   3,  18])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 46,  30,   9,  60,  39,  16,  18,  39,  24,  22,  67,  35,  57,   9,\n",
      "         32,  36,  27,  21, 111,  37,  19,   9,  27,  23,  30,  86,   9,  53,\n",
      "         92,  85,  66,  28]) tensor([ 47,  33,  10,  64,  52,  24,  18,  42,  29,  32,  71,  36,  58,   9,\n",
      "         34,  38,  28,  24, 114,  40,  24,  12,  30,  26,  35,  88,   9,  73,\n",
      "         92,  87,  74,  30])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 57,  90,  16,  92,  31,  46, 105,  14,  14,  21,  26,  57,  31, 120,\n",
      "          2,  55, 130,   9,  91,  94,  83,  38,  76,  92,  19,   5,  86,  28,\n",
      "         51,  17,  91,   0]) tensor([ 61,  92,  17,  93,  34,  47, 107,  18,  16,  25,  29,  61,  40, 121,\n",
      "          3,  56, 131,  12,  94,  98,  90,  50,  79,  92,  27,  13,  89,  29,\n",
      "         58,  17,  92,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 49, 140,   8,   2,  17,   0,   3,  83, 116,  48,  16,   9,  30,  89,\n",
      "          3,  21,   0,  16,  72,   1,   0,  69,  52,  98,  34,  96,  56,  52,\n",
      "         49,  40,  87,  39]) tensor([ 54, 143,  12,   4,  18,   4,   6,  89, 117,  51,  16,  12,  30,  90,\n",
      "          6,  26,   6,  26,  74,  25,  10,  72,  52, 106,  36,  98,  59,  54,\n",
      "         50,  41,  90,  40])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 69,  25,   3,  21,   0,  14,  16,  40,   7,  10,  82,   8,  99,   0,\n",
      "         44,  30,  19,  30,  34,  13,  82,  17,  45,  58,  10,  37,  24,  17,\n",
      "        122,   0,  36,  26]) tensor([ 71,  28,   3,  21,   4,  15,  28,  43,   7,  13,  84,   9, 104,  12,\n",
      "         48,  32,  20,  35,  52,  15,  82,  21,  46,  58,  12,  41,  25,  18,\n",
      "        127,   4,  37,  26])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 18,  53,  31, 108,  55, 117,  96,  29,   7,   2,  24,  12,  30, 115,\n",
      "         33,   8,  47,   0, 120,  39,   0,  79,  54,  23,  17,  23,  35,  90,\n",
      "         63,   0,  88, 136]) tensor([ 26,  54,  32, 109,  61, 120,  96,  29,   8,   6,  28,  27,  35, 118,\n",
      "         34,  11,  49,   2, 120,  40,   5,  83,  58,  24,  19,  25,  36, 118,\n",
      "         68,   5,  90, 142])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 97,  81,  10,  53,  24,  73,   4,   3,  25,  42,  10,  61,  80, 123,\n",
      "         52,  59,  63, 148,  43,  33,  27,  62,  81,   9,  47,  52, 140,  22,\n",
      "          0,  50,  12,  45]) tensor([116,  91,  11,  60,  28,  79,   9,   6,  27,  45,  13,  61,  81, 125,\n",
      "         54,  62,  67, 152,  48,  33,  30,  66,  89,  19,  48,  55, 144,  24,\n",
      "         32,  50,  16,  51])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 40,  19,  35, 104,  81,  45,   4,   5,  90,  84,  24,   8,  88,  42,\n",
      "         85,  53,  24,  34, 121,  55,  43,  24,  11,   9,  71,  58,  45,  46,\n",
      "         53,  22,  67,  97]) tensor([ 44,  19,  37, 106,  84,  53,   5,   7,  92,  89,  26,  10, 100,  44,\n",
      "         90,  57,  30,  39, 134,  57,  43,  28,  11,  12,  79,  59,  50,  48,\n",
      "         54,  24,  67, 102])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  5,   4,  31,  55,   2,  62,   8,  76,  75,  71, 132,  82,  74,   3,\n",
      "         95, 100,  36,  21,  68,  57,  75,  63,   3,   5,  40,  41,  15,  21,\n",
      "         10,  27,  16,   9]) tensor([  9,   6,  33,  57,   2,  64,   8,  87,  78,  72, 141,  89,  75,   3,\n",
      "         97, 101,  41,  36,  69,  60,  75,  64,   5,  10,  75,  51,  16,  23,\n",
      "         11,  29,  16,  10])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8,  39,  33,  29,   0,  48,  16, 126,  23,  98,  94,  24,  74, 101,\n",
      "         62,  11,  28,  56,  68,  31,  46,  50,   0,   0,  42,  84,  59,  20,\n",
      "         31,  35,  89,  58]) tensor([ 10,  45,  42,  33,   1,  59,  19, 133,  31, 101,  95,  28,  77, 105,\n",
      "         64,  13,  32,  60,  71,  35,  47,  50,   6,   2,  43,  87,  60,  21,\n",
      "         31,  37,  92,  59])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 47,  56,   3,  21,   0,  55,  53,  38,  39,  69,   7,  59,  33,  76,\n",
      "         79,  11,  54,  13,  92,  61,  43,  14,  72, 121,  19,   3,   5,  16,\n",
      "         23,  27,  26,   2]) tensor([ 62,  57,   6,  21,   2,  55,  59,  38,  46,  76,  13,  68,  35,  79,\n",
      "         80,  12,  55,  15,  94,  65,  58,  16,  76, 123,  21,   4,   6,  16,\n",
      "         24,  30,  27,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 57,  93,   8,  36, 110,  68,   6,  39,  40,  56,  90,  10,  64,  11,\n",
      "        108,  84, 138,   0,  29,  65,  17,  13,  27,  85,  56,  62, 142,  90,\n",
      "        103,  45,  69,  29]) tensor([ 59,  98,   8,  36, 128,  72,   6,  43,  40,  56,  95,  15,  64,  15,\n",
      "        109,  90, 140,   4,  53,  71,  18,  16,  28,  90,  56,  64, 143,  94,\n",
      "        108,  54,  84,  30])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([119,  50,  14,  20,  30,  43,  16,  19,  45,   2,   2,  89, 121,  82,\n",
      "         14,  24,  30,  60,  50,  46,  40, 123, 104,  49,  37,  32,  30,  58,\n",
      "         40, 100,   3,   6]) tensor([121,  53,  16,  24,  40,  44,  16,  26,  46,   6,   2,  91, 125,  83,\n",
      "         22,  27,  34,  62,  51,  51,  42, 126, 107,  57,  37,  34,  30,  58,\n",
      "         44, 104,   7,   8])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 98,  29,  21,  90,  42,  53, 107,  93,  14,   6, 127,  52,  24,  70,\n",
      "         80,   0,  24,  75,   5,  51,  19,  17,  56,  92,  46,   5,  32,  26,\n",
      "         41,  61,  28,  44]) tensor([ 99,  35,  39,  99,  42,  53, 112, 107,  15,   8, 129,  53,  32,  72,\n",
      "         82,   6,  28,  80,   5,  55,  20,  19,  58,  92,  48,  11,  47,  26,\n",
      "         45,  65,  28,  46])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 17,  41,   6,  27,  26, 110,  26,  11,  29,  13,  15,  69,  71,  31,\n",
      "          0,  16,  55,  37,   3,  90, 100,  23,  70,  77,   0,  20,  29,   3,\n",
      "         90, 105,  73,  18]) tensor([ 32,  48,   8,  31,  31, 113,  33,  18,  34,  16,  20,  94,  74,  37,\n",
      "          6,  21,  55,  39,   6,  92, 102,  26,  76,  78,   7,  20,  29,   5,\n",
      "         96, 110,  73,  22])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 79,  27,  12,  13,  46,  50, 153,  80,  47,  16,  46,  25,   0,   0,\n",
      "         39,   2,  77, 112, 109,  39,  56,  50,  74,   7,  25,  30,  11,   0,\n",
      "         51,  52,  14,  78]) tensor([ 83,  27,  13,  14,  47,  52, 153,  85,  50,  17,  50,  29,  16,   3,\n",
      "         40,   2,  78, 123, 111,  42,  60,  57,  76,   8,  29,  33,  21,   6,\n",
      "         58,  68,  16,  79])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 57,  92,  54,  60,  98,  57, 115,   7,   8,  18,  68,  30,  25,  17,\n",
      "         16, 104,   3,  57,  44,   2, 109,  11,  71,  45,  80,  65,  65,  67,\n",
      "         78,  73,  38,   8]) tensor([ 65,  94,  57,  62, 100,  57, 116,  12,  10,  22,  72,  30,  29,  17,\n",
      "         17, 106,   3,  60,  49,   2, 112,  15,  75,  47,  82,  71,  65,  68,\n",
      "         83,  73,  42,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 42,  92,  60,  88,   7,   9, 100,  18,   2,  65,  59,  27,   5,  29,\n",
      "         36,  14,  59,  22,  56,  81,  79,  36,  79,  69,  18,  30,  12,  81,\n",
      "         28,   0,  45,  76]) tensor([ 42,  93,  63, 101,  15,  11, 103,  30,   3,  65,  61,  27,   5,  35,\n",
      "         38,  18,  62,  22,  56,  88,  83,  37, 100,  69,  18,  32,  14,  96,\n",
      "         30,   9,  49,  76])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 24,  28,  30,  27,  83,  55,  20,  57,   2, 100,  47,  60,  19,  62,\n",
      "         43, 113,  77,  19,   8,   0, 117,   0,   3,   0,   7,  70,  22,  16,\n",
      "         10,  18,  12,  21]) tensor([ 29,  28,  33,  29,  85,  57,  21,  63,   3, 101,  51,  62,  21,  69,\n",
      "         48, 118,  82,  24,   8,   1, 118,   4,   3,   6,   9,  72,  25,  20,\n",
      "         17,  20,  14,  23])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([104,   0,  61,  39,  57,  40,  68,  16,  73,  67,  10,  33,  83,  16,\n",
      "         48,  27,  59,  36,   3,  53,  59,  17,  58,  86, 112,  44,  69,  42,\n",
      "         88,   8,  16,  22]) tensor([112,   2,  62,  40,  58,  41,  69,  22,  73,  70,  23,  35,  84,  21,\n",
      "         49,  35,  61,  43,   8,  56,  72,  19,  62,  87, 113,  45,  76,  45,\n",
      "         91,  10,  21,  30])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  2,   3,  63,  17,  45,  27,  15,  50,  31,  12,  49,   7,  91, 119,\n",
      "        115,  69,   3,  30,  26,  69,  20,  13,  25,  17,   0,  42,  47,  57,\n",
      "         80,   8, 138,  74]) tensor([  4,   3,  84,  19,  48,  32,  19,  51,  36,  14,  51,   7,  97, 120,\n",
      "        116,  70,   6,  30,  33,  69,  22,  13,  28,  17,   6,  46,  50,  57,\n",
      "         86,   9, 141,  77])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([127,  79,  42,  48,  59,  12,  19,  54,  59,  83,  71,  62,  90,  19,\n",
      "         49,  83,  12, 139,  31,  51,   4,  72,  16,  83, 106,  76,  40,  19,\n",
      "         23,   0,   2,  13]) tensor([159,  79,  44,  60,  60,  14,  23,  54,  63,  83,  75,  69,  91,  30,\n",
      "         54,  85,  14, 139,  40,  57,   4,  73,  20,  85, 112,  77,  43,  33,\n",
      "         24,   3,   5,  15])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  2,  46,   8,  91,   2, 109,  81,  63,  36,  43,  19,  67,  45,   6,\n",
      "         10,  67,  16, 103,   5,   5, 105,  43,  14,  93,  28,  40,   3, 117,\n",
      "         10,  50,  16,   0]) tensor([  6,  49,  10,  94,   2, 114,  82,  63,  38,  43,  21,  71,  46,   6,\n",
      "         12,  69,  18, 105,   6,   5, 106,  44,  15,  97,  31,  42,   5, 120,\n",
      "         10,  50,  18,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 21,   4,  37,  22,  17,  20,  55,  82,  97,  65,  18,  93,  57,  10,\n",
      "         71,  56,  83,  12,  40,  28,  17,  45,  52,  19,  23, 115,  64,   3,\n",
      "         10,  12,  84,  74]) tensor([ 21,   9,  42,  26,  21,  21,  56,  91, 100,  69,  21,  95,  58,  12,\n",
      "         72,  59,  84,  14,  43,  30,  20,  50,  52,  24,  25, 117,  65,   3,\n",
      "         16,  14,  86,  79])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 49,  26,  34,  29,   9,  80,   7,   6,  40,  34,  33,  70,  44, 122,\n",
      "          0,  61,   0,  50,  96, 102,  46,  28,  23,  82, 106,  44,  18,   4,\n",
      "         50,  24,  48,   0]) tensor([ 51,  28,  36,  31,  10,  91,   7,   8,  42,  35,  34,  80,  47, 126,\n",
      "          3,  70,   1,  53, 103, 104,  47,  29,  24,  88, 107,  48,  20,  51,\n",
      "         53,  28,  49,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 74,  32, 101,  73,  87,  37,  17,  46,   7,  16, 104,  53,  15,  70,\n",
      "         48,  30,  48,  15,  50,  24,  42, 101,  10,  97, 111,  19,  79,  74,\n",
      "         25,  47,   2,  26]) tensor([ 76,  36, 103,  82,  91,  63,  19,  49,   8,  33, 106,  57,  17,  71,\n",
      "         59,  31,  60,  15,  54,  26,  45, 103,  11,  98, 115,  22,  84,  75,\n",
      "         28,  57,   3,  32])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,  68,  81,   2,  19,   4,  16,  44,  34, 111,  14,  36,  24,  83,\n",
      "         21,  32,   7,  88,  43,  11,  65,  27,  31,   0,  37,  22, 123,  24,\n",
      "         13,  36,  91,   4]) tensor([ 12,  71,  84,   2,  19,   5,  48,  55,  35, 120,  15,  41,  26,  97,\n",
      "         24,  35,  15,  88,  57,  12,  69,  27,  36,   3,  39,  27, 123,  27,\n",
      "         19,  39,  91,   6])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 23,  11,  97,   8,  17,  98,  18,  38,  43,  75,   5,  46,  12,  73,\n",
      "         37,  41,  60, 104,  58,  76,  28,  96, 100,   8,  26,  39,  20,   4,\n",
      "          2,  78,  31,  31]) tensor([ 23,  15, 100,  26,  17, 101,  19,  39,  49, 107,   9,  47,  15,  74,\n",
      "         69,  41,  64, 105,  66,  77,  29,  99, 101,   9,  26,  41,  23,   4,\n",
      "          5,  79,  33,  32])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 35, 127,  88, 114,  73,  16,  22,  32,  13,  55,  92,  18,  84,  37,\n",
      "         43, 137,  72,   0,  16,  89,  51,  42,  63,  16,  79,  31,  44,  10,\n",
      "         67,  13,  21,  47]) tensor([ 47, 128,  89, 116,  78,  16,  23,  33,  13,  56,  96,  30,  88,  38,\n",
      "         45, 137,  87,   2,  18,  99,  57,  43,  64,  17,  81,  32,  47,  16,\n",
      "         70,  20,  26,  60])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 89,   4, 103,  17,  40,  98,  33,  84,   2,  31, 112,   7,   6,  89,\n",
      "         16,  10,  47,  11,   5,  21,  89,  17,  75,  50,  26,  35,  12,  79,\n",
      "         21,  15,  10,  78]) tensor([ 89,   4, 105,  18,  43, 106,  33,  95,   5,  41, 117,  11,   8,  90,\n",
      "         17,  11,  50,  23,  13,  22,  91,  20,  82,  51,  27,  44,  20,  80,\n",
      "         25,  18,  14,  83])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 48, 110,  19,  60,  92,  57,  38,  77,  39,   5,  55,  71,  17,  71,\n",
      "         15,  51,   0,  19,  62,  15, 109,  54,  37, 104, 119,   2,  16, 103,\n",
      "         65,  53,  74,  69]) tensor([ 62, 111,  24,  60,  93,  61,  40,  83,  55,  10,  58,  77,  23,  71,\n",
      "         17,  54,   2,  21,  63,  18, 112,  58,  37, 106, 122,   4,  22, 106,\n",
      "         65,  53,  75,  75])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13,  73,  92,   4,  29,  32,  22,  14,  40, 108,  65,  36,  42,  34,\n",
      "        110,  93,  37,  47,  46,  77,  33,  77,  28, 104,  41, 103,  13,  82,\n",
      "         51,  83,  90,  71]) tensor([ 16,  76, 103,  16,  59,  39,  23,  14,  42, 109,  67,  42,  49,  36,\n",
      "        111, 100,  41,  53,  48,  80,  34,  81,  33, 110,  52, 110,  15,  84,\n",
      "         54,  84,  90,  72])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  2,  12,  32,  50, 130,  38,  49,  60,  39,  66,  37,   2,  50,   9,\n",
      "         44,  45,  82, 118,   8,   0, 103,  37,  38,   8,  83,  20,  81,   3,\n",
      "         89,  13, 125,  38]) tensor([  5,  12,  34,  71, 131,  60,  51,  66,  45,  71,  40,   2, 122,  16,\n",
      "         44,  48,  85, 122,  16,   2, 107,  50,  46,  13,  85,  21,  82,   8,\n",
      "         95,  14, 131,  40])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  42,   2,  19,  76,  22,  44,   6,  28,  57,   0,   3,  36,  26,\n",
      "        120,  11,  37,   8,  11,   2,  88,  41, 104,  65,  71,  36,  78,  55,\n",
      "         12,  44,   0, 119]) tensor([  3,  42,   4,  19,  88,  23,  45,  10,  30,  60,   5,   3,  41,  26,\n",
      "        121,  16,  37,  16,  11,   5,  92,  43, 109,  66,  72,  43,  95,  59,\n",
      "         13,  47,   1, 122])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 27,  62,  41,  73,  88,  84,  85,  88,  27,  42,  48, 125,   2,  28,\n",
      "        106,  28,  58,  19, 103,  91,  32,  33,  11,  31, 125,  55,  42,  16,\n",
      "         44,  13,  37,  57]) tensor([ 31,  64,  48,  82,  90,  84,  89, 101,  32,  46,  73, 129,   4,  59,\n",
      "        106,  29,  61,  21, 105,  95,  36,  35,  14,  37, 126,  56,  42,  32,\n",
      "         48,  13,  43,  61])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 61,  88,  48,  69,  76,  43,  72,  10,   8,   3,  61,   0,  99,  30,\n",
      "         25, 102,  91,  54,  22,   7,  29,  83,  22,  49,  34,  51,  74,  14,\n",
      "          5,  66,  35,   0]) tensor([ 64,  95,  53,  70,  77,  45,  76,  18,  17,   6,  62,  10, 103,  33,\n",
      "         26, 104,  94,  56,  22,   9,  33, 110,  23,  56,  36,  56,  76,  22,\n",
      "          7,  67,  36,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 6, 11, 58, 51, 28, 85, 98, 15, 15,  9, 39,  2, 12,  6,  2, 29, 49, 29,\n",
      "        85, 76,  0, 38,  5, 44, 40, 51, 36,  8, 18, 48, 65, 97]) tensor([  6,  12,  61,  52,  33,  90, 100,  17,  19,  11,  42,   2,  17,  15,\n",
      "          2,  33,  54,  31,  91,  77,   3,  38,   5,  51,  42,  54,  40,   9,\n",
      "         22,  55,  71,  99])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 36,   0,  18,  61,   8,   3,  52, 104,   5,  46,  22,  76,  63, 130,\n",
      "         73,  85,  55,  59,   9,  37,  14,  39,  89,   6,   7,  27, 105,  18,\n",
      "         50,  87,  56,  46]) tensor([ 46,  23,  23,  64,   9,   3,  61, 109,   6,  56,  23,  76,  63, 131,\n",
      "         81,  87, 115,  63,  13,  41,  14,  42,  95,   8,   9,  33, 106,  22,\n",
      "         53,  89,  57,  46])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([59, 15, 14, 52,  0, 27, 31, 76, 51, 72, 41, 25, 66, 55, 96, 24,  9, 46,\n",
      "        12,  6, 45,  9, 63, 49,  4, 40, 76, 11, 58, 19,  0,  6]) tensor([ 72,  16,  18,  53,   6,  27,  41,  78,  52,  80,  45,  32,  68,  60,\n",
      "        100,  27,  12,  47,  15,  11,  52,  21,  71,  53,   4,  42,  87,  12,\n",
      "         66,  22,   3,   6])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 78,  47,  52,  42,  13,  20,   0,   2,  12,  15, 122,  13,  65,  75,\n",
      "         46,  98,  64,  69,  16,   6,  37,  56,  73,  48, 120,  54,   3, 130,\n",
      "         29, 116,  67,  43]) tensor([ 78,  50,  54,  44,  15,  25,  10,  12,  17,  16, 123,  14,  66,  75,\n",
      "         48, 101,  65,  69,  20,   8,  38,  58,  75,  50, 125,  54,   3, 130,\n",
      "         29, 117,  68,  46])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 82,  69,  53,  25,  15,  27,  34,  16,   2,  53,  28,  73,   2,  12,\n",
      "         43,  88,   0,   0,  89,  40,  55,  28,   9, 121,  26,  70,  38,  21,\n",
      "         29,   3,  14,  24]) tensor([ 87,  73,  53,  25,  17,  28,  35,  24,   4,  54,  30,  81,   2,  13,\n",
      "         43,  91,   4,   6,  94,  43,  59,  40,  11, 124,  28,  71,  50,  23,\n",
      "         35,   4,  14,  24])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 30,  14,  42,  43,  53,  26,  34,  63,  28,  38,  11,  11,  63,  56,\n",
      "         61, 118,  25,  46,   6,  27,  99, 112,  73,  26,  65,   8,  42,  44,\n",
      "         44,  28,  67,  80]) tensor([ 30,  18,  45,  46,  59,  28,  35,  65,  33,  39,  14,  15,  63,  60,\n",
      "         69, 120,  26,  48,   8,  31, 102, 113,  74,  30,  67,  12,  44,  44,\n",
      "         49,  28,  71,  80])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 10,  44,  59,  53,   3,  79,  19,  19,  42,   3,  11,  74,  52,  68,\n",
      "         45,  29,  11,   0,  60,  47,  80,  31,  32,   4,   2,  19,  23,  10,\n",
      "          4,  10,   3, 101]) tensor([ 13,  48,  63,  54,   8,  80,  27,  34,  45,   3,  13,  75,  58,  81,\n",
      "         46,  33,  13,   5,  64,  52,  85,  32,  38,   6,   2,  20,  26,  13,\n",
      "          6,  10,  10, 103])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 56,  98,  32,  42,  11,  69,  36,   9,  32,  50,  56,  30,  50,  73,\n",
      "         15, 143,  50,  27,  46,  55,  92,  40,  19, 124,  20,  14,  25,   2,\n",
      "         51,  96,   0,  66]) tensor([ 73, 101,  32,  44,  36,  71,  42,  12,  36,  52,  59,  31,  54,  77,\n",
      "         16, 143,  53,  34,  47,  56, 102,  40,  23, 125,  22,  16,  25,   3,\n",
      "         54, 106,   5,  67])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  5,  47,  35,  37,  14,  14,  31,  39,  39,  22, 112,  63,  14,  22,\n",
      "          0,  37,   9,  14,   4,  16,  45,   2,   9,  28,  54, 115,   0,  48,\n",
      "         52,  75,   9,  84]) tensor([  6,  47,  35,  38,  18,  16,  33,  44,  43,  30, 115,  66,  16,  24,\n",
      "          4,  41,  12,  19,   7,  19,  48,   5,  11,  31,  54, 117,   6,  55,\n",
      "         55,  78,  14,  86])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 55,  49,   4,   0,  48,  65, 112,  56,  78,   9,  99,  81,  81,  90,\n",
      "        104,  21,  30,  13,  50,   2,  75,  99,  51, 104,  70,  13,  42,  70,\n",
      "         53,  86,  31,  87]) tensor([ 60,  57,  17,   4,  50,  67, 114,  59,  80,  10, 103,  82,  84,  92,\n",
      "        105,  24,  38,  17,  50,   4,  78, 101,  53, 108,  73,  14,  45,  87,\n",
      "         65,  95,  34,  94])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 70,  95,  72,  26,   2, 121,  61,  66,   0,  92,  97,  93,  41,  57,\n",
      "          0,  46,  49,  19, 111,  66,  21,  36,  21,  37,   6,  38,  12,  27,\n",
      "        116, 102,  11,  18]) tensor([ 75, 100,  76,  42,   2, 128,  61,  67,   3,  94, 105,  94,  43,  71,\n",
      "          3,  48,  50,  30, 111,  66,  24,  40,  29,  45,   8,  42,  14,  35,\n",
      "        117, 104,  12,  19])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 67,  78,  78,  99,  84,   6,  55,  34,  30,  50,  26,  17, 106,   3,\n",
      "         59,  70,  84,  63,  37,   5,  59,  26,  11,  15,  13,  90,  35,  20,\n",
      "         60,  68,  38,  75]) tensor([ 82,  79,  85,  99,  88,   9,  57,  36,  35,  53,  26,  22, 114,   6,\n",
      "         60,  73,  84,  64,  46,  12,  60,  26,  14,  17,  15, 105,  49,  22,\n",
      "         62,  69,  43,  76])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 56,  37,  49,  28,  59, 114,  78,  54,  56,  35, 104,   5,  77,  21,\n",
      "         16,  26,  54,  95,  73,  28,  52,   0,  25,  27,  57,  25,  40,  48,\n",
      "         15, 118,  36,   0]) tensor([ 58,  41,  54,  33,  63, 115,  81,  57,  56,  36, 112,   6,  78,  22,\n",
      "         17,  27,  55,  95,  73,  31,  60,   3,  28,  31,  59,  26,  42,  50,\n",
      "         16, 119,  39,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([107,  18,  24,  11,  10,  30,  23,  40,  26,  43,   7,  45,  70,  39,\n",
      "         73,  83,   2,  92,  74,  72,  92,  20, 152,  23,  25,  89,  52,  41,\n",
      "         24,   2,  94,  10]) tensor([126,  19,  27,  13,  11,  38,  27,  42,  31,  62,   7,  46,  75,  40,\n",
      "         73,  88,  17,  95,  77,  72,  96,  24, 152,  26,  39,  90,  54,  46,\n",
      "         26,   6,  99,  13])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 38,  41, 103,  40,   6,  13,  61,   2,  60,  66,  32,  46,  19,  61,\n",
      "         57,  46,   3,  65,  44, 113,  41,   6, 109,  16,  36,  82,  31, 126,\n",
      "         22,  85,  32, 139]) tensor([ 43,  50, 106,  46,   8,  14,  63,   3,  61,  70,  32,  60,  23,  66,\n",
      "         60,  49,   6,  69,  52, 115,  42,   7, 109,  17,  37,  85,  32, 128,\n",
      "         25,  87,  38, 148])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 47,  32,   6,  91,  42,   5,  17,  35, 100,  59,  78,  15,  35,  34,\n",
      "         27,   3,  20,   2,  27,  87,  22,  31,  29,  28,  12,  90,  89, 100,\n",
      "         81,  47,  31,  86]) tensor([ 48,  38,  14,  92,  42,   8,  17,  39, 101,  59,  81,  16,  40,  35,\n",
      "         35,   4,  25,   3,  27,  88,  37,  33,  31,  35,  19,  92,  92, 100,\n",
      "         84,  56,  31,  86])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 75,  51,  25,  13,  19,  57,   3,  79,  38,  87,  41,  37,  31,  11,\n",
      "         31,   6,  60, 101,  33,  63,  72,  17,  41,   0,   0,  12,  68,  38,\n",
      "         32,  35,  84,  40]) tensor([ 76,  51,  30,  14,  24,  62,   3,  84,  65,  88,  44,  42,  31,  12,\n",
      "         40,   8,  62, 103,  35,  64,  81,  20,  42,   4,   7,  12,  68,  40,\n",
      "         35,  36,  88,  42])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 41,   0, 140,  63,   6,   4,  68,  12,  26,  30,  43,  13, 109,  10,\n",
      "         13,  85,  19,  16, 114,  82,  25,  75,  16,  52,  38, 118,  79,  43,\n",
      "         27,  77,  21,  82]) tensor([ 41,   1, 140,  71,   6,   4,  73,  18,  29,  33,  45,  14, 111,  12,\n",
      "         15,  87,  27,  20, 117,  83,  27,  78,  16,  54,  42, 121,  99,  47,\n",
      "         28,  83,  24,  82])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 14,  38,  31,   6,  35,  68,  87, 132, 110,  39,  51,  88,   6,  59,\n",
      "         51,  83,  21,  89,  46,  34,  32,  76,  46,  40,  58,  33,  88,   0,\n",
      "         28,  24,  88,  48]) tensor([ 15,  39,  34,   6,  43,  71,  90, 136, 112,  43,  56,  88,   8,  59,\n",
      "         52,  87,  21,  91,  59,  34,  35,  79,  46,  42,  64,  36,  90,   5,\n",
      "         31,  25, 110,  50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 79,   4,  40,   0,  95,  58,  39,  16,  57,  25,  54,  86,  41,  20,\n",
      "         90, 145,  74,   8,   0,  33, 106, 117, 111,   2,  27,   3,  30, 124,\n",
      "          5,  53,  90,  29]) tensor([ 80,   8,  43,   6,  98,  65,  41,  20,  59,  26,  59,  89,  42,  20,\n",
      "         96, 148,  74,  13,   2,  39, 109, 119, 116,   4,  27,   7,  30, 127,\n",
      "         10,  54,  96,  30])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 64,  28,  66,   4, 102,  26,  53,  23,  63,  68,   2, 111,  93,  32,\n",
      "         36,  37,  41,  13, 115,   0,  40, 102,  18,  57,  26,   9,  46,  26,\n",
      "         95,  16,  36,  22]) tensor([ 73,  31,  69,   9, 103,  29,  57,  27,  64,  68,   5, 115,  99,  37,\n",
      "         44,  41,  42,  18, 125,   5,  49, 105,  20,  58,  26,  12,  47,  29,\n",
      "         97,  21,  36,  24])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 16,  32,   3,  17,  45,  55,  24,  56,  71,  15,   3,  13,  68,  25,\n",
      "         57,  48,  19,  28,  29,  53,  16,   6,  50,   8,  84, 119,  17,  51,\n",
      "         45,  49,  45,   8]) tensor([ 18,  37,   4,  18,  50,  56,  29,  57,  73,  15,   3,  19,  70,  26,\n",
      "         57,  48,  29,  29,  29,  54,  35,  10,  62,  10,  87, 121,  17,  52,\n",
      "         53,  57,  54,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 96,  45,  29,  56,  26,  20,  68,   9,  67,  47, 103,  88,  55,  26,\n",
      "         24,   6,   2,  35,  63,  64,  11, 116, 113,  57,  36,  72,   6,  63,\n",
      "         16,   0,  28,  32]) tensor([ 99,  46,  29,  62,  27,  25,  70,  19,  70,  47, 106,  88,  57,  27,\n",
      "         27,   7,  11,  38,  64,  67,  11, 127, 114,  60,  37,  77,   9,  64,\n",
      "         26,   4,  29,  39])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 20,  60,   7,  11,  25,  10,  49,  35,   9,  43,  30,  37,  39,  78,\n",
      "        119,  21,  13,  35,  78,  13,  71, 107,  70,  56,   5,  90,   0,  30,\n",
      "         13,  17,  28,  31]) tensor([ 20,  60,   9,  33,  28,  18,  53,  40,   9,  46,  36,  38,  40,  78,\n",
      "        122,  24,  16,  36,  86,  15,  79, 109,  73,  61,  10, 123,   4,  31,\n",
      "         13,  19,  33,  33])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 12,  98,  33,  57,   9,   0,  67, 112,   3,  71,  41, 120, 101,  25,\n",
      "         59,   9,  89,   0,  90,   0,  31,  77,  53, 102,   0,  50,  29,   0,\n",
      "         74,   3,  73,  22]) tensor([ 14, 101,  34,  59,  22,   2,  69, 118,   8,  72,  41, 126, 102,  26,\n",
      "         61,   9,  96,  10,  98,   5,  34,  85,  58, 105,   2,  50,  32,   2,\n",
      "         78,   6,  75,  27])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 35,  36,   0,  57,   6,  27,   5,  72,  20,  94,  81,  67,   2,   4,\n",
      "         40,  53,  66,  33,  69,  99,  33, 121,  23,   6,  74,  34,  41,   5,\n",
      "         54,  50,  67,  22]) tensor([ 37,  36,   2,  69,  10,  36,   6,  75,  23, 100,  85,  67,   3,   4,\n",
      "         42,  57,  67,  38,  77, 100,  34, 124,  27,   8,  81,  35,  43,   5,\n",
      "         56,  53,  69,  23])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([40, 15, 64, 72,  0, 10, 36, 46, 19, 33, 51, 39,  5, 37, 72, 74, 10, 98,\n",
      "        37,  7, 11, 36, 10, 13, 18,  2, 14, 50, 57, 90,  0, 24]) tensor([ 53,  17,  64,  73,   3,  18,  40,  47,  26,  34,  57,  40,   7,  39,\n",
      "         74,  82,  12, 104,  41,   7,  15,  38,  12,  21,  19,   3,  19,  53,\n",
      "         62,  91,   4,  29])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([98, 43, 91,  5, 71, 20,  0, 11,  4, 69, 35, 40, 31, 33, 85, 87, 19, 80,\n",
      "        84,  7, 42, 21, 85, 10, 26, 46, 45, 13, 91, 15,  9, 10]) tensor([101,  54,  95,   6,  75,  23,   4,  14,   8,  72,  39,  44,  31,  36,\n",
      "         92,  92,  25,  82,  88,  19,  46,  24,  87,  11,  29,  49,  45,  19,\n",
      "         93,  16,  13,  25])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,  13, 110,   9,  56,  35,  10, 140,  95,  15,   0,  31,  97,  17,\n",
      "         45,  36,  34,  26,  55,  65,  61,  38,   6,  41,  44,  37,  79,  14,\n",
      "         37,  20,  41,  15]) tensor([  4,  13, 110,  14,  56,  38,  15, 145,  95,  15,   4,  32, 103,  19,\n",
      "         51,  40,  43,  31,  57,  66,  64,  39,   9,  41,  51,  37,  81,  36,\n",
      "         39,  26,  41,  17])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  6,  53,  56,  26,  11,  31,  10,  25,  64,  28,  37,  11,   2,   2,\n",
      "        116,  88,   3,  32,  95,  32, 104,  25,  31,  17,  37,  20,  22,  65,\n",
      "         50,  43,  40,  25]) tensor([ 12,  59,  61,  28,  14,  31,  10,  32,  65,  29,  41,  12,   3,   2,\n",
      "        117,  90,   4,  35, 101,  34, 113,  26,  32,  17,  44,  32,  23,  66,\n",
      "         54,  43,  47,  35])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8,  50,  24,  53,   0,  59,  20,  55, 106,  60, 114,   6, 113,  48,\n",
      "        100,  55,  59,   2,  67, 147,   6, 124,   2,  41,  13,  15,  44,  55,\n",
      "         41,  29,  73,  82]) tensor([  9,  53,  26,  55,   5,  64,  21,  58, 109,  64, 117,   8, 114,  49,\n",
      "        103,  59,  63,   2,  74, 152,  10, 127,   3,  45,  17,  16,  49,  56,\n",
      "         46,  31,  76,  85])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 94,  34,  11,  28,  22,  31,  51,  76,  80,  70,  49,  32, 109,   9,\n",
      "          0,  94,  81,  82,  63,   4,  18,  67,  97,   7,  31,  94,  34,  32,\n",
      "         74, 103,  35,   8]) tensor([ 99,  36,  13,  28,  25,  31,  53,  81,  81,  75,  57,  33, 109,  17,\n",
      "          5,  95,  84,  87,  68,   6,  21,  87,  99,   8,  37,  95,  37,  34,\n",
      "         74, 120,  35,   8])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 39,   3,  66,   7,  65,  59,  35,  17,  12,  33,  20,  24,  20,  77,\n",
      "         88,  61,  51,  89,  18, 116, 102,  95,  46,  33,  34,  76,   2,  26,\n",
      "         95,  20,  13,  98]) tensor([ 39,   5,  93,   8,  65,  66,  43,  19,  13,  37,  23,  26,  21,  89,\n",
      "         89,  75,  55, 112,  18, 120, 108,  96,  55,  38,  51,  79,   4,  57,\n",
      "         96,  23,  14, 100])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([34, 25, 94,  7,  9, 50, 65, 66, 38, 62, 61, 56,  0, 11, 58, 71, 27, 59,\n",
      "        92, 55, 58,  7, 73, 53, 14, 21, 19, 52,  5, 35, 73, 50]) tensor([35, 26, 97,  9, 11, 51, 67, 69, 43, 64, 64, 56,  3, 17, 58, 71, 29, 59,\n",
      "        95, 58, 61, 14, 79, 55, 14, 24, 25, 53,  5, 42, 73, 53])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 19,  25,  43,  29, 128,  50,  25,   9, 100,  84,  28,  68,  60,  12,\n",
      "         18,  14,   3,  12,  47,  47,  50,  48,  32,  64, 101,  54,  41,  20,\n",
      "         11,  68,  94,  29]) tensor([ 29,  27,  43,  33, 132,  69,  25,  13, 101,  86,  29,  72,  63,  15,\n",
      "         21,  16,   9,  14,  49,  68,  51,  54,  35,  67, 104,  65,  48,  24,\n",
      "         14,  69,  95,  29])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 44,  46,  20,  60,  61,  16,   6,  47,  11,   6,  21,  34,   0,   6,\n",
      "         74,  76,   7,  83,  19,  30,   7,  59,  29,  92,  21, 117,   6,  51,\n",
      "         66,  77,  30,  51]) tensor([ 45,  52,  29,  66,  65,  16,   9,  48,  12,  18,  22,  39,   2,   9,\n",
      "         76,  78,   7,  85,  21,  31,   9,  63,  35,  94,  23, 120,   7,  69,\n",
      "         68,  77,  34,  54])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([123,  10,  30,  33,  43,  53,  15,  41,  11,  10,  92,  50,  40,  86,\n",
      "         44,  36,  84,   5,  11,  44,  29,   5,  76,  20,  59,  79,  92,  71,\n",
      "         48,  11,  81,  12]) tensor([126,  10,  35,  39,  45,  56,  27,  47,  13,  13,  93,  52,  40,  88,\n",
      "         49,  41,  92,   8,  20,  83,  29,  16,  80,  23,  63,  79,  93,  76,\n",
      "         51,  14,  81,  14])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 37,  75,  22,  60,  87,  21,  13,   6,  24,  30,  23,  22,  91,  22,\n",
      "         12,  35, 109,  72,  63,  72,   0,  10,  11,  34,  20,  11,   3,   9,\n",
      "         12,  22,  35,  79]) tensor([ 58,  79,  23,  66,  96,  40,  18,   7,  28,  33,  27,  23,  93,  25,\n",
      "         16,  38, 111,  75,  68,  74,   7,  13,  15,  39,  23,  15,  10,  13,\n",
      "         14,  25,  40,  81])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,  12,  93,  83,  79,  38,  55,  55,  82,  45,   8,   6,   4, 105,\n",
      "         70,  36,  41,  36,  28,  74,  25,  24,   2,  67, 109,  21,  58, 103,\n",
      "         58, 118,  98,  43]) tensor([ 22,  17,  93,  90,  81,  39,  56,  62,  87,  46,   8,   6,   7, 111,\n",
      "         78,  36,  51,  39,  28,  75,  28,  25,   5,  67, 109,  25,  58, 106,\n",
      "         90, 124,  98,  43])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 27,  11, 100, 139,   0,  16,   8,  32,  20,   6,  97, 127,  30,  65,\n",
      "          6,  41,  79,  38,  23,  36,  18,  19,   0,  17,  24,  55,  55,  38,\n",
      "         35,  40,  50,  10]) tensor([ 29,  21, 100, 140,   3,  17,   8,  34,  20,   6,  99, 128,  32,  68,\n",
      "          7,  42,  80,  40,  27,  37,  29,  22,   3,  17,  27,  55,  55,  39,\n",
      "         38,  43,  51,  10])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 37,  13,   0,  65,  74,  44,  19,  77,  13,  53,  33,  39,  91, 136,\n",
      "         47,  59,  14,  66,  55,  47,  95,  35,  50,  13,  70,  75,   8, 111,\n",
      "         26,  85,  43,  22]) tensor([ 43,  16,   1,  66,  76,  45,  20,  77,  14,  55,  34,  42,  94, 136,\n",
      "         51,  59,  20,  77,  56,  47,  98,  43,  55,  23,  72,  76,  12, 113,\n",
      "         28,  94,  46,  26])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  75,  32,  98,  38,  68,  61, 104,  90,  55,  52,  29,  92,  67,\n",
      "        104,  67,  25,  28,  47,  68,  31, 102,  53,   2,  78,  55,  40,   3,\n",
      "         33,   9,  33,  91]) tensor([  6,  75,  40, 103,  40,  68,  67, 107,  91,  56,  59,  29,  94,  67,\n",
      "        104,  79,  29,  55,  49,  69,  32, 102,  54,   8,  84,  55,  46,   5,\n",
      "         37,  10,  36,  95])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([120,  58,  16,  20,  44,  57,  33,  62, 101,  41,  10, 120,  34,  79,\n",
      "         17,  47,  50,   4,  28,  16, 138,  99,  86,  21,   0,  45,  59,  19,\n",
      "         60,  69,  86,  93]) tensor([122,  62,  19,  23,  45,  70,  37,  64, 103,  43,  10, 121,  35,  87,\n",
      "         17,  47,  52,   5,  30,  16, 140, 104,  90,  22,   4,  60,  59,  22,\n",
      "         65,  81,  87,  97])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 96, 115,  60,  24,  57,  34,  19,  13,  46,  30,  47,  65,  60,   9,\n",
      "        120,  64, 105,  24,  98,   0,  26,  15,  41,  46,  42,  28,  10,  28,\n",
      "         83,  19,  27,  39]) tensor([ 99, 124,  62,  25,  60,  34,  19,  17,  49,  30,  50,  66,  66,  11,\n",
      "        120,  66, 106,  31,  98,   3,  26,  16,  41,  47,  45,  29,  18,  30,\n",
      "         83,  24,  34,  43])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 74,  17,  55,  54,  19,  36,  82,  28,  41,  21,   0,  77,  32,  70,\n",
      "         25,   5,  17,  69,   0,  58,  19,  41, 102,  22,  12,   2,  91,  77,\n",
      "         22,   2,   7, 117]) tensor([ 80,  22,  59,  54,  38,  40,  84,  32,  48,  25,   4,  81,  34,  72,\n",
      "         30,   6,  18,  71,   3,  61,  26,  44, 108,  31,  14,   3,  94,  87,\n",
      "         24,   2,   7, 119])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 39,  29,  43,  76,  50,  94,  23,  27, 146,  12,  30,   0, 127,  45,\n",
      "         37,  74,   2,  95,  42,  53,  53, 114,  99,  55, 105,  85,  45,  27,\n",
      "          7,  26,  19,  43]) tensor([ 40,  36,  48,  76,  57,  97,  36,  27, 148,  14,  31,   4, 127,  48,\n",
      "         38,  75,   3,  96,  42,  57,  54, 115,  99,  58, 106,  88,  51,  32,\n",
      "         12,  28,  21,  43])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 30,   9, 115,   0,  38,  61,   6,   5,  16,   7,  78, 102, 113,  47,\n",
      "         32,   2,  68,  74,  31, 125,  30,  54,  13,  20,  89,  34,  96,  13,\n",
      "         28,  95,  78,  28]) tensor([ 35,   9, 117,   3,  43,  66,   6,   8,  19,   7,  82, 109, 114,  53,\n",
      "         37,   5,  69,  79,  33, 140,  31,  55,  13,  27,  93,  34, 116,  15,\n",
      "         36,  97,  80,  28])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([114,  24,  41,  29,  62,   0,  17,  20,  20,  45,  70,  60,  10,  69,\n",
      "         49,  51,  52, 118,  84,  63,  13, 126, 118,   2,   2,  85,   6,  33,\n",
      "         40,  85,  69,  63]) tensor([119,  26,  43,  37,  99,   7,  33,  20,  31,  47,  75,  63,  11,  70,\n",
      "         49,  52,  59, 120,  87,  66,  21, 126, 119,   4,   5,  86,  19,  35,\n",
      "         40, 109,  71,  67])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 20,  94, 107,  38,  71,  49,  76,  46,  46,  24,  34,  10,  97,   2,\n",
      "          0,  45,  22,  10,  33, 111,  88,  10,   2,  37,  37,  37,  30,   9,\n",
      "         22,  19,  12,   5]) tensor([ 24,  97, 108,  38,  77,  63,  83,  63,  49,  28,  37,  15,  99,   3,\n",
      "          3,  48,  31,  15,  43, 113,  88,  14,   6,  40,  40,  40,  31,   9,\n",
      "         25,  19,  14,   7])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 16,  38,  60,   7,  54,  42,   6,  25, 105,  37,  92,  51,  98,  73,\n",
      "         69,  70,  53,  90,   2,  54,   4,   9,   0,  30,  71,  63,  44,  12,\n",
      "         85,  85,   9,  66]) tensor([ 23,  39,  65,  13,  55,  49,   8,  27, 119,  37,  93,  62, 106, 103,\n",
      "         75,  72,  73,  93,   3,  54,   4,   9,   7,  34,  74,  65,  47,  16,\n",
      "         87,  86,  15,  66])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 29,  41,   8,  16,  19,   0, 125,  85, 117,  22, 106,  17,   2,  77,\n",
      "         76,  18,  82,  20,  46,  36,  95,  38,  80,  19,  25,  55,  19,  41,\n",
      "         34,  73,  16,  14]) tensor([ 32,  44,   9,  36,  21,   2, 128,  88, 122,  31, 107,  22,   5,  80,\n",
      "         84,  23,  85,  21,  49,  38,  95,  40,  85,  19,  26,  56,  20,  44,\n",
      "         37,  75,  18,  15])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  7,   6,   9,  27,  37,  47,  20,  72,  11,  49, 123,   7,  18,   4,\n",
      "         21,  95,   7,  17,  21,   9,  38,  72,   0,  35,   0,  65,  12,  95,\n",
      "          6,  46,  55,  55]) tensor([  7,   6,  12,  28,  51,  48,  22,  72,  12,  54, 126,  10,  19,   4,\n",
      "         21, 101,   8,  21,  21,   9,  40,  72,   3,  38,   4,  81,  18,  99,\n",
      "          6,  48,  57,  58])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  5,  15,  25,  33,  68,  43,  19,  85,   8,  71,   8,  89,  42,  60,\n",
      "         80,   2,  36, 101,  60, 123,  62,   3,  30,   9,  86,  18,  59,  65,\n",
      "          0,  45,  13,  19]) tensor([ 10,  15,  30,  35,  72,  53,  20,  85,  13,  75,   8,  91,  42,  60,\n",
      "         83,   4,  39, 103,  61, 126,  64,   3,  46,  11,  87,  18,  64,  70,\n",
      "          5,  48,  16,  20])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 93,  20,  77,   6,  67,  13,  60,  65,  52, 102,   6,  92,  35,  94,\n",
      "         63,  39,   2,  47,  21, 119,  17,  71,  65,  46, 132,  69,  61,   2,\n",
      "         49,  71,   8,  70]) tensor([ 97,  24,  78,   9,  73,  21,  61,  77,  52, 103,  13,  96,  35,  97,\n",
      "         64,  43,   3,  99,  24, 129,  19,  80,  68,  46, 134,  70,  62,   2,\n",
      "         50,  72,   9,  75])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,   7,  27, 100,  23, 107,  71,   5, 106,  75,  27,   0,  46,  92,\n",
      "         76,  90,   8,  32, 104, 116,  57,  27,   9,  39,  29,  43, 113, 107,\n",
      "         85,  66,  78, 100]) tensor([ 22,  15,  39, 105,  38, 109,  71,  10, 112,  77,  33,   2,  48,  94,\n",
      "         83,  95,  22,  36, 114, 131,  59,  27,  24,  41,  32,  46, 113, 108,\n",
      "         89,  68,  80, 107])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 87,   0,  33,  71,  25,  10,  49,  79,  50,  25,  92,  24,  40,  22,\n",
      "          9,  24,  74,  33,  86,  93,  27,  40,  23,  32,  13,  60,  87,  22,\n",
      "         22,  45,  52, 126]) tensor([ 89,   1,  34,  71,  27,  10,  50,  84,  51,  27,  93,  26,  40,  24,\n",
      "         15,  25,  79,  44,  89,  99,  51,  44,  25,  34,  21,  76,  87,  24,\n",
      "         27,  49,  53, 131])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([29, 25,  9,  9,  3, 49, 25, 29, 13, 89, 21, 69, 79, 71,  2, 39, 96, 44,\n",
      "         3, 51, 31, 43, 78, 52, 22, 34,  5, 23,  2, 65, 21, 46]) tensor([33, 26, 30, 12,  3, 50, 27, 31, 15, 91, 24, 72, 79, 84,  8, 44, 98, 46,\n",
      "         3, 55, 38, 46, 79, 55, 25, 37,  5, 25,  6, 67, 25, 50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 70,  27,  28,  16,  23,  43,  91,  95,  43,  15,  42,  23,  52,  29,\n",
      "         82,   5,   0,  12,  12, 100,  53,   5,  10,  31,   8,  29,  25,  20,\n",
      "         16, 116,   0,   2]) tensor([ 71,  28,  28,  17,  24,  46,  97, 103,  46,  25,  44,  23,  64,  38,\n",
      "         86,  10,   4,  16,  15, 100,  59,   6,  14,  32,  13,  37,  36,  20,\n",
      "         18, 117,   2,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 14,  47,  96,  30,  67,  54,   7,  79,  24, 126,  84, 140,   9,  40,\n",
      "         76,  88,  51,  45,  59,  76,  13,   0,  29,   4,  64,  16,  70,  87,\n",
      "         53,   2,  11, 103]) tensor([ 14,  48,  97,  31,  96,  60,   7,  85,  26, 131,  87, 143,  14,  42,\n",
      "         85,  91,  51,  46,  62,  79,  13,   9,  35,   9,  69,  20,  70,  92,\n",
      "         58,   2,  15, 118])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 42, 106,  45,  10,   2,  24, 100,  66,  49,  37,   0,  72,  75,  15,\n",
      "          5,  43,   4,  40,  21,  89,  28,   6,   2, 119,  27,  39,  83,  36,\n",
      "         69,  71,  46,  32]) tensor([ 44, 112,  47,  11,   4,  28, 100,  67,  51,  39,   3,  76,  88,  18,\n",
      "          7,  45,   4,  45,  22,  91,  32,   6,   6, 119,  30,  54,  85,  37,\n",
      "         71,  73,  55,  45])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,  11,  41,   4,  42,  18, 108,  44, 102,  28,  11,   9,  34,  53,\n",
      "         34,  60,  79,  46,  14,  11,  87,   3,  41, 101,  13,  96,  66,  25,\n",
      "         26,  28,  24,  28]) tensor([ 13,  23,  44,   6,  45,  22, 109,  50, 103,  43,  15,  11,  36,  54,\n",
      "         34,  62,  85,  48,  18,  35,  87,   3,  48, 109,  19, 101,  68,  26,\n",
      "         26,  29,  25,  31])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 26,  62,  37,  62,  69, 102,  13,   9,  33,  33,  30,   7,  50,  57,\n",
      "          9,  36,  15,  21,  15,  78,  80,  37,  45,  11,   0,  33,   3,  34,\n",
      "         25,   2,   6,  35]) tensor([ 26,  62,  41,  88,  69, 105,  20,  13,  34,  35,  32,   8,  53,  60,\n",
      "         11,  37,  17,  23,  30,  78,  83,  41,  46,  15,   1,  37,   4,  34,\n",
      "         43,   5,   8,  40])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 61,  24,  49,   6,  93,   6,  32,   5,  56,  52,  50, 105,  65,  17,\n",
      "         11, 113, 110,   7,   7,  72,  47,  90,  40,   3,  59,  32,  35,  39,\n",
      "         60,  33,  36,  33]) tensor([ 62,  24,  53,  10,  95,   9,  34,   6,  62,  55,  52, 106,  67,  20,\n",
      "         13, 114, 121,   9,   8,  74,  48,  91,  41,   6,  62,  32,  38,  43,\n",
      "         65,  34,  38,  53])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 33,  87,   9,  52,  44,  95,  27,  10,  94,   2,  27,  35,  20,  66,\n",
      "         24,  26,  27,  19,   9,  55,  19, 152,  12, 108,  13,   8,  40,  60,\n",
      "         37,  56,  71, 113]) tensor([ 46,  88,  11,  53,  46,  96,  34,  18, 101,   5,  29,  37,  26,  67,\n",
      "         29,  26,  29,  19,  18,  59,  19, 159,  12, 112,  16,   8,  43,  62,\n",
      "         40,  65,  72, 114])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 41,  25,  79,  42,  92, 119,  51,  29,  94,  29,   9,  60, 113,  57,\n",
      "        113,  44,   0,  15,  31,  45,  41,  69,   6,   0,  33,  71, 107,  26,\n",
      "         31,   9,  33,  17]) tensor([ 44,  28,  85,  45, 101, 119,  55,  30,  97,  35,  10,  61, 113,  61,\n",
      "        116,  46,   6,  19,  32,  52,  42,  72,   7,   2,  38,  71, 108,  26,\n",
      "         40,  12,  35,  20])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 94, 118,  36,  13,  92,  97,  31,  51,   9,   0,  29, 107,  51,  17,\n",
      "         49, 116, 105,  18,  12,  62,  51,  73,  69,  90,  78,  18,  76,   4,\n",
      "         35,  76,  78,  14]) tensor([ 98, 119,  42,  13,  97,  98,  31,  55,  10,   5,  29, 108,  62,  17,\n",
      "         51, 117, 111,  21,  15,  65,  52,  77,  71,  92,  78,  18,  79,  11,\n",
      "         38,  89,  87,  29])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,  24,  72,  99,  45,  30,  34,  13,  21, 115,  24,  56,  11,   9,\n",
      "         40,  34,  11,  99,  95,  26,  62,  24,   0,   3,  12,  75,  45,  70,\n",
      "         50,  87, 103,  27]) tensor([ 22,  25,  72, 102,  47,  33,  35,  23,  31, 117,  26,  56,  15,  34,\n",
      "         41,  35,  14, 107, 100,  26,  62,  26,   6,   4,  12,  78,  50,  76,\n",
      "         55, 107, 110,  29])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 24,  28, 107, 113, 100,  34,  22,   7,  99,  11,  56,  49,  65,  61,\n",
      "          0,  61,  12,  22,  22,  16,  92,  27,  55,  58,  28,   7,  49,  25,\n",
      "          9, 125,  31,  81]) tensor([ 29,  35, 109, 119, 101,  45,  26,   9, 109,  12,  58,  50,  69,  80,\n",
      "          1,  63,  12,  40,  31,  18,  93,  34,  57,  61,  30,  10,  50,  50,\n",
      "          9, 133,  32,  81])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  45, 101,  98,  49,  44,  47,  31,  47,  40,  92,   2,  76,  14,\n",
      "         25,  57,  55,  52,  63,  59,  58, 110,  19,  29,  84,  54,  54,  17,\n",
      "         76,   0,  53,  33]) tensor([  4,  49, 101, 107,  50,  50,  48,  36,  47,  42,  92,   4,  76,  16,\n",
      "         26,  60,  65,  56,  65,  61,  61, 110,  21,  44,  86,  56,  56,  19,\n",
      "         83,   2,  53,  36])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 15,  57,   8,  24,   2,  29,  70, 123,  53,  12,  48,   6,  25,   9,\n",
      "         37,  23,  56,  43,  43,  15,   4,  41,  49,  53,   5,   8,  75, 104,\n",
      "         38,  97,  33,  75]) tensor([ 22,  60,  10,  28,   2,  30,  76, 126,  55,  12,  49,   9,  26,  10,\n",
      "         38,  23,  60,  46,  46,  15,  10,  41,  49,  54,   7,  23,  78, 104,\n",
      "         40, 110,  36,  77])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  5,   5,   5,   2,  63,  64,  67,  92,   2,  58,  31,  22,   9,  99,\n",
      "         42,  57,  67,  61,   0,  70,  60,  37,  28, 123,  61,  46, 114,  22,\n",
      "         88,  58,  94,  34]) tensor([  5,   7,  14,   5,  66,  65,  69,  92,   3,  62,  55,  23,  10, 105,\n",
      "         45,  70,  67,  61,   2,  72,  64,  39,  32, 126,  67,  49, 115,  24,\n",
      "         90,  63,  95,  54])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 31,  27,  15,  59,  20,  69,  14,  53,  28, 103,  24,  40,  61,  30,\n",
      "         16,   7,  94,  38,  93, 108,  16,   6,   9,  80,   8,  79,  64,  35,\n",
      "         86,  50,  37,   2]) tensor([ 32,  31,  15,  74,  23,  71,  14,  61,  29, 105,  29,  45,  64,  32,\n",
      "         22,  11,  96,  41, 100, 114,  19,  11,  12,  80,   8,  82,  65,  40,\n",
      "         86,  51,  38,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 21,   0,  20,  62,  12,  12,  79,  13,  58, 108, 110,  23, 119,   4,\n",
      "        107,  49, 114,  64,  76,  16,  20,  77,  24,  37,  58,  61,  87,  70,\n",
      "         63,  18,  76,  19]) tensor([ 43,   3,  20,  62,  21,  14,  79,  13,  60, 111, 112,  28, 122,   4,\n",
      "        107,  49, 114,  65,  78,  18,  23,  86,  29,  37,  70,  66,  87,  71,\n",
      "         71,  20,  79,  21])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8, 103,  96,  53, 113,   6, 109,  32,  16,  33,  44,  47,  51, 104,\n",
      "         10,  35,  14,  49,  27, 106, 104, 132,  80,  12,  25,  21,  11,  68,\n",
      "        107,  88,  82,  75]) tensor([ 11, 107,  96,  59, 116,  11, 110,  37,  27,  37,  46,  48,  60, 107,\n",
      "         12,  38,  16,  53,  31, 107, 105, 135,  83,  13,  30,  24,  17,  68,\n",
      "        108,  90,  82,  81])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 97,  15,  57,  66,   5,  51,  60,   0,  62,  26,  12,   9,  26,  30,\n",
      "         74,  90,  17, 113,  40,  17,   2,  81,   6,  19,  11,  23,  93,  12,\n",
      "         71,  35,  11,  39]) tensor([100,  15,  60,  66,   8,  53,  60,   2,  63,  31,  14,  21,  29,  36,\n",
      "         75,  91,  18, 116,  44,  19,   2,  82,   9,  23,  14,  23, 104,  13,\n",
      "         71,  35,  12,  39])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,  46,  45,  41,  37,  32,  16, 105,  24,   7,  16,  46,  49,  20,\n",
      "          0,  47,  82,  31,  39,  15,  75,   9,   2,  85,  68,  91,   5,   2,\n",
      "         44,  67,  15,  16]) tensor([ 23,  50,  45,  41,  42,  34,  19, 113,  25,  10,  17,  49,  50,  24,\n",
      "          6,  50,  84,  31,  46,  16,  76,  11,   4,  87,  69,  92,   7,   4,\n",
      "         51,  68,  16,  18])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 82,  58,  23,  43,  51,  93,  99,  33,   2,  49,  16,  48,  95, 123,\n",
      "         15,   2,  35,   0,   4, 115, 100,  45,  10,  29,  14, 100,  84,  57,\n",
      "         55,  27,  31,  93]) tensor([100,  60,  27,  48,  58,  95, 102,  33,   8,  50,  19,  50,  97, 130,\n",
      "         19,   3,  38,   4,   7, 124, 101,  48,  12,  32,  15, 103,  85,  61,\n",
      "         56,  28,  43,  93])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([117,  13,   5,  73,  24, 104,  62,  67, 115,   9,  23,  81,  88,  61,\n",
      "          5,  40,  43,  66,  40,  62,  70,  11,  83,  69,  49,  41,  60,  52,\n",
      "         20,  43,  31,  39]) tensor([124,  20,   6,  76,  24, 107,  63,  67, 124,  11,  30,  82,  96,  65,\n",
      "          9,  54,  49,  71,  40,  67,  70,  11,  85,  69,  52,  41,  67,  54,\n",
      "         23,  48,  31,  47])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([145,   6,  23,  19,  31,  43,   7,   0,  40,  19, 109,   3,  43,  66,\n",
      "         27,  17,  35,  17,  49,  66,  23,  80,  38,  59,  45,  30,  33,  65,\n",
      "         42,  38,  45,  24]) tensor([148,   8,  24,  21,  32,  46,   7,   3,  42,  22, 112,   4,  49,  69,\n",
      "         29,  20,  36,  20,  49,  71,  28,  83,  49,  60,  46,  32,  38,  68,\n",
      "         42,  44,  47,  27])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 18,  78,  32,   0,   5,   2,  52,   4,  38,  37,  47,  82,  96,  40,\n",
      "         73,  57,   2,  94,  92,  25,  36,  32,  58,  26, 107,  33,  60,   0,\n",
      "          0,   0,  19,  57]) tensor([ 22,  84,  35,   3,  10,   3,  57,   4,  40,  37,  48,  86, 102,  45,\n",
      "         76,  57,   7,  95,  92,  27,  38,  36,  58,  31, 129,  35,  61,   3,\n",
      "          6,   5,  20,  60])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 20,  66,  17, 107,   4,  21,  41,  20, 124,  81, 116,  35,  60,  39,\n",
      "         88,  44,  27,  68,   6,  11,  22,  41, 110, 107, 126,   0,  65,  66,\n",
      "         33, 123,  63, 117]) tensor([ 22,  67,  17, 117,   5,  44,  42,  24, 126,  86, 121,  35,  65,  44,\n",
      "         89,  46,  29,  71,   8,  13,  24,  48, 114, 110, 127,   6,  68,  69,\n",
      "         36, 125,  64, 119])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([113,  31,  52,  39,  53,   0,  79,  15, 108,  42,  73,  32,  49,   5,\n",
      "          2, 108,   6,  80,  19,  91,   0,  99,  34,  74, 103,   9,  72,  22,\n",
      "         12,  21,  16,  49]) tensor([113,  32,  52,  41,  90,   3,  85,  15, 110,  43,  75,  36,  50,   8,\n",
      "          5, 116,   8,  80,  20,  95,   3, 100,  39,  77, 109,  12,  75,  24,\n",
      "         15,  26,  19,  53])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 82,   8,  47,  47,  63,  35,  71,  44,  98,  23,  20,  67,  19,  24,\n",
      "          0,   0, 111,  54, 116,  36,  65,  81,  46,  16,  27,  31,   9,  26,\n",
      "         57,  48,  35,  59]) tensor([ 84,  10,  54,  57,  69,  51,  75,  47, 106,  25,  26,  87,  22,  27,\n",
      "          1,  13, 118,  54, 117,  43,  65,  88,  46,  17,  34,  34,  12,  28,\n",
      "         60,  50,  39,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 47,  51,  45,  66,  26, 105,  19,  38,   2,   6,  57,  11,  59,   9,\n",
      "         55,  10,  26,  40,  60,  68,   2,  28,  61,  55,  90,  38,  19,  39,\n",
      "         65,  65,  15,  65]) tensor([ 48,  51,  46,  74,  26, 109,  20,  40,   4,   8,  58,  13,  63,  13,\n",
      "         64,  12,  26,  41,  66,  71,   2,  28,  61,  57,  91,  42,  19,  41,\n",
      "         72,  67,  15,  68])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([112, 137,  52,  59,  32,  29,  51,   0,  22,  78,  60,  69,  91,  51,\n",
      "        105,  25,  34,  64,  54,   9,  15,  35,  67, 108,  33,  34,  59,  48,\n",
      "         32,  62,   8, 105]) tensor([113, 138,  53,  60,  55,  32,  54,   6,  27,  87,  64,  71, 104,  51,\n",
      "        106,  25,  35,  65,  55,  12,  15,  35,  77, 110,  35,  36,  62,  48,\n",
      "         35,  63,  13, 111])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13, 136,   0,  76,  21,  10,  45,  43,   8,  45,  88,  46,  46,  35,\n",
      "         19,  24,  55,  62,  83,  32,  45,  15,  48,  12,   5,  11,  65,  13,\n",
      "         43,  25,  80,  65]) tensor([ 16, 136,   4,  78,  26,  10,  46,  44,   9,  47,  91,  65,  48,  35,\n",
      "         21,  25,  56,  67,  92,  38,  47,  19,  50,  13,   6,  12,  70,  19,\n",
      "         43,  26,  81,  70])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 50,  88,  94,  16,  24,   0,   0,  26,  28,  18,  45,  19,  85,  91,\n",
      "         22,  49,  25,  60, 103,  86,  28,   2,  92,  56,  68,  17,  34,  21,\n",
      "         61,  23,   2,  47]) tensor([ 55,  91, 111,  18,  25,   1,   3,  36,  29,  21,  48,  20,  88,  93,\n",
      "         34,  50,  26,  61, 107,  90,  29,   2,  93,  59,  68,  19,  41,  23,\n",
      "         80,  25,  10,  50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([109,  11,  64,  63,   0,  79,  35,  26,  39,  18,  62,  97,  50,   9,\n",
      "         29,  12,   0,  87,  54,  22,  83,  75,  87,  13,   2,  59, 112,  18,\n",
      "         32, 106,  50,  86]) tensor([110,  17,  65,  67,   2,  81,  35,  33,  41,  19,  68, 100,  50,  10,\n",
      "         38,  17,   5,  88,  56,  23,  91,  76,  90,  13,   4,  61, 114,  18,\n",
      "         47, 112,  51,  88])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 74,  14,  39,  73,  48,   9,  54, 101,  15,  36,  85,   2,  19,  91,\n",
      "         52,  43,  19,   2,  43,  55,  58,  10,  91,  85,  34,  29,  73,  67,\n",
      "          2, 102,  90,  14]) tensor([ 77,  17,  42,  73,  52,  20,  65, 107,  15,  38,  87,   4,  24,  93,\n",
      "         62,  45,  20,   5,  43,  58,  65,  12,  97,  86,  42,  30,  74,  71,\n",
      "          6, 105,  92,  17])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 21,  64,   3,  27,  57,  73,   3,  12,   3,  32,   2,  25,   0,  89,\n",
      "        119,  19,  74,  69,   4,  37,   6,   9,  36,  60,  57,  76,  36,  14,\n",
      "        102,  67,  76,   9]) tensor([ 22,  65,   5,  30,  61,  77,   3,  12,   4,  34,   2,  30,   4,  92,\n",
      "        127,  24,  87,  72,   5,  37,  11,  11,  41,  64,  58,  78,  45,  15,\n",
      "        102,  69,  76,  20])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 86,  98,  22,   7,  12,  51,  55,  25,  73,  15, 100,  80,   3,  39,\n",
      "         59,  50,  10,   0,   6,  99,  85,  48,  28,  32,  93,  62,  20,   7,\n",
      "         39,  41,   0,   8]) tensor([100, 100,  23,  14,  14,  83,  55,  25,  75,  21, 100,  82,   9,  40,\n",
      "         61,  53,  11,   3,  35, 111, 100,  57,  29,  35,  99,  62,  25,  11,\n",
      "         39,  44,   4,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([83, 49, 63, 16, 12, 48, 58, 27, 65, 45, 19, 18, 54,  2, 76, 99, 28, 79,\n",
      "        77, 19, 78, 24, 27, 17, 76, 19, 11, 26, 17, 42, 50, 76]) tensor([85, 50, 69, 20, 14, 50, 62, 37, 70, 46, 22, 21, 56,  6, 77, 99, 30, 85,\n",
      "        80, 23, 78, 25, 27, 21, 81, 21, 15, 28, 21, 49, 51, 79])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 18, 122,  34,  35,  27,  43, 100, 140,  15,  17, 133,  65,  63,  14,\n",
      "          3, 114,  81,  44,  72,  47,  48,  10,  11,   0,  54,  42,   3, 134,\n",
      "         51,  35,  29,  54]) tensor([ 21, 125,  51,  37,  28,  46, 101, 146,  15,  19, 139,  73,  68,  17,\n",
      "          3, 123,  83,  46,  75,  50,  53,  13,  13,   4,  55,  50,   5, 140,\n",
      "         52,  35,  41,  54])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 28,  33,  25, 127,  32,  95,  39,  27,   9,  13,  65,   7,   3,   8,\n",
      "        106,  20, 115,   7,   0,  28,   4,  62,  29,  11,  30,  54,  81,  35,\n",
      "         77,  43,  10,   0]) tensor([ 30,  38,  27, 127,  32,  96,  40,  28,  10,  14,  67,   9,   7,  20,\n",
      "        110,  22, 119,  11,  11,  34,   4,  62,  29,  14,  32,  54,  82,  36,\n",
      "         83,  45,  12,   4])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 10,  97,  60,   0,  93,  28, 107,  77,   0,  12,  65,  21,  75,  42,\n",
      "         49,  59,  83,  90,  12,  54,  92,   0,  79,  94,  57,  22,  58,  38,\n",
      "         66,  57,  65,  15]) tensor([ 17,  98,  63,   3,  96,  29, 115,  77,   6,  16,  66,  22,  89,  59,\n",
      "         50,  66,  88,  95,  14,  69, 111,   6,  87,  99,  63,  27,  59,  39,\n",
      "         67,  58,  66,  19])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 44,  94,  65,  52,  43,  42,  29,  57,  62,   6, 127,  38,   3,   9,\n",
      "         13,  59,  81, 136,   5,   3,  81,   2,  28,  13,  38,  44,  42,  14,\n",
      "         56,  64,  93,   6]) tensor([ 46,  97,  71,  53,  43,  42,  29,  57,  62,   6, 130,  40,   3,  10,\n",
      "         17,  61,  83, 139,  11,   5,  89,   5,  29,  13,  39,  54,  45,  14,\n",
      "         59,  65,  95,   6])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,   0,   2,  43,   8,  11,  22,  19,  72,  34,  98,  43,  55,  12,\n",
      "         62,  29,  73,  13,  68,   0,  85,  89,  49,  58,  22,  79,  54,  80,\n",
      "         55,  33, 102,  57]) tensor([ 16,   4,   2,  50,  15,  18,  23,  20,  74,  37,  99,  43,  58,  16,\n",
      "         62,  31,  78,  13,  69,   6,  90,  89,  52,  60,  24,  85,  54,  85,\n",
      "         62,  33, 109,  60])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 83,  74,  37,   8,  75, 127,  80,  11,  77, 105,   4,   2,  24,  34,\n",
      "         37,  30,  32, 102,  42,   0,  55,  11,  95, 104,  10,  72,  45,  58,\n",
      "         27,  16, 113,  50]) tensor([ 87,  77,  40,  14,  77, 128,  87,  17,  78, 128,  10,   2,  33,  37,\n",
      "         41,  51,  33, 104,  48,   5,  55,  13,  95, 106,  13,  96,  47,  62,\n",
      "         33,  18, 116,  52])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 38,   5,  57,   9,  33,   2,  26,   0,  73,  96,  24,  73,  39,  46,\n",
      "         83,  55,  81,   0,   2,  40,  46,  39,  18,  59,  37, 125,  14,  91,\n",
      "         47,  17,  51,  79]) tensor([ 43,   7,  57,  12,  35,   2,  35,   3,  78, 100,  28,  75,  41,  49,\n",
      "         85,  71,  87,   3,   8,  42,  49,  42,  40,  61,  67, 133,  17,  91,\n",
      "         49,  37,  54,  79])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 21,   7,  47,  44,  74, 123,   8, 104,   3,  43,  61,  41,  84,  12,\n",
      "         23,  53,  27,   6, 129,  54,  24,  80,  77,  20,  13, 107, 115,  29,\n",
      "         55,  78,  31,   0]) tensor([ 21,  11,  48,  46,  80, 124,  23, 111,   3,  45,  62,  43,  88,  13,\n",
      "         23,  54,  29,   8, 134,  62,  34,  82,  80,  26,  18, 110, 118,  31,\n",
      "         58,  79,  31,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 28,  29,  67,  58,   0,  12,  87,  63,  27,  76,  75,   6, 135,  24,\n",
      "         19,  63, 110,  40,  78,  67,  86,   4,  22,  67,  33,  44,  87,   0,\n",
      "        123, 127,  79,  97]) tensor([ 30,  29,  73,  59,   4,  15, 113,  72,  38,  80,  75,  10, 139,  47,\n",
      "         26,  64, 110,  42,  81,  69,  90,   5,  25,  67,  37,  47,  87,   3,\n",
      "        136, 131,  85, 106])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([49,  4, 11, 21, 83,  0, 17, 56,  0,  8, 11,  7,  7, 87, 13, 37, 74, 75,\n",
      "        12, 64, 11, 33,  9,  2, 42,  0,  0, 31, 85, 85,  8, 18]) tensor([49,  9, 11, 22, 87,  3, 22, 60,  6,  9, 20, 18, 12, 89, 16, 39, 79, 75,\n",
      "        14, 65, 13, 37,  9,  3, 44,  5,  6, 31, 88, 85, 16, 29])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 17,  47, 114,  45,  35,  99,  73,   6,  22,   9,  49,  42, 121,  41,\n",
      "         80,  20,  53,  45,  54,  56,   7,  70,  26,  47,  16,  43,  44,   6,\n",
      "         50,  31,  70,   0]) tensor([ 25,  52, 120,  47,  44,  99,  75,  11,  38,  13,  73,  44, 128,  43,\n",
      "         81,  23,  60,  45,  56,  59,   8,  72,  50,  49,  16,  51,  44,  13,\n",
      "         50,  51,  81,   4])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 79,   4,  93,  93,   0,  70,   6,   4,  11,  91,  23,  51,  10,   8,\n",
      "         39,  10,  33,  62,  32,  20,  16,  38, 114,  10,   0,  11, 118,  11,\n",
      "         26,  38,  37,  23]) tensor([ 85,  12,  95,  94,  14,  77,  11,   6,  13,  91,  26,  53,  12,  13,\n",
      "         40,  10,  35,  65,  36,  21,  19,  40, 115,  13,   1,  14, 119,  12,\n",
      "         27,  44,  38,  24])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 68,  57,  32,  24,   9,  73,  49,  68,  38,  30,  58,  43,   2,  88,\n",
      "         36,  71,   7,   7, 140,  27,  46,  81,  24, 128,  47,  73, 111,  27,\n",
      "        131,  22,  60,  70]) tensor([ 71,  58,  32,  28,  14,  78,  69,  73,  42,  39,  63,  44,   2, 100,\n",
      "         41,  76,   9,   9, 145,  33,  50,  84,  24, 128,  48,  75, 115,  28,\n",
      "        140,  44,  63,  74])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([15, 22, 19, 53, 34, 78,  5, 15, 14,  3, 15, 93, 56, 17, 67, 16, 29, 32,\n",
      "        80, 32,  2,  3,  0,  2, 41, 80, 86, 91, 90, 57, 90,  2]) tensor([ 16,  27,  21,  56,  36,  83,   8,  18,  18,   8,  15, 111,  78,  19,\n",
      "         69,  16,  29,  34,  86,  32,   3,   3,   3,   2,  52,  80,  87, 112,\n",
      "         93,  59,  98,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 69,  18,  35,  24,  65,  34,  46,  29,  39,  95,   0,  49,  26,  10,\n",
      "         23,  31,  98,  71,  47,  28,  89, 114,  36,  47,  90,  94,  81, 128,\n",
      "         91,  10,  45,   2]) tensor([ 72,  21,  37,  28,  69,  39,  46,  31,  42,  98,   3,  50,  26,  12,\n",
      "         28,  47, 103,  75,  52,  33,  91, 114,  44,  47,  97,  96,  84, 129,\n",
      "         92,  12,  47,   2])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  45,  93,   7,  99,   4,   2,  24,  94, 102,  29,  43,  17, 141,\n",
      "        108,  85,  21,  29,   4,   9, 103,  55,  16,  40,  35,  19,  44,  35,\n",
      "         40,  49,   6,  78]) tensor([  5,  46,  95,  10, 100,   7,   2,  36, 105, 103,  46,  44,  19, 145,\n",
      "        118,  86,  26,  33,   8,  13, 128,  63,  16,  43,  38,  21,  47,  41,\n",
      "         40,  50,   6,  78])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([102,  25, 110,  24,  98,  56,  69,  43,  33,  52,  29,  51,  33,   8,\n",
      "          2,  22,  50,  82,  71, 132,  34, 129,  52,  57,  79,  41,  60,  14,\n",
      "         15,  44,  29,  31]) tensor([104,  28, 117,  26, 120,  57,  75,  46,  38,  65,  32,  54,  35,   9,\n",
      "          3,  26,  52,  85,  72, 132,  38, 132,  52,  61,  79,  43,  70,  16,\n",
      "         30,  48,  29,  31])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([63, 14, 43, 44, 66, 34,  0, 52, 41, 30, 16, 37, 45,  8, 57, 29, 34,  7,\n",
      "        74, 29, 25, 61, 64, 12, 48, 54,  0, 26, 44, 78, 34, 78]) tensor([66, 17, 45, 46, 67, 34,  6, 54, 50, 41, 26, 42, 51, 27, 58, 39, 34, 13,\n",
      "        74, 34, 27, 62, 66, 17, 52, 59,  2, 60, 45, 80, 39, 84])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 62,  74,  52,  33,  21,   0,  92,   9,  36, 107,  37,  31,   5,  66,\n",
      "         11,  46,  27,  47,  56,  53,  22,   0,  17,  33,   6, 119,  36,  29,\n",
      "         16,  10,  27,   2]) tensor([ 64,  76,  53,  46,  24,   4,  92,  11,  41, 107,  55,  34,   8,  67,\n",
      "         17,  52,  27,  47,  59,  55,  22,   3,  18,  34,   7, 123,  37,  32,\n",
      "         16,  14,  27,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([28, 36, 52, 48, 86, 31, 13, 11,  4, 83, 11, 45, 93,  2, 43, 85, 39, 77,\n",
      "        62, 47, 61, 16, 19, 25, 60,  3, 30, 72, 49, 10, 54,  9]) tensor([30, 40, 55, 49, 87, 31, 20, 14,  4, 86, 12, 46, 94,  3, 43, 88, 47, 81,\n",
      "        67, 47, 61, 31, 25, 27, 61,  3, 30, 73, 50, 13, 59, 18])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,   2,  87,  25,  54,  70,  93,  24,  20,  21,  44,   7, 100,  51,\n",
      "         18,  93, 116,  47,  80,   8,  51,  19,  77, 103,  14,  51,  33,  94,\n",
      "         13,  10,  22,   4]) tensor([ 24,   5,  88,  27,  55,  71,  95,  34,  45,  22,  45,   7, 112,  53,\n",
      "         19,  96, 116,  63,  80,  18,  55,  19,  83, 107,  21,  52,  36,  97,\n",
      "         17,  12,  23,   7])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,  28,   8,  16,  31,  21,  29,  54,  87,  23,  46,   8,   6,   2,\n",
      "         53,   3,  77,  48,  16,  45,  59,  38,  70,  45,  46,  19,  71,  11,\n",
      "        106,  54,  34,   0]) tensor([ 24,  29,  10,  22,  40,  23,  32,  56,  92,  24,  50,  13,   7,   2,\n",
      "         54,   3,  82,  54,  16,  45,  61,  44,  71,  47,  50,  27,  74,  15,\n",
      "        112,  56,  39,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 38,  70, 103,  81,  86,  49,  16,  60,  13,   0,  29,  21, 111,  27,\n",
      "          7,  78,  56,  15,  18,  15,  73,   5,   0,  64, 106,  64,   3,  53,\n",
      "         21,   6,  66,   2]) tensor([ 39,  74, 103,  83,  86,  50,  17,  61,  14,  15,  30,  25, 114,  28,\n",
      "          7,  84,  57,  15,  19,  16,  77,   9,   4,  64, 116,  67,  10,  58,\n",
      "         27,  10,  77,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 78,  87,   9,   8,  35,  14,  27,  46,  55,   5,   6,  11,  53,  53,\n",
      "         65,   6,  13,  77,  54, 109,  32, 108,   7,  76,  19,  31,  46,  14,\n",
      "         70,  16,   0,  45]) tensor([ 79,  93,  16,  10,  39,  14,  35,  47,  61,   7,   9,  13,  57,  55,\n",
      "         67,   8,  15,  82,  59, 110,  34, 111,   8,  76,  22,  31,  51,  22,\n",
      "         81,  20,   3,  45])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 43,   8,  19,  34,   2, 109,  57,  40,  20, 103,  94,   6,  84,  39,\n",
      "         36,  44,  57,  14,  26,  36,  55,  90,  97,   7,  35,  69, 114,  66,\n",
      "         52,   4,  77, 119]) tensor([ 48,   8,  33,  35,  18, 113,  61,  42,  23, 107,  98,   7,  84,  63,\n",
      "         45,  45,  59,  17,  27,  36,  58,  92, 100,   8,  37,  73, 115,  67,\n",
      "         52,   5,  81, 121])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  3,  22,   1,  25,  46,  60,   7,  40,  53,  47,  31,  12,  36,  14,\n",
      "         59,  42,  36,  89, 110,  33,   2,   4,  21, 109,   7,  53,  35,  79,\n",
      "         26,  57,  67,  53]) tensor([  5,  28,   4,  29,  54,  61,  10,  54,  56,  75,  42,  18,  38,  17,\n",
      "         61,  46,  36,  91, 116,  33,   3,   8,  24, 111,   7,  54,  39,  80,\n",
      "         30,  58,  70,  57])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,  76, 106,  57,  38,   6,   8,  33,  21,  71, 116,  41,   8,   3,\n",
      "         62,  14,  68,  82,   0,  39,  13,   0,  41,  22,  75,  71,  67,  12,\n",
      "         66,  33,   9,  36]) tensor([ 12,  81, 106,  60,  40,   6,   9,  36,  22,  97, 121,  43,  10,   4,\n",
      "         65,  14,  72,  88,   8,  44,  15,   5,  42,  26,  80,  80,  68,  14,\n",
      "         69,  34,  10,  37])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 34,  23,  40, 101,   0, 108,  74,  16,  83,  38,  23,  57, 109,  39,\n",
      "         24,  34,  23,   0,  66,  79,  46,  32,  45,  19,  45,  88,  19,   2,\n",
      "         10,  10,  92,  24]) tensor([ 40,  28,  46, 111,   5, 110,  78,  17,  83,  40,  25,  66, 112,  42,\n",
      "         30,  34,  27,   3,  71,  81,  48,  35,  74,  20,  45,  96,  22,   3,\n",
      "         12,  15,  96,  24])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 76,  36,   2,  45,  19,  80,   5, 117,  60,   2,   2,  67,  14,  80,\n",
      "         35,  64,  40,   0,  42,  12,  39,  17,  79,  46, 106,  69,  13,  34,\n",
      "         66,  56,   0,  11]) tensor([ 82,  39,   3,  47,  24,  82,   8, 117,  62,   3,   4,  68,  23,  82,\n",
      "         38,  66,  42,   2,  43,  16,  40,  21,  86,  48, 109,  73,  14,  34,\n",
      "         67,  65,   5,  15])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([106,   5,  18,  67,  50, 101, 110,  87,  88,  86,  48,  17,  85,   3,\n",
      "         11,   9,  52,  45,  24,  38,  44,  79,  43,  96,  32,  36,   4,  71,\n",
      "         12,   0, 100,  64]) tensor([106,   6,  19,  72,  50, 104, 128,  89,  88,  89,  50,  18, 102,   9,\n",
      "         12,  14,  54,  47,  24,  41,  48,  83,  43, 101,  33,  38,   6,  75,\n",
      "         14,   3, 102,  67])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([104,  96,  23, 111,  91,  89,  16,   7, 101,  17,  74, 124,   0, 100,\n",
      "         46,  20, 123, 113,  49,  81,  55,  32,  24,  11,  12,   3,  74,  50,\n",
      "         49,  19,  26,  46]) tensor([105, 100,  27, 118,  97,  93,  16,  12, 102,  28,  76, 125,   3, 109,\n",
      "         51,  23, 127, 116,  55,  82,  62,  33,  30,  15,  17,  11,  75,  51,\n",
      "         51,  20,  26,  48])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([42, 83, 69,  0, 58, 85, 42, 23, 28, 21, 24, 30, 69, 56, 58,  0, 28,  0,\n",
      "         4, 25, 46, 86, 34, 20, 66, 46, 39, 70, 16,  4,  5,  3]) tensor([44, 85, 69,  6, 59, 88, 43, 26, 45, 26, 27, 33, 75, 59, 63,  3, 28,  2,\n",
      "         5, 26, 54, 95, 35, 22, 66, 51, 42, 74, 19,  6,  9,  7])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 33,  80,  51,  50,  43,  31,  49,  21, 104,   6, 134,  17, 114,  33,\n",
      "         68,  59,   2,   7,  69,   5,  90,  13,  19,  64, 114,  22,  31,   0,\n",
      "         17,   0, 107,   6]) tensor([ 46,  84,  55,  50,  45,  33,  49,  36, 106,  13, 134,  24, 114,  35,\n",
      "         72,  61,   5,   9,  79,   6,  92,  15,  22,  66, 117,  24,  33,   9,\n",
      "         22,   5, 110,  10])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,   2, 110,  46,  36,  23,  30,   8,  33,  48, 115,  64,  48,  25,\n",
      "         35,  30,  34,  35,  39,   9,  37,  31,  34,  69, 129,  82,  75,  36,\n",
      "         50,  30,  49,  57]) tensor([ 15,   4, 114,  49,  39,  23,  32,  13,  33,  49, 120,  68,  50,  29,\n",
      "         37,  32,  36,  38,  39,  11,  38,  31,  35,  72, 136,  90,  78,  36,\n",
      "         57,  34,  51,  60])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  6,  14,  48,  43,  64,  12,  65,  17,  43, 106,  40,  69,  79,  17,\n",
      "          3,  15,  97,  56,  80,  65,  20,  61,   8,  51,  42,  24,  71,  11,\n",
      "         27,   5,   3,  54]) tensor([  7,  18,  57,  46,  67,  13,  67,  19,  44, 109,  48,  71,  80,  19,\n",
      "          4,  20, 100,  59,  91,  68,  20,  63,  16,  54,  44,  24,  75,  12,\n",
      "         31,   8,   6,  55])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 69,  64,  49, 111,  28, 101,  44, 119, 104,  51,  31,  28,   6,  57,\n",
      "        109,  41,  41,  53,  41,   9, 109,  49,   8,  11,  24,   6,  76,  82,\n",
      "          5,  15,  70,  20]) tensor([ 75,  67,  55, 112,  28, 103,  45, 120, 107,  53,  33,  32,  15,  65,\n",
      "        111,  41,  50,  55,  46,  10, 112,  51,  10,  22,  24,   9,  85,  87,\n",
      "          9,  17,  72,  28])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 57,   9,  59,  48, 126,  29,  49,  45,   3,  25,  16,  46,  49,  32,\n",
      "         67,  82,   2,  26, 102,  72,  40,  19,  92,  17,  19,  27,  66,  41,\n",
      "        100,   2,  22,  22]) tensor([ 57,  10,  61,  49, 130,  30,  61,  53,   3,  45,  18,  50,  49,  34,\n",
      "         76,  84,   5,  29, 104,  76,  51,  19,  94,  21,  21,  30,  70,  41,\n",
      "        105,   3,  26,  22])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,  19,  89,   0,  85,   4,  65,  69,  47,  12,  20,  80, 114,  58,\n",
      "         37,  44,  33,  56,  23,  11,  45,  11,  35,   4,  94,  53,  98,  10,\n",
      "          8, 121,  76,  11]) tensor([  4,  20,  95,   3,  86,   9,  67,  70,  52,  13,  21, 111, 118,  58,\n",
      "         39,  45,  44,  59,  24,  13,  48,  12,  44,  12,  95,  54, 103,  10,\n",
      "          9, 121,  80,  12])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  6,  59,  75, 121,   0,  43,  43,  22,  57,  14,  44, 101,  31,  42,\n",
      "         22,  57,  29,   3,  14,  42,  54,  86,   3,  71,   7,  84,  42, 100,\n",
      "         10,   3, 119,  80]) tensor([ 12,  63,  81, 122,   5,  67,  48,  29,  61,  17,  48, 101,  31,  48,\n",
      "         26,  60,  35,   4,  16,  43,  55,  87,   6,  74,   8,  85,  48, 132,\n",
      "         10,   7, 122,  84])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 34,  63,  43,  57,   5, 109,   8,  97,  25,  12, 104, 131, 103,  27,\n",
      "         60,  45,  42,  85,  42,  46,  89,   7,   0,  11,  25,  29,  65,  73,\n",
      "         33,  52,  22,  95]) tensor([ 37,  63,  46,  66,   5, 111,  10,  97,  28,  13, 115, 131, 104,  27,\n",
      "         61,  48,  48,  87,  45,  49,  89,   8,   8,  14,  26,  31,  70,  77,\n",
      "         36,  55,  28,  96])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 28, 107,  62,  52,  43,  16,  96,  34,  56,  14,   9,  38,  66,  78,\n",
      "         46,  80,  89,  70,  40,  58,  55,  94,  24,  38,  40,  53, 113,   5,\n",
      "        100,  23,  51, 115]) tensor([ 34, 109,  62,  57,  44,  23, 103,  50,  57,  17,   9,  41,  67,  82,\n",
      "         48,  82,  92,  71,  42,  58,  58, 103,  28,  39,  43,  58, 133,   5,\n",
      "        109,  24,  53, 121])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 30,  12,  15,  30,  67, 103,  62,  39,  18,  45,  19,  32,   9,  17,\n",
      "          6,  82,  87,  83,  14,   7,  77,  12,  40,  58,  13,  30,   2,  11,\n",
      "          4,  53,  71,  92]) tensor([ 31,  14,  17,  34,  69, 106,  63,  46,  21,  48,  27,  34,  13,  19,\n",
      "          6,  83, 115,  84,  17,   8,  79,  13,  40,  58,  18,  30,   3,  13,\n",
      "          6,  58,  76,  99])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 44,  47,   6,  27,  31,   3,   0,  42,  84,  49,  82,  28, 113,   0,\n",
      "          0, 122,  44,  12,  65, 112,  55,  72,   0,  53,  84,  57,  69,  93,\n",
      "         69,   0,  66,  55]) tensor([ 45,  51,  11,  27,  33,   3,   8,  67,  89,  60, 102,  34, 117,   3,\n",
      "          1, 127,  52,  14,  68, 117,  59,  76,   1,  55,  85,  57,  70,  98,\n",
      "         75,   1,  69,  55])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 66,  53,  19,  67, 108,   2, 123,  12,  74,  63,   2,  63,  30,  19,\n",
      "          4, 119,  86,  46,  31,  63,   6,  38,  63,  40,  42,  46,  30,  93,\n",
      "         36,  33,  25,  22]) tensor([ 66,  53,  19,  71, 114,   4, 125,  12,  79,  68,   3,  66,  32,  22,\n",
      "          6, 124,  89,  52,  32,  64,   6,  47,  77,  41,  45,  53,  31,  97,\n",
      "         39,  37,  25,  24])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 47,  67, 119,  66,  19,  26,  75, 110,  63,  26,  55,  24,  53,  12,\n",
      "         18,  39,   5,  41,   7,  33,  28, 101,  80,  33,  99,   3,  92,  44,\n",
      "         58,  58,  26,  68]) tensor([ 49,  73, 119,  68,  23,  28,  89, 115,  67,  30,  60,  35,  56,  18,\n",
      "         19,  46,   5,  42,   7,  35,  32, 106,  80,  36, 102,  10,  93,  44,\n",
      "         58,  66,  26,  70])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  2,  64,  18,  26,  76, 110,   0,   2,  56,  97,  33,  73, 100,  55,\n",
      "         78,  36, 109,  19,  12,   2,  66,  71,  11,  99,  76,  28,   6,  38,\n",
      "         25,   9,   6, 110]) tensor([  3,  67,  22,  27,  78, 113,   3,   5,  57, 102,  48,  74, 100,  58,\n",
      "         80,  39, 119,  21,  17,   5,  70,  75,  16, 101,  80,  31,   8,  38,\n",
      "         27,  13,   7, 116])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 25,  56,  22, 124,   7,  93,  73,   8,  65,  86,   9,   8,  30, 104,\n",
      "        131,  67,  22,  22, 119,  81,  21,  84,  69,  59,  43,  42,   0, 118,\n",
      "          0,  11, 100,  64]) tensor([ 26,  59,  25, 127,  10, 112,  77,  16,  68,  88,  18,  15,  30, 106,\n",
      "        135,  68,  26,  24, 123,  82,  21,  88,  72,  62,  46,  43,   5, 122,\n",
      "          6,  11, 103,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([22, 84, 71, 18, 44, 13, 65, 61,  3, 43, 31, 18, 41, 44, 57, 92, 47,  3,\n",
      "        69,  8, 20, 32, 36, 75,  0, 34, 37, 37, 71, 51, 53, 70]) tensor([22, 88, 72, 20, 51, 14, 69, 70,  3, 48, 32, 20, 45, 44, 60, 95, 50,  3,\n",
      "        70,  8, 22, 35, 41, 78,  4, 38, 38, 42, 71, 53, 54, 75])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 80,  14,  97, 105,  23,  65,  50,  21,  10,  30,  16,   9,  93,   5,\n",
      "         22,  15,  30,  54,  76,  56,  42, 105, 113,  81,  68,   2,  42,  51,\n",
      "          7,   6,  68,   5]) tensor([ 81,  33,  99, 105,  25,  66,  59,  24,  11,  33,  22,   9,  94,   9,\n",
      "         24,  16,  31,  61,  76,  58,  48, 109, 126,  81,  74,   3,  45,  53,\n",
      "          8,   9,  70,   5])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  41,   3,  14,  79,   6,   4,   8,  65,  49,  21,  91,  37, 112,\n",
      "         57,  27,  57,  14,  54,  13,  83,  29,  41,  14,  46,   0,   0,  85,\n",
      "         24,  62,   0,  94]) tensor([  1,  42,   8,  17,  81,   9,  10,  10,  68,  50,  22,  93,  39, 114,\n",
      "         59,  27,  62,  18,  56,  13,  84,  32,  41,  16,  48,  15,  21,  85,\n",
      "         27,  62,   4,  97])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 85,  17,   5,   0,  68,  16,  67,  64,  56,  14,  21,  97,  52,  38,\n",
      "         37,  57,  80,  36, 116, 122,  72,  22, 109,  49,  61,  38,  24,  44,\n",
      "         16,  21,  90,  80]) tensor([ 85,  23,   5,   1,  69,  18,  75,  75,  56,  29,  38, 101,  53,  39,\n",
      "         47,  58,  80,  42, 116, 131,  75,  26, 110,  50,  63,  40,  24,  47,\n",
      "         19,  22,  90,  82])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  5,   8,  57,  22,   2,  34,  60,  34,   0,   4,  38,  23,  26,  28,\n",
      "        106,  39,  23, 112,  32,  86,  47,  32,  89,  42,  37,   7,   8,  57,\n",
      "         31,  54,  60,  36]) tensor([  6,  13,  61,  25,   2,  36,  61,  36,   5,   7,  40,  23,  30,  33,\n",
      "        107,  41,  27, 113,  32,  87,  51,  32,  91,  44,  40,   8,  16,  59,\n",
      "         34,  55,  66,  37])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,  17,  91,   9,  35,  93,  11,  25,  97,   0,  97,  59,  56,  27,\n",
      "         48,  29,  10, 113,  45,  16, 116,  53,  79,  19,  17,   2,  22,  28,\n",
      "         23,   0,  11,  15]) tensor([  4,  20, 105,  38,  44,  96,  11,  31, 104,   7,  97,  59,  61,  29,\n",
      "         66,  35,  14, 115,  47,  19, 118,  58,  83,  21,  20,   5,  25,  33,\n",
      "         58,  10,  13,  16])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 42,   5,  24, 116,  32,  61,   0,  67,  14, 101,  38,  49,  77,  65,\n",
      "         94,  42,  42, 104,  60,  33,  23,  33,  17,  26,   7,  11,  32,  82,\n",
      "         63,   2,  61,  79]) tensor([ 45,   5,  31, 129,  34,  62,   5,  82,  15, 102,  58,  49,  80,  66,\n",
      "        111,  45,  45, 113,  64,  49,  28,  34,  17,  28,   8,  11,  34,  83,\n",
      "         63,   5,  69,  91])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  2,  21,  17,  60, 115,  24,  24,  85,  12,  35,  55, 125,  23,  74,\n",
      "         68,  57,  19,  27,  37,  52,   5,  83,  62,  26,  41,  56,  47,  16,\n",
      "         54, 133,  34,  31]) tensor([  8,  22,  21,  63, 115,  32,  31,  90,  13,  38,  56, 127,  24,  78,\n",
      "         70,  60,  20,  27,  39,  55,  12,  86,  62,  26,  41,  57,  49,  19,\n",
      "         57, 134,  41,  33])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 98,   4,  27,  32,   2,   9,  45, 121,  29, 100,  96,  97,  35,  15,\n",
      "         25,  11,  63,  27,  99,  16,  85,  40,  53, 103,  89, 112,  29,   6,\n",
      "         14,   7,  69,  70]) tensor([ 99,   7,  28,  53,   2,  14,  51, 123,  30, 131,  98, 105,  38,  17,\n",
      "         25,  12,  65,  28, 103,  17,  89,  41,  53, 107,  90, 112,  32,   6,\n",
      "         15,   9,  71,  71])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 70,  41,   0,  73,  29, 114,  35,  42,  76,   2,  53,  47,  13, 118,\n",
      "          3,  33, 111,  55,  92,  76,  32,  87,  42,  16,  81,  31,  22,  13,\n",
      "         80,  71,  72,  83]) tensor([ 73,  41,   8,  73,  29, 117,  37,  42,  81,   5,  54,  54,  14, 119,\n",
      "          4,  33, 112,  59,  95,  77,  35,  94,  43,  17,  88,  47,  25,  16,\n",
      "         85,  73,  76,  89])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 26,  67,  28,  30,   0,   0,  89,  94,  35,  43, 109,  10,  87, 131,\n",
      "          0,  27, 106,  30,   0,  49, 100,  28,  33,  45,  78,  10,   2,  38,\n",
      "         34,  57, 129,  43]) tensor([ 43,  67,  40,  35,   1,   3,  90,  94,  39,  46, 111,  14,  90, 135,\n",
      "          4,  28, 109,  32,   3,  52, 103,  33,  52,  47,  81,  12,   5,  40,\n",
      "         36,  62, 129,  44])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 17, 134, 101,  52,  58,  49,  51,  35,  23,  25,  49,   5,  15,  94,\n",
      "         15,  42,  30,  42,  21,  40,  15,  56, 111,  85,  36,  30,  74,   3,\n",
      "          9,  19,   6,   9]) tensor([ 17, 139, 101,  64,  58,  50,  54,  35,  26,  27,  55,   6,  23,  97,\n",
      "         19,  46,  37,  45,  22,  41,  15,  57, 113,  87,  41,  34,  76,   3,\n",
      "         12,  25,   9,  19])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  67,  36,  62,  30,   3,   0,  23,  20,  12,  56,  73,  15,   7,\n",
      "         50,  69,  54,  84,  10,  35,  36,  24,  32,  38,  51,  58, 125,  32,\n",
      "         46,  87,  10,  68]) tensor([  3,  67,  39,  62,  31,   3,   8,  26,  25,  15,  57, 120,  18,   9,\n",
      "         51,  72,  65,  88,  11,  40,  36,  24,  32,  39,  55,  61, 130,  35,\n",
      "         60,  93,  12,  74])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 17,  12,  59,   5,  67,   7,  52,  33,  74,  43,  43,  70,  34,  48,\n",
      "         16,  28,  21,  10,  42,   2,   2,  68,  47,  16,  89,  16,   2,  14,\n",
      "         15,  40, 101,  60]) tensor([ 18,  18,  59,   5,  69,  11,  54,  41,  88,  44,  47,  70,  35,  58,\n",
      "         17,  31,  21,  22,  45,   9,   3,  69,  57,  20,  94,  19,   3,  16,\n",
      "         21,  42, 101,  63])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 96,  14,  29,  46,  49,   2,  76, 112,  84,  87, 120,   8,  38,  82,\n",
      "         39,  10,  57,  85,   8,  20,  71,   9,  85,  69,  46,   2,  45, 120,\n",
      "          5,  76,  24,  36]) tensor([102,  15,  29,  49,  52,   5,  76, 116,  86,  94, 121,   9,  43,  82,\n",
      "         45,  12,  61,  86,  11,  31,  77,  12,  95,  71,  57,   2,  46, 123,\n",
      "          8,  80,  31,  37])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 47,  12, 106,   6,  11,  64,  44,  36,  59,  43,  63,  42,  26,  70,\n",
      "         48,  62,  27,  46,  25,  38,  23,  15,  69,  69,  13,   0,  84,  98,\n",
      "         17,  47,  19,  69]) tensor([ 51,  18, 107,   9,  11,  64,  52,  42,  61,  43,  65,  48,  27,  75,\n",
      "         49,  70,  36,  47,  32,  39,  23,  16,  69,  69,  17,   1,  86,  98,\n",
      "         25,  47,  20,  74])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 38,  24,  53, 109,  91,  33,  18,  77,  26,  73,  87,  52,  34,  72,\n",
      "          9,  76,  32,  99,  10,   2,  78,  25,  12,  31,  64,  43,  95,  78,\n",
      "         95,  69,  21,  64]) tensor([ 39,  24,  53, 109,  92,  37,  28,  78,  29,  75,  92,  55,  40,  79,\n",
      "         13,  84,  38, 104,  12,   2,  81,  28,  15,  32,  69,  50,  95,  81,\n",
      "         98,  71,  24,  68])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([101, 119, 104,  62,   0,  43, 137,  83,  12,  15,  64,  33,  65, 103,\n",
      "         62,  32,   6,  46,  30,   7,  76,  48,  19,  37,  31,  20,  54,  72,\n",
      "         50,  22,  10, 118]) tensor([109, 119, 105,  65,   8,  43, 138,  85,  23,  17,  70,  35,  67, 105,\n",
      "         62,  32,  11,  55,  31,   9,  79,  51,  20,  40,  38,  23,  58,  80,\n",
      "         54,  23,  10, 135])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  9,  47,  49,  56,  46,  53,  22,  52,  23,  15,  13,  63,   2,  23,\n",
      "        112,  56,  28,   4,  36,  40,   0,  45,  96, 136,  15,  10,  30,  47,\n",
      "         40,  36,  10,  35]) tensor([ 12,  47,  55,  59,  64,  55,  25,  57,  23,  15,  13,  64,   2,  26,\n",
      "        117,  60,  28,   7,  36,  43,  12,  47, 102, 138,  23,  16,  31,  47,\n",
      "         41,  36,  35,  36])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  41,   6,   6,  40,   0,  72,  29,  13,  22,  98,  61,  37,  74,\n",
      "         55,  31,  49,  29,  14,  17,  24,  23,  14,  34,  36, 118,  49,  33,\n",
      "          2,  17,  13,  10]) tensor([  3,  42,   6,   8,  46,   3,  72,  30,  16,  22, 100,  62,  41,  78,\n",
      "         58,  38,  58,  34,  15,  20,  26,  26,  16,  34,  40, 119,  49,  38,\n",
      "          2,  18,  15,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  83,  30,  30,  29,   2,  74,  38,  94,  96,  58,  11,  80,  10,\n",
      "         34,  15,  65,  17,   9,  79, 137,  47, 112,  51,  17,  40,  72,  18,\n",
      "         49,   0,  63,  55]) tensor([ 20, 103,  41,  33,  35,   4,  76,  39,  97,  98,  70,  14,  81,  24,\n",
      "         56,  20,  67,  17,  13,  79, 141,  48, 112,  54,  20,  42,  76,  18,\n",
      "         52,   2,  72,  55])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 80,  51,  12,  52,  41,  48,  41,  26,  23, 101,  25,  67,   8,  39,\n",
      "         97, 115,  20,  66,  73, 117,  35,  14,  79,  52,   6,  64,  93,   6,\n",
      "         43,  47,  31,  57]) tensor([ 80,  55,  19,  60,  43,  49,  43,  29,  29, 104,  36,  69,  10,  53,\n",
      "         97, 121,  20,  77,  74, 117,  40,  14,  81,  56,   8,  65,  96,  11,\n",
      "         43,  56,  33,  60])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([30, 95, 58,  2, 46, 14, 99, 35, 50, 31,  5, 55, 79, 39, 27, 80, 35, 35,\n",
      "        25,  8, 29, 34, 76,  7,  0, 27, 81, 39, 68, 82,  3, 34]) tensor([ 30,  97,  60,   9,  50,  40, 100,  37,  53,  32,   5,  56,  81,  54,\n",
      "         29,  83,  37,  36,  33,  14,  49,  36,  88,  12,   6,  29,  83,  40,\n",
      "         69,  82,   3,  35])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([118,  28,   0,  11, 123,  37,  50,   0,  85,  44,  61,  42,   8,  12,\n",
      "        121,  44,  87,  26,  20,  35,   7,  42,  36,  29,  39,  16,  50,  54,\n",
      "         45,  29,  11,  63]) tensor([120,  38,   4,  14, 123,  42,  50,   7,  87,  44,  64,  44,  10,  23,\n",
      "        124,  49,  88,  26,  24,  36,  11,  42,  37,  30,  41,  20,  52,  59,\n",
      "         48,  36,  15,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 59,  14,  39,  69,   0,  52,  25, 124,  29,  31,  16,  35,  47,  68,\n",
      "         60,   7,  32,  46,  38,  11,  89,  15,  36,   9,  28, 117,  31,  32,\n",
      "         52,  29,   0,  62]) tensor([ 60,  15,  40,  71,   2,  77,  29, 125,  37,  32,  19,  37,  50,  68,\n",
      "         62,  12,  37,  49,  38,  11, 100,  16,  36,  13,  28, 118,  34,  35,\n",
      "         52,  37,   9,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 60, 114,  74,  20,   0,  17,  28,  52,  27,  95,  79,  76,   0,  60,\n",
      "        108,  91,   0,  55,  76, 117, 112,  97,  31, 117,  60,  19,  24,  87,\n",
      "         13, 100,  31,  81]) tensor([ 65, 122,  74,  24,   5,  18,  31,  64,  30, 101,  85,  78,   3,  61,\n",
      "        109,  98,   9,  56,  81, 119, 115, 101,  32, 118,  60,  21,  27,  91,\n",
      "         13, 103,  38,  83])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 23,  76, 103, 100,  47,   0,  57,  90,   0,   7,   0,  99,  31,  63,\n",
      "         34,  24,  28,  13,  51,   7,  37,  26,   0,  68,  31, 125, 113,  66,\n",
      "         43,  82, 109,  91]) tensor([ 24,  77, 107, 102,  48,   3,  61,  93,   4,  11,  10, 100,  32,  67,\n",
      "         34,  28,  32,  22,  53,   7,  39,  28,   2,  75,  33, 131, 120,  73,\n",
      "         48,  83, 113,  93])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 47,   5,  24,  11,  69,   2,   9, 111,  39,  43, 102,  86,  63,  11,\n",
      "         20,  33,  21, 100,  44, 104,  28, 109,  69,  11,  60,  77,  91,  34,\n",
      "         50, 116,  22,  21]) tensor([ 49,   8,  27,  11,  69,   5,  11, 116,  40,  43, 103,  97,  89,  16,\n",
      "         21,  35,  21, 101,  45, 107,  37, 117,  74,  21,  61,  78,  91,  34,\n",
      "         50, 118,  22,  21])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 87,  76, 108,  20,  35,  59,  14,  74,  19,  14,  68,  79,  18,  54,\n",
      "          2,  59,  82,  11,   9,   3, 109,  13,  41,   0,  68,  19,   4,  95,\n",
      "          6,  77,   9,  35]) tensor([ 89,  78, 110,  25,  39,  61,  15,  78,  19,  14,  70,  82,  21,  56,\n",
      "          4,  59,  85,  11,  12,   7, 110,  14,  43,   2,  68,  19,   5,  96,\n",
      "          7,  81,  10,  43])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 63,  25,  74,  57,  52,  40,  17, 111,  38,  78,  67,   4,  61,   0,\n",
      "         85,  89,  30,  54,  23,  55,  87,  52, 113,  27,  42, 103,  10,  10,\n",
      "         93,  64,  41,  25]) tensor([ 64,  34,  75,  60,  52,  42,  19, 116,  39,  81,  70,   6,  67,   2,\n",
      "         86,  93,  31,  55,  26,  57,  88,  52, 115,  30,  42, 104,  15,  12,\n",
      "         93,  70,  45,  29])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 96, 101,  58,  19,  38,  43,  22,  61,   3,  44,  68,  54,  20,  28,\n",
      "         19,  21,  36, 131,   0,  75,   5,  12,  81,  94,  90,  50,  71,  38,\n",
      "         27,  46,  55,  32]) tensor([ 96, 105,  62,  25,  40,  43,  23,  65,   3,  47,  70,  57,  29,  31,\n",
      "         23,  22,  38, 132,   3,  78,   5,  13,  89,  95,  95,  50,  72,  39,\n",
      "         29,  55,  58,  34])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 63,  32,  31, 122,  92,  19, 123,  45,  19,  55,  34, 124,  58,  54,\n",
      "         12,   4,  92,   0,  44,   5,  55,  17,  17, 123,  10,  43, 107,  33,\n",
      "         48,  67,  51,   8]) tensor([ 63,  37,  33, 124,  94,  21, 126,  47,  22,  55,  36, 125,  59,  55,\n",
      "         25,   8, 114,   2,  47,   6,  58,  49,  18, 133,  12,  47, 113,  36,\n",
      "         53,  67,  52,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 19, 118,  41,  29,  47,  67,  30,  99,  25,   2,  17,   0,  57,   2,\n",
      "         24,  54,  67, 119,  36,   7,  31,  51,  51,   0,  66,  49,  23,  32,\n",
      "         74,  36,   0,   0]) tensor([ 20, 119,  45,  32,  48,  68,  31, 101,  27,   2,  21,   3,  76,   2,\n",
      "         28,  59,  69, 123,  47,  11,  33,  54,  55,   4,  67,  52,  26,  34,\n",
      "         77,  45,   3,   5])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([93, 10, 42, 34, 32, 55,  5, 69,  2, 43, 61, 27, 74,  9, 24, 38, 91, 19,\n",
      "        43, 69, 16,  3, 84, 45, 36, 87, 90, 61, 23, 59, 99,  3]) tensor([ 93,  15,  46,  36,  33,  57,   5,  72,   2,  43,  63,  29,  79,  14,\n",
      "         28,  39,  92,  22,  45,  72,  25,   4,  89,  46,  40,  89,  93,  62,\n",
      "         23,  64, 103,   6])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 62,  34,  19, 115,   3,  67,  93,   2,  18, 119,  21,  68,   2,  80,\n",
      "         76,  44,  52,   6,  14,  19,  68,  16,  59,  65,  27,  95,  56,  16,\n",
      "         13,  59,   2,  89]) tensor([ 64,  34,  19, 119,   7,  69,  95,   4,  22, 121,  26,  71,   6,  82,\n",
      "         82,  47,  58,  10,  14,  20,  73,  19,  64,  65,  30,  98,  58,  17,\n",
      "         17,  69,   8,  90])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 27, 115,  91,  64,  13,  11,   6,  37,  35,  74,   4,   6,  93,  45,\n",
      "         14,   0,  62,  78,  27,   0,  12,   8,  14,  45,  20,  47,   9,   0,\n",
      "         70,  13,   9,  72]) tensor([ 28, 116,  93,  66,  14,  11,   9,  41,  37,  77,   5,   8,  96,  47,\n",
      "         26,   8,  65,  78,  29,   3,  12,   8,  15,  48,  22,  47,  14,   6,\n",
      "         70,  15,  10,  75])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 30,  91,  45,  41,  28,  39,  36, 122,  44,  50,  85,  74, 101,  34,\n",
      "        100,  16,   2,   8,   0,  65,  50,  26,  76,  46,  34, 116,  16, 101,\n",
      "        150,  40,  49,  39]) tensor([ 31,  94,  47,  41,  33,  40,  40, 126,  48,  53,  88,  76, 102,  38,\n",
      "        101,  17,   5,   9,   3,  67,  59,  28,  79,  46,  36, 120,  21, 105,\n",
      "        156,  41,  51,  39])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 60,   2,  11,  41,  85,  71,   3,   6,  44,  41,   7,  94,   0,  79,\n",
      "         13,  14,   6,  20,  11,  18,   4,  71,  63,  67,  87,  34,  30,   0,\n",
      "         50, 131,  60,  12]) tensor([ 81,   3,  13,  43,  90,  71,   3,  12,  45,  45,   9,  98,   5,  93,\n",
      "         13,  18,   8,  20,  11,  40,   5,  73,  67,  69,  88,  34,  36,   3,\n",
      "         53, 134,  63,  16])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 29,  75,  87,  93, 107, 110,  79,  33,   9,  21,  11,  80,  50,  50,\n",
      "         34, 104,  65,  21,  58,   9,  71,  38, 109,  73,  97, 113,  37,  26,\n",
      "         57,  61,  44,  59]) tensor([ 31,  75,  89,  96, 120, 111,  83,  41,   9,  22,  14,  81,  53,  53,\n",
      "         36, 105,  68,  27,  62,  11,  74,  39, 110,  76, 100, 120,  41,  30,\n",
      "         60,  61,  49,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([115,   0, 106,   7,  15,  55,  59,  35,  27,  56,  56,  63,  12,  13,\n",
      "         79,   0,  46,  19,  76,  93,  32,  97, 112,   2,  12,  80,  26,   2,\n",
      "         29,  82, 109,  49]) tensor([116,   3, 107,  11,  16,  57,  64,  37,  47,  59,  59,  71,  12,  32,\n",
      "         79,   3,  48,  22,  78,  93,  34,  99, 113,   7,  13,  82,  28,   4,\n",
      "         30,  87, 111,  51])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0, 100,  92,  54,  88,  90,  16,  87,  64,  22,   6,  90,  30,  57,\n",
      "         14,  51,  32,  92,  16,   2,  41,   3,  28,   2,  46,  63, 116,  57,\n",
      "         27,   9,  55,  41]) tensor([  3, 102,  97,  57,  96,  91,  21,  88,  66,  44,   7, 100,  31,  60,\n",
      "         16,  51,  35,  96,  18,   2,  42,   4,  33,   5,  46,  65, 118,  60,\n",
      "         33,  12,  64,  43])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,  77,  80,  50,  10,   8,  60,  85,  28,   0,  70,  59,  98,  31,\n",
      "        109,   4,  13,  83,  24, 129,  26,  85,  35,  26,   6, 126,  20,  40,\n",
      "         31,  33,  80,  58]) tensor([ 26,  78,  84,  54,  10,  10,  61,  86,  29,   4,  73,  67, 100,  33,\n",
      "        112,   5,  21,  83,  24, 142,  27,  88,  36,  32,   8, 132,  22,  42,\n",
      "         31,  41,  87,  58])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 52,  24,  15,  55,  43,   6,  19,  30,  12,  94,  89,  56,  23,  41,\n",
      "         56, 103,  29,  39,  11,  29,   5,  16,   6,  52,  95,  41,  51,  25,\n",
      "         41,  30,  38,  68]) tensor([ 58,  25,  18,  60,  46,  35,  20,  34,  14,  95,  95,  56,  25,  43,\n",
      "         67, 107,  31,  44,  17,  29,   9,  22,   7,  53, 103,  44,  53,  33,\n",
      "         41,  35,  40,  68])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([110,  15,  34,  73,  22, 119,  45,  11,   0,  12,  51,  63,  34,   0,\n",
      "         11, 116,  26,   2,  81,  76,   9,   0,  38,  25,  10,  47,   2,  35,\n",
      "         52,  34, 114,  53]) tensor([119,  17,  35,  78,  27, 120,  52,  12,   5,  19,  52,  65,  39,   6,\n",
      "         17, 121,  27,   6,  87,  78,  15,   3,  46,  29,  12,  47,   3,  39,\n",
      "         53,  36, 116,  53])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  7,  91,  12,  64, 120,  78,  46,  26,   2,   0,  27,  67,  42,   9,\n",
      "         44,   8,  43,  46,  44,  21,  92,  60,  13,  47,  78, 136,  47,  13,\n",
      "         60,   2,  39, 100]) tensor([  9,  96,  20,  64, 123,  81,  50,  31,   4,   8,  29,  67,  50,  11,\n",
      "         51,  11,  43,  47,  47,  23,  96,  70,  16,  47,  79, 137,  48,  14,\n",
      "         62,   5,  39, 107])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,   2,  60,  31,   8,  76,  22,  12,  22,  11,  41, 145,   7,  82,\n",
      "         80,   4,   9,  88,  38,  68,  62,   2,  16,  33,  17,  26, 107,  24,\n",
      "         45,  10, 102,  16]) tensor([ 27,   5,  61,  35,  10,  79,  25,  12,  26,  19,  44, 148,  12,  82,\n",
      "         84,  18,   9,  89,  39,  70,  64,   5,  17,  33,  19,  28, 107,  25,\n",
      "         47,  10, 118,  16])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 48,   9,  12,  31,  14,  15,  82, 123,  16,  29,  98,   3,  22,  38,\n",
      "          7,  43,  30,  17,  52,  72,  44,  86,  63,   9,  16,  27,  34,  40,\n",
      "         62,  93, 120,  36]) tensor([ 73,  16,  14,  33,  14,  15,  91, 123,  27,  32, 104,   3,  22,  46,\n",
      "          9,  46,  35,  19,  55,  77,  54,  88,  63,   9,  18,  31,  35,  44,\n",
      "         65,  94, 122,  38])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 69,  12,  11,  28,  87,  72,  76,  51,  67,  47, 131,  60,  16,  92,\n",
      "         36,   6,  26,   0,   2,   3,  64,  20,  27,   0, 105,  40,  50,  71,\n",
      "         31,  51,  43,  45]) tensor([ 69,  12,  11,  35,  95,  74,  83,  54,  78,  49, 136,  60,  17,  93,\n",
      "         39,   8,  27,   4,   5,   8,  67,  20,  28,   9, 107,  42,  50,  75,\n",
      "         34,  51,  47,  46])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 37,  98, 120,  17,   9,   0,   2,  48,  88,   8,  10,  38,  64,  81,\n",
      "         18,  12,  59,  16,  21,  67,  10,  49,  30,  24,  22, 131,  69,   4,\n",
      "         64,  42,  16,  53]) tensor([ 38, 101, 124,  21,  12,   3,   4,  48,  92,  11,  15,  43,  67,  89,\n",
      "         19,  16,  59,  16,  21,  68,  12,  52,  34,  28,  24, 141,  77,   6,\n",
      "         77,  43,  16,  53])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 65,  12,   2,  43,  78,  37, 100,   7,  92,  41, 100,  69,  48,  91,\n",
      "         17,  32,  93,  35,   4,  66,  20,  52,  39,  26,  31,   0,  21,   5,\n",
      "         29,  67,  69,  31]) tensor([ 70,  12,   2,  46,  86,  37, 102,  11,  92,  41, 115,  71,  53, 109,\n",
      "         24,  33,  95,  39,   4,  67,  22,  54,  39,  32,  33,   2,  26,   7,\n",
      "         32,  69,  69,  31])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 66,  86,  31,  80,  17,  68,  65,  97,  32,  23,   6,  25,  56,  17,\n",
      "         55,   5,  63,   4, 105,  21,  37,  13, 114,   7,  38,  21,  72,  88,\n",
      "         98,   2,  62,  59]) tensor([ 96,  86,  33,  85,  18,  78,  66, 104,  32,  28,   6,  27,  62,  22,\n",
      "         58,   7,  64,   5, 107,  23,  67,  13, 115,   9,  41,  22,  74,  88,\n",
      "        100,   2,  63,  63])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 57,  55,   0,  50, 104,  18, 100,  67,   2,  83,  22,  52,  34,  32,\n",
      "         12,  76,  47,  48,   6, 104,  41, 100, 117,   0,  88,  98,  23,  24,\n",
      "        112,  26,  11,  86]) tensor([ 59,  58,   3,  50, 108,  21, 103,  80,   2,  85,  22,  52,  39,  34,\n",
      "         12,  80,  50,  52,   7, 117,  45, 101, 121,   1,  92,  99,  25,  24,\n",
      "        116,  28,  17,  88])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 35,  78,   5,   0,   9, 113,  30, 103,  56,  43,  50,  76,  37,  58,\n",
      "         57,  55,  59,  79,  12,  19, 116,  68,  20,  81,  89,  73, 104,  95,\n",
      "         64,  55, 100,   3]) tensor([ 37,  81,  11,   4,  11, 115,  30, 104,  66,  45,  50,  76,  37,  60,\n",
      "         57,  55,  60,  83,  17,  21, 118,  73,  24,  85,  93,  75, 105,  97,\n",
      "         67,  57, 105,   4])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,  54,  26,  65,  52,  47,   6, 114,  31,  32,  52,  68,  47,  55,\n",
      "         34,  16,  15,  79,  64,  72,  45,  44,   3,   0,   3,  56,  62,  74,\n",
      "         47,  74,  63,  70]) tensor([  6,  57,  29,  66,  54,  58,   9, 131,  36,  38,  56,  70,  48,  62,\n",
      "         41,  17,  16,  83,  65,  72,  47,  44,   4,   1,   4,  56,  67,  76,\n",
      "         50,  75,  65,  72])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 31,  39,  57,  54,  43,  16,  63,  30,  58,  79,  33,  18,  46,  58,\n",
      "         56,  57, 105,  42,  53,   0,   4,  37,  99,  78,  25,  25,  89,   8,\n",
      "         41,  59,  36,  46]) tensor([ 43,  40,  57,  55,  43,  18,  64,  34,  61,  84,  37,  22,  50,  65,\n",
      "         57,  60, 108,  51,  57,   2,  11,  41, 100,  78,  34,  26,  92,  10,\n",
      "         43,  62,  39,  48])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([23,  4, 12, 45,  9, 42, 91, 98,  7, 25, 17,  4, 25, 82, 47, 78, 52, 21,\n",
      "        14,  9,  3, 51, 18, 49,  3, 10,  2, 39, 31, 11, 13, 22]) tensor([ 26,  12,  19,  48,  12,  45,  92, 101,   7,  29,  21,   5,  26,  88,\n",
      "         54,  80,  52,  23,  17,  13,   4,  58,  18,  55,   3,  13,   4,  45,\n",
      "         38,  12,  19,  37])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 54,   6,  30,  56,  31,  86,  50,   9,  90,  52,  28,  27,  55,  41,\n",
      "         29,  56,  85,  20,  28,  84,  12,  27,  41,  62,   2,  49,   4, 109,\n",
      "         26,  42,   6,  87]) tensor([ 55,   8,  39,  57,  39,  92,  59,   9,  95,  60,  34,  30,  58,  44,\n",
      "         34,  59,  86,  25,  30,  86,  15,  27,  41,  64,   2,  49,  11, 111,\n",
      "         27,  43,   6,  94])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 35,  25,  97,  66,  61,  14,  98,  74,  12,  31,  33,  80,   7,  71,\n",
      "         75,  73,  66,  65, 115,  81,  13,  80,  77, 121,  18,   2,  46,   8,\n",
      "        118,  12,  18,  12]) tensor([ 37,  29,  99,  75,  65,  17, 103,  79,  15,  32,  38,  82,  11,  72,\n",
      "         76,  75,  67,  67, 119,  81,  13,  82,  81, 124,  21,   3,  46,  11,\n",
      "        119,  25,  20,  27])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 23,  19,   0,  55,  92, 132,  55,  24,  19,  14, 111,  51,  41,  36,\n",
      "          4,   0,  38,  11,  51,   0,   5,  37,  16, 112,  55,  50,  18,   4,\n",
      "         89,   5,   0,  70]) tensor([ 24,  22,   4,  55,  95, 135,  56,  24,  19,  19, 118,  52,  41,  36,\n",
      "          9,   2,  42,  11,  52,   7,   9,  38,  17, 119,  55,  54,  23,   6,\n",
      "         92,   5,   2,  71])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 96,  34,  26,  72, 122, 107,  76,  96,  36,  52,  80,   4,  41,  22,\n",
      "         56,  72,  37,   7,   7,  63, 107,  23,  47,  92,  37,  70,  72,  14,\n",
      "         24, 125,  22,   5]) tensor([ 96,  34,  26,  72, 125, 109,  78,  98,  38,  57,  83,   4,  48,  23,\n",
      "         62,  73,  44,   7,  10,  65, 108,  26,  52,  96,  40,  73,  72,  14,\n",
      "         27, 130,  23,  13])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 72,  24,  16, 118,   0,  29, 125,   9,   0,  13,  59,  40,  29,  13,\n",
      "         37,  45,  19,  79,  53,  19,  14,  28,  42,   6,  38,   2,  28,  24,\n",
      "         83,   9,   9, 101]) tensor([ 74,  25,  19, 119,   3,  34, 126,  10,   2,  14,  62,  43,  30,  14,\n",
      "         38,  50,  24,  80,  58,  26,  17,  29,  44,   8,  45,   2,  31,  30,\n",
      "         83,  11,  11, 106])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 40, 107,  17, 104,  94,  88, 100,  94,  16,  21,  66,  30, 106,  38,\n",
      "         42,  22,  31,  15,  19,  49,  17,   2,  44,  74,   2,  55,  92,  28,\n",
      "          5,  60,  50,  75]) tensor([ 40, 108,  23, 111,  99,  93, 108,  98,  18,  26,  66,  33, 107,  43,\n",
      "         43,  23,  31,  15,  19,  54,  19,   3,  46,  83,   5,  56, 101,  29,\n",
      "         10,  60,  53,  79])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 98,  16,   7,  53,  20,  42,  19,  64,   3,  46,  78,  28,  25,  58,\n",
      "          8,  24,  27,   0,   3,   8,   8, 106,   3, 111,   0,  29,  42,  20,\n",
      "         36,  13,  25,  21]) tensor([103,  17,  27,  54,  20,  47,  23,  65,   4,  47,  81,  29,  26,  59,\n",
      "          8,  38,  28,   3,   4,   9,  10, 109,   4, 118,   5,  33,  51,  21,\n",
      "         40,  15,  25,  25])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 73,  62,  43,  29,  93,   6, 140,  52,  12,  54,  46,  30,  56,  85,\n",
      "         17,  22,  58, 102,  34, 119, 108,  38,  16, 107,  26,  12,  40,  70,\n",
      "         25,  80,  32, 108]) tensor([ 73,  65,  44,  33,  96,   8, 145,  53,  17,  62,  47,  31,  57,  86,\n",
      "         19,  30,  61, 107,  35, 119, 110,  41,  18, 111,  28,  14,  43,  73,\n",
      "         25,  85,  33, 109])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 60,  34,  26,  28,  18,  20,  57,  11,  78,  19,   7,  14,  46, 112,\n",
      "         41,  20,  69,  38,   9,  41,  24,   2,  44,  31,  28, 115,  72,  14,\n",
      "          9,  17,  67, 122]) tensor([ 64,  36,  29,  34,  19,  25,  57,  13,  85,  21,   7,  15,  46, 119,\n",
      "         42,  21,  70,  39,  11,  43,  24,   2,  47,  71,  33, 121,  75,  16,\n",
      "          9,  20,  67, 123])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 60,   3,  30,  30,  57,  61, 121,  92,  67,  28,   0,  22,   5,  95,\n",
      "         41,  57,  89,  55,  31,  50,  73,  59,  61,  33,   4,   6,  57,  41,\n",
      "         89,  78,  37,   9]) tensor([ 70,   4,  35,  50,  60,  62, 121,  97,  80,  30,   7,  24,   8,  98,\n",
      "         48,  58,  89,  60,  42,  55,  75,  64,  63,  37,   4,   9,  60,  54,\n",
      "         90,  83,  39,  10])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 69,  75, 101,   6,   2,  16,   0,  46,  70,  99,  56,  70,  51,  34,\n",
      "         23,  56,  57,  33,  10,  25,  79,   5,  83,  64,   2,  55,  13, 101,\n",
      "          2,  19,  13,  28]) tensor([ 80,  77, 116,   8,   4,  18,   4,  50,  74, 105,  57,  71,  55,  35,\n",
      "         25,  59,  61,  35,  13,  29,  81,  13,  89,  66,   7,  60,  19, 104,\n",
      "          2,  25,  19,  31])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 10,  86,  24,  81,  88,   3,  38,  53, 122,  30,  66,  20,  42, 145,\n",
      "        122,  23,   0,   0,   8,  57,  58, 143,  89,  25,  60,   0,  76,  25,\n",
      "         12,  53,  44,  17]) tensor([ 16,  88,  27,  85,  89,   4,  38,  53, 122,  33,  70,  27,  43, 146,\n",
      "        123,  28,   2,   1,  11,  80,  66, 149,  92,  28,  63,   4,  79,  31,\n",
      "         13,  55,  48,  25])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 39,  34,  66,   7,  23,  97,   3,  31,  26,  17,   8,  47,   0,  92,\n",
      "         55,  58,  49,  42,  40,  24,  13,   4, 116,   0,   0,  11,  10,  57,\n",
      "         56,  28,   9, 100]) tensor([ 41,  41,  66,  10,  25, 104,   3,  32,  28,  19,  11,  47,   1,  94,\n",
      "         60,  63,  50,  43,  42,  27,  16,  10, 117,   7,   2,  12,  12,  57,\n",
      "         59,  32,  10, 100])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,   6,  20,  72,   0,  69,  22,  46,  15,  50,  99, 104,  63,  93,\n",
      "         44,   2,  12,  36,   2,   9,  47,  40,  24,   0,  19,  25, 120,  40,\n",
      "         12,   7,  62,  67]) tensor([ 11,  10,  20,  72,   5,  72,  22,  47,  17,  53, 101, 104,  64,  93,\n",
      "         48,   2,  12,  37,   2,  10,  51,  48,  28,   4,  19,  25, 120,  43,\n",
      "         12,  22,  70,  68])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 55,  68,   2,  91,  93,  49,  36,  60,  56,  59,  32,  55, 100,  69,\n",
      "         51,  35,   3,  17,   5,  55,   4,  48,   2,  88, 101,  26,  83,  20,\n",
      "         14,  24,  52,  59]) tensor([ 59,  70,   2,  91,  96,  56,  38,  66,  61,  65,  45,  55, 106,  69,\n",
      "         51,  39,   3,  23,   7,  55,   4,  48,   9,  94, 106,  28,  87,  24,\n",
      "         14,  29,  53,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 20,  31, 128,  29,  27,  69, 114,  73,  48,  68, 117,  42,  78,   2,\n",
      "         30,  53,  17,  12,  16,  16,   6, 120,  86,  40, 106,  97,  19,  62,\n",
      "          8,  25,  80,   9]) tensor([ 23,  34, 130,  37,  29,  70, 115,  77,  50,  71, 118,  43,  78,   6,\n",
      "         37,  55,  17,  16,  17,  21,  10, 120,  88,  44, 109,  99,  21,  65,\n",
      "          9,  26,  94,  13])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  94,  51,  33,  81,  63, 121,  37, 121,  50,  74,   2, 119,  35,\n",
      "         92,   0,  19,  57,  53,  12,  81,  35,  16,  30,  94,  17,  39, 128,\n",
      "         15,  10,  28,   6]) tensor([  2,  94,  51,  34,  81,  63, 134,  46, 121,  52,  77,   3, 121,  35,\n",
      "        101,   2,  26,  61,  57,  16,  84,  44,  16,  33,  94,  20,  41, 132,\n",
      "         15,  12,  30,  15])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 31,  41,  35,  67, 107,   4,  14,  72,  24,  27,  19,   0,   0,  21,\n",
      "         23,   5,  31,  54,  51,  14,  34,  77,  10, 113,  38,   8,   2,  36,\n",
      "        103,  23, 111,  62]) tensor([ 35,  45,  37,  68, 119,  18,  19,  76,  31,  27,  19,   2,   1,  23,\n",
      "         27,   7,  36,  62,  52,  16,  38,  78,  12, 124,  43,  12,   5,  38,\n",
      "        107,  29, 122,  70])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 33, 118,  93,  34,  22,  48,   6,  74,  71,   2,  10, 114,   4,  97,\n",
      "         65,   9,   4,  30,  75,  14,  26,  48,  29,  65,  55,  43,  79,  31,\n",
      "         75,  36,  66,  35]) tensor([ 35, 129,  95,  34,  28,  50,   6, 100,  72,   5,  11, 115,   4, 102,\n",
      "         65,  15,   8,  43,  76,  19,  29,  56,  31,  68,  64,  46,  80,  36,\n",
      "         90,  38,  67,  36])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 10,  41,  39,  62,  97,   4,  89, 120,  38,  73,  11,   6,  21, 139,\n",
      "         34,  53,  39,  10,  30,  67,  54,   2,  26,  51,  70, 102,  63,  58,\n",
      "         19,  43,   0,  73]) tensor([ 12,  42,  46,  65,  98,   5,  89, 126,  41,  74,  11,   9,  22, 140,\n",
      "         42,  54,  39,  16,  51,  68,  59,   4,  30,  53,  71, 105,  67,  62,\n",
      "         19,  50,   4,  76])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 40,  15,   8,   6,  67,  50,  99,  60,  21,  32,  38,  48,  26,  32,\n",
      "          4,  73,  92,  45,  74,   3,  66,   5, 107,  12, 131,  35,  20, 134,\n",
      "         11,  18,  84,  91]) tensor([ 46,  16,   8,   9,  74,  53, 107,  62,  23,  38,  46,  55,  31,  34,\n",
      "          8,  77,  96,  46,  76,   6,  68,  18, 121,  15, 132,  40,  22, 136,\n",
      "         11,  20,  89,  96])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 65,   2,   2,  24,  19,  54,  32,   6,  15,   7,  30, 112,  38,  40,\n",
      "          5, 102,  39,  26,  86,  21,  38,   6,  46, 103, 137,  57, 126,   0,\n",
      "          6,  43, 121,  25]) tensor([ 65,   2,   3,  38,  20,  59,  46,   9,  16,   7,  50, 116,  38,  40,\n",
      "         12, 104,  42,  27,  88,  27,  40,  10,  50, 110, 139,  57, 131,   4,\n",
      "         10,  45, 130,  25])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 65,   3,  71,  33, 107,  28,  26,  23,  19,  45,  97,  73,  27,  51,\n",
      "         62,  42,  15,  32,  32,  44,   3,  19,  36,  43,  85,  36,  34,  93,\n",
      "         42,  49,  57,  44]) tensor([ 65,   3,  75,  34, 117,  30,  32,  38,  21,  46, 104,  75,  30,  54,\n",
      "         65,  43,  15,  34,  34,  49,   4,  19,  37,  45,  89,  50,  41,  97,\n",
      "         43,  51,  58,  60])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 31,  82,  19,  52,  26,  11,   5,  78,  90,  14,  83,  30,  32,  63,\n",
      "        100,  52,  74,  39, 119,  75,  22,  49,  51,  76,  52,  21,  91,  50,\n",
      "         30,  23,   6,  85]) tensor([ 31,  82,  43,  56,  29,  11,   6,  82,  97,  17,  84,  32,  37,  65,\n",
      "        101,  53,  76,  39, 123,  77,  22,  50,  55,  81,  54,  28,  93,  55,\n",
      "         30,  31,  10,  87])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 14,  35,   6,  55,  89,  99,  18,  92,  13,   8,  48,  72,  17,  57,\n",
      "         90,  73,  20,   7,  74, 105,  85,  91,  22,  85,  22,   3,  44, 117,\n",
      "         23,   4,   5,  13]) tensor([ 27,  37,   9,  56,  91, 102,  21, 103,  16,  10,  51,  76,  24,  69,\n",
      "         92,  84,  24,  12,  79, 115,  86,  98,  25,  86,  25,   6,  46, 119,\n",
      "         23,   4,   5,  17])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 17,  86,  81,   2,  42, 103,  31,  71,  17,  16,  62,  41,  50,  14,\n",
      "          3,  23,  69, 101,  28,  14,  26,  64,  42,   0,  44, 112,  23,  32,\n",
      "         18,  67,  30,  47]) tensor([ 20,  90,  81,   3,  43, 105,  32,  72,  17,  17,  73,  45,  52,  15,\n",
      "          3,  24,  81, 102,  29,  17,  29,  68,  46,   3,  44, 112,  24,  32,\n",
      "         18,  68,  31,  55])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 20,   7,  31,   6,  24,  46,  78,  53,  42,  75,  14,  56,  71,  31,\n",
      "         15,  28,   2,   8,   0,  13,   2,  45,  38,  50, 109,  75,  66, 102,\n",
      "         73,  10,  28,  11]) tensor([ 20,  14,  33,   9,  29,  49,  80,  55,  47,  78,  14,  62,  72,  33,\n",
      "         27,  29,   8,  11,   1,  19,   2,  48,  40,  51, 111,  78,  70, 103,\n",
      "         77,  22,  29,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  2,  47,  34,   2,   3,  52,  48,  69,  72,  69,  20,  95,  30,  80,\n",
      "         27,   7,  36, 108,  57, 106, 117,  30,  27,  52,   0,   2,  38,  34,\n",
      "         14,  38,  70,  39]) tensor([  5,  57,  34,   4,   3,  54,  48,  73,  76,  73,  28,  96,  40,  83,\n",
      "         46,  12,  42, 115,  60, 110, 118,  33,  35,  53,   6,   3,  40,  37,\n",
      "         17,  48,  72,  39])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 14,  46, 106,  80,  45,  85,  19,  17,  65,  88,  62,  13,  35,  87,\n",
      "          5,  94,  94, 115,  40,  59,  40,  41, 112,  51,  88,  46,  22,   2,\n",
      "         30,   0, 109, 151]) tensor([ 14,  48, 114,  83,  47,  87,  20,  17,  66,  91,  66,  16,  36,  91,\n",
      "          9,  96,  97, 116,  42,  64,  42,  45, 113,  53,  91,  47,  23,   9,\n",
      "         30,   6, 111, 152])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 49,  15,  85,   2,  92,  63,   2,  16,  23,  13,  61,  21,  72,  76,\n",
      "         15,  19,  48,  83,  80,  66,  13,  24,  29,   2,  57, 119,  86,  74,\n",
      "         66,  63,  36, 110]) tensor([ 68,  18,  87,   2,  92,  69,   3,  18,  26,  13,  62,  23,  81,  79,\n",
      "         17,  21,  49,  85,  81,  67,  13,  27,  33,   5,  58, 120,  98,  77,\n",
      "         70,  65,  38, 113])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([23, 77, 37, 46, 40, 40, 66, 50,  0, 59, 63, 36, 66, 88,  6, 56,  7, 35,\n",
      "        72, 63, 83, 43,  8, 66, 33, 62,  2, 72, 42, 86, 30, 11]) tensor([24, 82, 39, 47, 49, 60, 69, 54,  1, 66, 63, 37, 94, 91,  6, 58, 17, 39,\n",
      "        72, 65, 84, 49, 12, 66, 37, 63,  6, 75, 49, 90, 31, 14])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 29,  44,  50,   0,  46,  17,  38,  62,  58,  48,  51, 106,   0,  40,\n",
      "         50,  51, 103,  23,  21,  14,  23,  61,  14,  26,  53,  47,  47, 122,\n",
      "         22,  80,  90, 111]) tensor([ 30,  44,  56,   3,  46,  23,  40,  64,  68,  50,  56, 112,   9,  46,\n",
      "         50,  56, 108,  27,  22,  18,  40,  63,  15,  29,  57,  52,  49, 126,\n",
      "         39, 101,  92, 115])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 84,  47,  67,  27,  68,  12,  31, 105, 140,  42,  11,  26,   6,  63,\n",
      "         62,  63,  14,   6,  33, 132,   0,  47,  99,  49,  22,   6,  51,  33,\n",
      "        112, 107,   0,   6]) tensor([ 84,  48,  69,  30,  78,  13,  33, 106, 143,  43,  12,  44,   8,  63,\n",
      "         64,  68,  15,   7,  36, 132,   2,  50, 100,  53,  25,   7,  54,  34,\n",
      "        117, 115,   3,  14])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 75,  87,  95,  15,  61,  35,  40,  41,  15,   6,  27,  13,  67,  23,\n",
      "         59,  14, 113,  43, 120,  76,  96,  29,  17,   0,  59,  31,   0,  53,\n",
      "         57,  92,   4,  97]) tensor([ 83,  89,  95,  16,  65,  37,  40,  45,  18,  14,  27,  13,  67,  23,\n",
      "         65,  16, 115,  43, 121,  81,  97,  31,  24,   1,  59,  33,   4,  53,\n",
      "         58,  94,   8,  98])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 35,   5,  33,  28,  59,   2,  75,  58,  91,  89,  17,   4,  42, 104,\n",
      "         37,  29,   8,   8,  43,  46,  67,  29, 105,  42, 103,  71,  10,  62,\n",
      "        109,  89,  47,  16]) tensor([ 37,   7,  37,  32,  65,   2,  76,  59,  95,  89,  17,   7,  44, 104,\n",
      "         38,  45,  12,  13,  43,  48,  72,  35, 124,  44, 105,  72,  10,  73,\n",
      "        110,  91,  48,  19])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 61,   0,  27, 120,  69,   2,  34,  42,  96,  14,  75,  85,  64,  12,\n",
      "         47,  17,  15,  11,  85,  26, 109,  25,  11,   0,  16,  69,  42,  24,\n",
      "          2,  50,  50,  87]) tensor([ 62,   4,  29, 120,  89,   3,  38,  47, 100,  15,  75,  85,  68,  13,\n",
      "         49,  20,  19,  11,  90,  29, 113,  30,  13,   3,  24,  70,  42,  24,\n",
      "         12,  54,  55,  91])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 18, 102,  86,  47,   0,  37,  19,  20,  23,  31,  71, 117,  50,  53,\n",
      "         47,  96,  10,  48,  46,  19,   2, 107,  56,  13,  46,  69,  62,  27,\n",
      "         81,  91,  77,  28]) tensor([ 21, 110,  91,  50,   4,  39,  20,  22,  25,  32,  78, 121,  58,  59,\n",
      "         51, 102,  13,  52,  46,  19,   2, 119,  58,  15,  50,  83,  69,  29,\n",
      "         83,  94,  81,  28])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 33,  10,   2, 103,  77,  84,  78,  21,   5,  44,  31,  50,  79,   4,\n",
      "         34,  17,  35,  10,  15,   9,  36,  45,  10,  59,  42, 115,  60,  23,\n",
      "          7,  60,  34,  56]) tensor([ 34,  12,   2, 103,  78,  86,  79,  23,   8,  50,  32,  54, 101,   4,\n",
      "         35,  20,  36,  10,  19,  10,  39,  49,  12,  60,  51, 118,  62,  25,\n",
      "         10,  62,  37,  58])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 58,   2,  32,  14,  21,  64,  84,  25,   4, 109,   9, 133,  89,  21,\n",
      "        122,  61,  15,  22,  61,  17,  88,  63,   7,  72,   0, 101,  21,  73,\n",
      "         48,  73,  28,  17]) tensor([ 60,   5,  41,  17,  22,  68,  89,  29,   4, 121,  26, 135,  91,  24,\n",
      "        126,  62,  18,  22,  63,  17,  88,  68,   9,  79,   3, 105,  43,  75,\n",
      "         54,  78,  30,  20])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  24,  47,  64,  60,  12,  44,  75,   0,  32,  52,   3,  37,  63,\n",
      "         58,  89,  22,  47,  14,  44,   0,   0,  67,  54,  23,  96,  29,  38,\n",
      "         22, 117,  92,  23]) tensor([  2,  27,  53,  65,  64,  12,  64,  85,   3,  36,  54,   3,  39,  65,\n",
      "         71,  91,  24,  47,  21,  48,   5,   4,  72,  56,  25,  98,  33,  39,\n",
      "         22, 120,  93,  24])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 59,  12,  45,  63,  97,  30,   0,  52,  32,   0,  96,  70,   6,  22,\n",
      "         10,   8,  74,   0,  20,  13,  93,  32,  76,  49, 117,  52,  15,  41,\n",
      "          0, 108,  23,  62]) tensor([ 66,  15,  56,  63, 101,  38,   3,  53,  44,  12,  97,  73,   8,  31,\n",
      "         10,  14,  78,   3,  23,  14,  93,  32,  78,  54, 131,  57,  19,  42,\n",
      "          2, 110,  25,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 61, 125,  93,  65,  75,  22,  12,  56,  89,   8,  15,  22,  27,  10,\n",
      "         21, 112,  14,   8,  98, 142, 108,  92,  66,  11,  44,  11, 132,  95,\n",
      "         66,  12,  14,  55]) tensor([ 63, 125,  98,  65,  85,  23,  15, 106, 108,   8,  18,  26,  29,  10,\n",
      "         27, 118,  17,  15,  99, 145, 110,  93,  71,  15,  45,  11, 134,  98,\n",
      "         70,  15,  18,  58])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 15,  22,   9, 143,   0,  60, 107,  60,   0,  62, 131,  39,  17,  68,\n",
      "         28, 112,  22,  71,  82,  17,  95,  46, 104,  36,  31,   0,  45,  82,\n",
      "         42,  49,  71,   0]) tensor([ 19,  22,  11, 144,   5,  64, 113,  61,   2,  65, 136,  43,  21,  70,\n",
      "         33, 112,  27,  77,  83,  22,  97,  49, 109,  36,  55,   3,  49,  83,\n",
      "         44,  51,  72,   4])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([104,  55,  37,  12, 100,  54,   2,  15,  12,  52,  56,  39,   5,  23,\n",
      "         41,  88,  37,  57,   0, 105,  24,  75,  63,  86,  10,  23,  17,  79,\n",
      "         51,  34,  54,  53]) tensor([108,  59,  55,  12, 100,  57,   5,  18,  13,  56,  58,  43,   9,  29,\n",
      "         43,  88,  38,  66,   7, 105,  25,  80,  64,  88,  14,  23,  20,  79,\n",
      "         53,  38,  63,  55])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 86,   2,   6,  23, 133,   0,   4,  21, 136,  13, 105,   5,  11,  41,\n",
      "         27,  28,  75,  65,  26,  18,  15,  21, 112,   3,  21,  92,  44, 101,\n",
      "          2,  60,  42,  35]) tensor([ 93,   7,   9,  24, 134,   1,   7,  21, 136,  17, 105,  10,  12,  57,\n",
      "         29,  33,  76,  66,  36,  26,  15,  24, 114,   3,  23,  94,  46, 102,\n",
      "          9,  65,  44,  38])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 37,  32,  12,  15,   6,   0,  55, 120,  13,  50,  14,  16,  90,  29,\n",
      "         68,  14,  52,   8,  76,  50,  43,  29,   9,   2,  27,  16,  22,  32,\n",
      "          8,  14,  88,  23]) tensor([ 38,  36,  15,  18,   7,   1,  56, 122,  13,  57,  17,  18,  93,  32,\n",
      "         68,  19,  52,  11,  79,  54,  44,  33,  10,   3,  27,  24,  24,  33,\n",
      "         10,  17,  93,  26])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([110,  53,  20,  33,  28,  46,  36,   3,   0,  13, 104,  27,  53,  88,\n",
      "          0,   5,  10, 101,  36,  89,  66, 110,   8,  45,  49,  74,  62,  79,\n",
      "        115,  25,   0,  35]) tensor([117,  55,  22,  34,  39,  49,  43,   3,   3,  15, 109,  27,  53,  89,\n",
      "          4,   7,  13, 101,  39,  90,  67, 112,   8,  50,  51,  88,  63,  81,\n",
      "        115,  30,   7,  38])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  17,  97,  94, 126,  75,   2,   9, 128,   6,  25,  32,  39,  72,\n",
      "         10,  75,  68,   3,  21,  36,  41,  38,  43,  56,  42,  46,  13,  72,\n",
      "         13,   4,  11,  45]) tensor([  1,  21,  97,  97, 127,  91,   4,  12, 149,   8,  26,  35,  45,  76,\n",
      "         16,  81,  73,   3,  29,  41,  44,  41,  45,  60,  43,  47,  23,  75,\n",
      "         39,   5,  14,  45])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 42,  51,  70,  23,  60,  40,  24,  17,  47,  50,   0,  51,  93, 105,\n",
      "         59,  47,   2,  70,  17,  60,  16,   0,  32,  75,  53,  17,  64,  54,\n",
      "         27, 101,  64,  15]) tensor([ 45,  53,  75,  24,  60,  44,  29,  17,  62,  53,   4,  52,  93, 106,\n",
      "         62,  47,   5,  71,  19,  60,  17,   4,  36,  77,  58,  19,  87,  66,\n",
      "         27, 101,  68,  16])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([61, 87, 83, 58, 17, 99, 96, 17, 85, 18,  0, 32,  8,  8, 97, 25, 18, 97,\n",
      "         9, 23, 45, 12, 15,  2, 50, 52, 71, 19, 53,  0, 56, 27]) tensor([ 64,  94,  90,  67,  22, 100, 100,  20,  88,  23,   7,  33,  17,   9,\n",
      "        102,  25,  19, 110,  13,  25,  45,  15,  16,   3,  55,  55,  72,  21,\n",
      "         53,   3,  56,  52])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 30,  66,   2,  29,  37,  55,  52,   9,  21,  11,  72,  65, 109, 129,\n",
      "         35,   5,  70,  56,  55,  53,   9,  15,  13,  25,  12,  52,  65,  12,\n",
      "          0,   7,  66,  43]) tensor([ 34,  77,   5,  52,  43,  58,  52,  13,  23,  12,  75,  68, 110, 130,\n",
      "         37,   6,  71,  57,  80,  64,  10,  19,  13,  28,  12,  56,  65,  12,\n",
      "          6,   7,  69,  44])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 39,  68,  80,  19,  96,  42,  57, 101,   7,  22, 107,  31,   0,  21,\n",
      "         52,  12,  16,   8,  81,  69,  36,  11,  39,  96,   9,  24,   7,  28,\n",
      "        115,  11,  14,   9]) tensor([ 41,  68,  84,  44, 116,  44,  63, 103,  12,  25, 108,  31,   5,  38,\n",
      "         52,  14,  18,  18,  86,  69,  42,  11,  42, 100,  10,  55,  11,  32,\n",
      "        116,  13,  15,  18])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 35,  56,  44,  11, 117,   4,  68, 101,  81,  38,  55,  30,  40, 111,\n",
      "         58,   6,  28,  24,  25,  35,   6,  79,  19,  54,  58,  48,  29,   4,\n",
      "         10,  48,   2,   7]) tensor([ 41,  58,  48,  13, 119,   6,  72, 101,  88,  41,  57,  31,  45, 116,\n",
      "         62,   9,  32,  27,  25,  39,   8,  81,  19,  63,  61,  48,  29,   5,\n",
      "         11,  49,   3,   8])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 30,  58,  99,   8,  39,  14,  98, 113,  76,  23,  38,  25,  53,  36,\n",
      "         31,  24, 109,  34,   5,  50,  76,  94, 110, 128,  61,  42,   0,  82,\n",
      "          7,  45,  21, 112]) tensor([ 35,  58, 102,  18,  39,  14, 101, 115,  78,  31,  43,  26,  55,  36,\n",
      "         32,  27, 111,  38,   7,  52,  76,  95, 112, 130,  62,  46,   8,  85,\n",
      "          8,  52,  22, 112])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 71,  92,  33, 107,  50, 112,  42,  42,  58,  29,  36,  15,   0,  86,\n",
      "         15,  40,   0,   2,   4,  39,  40,  92,  92,  18,  45,  70,  94,  45,\n",
      "         11,  75,  41,  25]) tensor([ 71,  95,  37, 108,  52, 113,  43,  46,  68,  30,  39,  19,   4,  86,\n",
      "         20,  43,   5,   3,   5,  44,  45, 105,  99,  23,  53,  72,  96,  47,\n",
      "         12,  80,  41,  28])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 73,  26,  16,  40,  57,  36,  16,   2,  31,  46,  42,   6,  10,  42,\n",
      "          0,   8, 107,  14,  34,  46,  25,  50, 123,   2,   9,  22,  17,  54,\n",
      "         37, 101,  70,  24]) tensor([ 86,  26,  18,  44,  63,  36,  16,   5,  36,  57,  45,  10,  13,  45,\n",
      "          3,  22, 110,  20,  37,  51,  26,  57, 125,   3,  10,  22,  19,  59,\n",
      "         45, 102,  73,  26])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 81,  36,  51,  72,  11,   2,  51,  63, 109,   7, 124,  23,  38,  39,\n",
      "         38,  10,  40,  24,  23,  49,  92,   9,   0,   6,  95,  16,   2,  62,\n",
      "        124,   5,   0,  57]) tensor([ 81,  37,  63,  72,  15,   3,  55,  67, 111,   8, 125,  28,  44,  42,\n",
      "         44,  13,  46,  26,  25,  52,  99,  10,   5,   7,  99,  21,   5,  65,\n",
      "        125,   8,   6,  58])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 72,  73,  33,  57,  13,   0,  13,  50,  52,  10,  89,  47,   9,   1,\n",
      "         27,  55,  21,  93,  27,  94,  48,  36,  86,  10,  58, 121,   5,  49,\n",
      "         50,  62,  14,  14]) tensor([ 78,  76,  35,  59,  13,   5,  15,  60,  55,  12,  89,  50,  11,   4,\n",
      "         28,  63,  25,  95,  29,  97,  48,  41,  90,  11,  59, 121,  10,  51,\n",
      "         59,  66,  19,  14])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([94, 37, 59, 59,  5, 20, 66, 11, 46, 57, 11, 21, 12, 17, 62,  0, 49, 73,\n",
      "        51, 17,  0, 30, 52,  6, 19, 79, 13, 14,  0, 65, 27, 60]) tensor([111,  44,  65,  61,   9,  23,  68,  14,  46,  62,  13,  21,  13,  17,\n",
      "         62,   4,  59,  75,  51,  18,   7,  34,  59,   7,  20,  81,  13,  15,\n",
      "          3,  76,  30,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  41,  40,  37,  12,  12,   9,  96,  10,   5,  50,  24,  16,  96,\n",
      "        115,   5,  30,  28,  53,  29,  90,  34,  11, 135,   3,   9,  61,  69,\n",
      "         65,  12,  65,  52]) tensor([  3,  49,  42,  41,  14,  13,  10,  99,  13,  13,  51,  28,  37,  97,\n",
      "        115,  10,  32,  30,  58,  31,  93,  38,  12, 135,   5,  11,  63,  72,\n",
      "         70,  18,  65,  56])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 33,  60,  14,  23,  52,  21,  32,  44,   9, 104,  66,  22,  17,   0,\n",
      "         22,  11,  99,  16,  39,  41, 114, 110,  19,  92,  62,   2,  44,  50,\n",
      "         32,  14,  36,  75]) tensor([ 34,  68,  15,  31,  54,  22,  32,  47,   9, 111,  66,  29,  23,  10,\n",
      "         23,  14, 105,  21,  48,  45, 119, 111,  25,  96,  66,   6,  47,  51,\n",
      "         34,  17,  43,  85])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,  75,  90,   6,  90, 104,  13,   0,   9,  31,  64,  10,  28,  26,\n",
      "         32,  20,  97,  78,  12,  12,  21,  13,   0,  19,  18,   4, 107,  72,\n",
      "         35,  67,  38, 101]) tensor([  6,  77,  98,  10,  97, 106,  17,   4,   9,  31,  66,  14,  30,  26,\n",
      "         37,  20,  99,  79,  13,  14,  25,  26,   5,  22,  19,   5, 117,  76,\n",
      "         35,  69,  44, 104])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([84, 41, 27, 45, 11, 15, 17, 13, 60, 41, 14, 71, 21, 37, 16, 33, 52, 56,\n",
      "        47, 24, 48, 44, 22, 47, 86, 12,  2,  8, 73, 29, 39,  6]) tensor([104,  41,  27,  48,  15,  17,  23,  16,  62,  44,  18,  71,  25,  39,\n",
      "         17,  40,  56,  56,  47,  25,  53,  45,  27,  52,  89,  15,   3,  12,\n",
      "         74,  37,  53,   8])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 34,  84, 114,  53,  45,   3,  83,  72,  57,  50,  67,   4,  30,  43,\n",
      "        124,  20,  41,  81,  12,  42,  37,  45,  39,  20, 112,   0,  20, 129,\n",
      "         34,  24,  21,  96]) tensor([ 37,  87, 117,  58,  52,   3,  87,  75,  61,  66,  67,   9,  47,  49,\n",
      "        124,  25,  45,  84,  12,  45,  42,  47,  40,  22, 120,   1,  21, 130,\n",
      "         34,  25,  24, 118])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 34,   2,  35,  30,  54, 143,  26,  14,  55,  24,  22,  16,  12,  10,\n",
      "         68,   5,  96,   7,   8,   5,  17,   8, 108,   2,  31,  85,   8,   4,\n",
      "         92,  13, 117,  33]) tensor([ 36,  18,  37,  31,  66, 143,  28,  17,  59,  32,  23,  17,  14,  11,\n",
      "         69,  11,  97,   7,  16,   8,  17,   9, 112,   9,  34,  86,  12,   7,\n",
      "         96,  13, 122,  34])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 63,  14,  86,   3,  16,   0,   6,  19,   8,  49,  19,  64,  40,  17,\n",
      "         57,   7,  54,  65,  50, 143,  34,  20,  21,  10,   4,  46,   2,  28,\n",
      "         27,  15,  36,  97]) tensor([ 66,  15,  89,   3,  25,   5,   9,  22,   8,  53,  20,  76,  45,  19,\n",
      "         58,  11,  57,  67,  53, 144,  38,  24,  22,  14,   6,  53,   3,  28,\n",
      "         27,  18,  39, 104])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 14,   6,  80,  26,  54,  31,  32,  86,  45,  76,  97,  34,  59,  85,\n",
      "        106,  19,  11,  40, 104,  73,  39,  24,   0,  34,  24,  64,   0,   8,\n",
      "         28,  77, 101,  98]) tensor([ 20,   9,  80,  40,  54,  31,  33,  89,  52,  77, 111,  35,  63,  90,\n",
      "        111,  23,  12,  56, 106,  74,  44,  24,   2,  35,  26,  67,   4,  10,\n",
      "         31,  78, 102, 109])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13,  68,   5,   2,  82,  50, 105, 120,  16,  44,  80,  16,  41,   3,\n",
      "         36,  91,   7,  11,  92,  97,  27,  27,  78,  49,  20,   0,  29, 108,\n",
      "         53,  26,  87,   3]) tensor([ 17,  81,   6,   4,  83,  54, 114, 126,  18,  45,  83,  17,  50,   3,\n",
      "         40,  94,  10,  12,  94, 100,  27,  31,  79,  51,  24,   2,  32, 114,\n",
      "         56,  27,  90,   8])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 37,  72,  37,  29,   7,  19,  86,   2,  40,  50,  48, 145,  18, 103,\n",
      "         55,  45,  19,  94,   0,  22,  18,  40,  29,  33,  86,   9,   6,   9,\n",
      "         55,  68,  63,  25]) tensor([ 42,  77,  41,  96,   9,  21,  89,   7,  62,  60,  48, 151,  18, 106,\n",
      "         55,  49,  19,  94,   2,  23,  19,  43,  39,  34,  90,  10,   8,  17,\n",
      "         58,  70,  64,  25])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,  22,  76, 111,  53,  13,  19,  15,  45,  12,  63,  27,  45,  29,\n",
      "         16,  45,  39,  99,  42,  76,   9,  25,  21,  16,  28,  66,  85,  11,\n",
      "         47,  50, 100,  97]) tensor([ 26,  26,  79, 113,  54,  17,  30,  18,  46,  14,  69,  33,  53,  32,\n",
      "         22,  52,  39, 103,  46,  78,   9,  37,  26,  18,  29,  66,  86,  12,\n",
      "         48,  52, 145,  98])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 30,  46,  90,  11, 109,  13,   2,  10,   4, 113,  34, 115,  35,  90,\n",
      "         11,  21,  30,  33,   7,  84,  96,  12, 109,  51,  58,  49,  63,  51,\n",
      "         73,  13,  27,  16]) tensor([ 32,  49,  96,  12, 111,  36,   3,  16,   5, 119,  39, 116,  36, 107,\n",
      "         12,  23,  31,  36,   9,  88,  99,  15, 120,  53,  58,  55,  64,  54,\n",
      "         75,  18,  30,  17])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([106,   0,   0,  91,   9,  45,  74, 104,  56,  73,  27,  46, 112,  56,\n",
      "         98,  76,   7,  30,  43,  58, 121,  97,  14,  23,  22,  12, 108,  11,\n",
      "         14,  16,  40,  69]) tensor([106,   4,   1,  95,  12,  57,  80, 106,  57,  74,  29,  47, 115,  62,\n",
      "         98,  82,  10,  34,  47,  59, 121,  98,  16,  23,  25,  16, 112,  11,\n",
      "         14,  17,  47,  70])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,  48,  16,   2, 108,  30,  77,  46,   8,  55,  16,  39,  52, 115,\n",
      "         85,   0,  44,  61,  60,  33,  24,  48,   9,  50,  27,  46,  84,  14,\n",
      "         76,  29,  59,  85]) tensor([ 32,  67,  17,   5, 112,  39,  78,  51,   9,  55,  17,  43,  53, 118,\n",
      "         87,   3,  48,  62,  62,  37,  26,  50,  11,  52,  32,  49,  87,  34,\n",
      "         76,  34,  62,  86])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 23,  78,  79, 102,  93,  67,  39,  72,  33,  66,  78,  46,  38,  50,\n",
      "          3,  45,  56,   3, 107,  24,  21,  16,  42,   8,  14,  58,  31,  80,\n",
      "         95,   7,  83,  14]) tensor([ 28,  78,  79, 112,  93,  72,  44,  77,  34,  70,  79,  62,  44,  52,\n",
      "          3,  84,  60,   8, 111,  28,  29,  16,  47,  14,  19,  68,  36,  80,\n",
      "        104,   8,  87,  21])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 36,   0,  13,  36,   0,  12,  97,  49,  17,  39, 123,  29,  23,  88,\n",
      "         23,  10,  63,  32,  33,  17,  36,  95,  57, 118,  57,  95,   6,  29,\n",
      "         19,  12,  61,  16]) tensor([ 39,   4,  14,  37,   2,  14, 104,  52,  20,  43, 125,  32,  26,  90,\n",
      "         37,  13,  63,  36,  35,  27,  40, 106,  61, 122,  65,  95,   8,  29,\n",
      "         24,  14,  61,  37])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 50,  23,  21,  10,  57,  57,   2,  40,  95, 115,  30,  18,  37,   5,\n",
      "         12,  98,  67, 101,  87,  23, 113,  80,  60,  22,   2,  45, 103,  76,\n",
      "          9,   2,  55,  10]) tensor([ 55,  26,  24,  10,  61,  58,   3,  40,  97, 115,  55,  21,  38,   8,\n",
      "         13,  99,  67, 109,  94,  24, 131,  82,  62,  28,   9,  45, 103,  81,\n",
      "         16,   5,  58,  16])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  7,  66,  41,  29, 120,   0,  54,   4, 127,  30,   2,  64,   7,  32,\n",
      "         74,  11,  47,  37,  82,  68,  37,  32,  44,  12,  50,   9,  62,  86,\n",
      "        136,  40,  24,  58]) tensor([ 11,  71,  44,  41, 122,  16,  55,   4, 129,  35,   3,  70,  13,  36,\n",
      "         74,  13,  47,  39,  84,  71,  44,  35,  46,  16,  54,  11,  66,  89,\n",
      "        136,  41,  27,  59])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([118,   6,  39,  64,  81,  34,  18,  14, 120,  35,  79,   8,   0, 132,\n",
      "          7,  46,  35,  34,  49,  33,  85,   2,  30,  19,  29,   0, 132,  18,\n",
      "         67,  53,  31,  14]) tensor([126,  11,  41,  66,  89,  38,  18,  16, 126,  41,  82,  10,   1, 136,\n",
      "          8,  48,  50,  36,  49,  36,  93,   3,  31,  19,  33,   3, 133,  19,\n",
      "         67,  56,  33,  17])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 30, 116,  68,  68,  24,  34,   5,  88,  82,  70,  61,   4,  72,  68,\n",
      "         33,   2,  16,  94, 116,  22,  39,   6,  54,  58,  15, 150,  35,   0,\n",
      "         70,   2,   8,  32]) tensor([ 37, 122,  69,  68,  26,  39,   5,  91,  87,  73,  71,   4,  76,  71,\n",
      "         37,   4,  17,  96, 120,  26,  43,   8,  56,  61,  21, 154,  37,   4,\n",
      "         70,   6,  15,  33])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 25,  80,  18,  91,   8,   3,  63, 138,  38,  48,   6,  38,  81,  80,\n",
      "         99,  49,  19,   6,  98,  14,  83, 116,   0,  63,  62,  39, 104,  67,\n",
      "         91,  11,  22,  19]) tensor([ 26,  90,  21,  97,  10,   7,  66, 140,  40,  49,  10,  41,  82,  81,\n",
      "        102,  51,  20,   9, 103,  20,  86, 130,   2,  64,  62,  44, 105,  67,\n",
      "        122,  12,  32,  26])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 25,  75,   0,  22,  83,  44,  99,  74,  34,  86,  58,  40, 110,  20,\n",
      "         27,  43,  44, 128,  54,  90,  92,  67,  80,  93,  50,  15,  22,  40,\n",
      "         45,  25,  43,  25]) tensor([ 29,  79,   3,  25,  86,  46, 103,  75,  39, 109,  68,  43, 112,  22,\n",
      "         29,  77,  50, 129,  55,  91,  94,  81,  86,  96,  62,  25,  22,  40,\n",
      "         47,  30,  56,  26])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 45,  49,  14,  20,  37,  78,  35,   7,  88,  90,   9,  39,  92,  69,\n",
      "         31,  38,   0,  57,  88,  99,  43, 118,  41,  31,  57,  38,  21, 105,\n",
      "         29,  61,  10,  67]) tensor([ 51,  51,  15,  21,  43,  78,  37,  10,  91,  90,   9,  40,  94,  69,\n",
      "         33,  38,   8,  59,  91,  99,  43, 118,  44,  32,  57,  59,  21, 117,\n",
      "         30,  62,  16,  68])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 73,   0,  85,  39,  22,  64,  31,  94,  66,   0,  41,  21,  45,  51,\n",
      "         40, 107,  40,  29,  31,  25,  27,  12, 110,  71,  14,  60, 103,  26,\n",
      "          0,  10,  25,  40]) tensor([ 73,  14,  87,  39,  22,  64,  42, 100,  66,   1,  42,  23,  45,  55,\n",
      "         41, 108,  42,  34,  32,  28,  29,  13, 126,  73,  16,  62, 107,  27,\n",
      "         40,  14,  25,  43])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13,  56,  26,  58,  40,  61,  84, 102,  10,  17,  13,  81,   9,  47,\n",
      "         99,  78,  28,  26,  25,  27,  46,  10,   4,  33,  82,  19,  60,  54,\n",
      "         18,  45,  17,  78]) tensor([ 13,  58,  29,  61,  43,  64,  88, 104,  13,  17,  30,  82,  13,  54,\n",
      "        105,  79,  29,  32,  27,  31,  57,  20,   6,  36,  85,  29,  66,  60,\n",
      "         19,  52,  22,  87])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 68,  11,  72,  32,  27, 110,  72,  69,  58, 103,   5,  77,  23,  94,\n",
      "         57,   9,  98,  35,   0,   6,  34,  73,  69,  18,  65,  26,  24,  59,\n",
      "        105,  95,  52,  46]) tensor([ 71,  18,  74,  38,  30, 110,  74,  73,  60, 106,  15,  82,  27,  94,\n",
      "         58,  11, 102,  38,   2,   9,  34,  74,  69,  20,  69,  28,  30,  62,\n",
      "        105,  97,  55,  50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 16,  98,  10, 154,  48,  20, 115,   4,  58,  70,   9,   4,  56,  72,\n",
      "         11,  23,  85,  22,  18, 118,  49,   8,  42, 141,  78,   8,  94,  89,\n",
      "         49,  75,  14,  47]) tensor([ 21, 103,  16, 159,  57,  22, 120,   6,  59,  70,  11,   7,  59,  80,\n",
      "         15,  24,  96,  24,  18, 119,  52,  11,  42, 141,  85,   8,  94,  90,\n",
      "         51,  75,  17,  52])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 85,  34,  15,  80,  43,  30,  51,  42, 117,   8,  95,  13,  14,   6,\n",
      "         59,  26,  65,  29,  28,  49,  94,  95,  18,  29,  25, 104,  24,  56,\n",
      "         49,  76,  10,  67]) tensor([ 87,  36,  29,  86,  43,  30,  52,  45, 118,  11, 101,  14,  21,   9,\n",
      "         60,  27,  70,  29,  29,  53,  98, 113,  20,  35,  26, 106,  24,  59,\n",
      "         54,  78,  16,  71])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 94,  82,  46,  63,   0,  11,  45,  34,  23,  50,  69,   0,  84,  64,\n",
      "         17,  28,  85,  20,  16, 104,  65,  18,   2,  31,  65,  28,  54,  55,\n",
      "         94,   8,  41,  56]) tensor([ 95,  83,  54,  64,   2,  15,  49,  37,  24,  55,  74,   2,  92,  68,\n",
      "         20,  28,  87,  25,  22, 105,  65,  21,   3,  32,  68,  29,  56,  59,\n",
      "        114,  13,  42,  58])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 13,  13,   3,  30,  83, 114,  57,  86,   8,  21,   5,  34,   9,  47,\n",
      "         65,  40,  36,   4,  11,  13,  37,  59,  67,  56,  68,  13,  19,   8,\n",
      "         42, 110,  82, 152]) tensor([ 15,  13,   3,  31,  89, 116,  57,  98,  10,  23,   7,  45,  12,  48,\n",
      "         68,  42,  37,   8,  12,  16,  37,  63,  70,  71,  68,  15,  19,   9,\n",
      "         45, 111,  83, 152])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,   7,  14, 114,  24,  30,  26,  58,  55,  39,  15,  25, 130, 125,\n",
      "         17, 113,   3,  39,  53,   0,  40,  67, 111,  79,   4,  25,  63, 100,\n",
      "         38,  73,  52,  42]) tensor([  4,  13,  14, 116,  36,  30,  28,  59,  62,  40,  15,  32, 136, 126,\n",
      "         19, 114,   4,  40,  55,   3,  41,  75, 112,  82,   8,  30,  64, 108,\n",
      "         39,  76,  55,  47])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 22,  29, 142,  39,  35,  94,   9, 122,  12,  63,  70,  19,  24,  50,\n",
      "         11,  43,  51,  91,  94,  65,  32,  33,  43,  19,  67,  44,  14,  44,\n",
      "         25,   6,  62,  57]) tensor([ 23,  31, 146,  42,  38,  94,  15, 123,  17,  65,  70,  21,  25,  56,\n",
      "         11,  44,  53,  91, 107,  72,  34,  34,  44,  38,  70,  46,  14,  47,\n",
      "         27,  21,  63,  58])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 38,  39,  52,  50,  88,  37,  60,  18,  81,  13,  35,  81,  88,  29,\n",
      "        106,  21,  14, 110,  12,  21,  89,   3,  29, 100,  18,  10,  91,  14,\n",
      "         89, 100, 104,  55]) tensor([ 43,  39,  52,  53,  92,  45,  67,  21,  88,  16,  40,  86,  90,  35,\n",
      "        110,  37,  17, 112,  22,  26,  91,   8,  31, 102,  21,  19,  94,  22,\n",
      "         94, 101, 105,  58])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  4,   4,   2,  20,  51,   2,   0,  12,  12,  81,  44,  26,  22,  63,\n",
      "         31,   9,  38,   0,  88,  49,  51,  97,  20,  24,  18, 113,  52,  19,\n",
      "         43,  73,  18,  56]) tensor([  5,   6,   2,  23,  53,   4,   5,  13,  14,  82,  57,  28,  22,  65,\n",
      "         31,  11,  50,   1,  88,  52,  53, 100,  23,  25,  21, 115,  55,  32,\n",
      "         43,  74,  22,  56])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  8,   2,  66,  17,  49,  11,  58,   7,   0,  41,  39,  14,  68,  54,\n",
      "         49,  48, 107, 136,  19,  31, 114,   3,  53,  25,  28,  47,  13,  25,\n",
      "         41,  33,  26,  29]) tensor([ 10,   6,  70,  23,  52,  23,  72,  11,   2,  41,  48,  15,  68,  58,\n",
      "         52,  50, 109, 140,  20,  33, 117,   3,  56,  27,  28,  54,  15,  25,\n",
      "         42,  47,  27,  29])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 17,  77,  84, 102,  37,  49,  66,  18,  40,  10,   2,  64,  11,  68,\n",
      "         24,   0,  30,  36,  42,  61,   4,  24,  59,  82,  49, 138,  18, 103,\n",
      "         28,  57,   8,  56]) tensor([ 27,  77,  85, 130,  40,  52,  68,  39,  41,  18,   6,  68,  12,  68,\n",
      "         24,   2,  30,  37,  43,  81,  10,  26,  89,  87,  50, 140,  21, 103,\n",
      "         29,  62,  10,  66])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 52,  22,  11,  60,  24,  26,  41,  45,   8,  53,   9,   0,  10,   5,\n",
      "         27,  76,  21,  19, 119,  20,  67, 116,  22,  61,   7,  15,  34,   4,\n",
      "         44,  43,  31, 104]) tensor([ 54,  26,  14,  60,  29,  26,  43,  46,  13,  58,  20,   5,  17,   5,\n",
      "         36,  77,  21,  20, 125,  22,  71, 117,  24,  63,   9,  15,  38,   5,\n",
      "         49,  52,  31, 104])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([108,  40,  70,  66,  98, 113,  11,  72,  16,  22, 104,  16,  54,  53,\n",
      "         79,  88,  79,   2,   7,  36,  83,  26,   4,  44,   2,  28,  32,  50,\n",
      "         57,   6,   7,  16]) tensor([111,  44,  75,  73, 109, 115,  11,  72,  16,  25, 109,  17,  59,  53,\n",
      "         80,  91,  89,   3,  10,  38,  85,  28,   4,  46,   3,  28,  32,  53,\n",
      "         58,  12,  13,  17])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 71,  49,  54, 112,  38,  20,  41,   2,  98,   0,   9,  56,  20,  39,\n",
      "         43,  14,  92,  35, 106,  15,  30, 107, 105,   2, 103,   0,  86,  70,\n",
      "         59,  16,  13,  18]) tensor([ 71,  50,  54, 121,  41,  31,  42,   2, 101,   2,  12,  61,  21,  39,\n",
      "         48,  17,  93,  37, 112,  18,  34, 107, 106,   3, 105,   2,  86,  75,\n",
      "         59,  17,  16,  25])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([106,  22,  75,  67,  13,  83,  35,  60,  68,   3,  62,  14,  57,  24,\n",
      "         86,  30,  68,  37,  52, 111,  26,  81,  68,  13, 103,  25,  15,  28,\n",
      "         57,  76,  17,  64]) tensor([111,  25, 104,  68,  14,  83,  40,  65,  71,   3,  63,  17,  57,  27,\n",
      "         87,  32,  70,  45,  53, 115,  32,  83,  68,  18, 105,  25,  15,  28,\n",
      "         58,  77,  21,  65])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 42,  30,  14,  95,  35,  31,  67,  52,  23,  40,  21,  78,  33, 102,\n",
      "         15,  86,  18,   0,  20,   2,  26,  46,  24,  86,  14,  95, 134,  97,\n",
      "        104,  63,  54,  14]) tensor([ 48,  38,  15,  96,  39,  34,  67,  54,  25,  42,  21,  81,  36, 110,\n",
      "         15,  87,  19,   2,  21,   3,  29,  48,  26,  93,  16, 105, 140,  97,\n",
      "        106,  69,  59,  17])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  2,  38,  57,  22,  41,  20,  42, 110,  42,  19,  82,  33,  43,  56,\n",
      "         79,  27,  24,  20,  21,  79,   3,  99,  68,  78,  18,   3,   0,  72,\n",
      "         63,   2,  67,  17]) tensor([  4,  41,  57,  49,  42,  23,  49, 117,  44,  25,  83,  38,  44,  60,\n",
      "         81,  42,  29,  31,  24,  83,   7, 102,  73,  83,  36,   6,   2,  75,\n",
      "         64,   3,  80,  23])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 42,   4,  13,  65,  60,  13,  29,  60,  56,  54,   6,  18, 125,  22,\n",
      "         26,  10,   3,  56,  86,  94,  34,  42, 113,  66,  97,  62,  26,  38,\n",
      "         42,  89,   3, 126]) tensor([ 42,   6,  16,  73,  60,  14,  29,  61,  61,  57,   7,  37, 125,  26,\n",
      "         29,  11,   6,  56,  91,  99,  37,  42, 115,  68,  98,  64,  26,  43,\n",
      "         44,  92,   4, 129])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([106,  26,  76,   0,  59,  81,  30,  19,  23,  82, 111,  83,  30,  82,\n",
      "         85,  29,  88, 114,  16,  42,   2,  49,  12,  26,  46,  44,  52,  53,\n",
      "         76,  22,  61,  34]) tensor([109,  27,  76,   2,  63,  82,  49,  23,  26,  87, 111,  91,  35,  85,\n",
      "         86,  36,  94, 115,  17,  46,   6,  50,  17,  29,  47,  48,  73,  56,\n",
      "         79,  25,  80,  50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 58,   3,  36,   6,  66,  48,  54,  45, 124,  69,  92,  88,  12,  17,\n",
      "          0,  22,  25,  22, 143,  66,  42,  85,   9,  68,  20,  37,  49,  83,\n",
      "         38,  34,  84,  17]) tensor([ 65,   8,  37,   8,  76,  48,  54,  45, 150,  71,  93,  97,  26,  18,\n",
      "          3,  25,  27,  27, 144,  66,  50,  89,  10,  70,  33,  39,  49,  83,\n",
      "         40,  34,  85,  18])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 31,  10,  76,  47,  96,  41,  57,  78,  35,  75,  86,  21,  53,  62,\n",
      "         27,  22,  44,  83,  96,  63, 130,  74,  74,  13,  50,  46,  10,  15,\n",
      "         46,  51,  80,  59]) tensor([ 32,  10,  80,  50,  97,  44,  75,  98,  45,  84,  92,  22,  58,  62,\n",
      "         28,  25,  48,  89, 109,  64, 131,  74,  77,  15,  52,  55,  21,  16,\n",
      "         53,  53,  91,  62])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 10,  31,  22,   0,  78,  47,  23,   5,  87,  46,  54, 106,  20,  16,\n",
      "         46,   9,  40,  68,  53,  60,  26,  57,  59, 137,  27,  13,  26,   8,\n",
      "         21,  12,  92,  44]) tensor([ 14,  31,  23,   2,  80,  61,  26,   5,  93,  48,  54, 106,  23,  20,\n",
      "         46,   9,  42,  69,  53,  63,  27,  60,  61, 138,  27,  20,  31,  27,\n",
      "         21,  19,  95,  49])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 27,   6,  28,  24, 121,  23,  25,  92,  62, 114,  42,   9,  22,  59,\n",
      "         69,  87,  32,  72,   0,  63,  62,  23,  23,  85,  54,  42,  71,  56,\n",
      "         50,  31,   8,   0]) tensor([ 28,   9,  28,  28, 123,  26,  30,  94,  62, 117,  45,   9,  33,  59,\n",
      "         72,  89,  32,  73,   3,  64,  64,  25,  25,  87,  54,  45,  71,  59,\n",
      "         52,  32,  11,  35])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 95,  21,   5,  54,  40,  10, 123,   8,  64,  14,  82,  74,   4,  45,\n",
      "         54,   4,   8,  59,  80,  20,  12,  16,  74,  65,  18,  41,  39,   7,\n",
      "        102,  45,  26, 102]) tensor([105,  24,   9,  58,  57,  14, 126,  12,  69,  17,  84,  78,   5,  48,\n",
      "         55,   4,  18,  64,  83,  25,  18,  18,  80,  67,  20,  47,  44,  12,\n",
      "        110,  48,  33, 104])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 25,   2,  33,  15,  54,  80,  47,  31,  35,  49,  87,  86,   9,   6,\n",
      "         34,  66,  33,  48,   8,  35,  51,  19,  80,  63,  66,  62,  42,  11,\n",
      "        128,  41,  31, 110]) tensor([ 27,   4,  35,  17,  58,  85,  47,  31,  38,  51,  92,  92,   9,   7,\n",
      "         37,  66,  33,  51,  11,  38,  54,  33,  82,  63,  66,  63,  56,  12,\n",
      "        132,  43,  36, 112])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  5,   9,  91,  33,  68,  11,  51,  12, 113,  14,  16,  20,  25,  81,\n",
      "          6,  23,  65,  41,  50,  38,  10,  32,  12,  12,  66,  30,   6,  23,\n",
      "         41,  48,  95,  44]) tensor([  7,  10,  91,  38,  70,  14,  54,  14, 115,  15,  17,  27,  26,  87,\n",
      "         11,  24,  66,  49,  51,  41,  31,  32,  14,  14,  69,  31,  17,  45,\n",
      "         47,  49,  99,  54])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 91,  46,  26,  71,  41,  12,  14,  52,  28,  70,  53,   9,  35,   0,\n",
      "         56, 112,   2,   7,  15, 124,  77,  11, 109,  67,  39,  56,  10,   7,\n",
      "         24,  33,  13, 109]) tensor([ 91,  50,  28,  76,  41,  22,  19,  54,  32,  72,  62,   9,  37,   5,\n",
      "         58, 120,   3,   9,  26, 124,  84,  18, 111,  70,  52,  56,  13,   9,\n",
      "         28,  36,  15, 113])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 19,  42,  79,   0,  34,  86, 113,  72,  68,  25,  54,  44,  20,  69,\n",
      "         50,  20,  43,  29,  69,  60,  45, 110,  53,   0,  48,  85,  73,  46,\n",
      "          0,  19,  62,  49]) tensor([ 19,  44,  83,   5,  36,  87, 116,  74,  70,  29,  55,  49,  44,  73,\n",
      "         53,  24,  53,  31,  72,  60,  45, 110,  56,   3,  48,  88,  81,  46,\n",
      "          4,  19,  66,  50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  7,   2,   0,  52,  22,  14,  15,  21,  24,  95,  55, 113,  89,  55,\n",
      "          4,  36,  69,  48,   2,  29,   3,  78,  73,   2,  65,  21,  37,   3,\n",
      "         28,   2,  25,   3]) tensor([  7,   3,   2,  53,  30,  18,  18,  26,  30,  98,  56, 113,  90,  59,\n",
      "          5,  40,  73,  60,   4,  32,   4,  79,  76,   3,  67,  21,  41,   4,\n",
      "         31,   2,  26,   3])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  9, 117,  27,  53,  85,  14,  97,  23,  24,  38,   6,  51,  58,   9,\n",
      "         35,  39,  82,  58,  11,   0,  13, 106,  14,  38,  23,  13,  45,   0,\n",
      "         33,  42,  15, 112]) tensor([ 12, 120,  29,  53,  87,  15, 101,  27,  26,  38,   9,  82,  67,  23,\n",
      "         39,  41,  84,  61,  18,   8,  18, 110,  19,  39,  26,  15,  48,   2,\n",
      "         45,  42,  17, 115])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 25,  41,  21,  85,  76,  15,  61,  17, 123,  57, 109,   0,  72,  83,\n",
      "          0,  22,  31,  80, 115, 130,   2,  83,  45,  47,   3,  56,  89,  37,\n",
      "         87, 111,  28,  99]) tensor([ 31,  42,  22,  86,  79,  28,  73,  18, 130,  58, 112,   3,  74,  84,\n",
      "          9,  25,  31,  80, 117, 131,   4,  88,  45,  48,   5,  59,  92,  45,\n",
      "         87, 114,  29, 106])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 14,  18, 121,  36,  42,  63,  34,  48,  19,   7,  96, 107,  61,  71,\n",
      "         53,  27,  77,  17,  69,  20,  74,  15,  54,  54,  16,  32,  71,  96,\n",
      "          5,  93,  19,  34]) tensor([ 19,  19, 124,  36,  42,  64,  39,  50,  20,   8, 103, 109,  68,  75,\n",
      "         53,  27,  80,  18,  73,  20,  77,  16,  59,  59,  19,  34,  71,  98,\n",
      "          9,  97,  21,  41])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 16,  92,  24,  17,  50, 137,  80,   8,  43,  19,  60,  37,  66,  10,\n",
      "        104,  23,  16, 104,   9,  17, 100,  71,  59,   2,  12,  11,   7,  57,\n",
      "          0,  63,  76,  17]) tensor([ 17,  95,  25,  23,  55, 144,  90,  11,  45,  19,  64,  37,  74,  13,\n",
      "        104,  24,  16, 109,  13,  20, 105,  79,  60,   3,  14,  11,   9,  59,\n",
      "          1,  65,  84,  20])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 31,  67, 104,  20, 126,  45,  27,   2,  36,  78,  71,  17,  50,  35,\n",
      "         67, 103,  41,  36,  49,  43, 111,  49,  26,   2,  70,  52,   7, 107,\n",
      "         94,  63,  18, 100]) tensor([ 35,  67, 107,  26, 128,  47,  36,   2,  57, 117,  73,  18,  52,  36,\n",
      "         72, 105,  44,  43,  58,  43, 112,  52,  29,   3,  73,  56,  12, 107,\n",
      "         95,  64,  20, 100])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  7,  63,  41,  23,  46,  46,  68,  53,  65,  90,  24,  48,  29,  58,\n",
      "         47, 103,   0,   8,  49,  65,   3,  60,  55,  44,   2,   2,  36,  78,\n",
      "         16,  69,  20,  90]) tensor([  7,  64,  41,  24,  46,  48,  70,  56,  67,  90,  24,  50,  30,  59,\n",
      "         48, 104,   1,  17,  49,  79,   3,  64,  55,  50,   4,   6,  36,  81,\n",
      "         18,  72,  25,  93])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 44,  55,   0,   9,  17,  45,  46,  15,  71,   2,  16, 110,  42,  91,\n",
      "          2,  28, 106,   4,  69,  39,  19,  56,  13,  96, 118,  12, 131,  36,\n",
      "         11,  50,  33,  56]) tensor([ 48,  55,   3,  11,  20,  49,  50,  23,  73,   3,  17, 113,  43,  92,\n",
      "          2,  32, 108,   4,  71,  39,  20,  58,  16,  98, 126,  12, 132,  44,\n",
      "         16,  53,  33,  61])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 96,  33,  23,  24,   2,  37,  11,  14,  18,  62,  39,  16,   0,  78,\n",
      "         54,   7,  45,  15,  44, 105,  65, 115,  14,   5,   0,  57,  53,  94,\n",
      "         65,  47,  31,  60]) tensor([100,  35,  26,  24,   3,  39,  14,  15,  22,  62,  43,  18,   7,  80,\n",
      "         58,   8,  50,  21,  46, 111,  67, 118,  20,   5,  12,  57,  57, 105,\n",
      "         67,  48,  35,  60])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([108,   7,  49,  26,   8,  41,  59,  60,  45,  19,  25,  15,   2,   3,\n",
      "         55,  18,  29,  44,   7, 127,  71, 133,  10, 112,  30,  20,  34,   9,\n",
      "          7,  26,  23,  56]) tensor([111,   8,  52,  32,   8,  46,  59,  62,  47,  20,  25,  15,   3,   3,\n",
      "         58,  19,  33,  50,  11, 127,  75, 137,  13, 116,  33,  21,  37,   9,\n",
      "         14,  32,  26,  57])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 12,   2,  52,  67,  53,  35, 100,  59,  67,  22,  36,  37,  95,   3,\n",
      "          2,  16,   9,  71,  56,   2,   9,  52,  21, 121,  63,  11,  86,  10,\n",
      "         51,  82,  67,  24]) tensor([ 15,   5,  54,  67,  77,  39, 100,  61,  67,  25,  40,  42,  98,   3,\n",
      "          3,  20,  12,  73,  57,   5,   9,  62,  24, 123,  65,  11,  87,  14,\n",
      "         55,  86,  71,  26])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 31,   9,  98,  89,  65, 107,  11,  99,   8,  42,  52,   5, 110,  23,\n",
      "          2,  66,   8,   8,  33,  30,  62,  64,  17,  13,  57, 112,  72, 132,\n",
      "         22, 112,   3,  13]) tensor([ 36,  12, 103,  93,  72, 109,  17, 101,   8,  43,  54,  10, 115,  23,\n",
      "          3,  72,   9,  14,  36,  31,  71,  68,  18,  15,  61, 114,  75, 133,\n",
      "         22, 120,   7,  16])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 74,  55, 126,  44,  79,   9,  51,   5,  38,  37,  65,  21,  44, 133,\n",
      "        114,  15,  10,  14,  33,  56,  44,  31,  50,  97,  20,  13,  36,  61,\n",
      "         78,  87,  37,  47]) tensor([ 83,  56, 130,  46,  87,  21,  53,   5,  43,  57,  72,  25,  46, 136,\n",
      "        132,  17,  12,  14,  33,  59,  46,  32,  50, 109,  26,  20,  44,  64,\n",
      "         80,  90,  37,  50])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 29,  45,  25,  45,  13,  66,  16,  77,   2, 110,  39,  74,  54,  28,\n",
      "         35,  42,  27,  46,   8,  69,  29, 103,  57,  52,  15,  43,  27, 107,\n",
      "        109,  50,  44,  30]) tensor([ 30,  47,  26,  45,  15,  70,  20,  79,   2, 116,  39,  74,  60,  35,\n",
      "         37,  42,  32,  46,  11,  72,  31, 114,  60,  56,  17,  47,  28, 109,\n",
      "        110,  51,  45,  34])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 41,   0,  28,  60,  54,   8,  23,  52,  52,  35,  67,   2,  38,  22,\n",
      "         80,  30,  55,  34,  28,  81,  58, 106,  43,  10,  18,  44,  45,  10,\n",
      "         80,  77,  22,  11]) tensor([ 42,   5,  32,  64,  56,  14,  29,  52,  73,  37,  71,   5,  39,  25,\n",
      "         84,  33,  55,  34,  40,  82,  58, 113,  45,  10,  24,  47,  48,  10,\n",
      "         84,  80,  23,  11])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 27,  30,  59,  23,   2,  24,   9,  15,  91, 101,   0,   7,   5,  87,\n",
      "         51,  43,  34,  61,  33,  69, 107,  72,  23,  15,  40,  75,  73,  64,\n",
      "         68,  36,  33,  38]) tensor([ 40,  33,  63,  28,   6,  25,   9,  22,  96, 110,   2,   7,   6,  98,\n",
      "         52,  48,  39,  68,  37,  69, 110,  87,  24,  16,  40,  75,  75,  66,\n",
      "         70,  40,  35,  39])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 67,  96,  59,  79,  32,  13, 106,  19,  77,  30,  25,  61,  63,  37,\n",
      "         15,  32,  20,  56,  58,  90,  10,   5,  93,   8,  25,  93,  11,  35,\n",
      "         44,  43,  36,  34]) tensor([ 69, 101,  61,  82,  36,  17, 106,  26,  77,  34,  28,  66,  64,  40,\n",
      "         16,  36,  21,  64,  58,  95,  23,   7,  95,  12,  28,  95,  11,  36,\n",
      "         46,  47,  39,  41])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([111,  84,  71,  27,   7,  75,  52,  56,  55,  60, 104,  52,  37,  51,\n",
      "         21,  66,   0,  46,  77,  79,  69,  95,   7, 105,  34,  56,  35,  51,\n",
      "         21,  91,  37,   8]) tensor([113,  86,  72,  29,   8,  82,  66,  56,  56,  62, 109,  53,  47,  56,\n",
      "         25,  74,   1,  48,  79,  83,  70, 100,   9, 107,  34,  57,  36,  54,\n",
      "         28,  92,  44,   9])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 60,  72,  42, 113,  23, 105,  36,   0,  96, 135,  97,  33,  54,  17,\n",
      "         32,  22,  85,  18,  16, 117,  28,  59,  88,  20,   7,  47,  54,  54,\n",
      "         72,  21,  13,  68]) tensor([ 67,  80,  45, 130,  26, 105,  41,   4, 113, 143, 110,  33,  54,  17,\n",
      "         38,  24,  85,  19,  16, 119,  31,  66,  93,  24,   9,  48,  55,  56,\n",
      "         74,  23,  16,  68])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 82,  25,  81,   8,  24,  45,  28, 126,  37,  96,  32,  97,   5,  24,\n",
      "         40,  22,   2,   6, 133,  51,  99,  80,  93,   0,  57,  86,  93,  82,\n",
      "          2, 112,   2,  55]) tensor([ 84,  36,  81,   8,  24,  53,  43, 129,  39,  96,  34, 102,   7,  26,\n",
      "         43,  24,   4,   9, 135,  52, 102,  81,  95,   6,  59,  90,  99,  87,\n",
      "          3, 116,   4,  60])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 54,  95,  32,  14,   0,   6,  14,  12,  37,  13,  27,  31,  29,  38,\n",
      "        124,  33,   5, 130,   9,  25,  64,  80,  13,   3, 113,  43,  25,  14,\n",
      "         45,  24,   9, 104]) tensor([ 55,  98,  38,  18,   2,   7,  15,  17,  41,  19,  29,  34,  34,  43,\n",
      "        125,  35,   8, 137,  10,  27,  66,  81,  13,   4, 114,  43,  30,  17,\n",
      "         49,  26,  10, 120])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([  0,  49,  66,  28,  51,   0,  75,  39,  65, 111,  18,  66,  11, 115,\n",
      "         33,  75,  16,  51,  12,   7,  69,  43,  20,  39, 112,  24,  60,  27,\n",
      "         13,   9,   3,  40]) tensor([  5,  53,  78,  28,  63,   8,  77,  44,  67, 112,  21,  67,  15, 118,\n",
      "         35,  75,  18,  58,  14,   8,  75,  44,  22,  43, 127,  26,  65,  31,\n",
      "         14,  16,   3,  43])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 74,  65,   2,  64,  32,  30,  10,  59,  65,  20,  75,  29,  20,  21,\n",
      "        120,  79,  59,  19,  34, 120,  85,  23,  28,   9,  25,  52,  31,  15,\n",
      "         24,   8,  63,  34]) tensor([ 75,  66,   2,  65,  45,  34,  10,  61,  68,  21,  76,  31,  23,  22,\n",
      "        121,  84,  65,  37,  43, 125,  89,  24,  31,  10,  25,  71,  52,  19,\n",
      "         25,  11,  63,  41])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([101,  67,   9, 108,  60,  14,  81,  48,  26,  27,  23,  43,  45,  82,\n",
      "         24,  22,  58,  30,  32,  10,   6,  22,  85,  67,   6, 111,   8, 115,\n",
      "         14, 105,  49,  34]) tensor([102,  80,  14, 111,  67,  15,  86,  53,  29,  28,  30,  46,  48,  84,\n",
      "         28,  24,  63,  32,  33,  14,   7,  28,  89,  72,  10, 113,  10, 125,\n",
      "         17, 108,  51,  38])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 32,   6,  61,  36,  89,  77,  45,  71,  56,  18,  36,  40,  10,  62,\n",
      "         19,  42,  74,   0,  25,  57,  36,  10,  20,  14,  38,  99,  16, 120,\n",
      "         28,   9,  46,  70]) tensor([ 33,  28,  62,  39,  98,  78,  67,  72,  61,  21,  38,  43,  17,  63,\n",
      "         19,  50,  79,   3,  27,  63,  37,  13,  21,  15,  38, 102,  18, 122,\n",
      "         30,  10,  60,  72])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 11,  69,  46,  13,  35,  45,  12,  80,  34,  46,  31,  22,   3,  92,\n",
      "        123,   2,  59,  55,  81,  27,  56,  62,  27,  44,  87,  37,  12, 123,\n",
      "         87,  24,  13, 109]) tensor([ 11,  78,  51,  14,  39,  47,  12,  82,  46,  49,  31,  26,   5,  98,\n",
      "        124,   5,  61,  56,  82,  28,  57,  65,  30,  47, 100,  37,  12, 125,\n",
      "         91,  26,  20, 112])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 54,  36,  20,  34,  89, 121,  16,  25, 105,  20,  84,  96,  13,  75,\n",
      "         26,  78,   0,   0,  33,  39,  64,  20, 110,  63,  46,   8,  89,   8,\n",
      "          5,  54,  67,  59]) tensor([ 62,  37,  25,  36,  98, 127,  18,  26, 125,  23,  87,  99,  16,  80,\n",
      "         26,  82,   5,   4,  38,  42,  69,  33, 114,  71,  49,   8,  91,  12,\n",
      "          6,  54,  69,  64])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([32, 191])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 191])\n",
      "tensor([ 42,  46,  66,  99,  33,   0,  43,  45,  93,  36,   2,  32,   0,  77,\n",
      "         40,  39,   6, 101,  46,  10,  33,  57,   7,  36,  15,  79,   2,  49,\n",
      "         10,  67, 113,   8]) tensor([ 43,  47,  69, 102,  34,  15,  46,  49,  99,  48,   6,  33,   5,  87,\n",
      "         44,  44,   9, 102,  52,  15,  33,  60,   8,  39,  16,  79,  14,  50,\n",
      "         14,  71, 123,   9])\n",
      "--------------------------------------------------\n",
      "dict_keys(['question', 'attention_mask_question', 'answer', 'attention_mask_answer', 'context', 'attention_mask_context', 'context_question', 'attention_mask_context_question', 'answer_start', 'answer_end'])\n",
      "torch.Size([25, 191])\n",
      "torch.Size([25, 30])\n",
      "torch.Size([25, 25])\n",
      "torch.Size([25, 30])\n",
      "torch.Size([25, 25])\n",
      "torch.Size([25, 191])\n",
      "tensor([ 20,  39,  66,  17,  91,  17,  37,  47,  81,  22,  52,  33,  34,  88,\n",
      "         24,  50,  19,  39,   2,  22, 106,  29,  24,  83,   0]) tensor([ 40,  41,  67,  21,  92,  18,  40,  48,  83,  24,  61,  36,  36,  92,\n",
      "         24,  54,  20,  41,   2,  24, 108,  33,  28,  83,   3])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Creating Dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True) # add this `num_workers=0` if you want to see print in __getitem__ in dataset class\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    print(batch.keys())\n",
    "    print(batch['context_question'].shape)\n",
    "    print(batch['question'].shape)\n",
    "    print(batch['answer'].shape)\n",
    "    print(batch['attention_mask_question'].shape)\n",
    "    print(batch['attention_mask_answer'].shape)\n",
    "    print(batch['attention_mask_context_question'].shape)\n",
    "    print(batch['answer_start'], batch['answer_end'])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Phase 1: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context [SEP] Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|| 625/625 [00:13<00:00, 46.76it/s, loss=6.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 7.7158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 60.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.6206\n",
      "Validation Metrics: {'start_accuracy': 0.08216432865731463, 'start_precision': 0.08784456494918455, 'start_recall': 0.08216432865731463, 'start_f1_score': 0.07825977613824404, 'end_accuracy': 0.09168336673346693, 'end_precision': 0.09137172274059968, 'end_recall': 0.09168336673346693, 'end_f1_score': 0.08528390412564232, 'joint_exact_match': 0.024549098196392786, 'span_overlap_f1': 0.06088804753580131}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|| 625/625 [00:13<00:00, 46.46it/s, loss=6.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 7.1858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 60.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.7867\n",
      "Validation Metrics: {'start_accuracy': 0.0811623246492986, 'start_precision': 0.08365035911246604, 'start_recall': 0.0811623246492986, 'start_f1_score': 0.07581565350198566, 'end_accuracy': 0.08366733466933868, 'end_precision': 0.07222468673574467, 'end_recall': 0.08366733466933868, 'end_f1_score': 0.0707134317967252, 'joint_exact_match': 0.02004008016032064, 'span_overlap_f1': 0.05533935375528682}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|| 625/625 [00:13<00:00, 46.37it/s, loss=7.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 6.7167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.5606\n",
      "Validation Metrics: {'start_accuracy': 0.08767535070140281, 'start_precision': 0.0842003923703452, 'start_recall': 0.08767535070140281, 'start_f1_score': 0.07943862907756531, 'end_accuracy': 0.09018036072144289, 'end_precision': 0.0894025599067649, 'end_recall': 0.09018036072144289, 'end_f1_score': 0.07950637694362112, 'joint_exact_match': 0.03206412825651302, 'span_overlap_f1': 0.06359990012204257}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|| 625/625 [00:13<00:00, 46.29it/s, loss=7.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 6.2998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 56.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.6494\n",
      "Validation Metrics: {'start_accuracy': 0.09719438877755511, 'start_precision': 0.0893825063332601, 'start_recall': 0.09719438877755511, 'start_f1_score': 0.08514701347261106, 'end_accuracy': 0.0966933867735471, 'end_precision': 0.08611839361647919, 'end_recall': 0.0966933867735471, 'end_f1_score': 0.08489628359608191, 'joint_exact_match': 0.036072144288577156, 'span_overlap_f1': 0.07092690680662828}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|| 625/625 [00:13<00:00, 46.36it/s, loss=6.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 5.9899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 60.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.7686\n",
      "Validation Metrics: {'start_accuracy': 0.09819639278557114, 'start_precision': 0.09674655679549422, 'start_recall': 0.09819639278557114, 'start_f1_score': 0.09183084772598536, 'end_accuracy': 0.09719438877755511, 'end_precision': 0.08496588194560256, 'end_recall': 0.09719438877755511, 'end_f1_score': 0.08509197705714876, 'joint_exact_match': 0.04408817635270541, 'span_overlap_f1': 0.07836650157844181}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|| 625/625 [00:13<00:00, 46.92it/s, loss=5.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 5.7068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 59.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 8.0832\n",
      "Validation Metrics: {'start_accuracy': 0.09468937875751503, 'start_precision': 0.09267473128745354, 'start_recall': 0.09468937875751503, 'start_f1_score': 0.0869932121381396, 'end_accuracy': 0.09919839679358718, 'end_precision': 0.09289729538725193, 'end_recall': 0.09919839679358718, 'end_f1_score': 0.08917738664111341, 'joint_exact_match': 0.03707414829659319, 'span_overlap_f1': 0.07323537262496906}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|| 625/625 [00:13<00:00, 47.70it/s, loss=5.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 5.4105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 8.2478\n",
      "Validation Metrics: {'start_accuracy': 0.093687374749499, 'start_precision': 0.08801059753495605, 'start_recall': 0.093687374749499, 'start_f1_score': 0.08483037463447647, 'end_accuracy': 0.09118236472945891, 'end_precision': 0.0846650146818527, 'end_recall': 0.09118236472945891, 'end_f1_score': 0.0810033096771122, 'joint_exact_match': 0.04308617234468938, 'span_overlap_f1': 0.07565305001161385}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|| 625/625 [00:13<00:00, 48.03it/s, loss=5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 5.0846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:00<00:00, 64.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 8.8936\n",
      "Validation Metrics: {'start_accuracy': 0.08066132264529058, 'start_precision': 0.0735532333715045, 'start_recall': 0.08066132264529058, 'start_f1_score': 0.0669081085468651, 'end_accuracy': 0.08767535070140281, 'end_precision': 0.08614645797846895, 'end_recall': 0.08767535070140281, 'end_f1_score': 0.07780256591644372, 'joint_exact_match': 0.03256513026052104, 'span_overlap_f1': 0.06808839233797154}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|| 625/625 [00:12<00:00, 48.23it/s, loss=4.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 4.8059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 62.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.1814\n",
      "Validation Metrics: {'start_accuracy': 0.09118236472945891, 'start_precision': 0.08333511834999413, 'start_recall': 0.09118236472945891, 'start_f1_score': 0.07918260031008897, 'end_accuracy': 0.08016032064128256, 'end_precision': 0.07809112134905873, 'end_recall': 0.08016032064128256, 'end_f1_score': 0.07193130621200164, 'joint_exact_match': 0.033066132264529056, 'span_overlap_f1': 0.0665695581918706}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|| 625/625 [00:13<00:00, 47.39it/s, loss=5.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 4.5488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.6084\n",
      "Validation Metrics: {'start_accuracy': 0.08216432865731463, 'start_precision': 0.07839394240354328, 'start_recall': 0.08216432865731463, 'start_f1_score': 0.07286083962367021, 'end_accuracy': 0.08667334669338678, 'end_precision': 0.08291753729292645, 'end_recall': 0.08667334669338678, 'end_f1_score': 0.07806535220639751, 'joint_exact_match': 0.028056112224448898, 'span_overlap_f1': 0.06438999009942044}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|| 625/625 [00:12<00:00, 48.46it/s, loss=4.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 4.3202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 10.3559\n",
      "Validation Metrics: {'start_accuracy': 0.07965931863727455, 'start_precision': 0.07438974329348991, 'start_recall': 0.07965931863727455, 'start_f1_score': 0.07181477280192786, 'end_accuracy': 0.08216432865731463, 'end_precision': 0.07719468525728934, 'end_recall': 0.08216432865731463, 'end_f1_score': 0.07519147145959618, 'joint_exact_match': 0.02655310621242485, 'span_overlap_f1': 0.05783906665848703}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|| 625/625 [00:13<00:00, 47.62it/s, loss=4.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 4.1442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 10.5947\n",
      "Validation Metrics: {'start_accuracy': 0.08567134268537074, 'start_precision': 0.07822457758004048, 'start_recall': 0.08567134268537074, 'start_f1_score': 0.07373314023288104, 'end_accuracy': 0.08066132264529058, 'end_precision': 0.07769021435657271, 'end_recall': 0.08066132264529058, 'end_f1_score': 0.07178729629862987, 'joint_exact_match': 0.02655310621242485, 'span_overlap_f1': 0.06159627745128422}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|| 625/625 [00:13<00:00, 47.90it/s, loss=3.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 3.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 59.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 10.4436\n",
      "Validation Metrics: {'start_accuracy': 0.0746492985971944, 'start_precision': 0.06362230341406114, 'start_recall': 0.0746492985971944, 'start_f1_score': 0.06206356393511729, 'end_accuracy': 0.06162324649298597, 'end_precision': 0.06274869953913009, 'end_recall': 0.06162324649298597, 'end_f1_score': 0.05693064539908484, 'joint_exact_match': 0.016533066132264528, 'span_overlap_f1': 0.058353076890988814}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|| 625/625 [00:13<00:00, 47.92it/s, loss=4.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss: 3.8534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 11.7263\n",
      "Validation Metrics: {'start_accuracy': 0.061122244488977955, 'start_precision': 0.05185911867564638, 'start_recall': 0.061122244488977955, 'start_f1_score': 0.05264575844624525, 'end_accuracy': 0.07515030060120241, 'end_precision': 0.07329259257570069, 'end_recall': 0.07515030060120241, 'end_f1_score': 0.0692851300208513, 'joint_exact_match': 0.01753507014028056, 'span_overlap_f1': 0.06021468129859597}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|| 625/625 [00:13<00:00, 47.58it/s, loss=3.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss: 3.7174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:00<00:00, 65.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 11.7528\n",
      "Validation Metrics: {'start_accuracy': 0.06513026052104208, 'start_precision': 0.058785100192159746, 'start_recall': 0.06513026052104208, 'start_f1_score': 0.055223657735248774, 'end_accuracy': 0.07064128256513026, 'end_precision': 0.07199723737072745, 'end_recall': 0.07064128256513026, 'end_f1_score': 0.06544998422438242, 'joint_exact_match': 0.021042084168336674, 'span_overlap_f1': 0.06096496737716035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|| 625/625 [00:13<00:00, 48.06it/s, loss=3.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss: 3.6458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 11.4283\n",
      "Validation Metrics: {'start_accuracy': 0.06212424849699399, 'start_precision': 0.060934177858856194, 'start_recall': 0.06212424849699399, 'start_f1_score': 0.05808567282722514, 'end_accuracy': 0.0746492985971944, 'end_precision': 0.08803448411962826, 'end_recall': 0.0746492985971944, 'end_f1_score': 0.07094066245852722, 'joint_exact_match': 0.02404809619238477, 'span_overlap_f1': 0.06354540782512336}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|| 625/625 [00:12<00:00, 48.86it/s, loss=3.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss: 3.5406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:00<00:00, 64.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 12.0771\n",
      "Validation Metrics: {'start_accuracy': 0.07064128256513026, 'start_precision': 0.07327850950890649, 'start_recall': 0.07064128256513026, 'start_f1_score': 0.06595566498189397, 'end_accuracy': 0.0811623246492986, 'end_precision': 0.0921144996205529, 'end_recall': 0.0811623246492986, 'end_f1_score': 0.07858615372186263, 'joint_exact_match': 0.02655310621242485, 'span_overlap_f1': 0.06761679941032658}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|| 625/625 [00:13<00:00, 47.45it/s, loss=3.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss: 3.4674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 56.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 12.4993\n",
      "Validation Metrics: {'start_accuracy': 0.08166332665330661, 'start_precision': 0.08281911123190895, 'start_recall': 0.08166332665330661, 'start_f1_score': 0.07515140508376308, 'end_accuracy': 0.08567134268537074, 'end_precision': 0.09806087142538261, 'end_recall': 0.08567134268537074, 'end_f1_score': 0.08175806645983157, 'joint_exact_match': 0.03256513026052104, 'span_overlap_f1': 0.07318026551390634}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|| 625/625 [00:13<00:00, 47.84it/s, loss=3.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss: 3.3603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 59.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 12.1746\n",
      "Validation Metrics: {'start_accuracy': 0.0781563126252505, 'start_precision': 0.09303575294556324, 'start_recall': 0.0781563126252505, 'start_f1_score': 0.07807592294708345, 'end_accuracy': 0.0906813627254509, 'end_precision': 0.10883784237706651, 'end_recall': 0.0906813627254509, 'end_f1_score': 0.08994133679414142, 'joint_exact_match': 0.039579158316633264, 'span_overlap_f1': 0.08259626422946569}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|| 625/625 [00:13<00:00, 47.00it/s, loss=3.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss: 3.2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 57.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 12.6089\n",
      "Validation Metrics: {'start_accuracy': 0.0746492985971944, 'start_precision': 0.0911131577297584, 'start_recall': 0.0746492985971944, 'start_f1_score': 0.07390145440985474, 'end_accuracy': 0.08667334669338678, 'end_precision': 0.09749504430827519, 'end_recall': 0.08667334669338678, 'end_f1_score': 0.08441131854125897, 'joint_exact_match': 0.039579158316633264, 'span_overlap_f1': 0.08341328323366551}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|| 625/625 [00:13<00:00, 47.96it/s, loss=3.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Loss: 3.1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 57.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 12.5164\n",
      "Validation Metrics: {'start_accuracy': 0.08867735470941884, 'start_precision': 0.10457060234597283, 'start_recall': 0.08867735470941884, 'start_f1_score': 0.086486053887253, 'end_accuracy': 0.09819639278557114, 'end_precision': 0.12224209982795482, 'end_recall': 0.09819639278557114, 'end_f1_score': 0.10040776052576253, 'joint_exact_match': 0.04959919839679359, 'span_overlap_f1': 0.09702928727783038}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|| 625/625 [00:13<00:00, 47.07it/s, loss=3.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Loss: 2.9945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 12.4039\n",
      "Validation Metrics: {'start_accuracy': 0.08767535070140281, 'start_precision': 0.12119900465225472, 'start_recall': 0.08767535070140281, 'start_f1_score': 0.08768204533245406, 'end_accuracy': 0.10170340681362726, 'end_precision': 0.14968532873920942, 'end_recall': 0.10170340681362726, 'end_f1_score': 0.10185281102602907, 'joint_exact_match': 0.050100200400801605, 'span_overlap_f1': 0.09462225333877049}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|| 625/625 [00:13<00:00, 47.49it/s, loss=3.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Loss: 2.8764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 12.7879\n",
      "Validation Metrics: {'start_accuracy': 0.10220440881763528, 'start_precision': 0.11116307922552951, 'start_recall': 0.10220440881763528, 'start_f1_score': 0.0989941995862921, 'end_accuracy': 0.11372745490981964, 'end_precision': 0.1362789983596334, 'end_recall': 0.11372745490981964, 'end_f1_score': 0.1140797444899898, 'joint_exact_match': 0.05811623246492986, 'span_overlap_f1': 0.11088058672509336}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|| 625/625 [00:13<00:00, 47.49it/s, loss=2.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Loss: 2.7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 59.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 12.9313\n",
      "Validation Metrics: {'start_accuracy': 0.09919839679358718, 'start_precision': 0.10672952111012324, 'start_recall': 0.09919839679358718, 'start_f1_score': 0.09563248779921944, 'end_accuracy': 0.10220440881763528, 'end_precision': 0.12605064768294857, 'end_recall': 0.10220440881763528, 'end_f1_score': 0.10481617119124864, 'joint_exact_match': 0.050100200400801605, 'span_overlap_f1': 0.09980016763195904}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|| 625/625 [00:13<00:00, 47.39it/s, loss=2.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Loss: 2.6595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 60.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 12.9455\n",
      "Validation Metrics: {'start_accuracy': 0.09519038076152304, 'start_precision': 0.1152542464572385, 'start_recall': 0.09519038076152304, 'start_f1_score': 0.09483356292880604, 'end_accuracy': 0.10671342685370741, 'end_precision': 0.13017063693728623, 'end_recall': 0.10671342685370741, 'end_f1_score': 0.10782493655695385, 'joint_exact_match': 0.05511022044088176, 'span_overlap_f1': 0.10476735129196524}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|| 625/625 [00:13<00:00, 47.57it/s, loss=2.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Loss: 2.5642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 58.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 13.4022\n",
      "Validation Metrics: {'start_accuracy': 0.09519038076152304, 'start_precision': 0.10404731846203469, 'start_recall': 0.09519038076152304, 'start_f1_score': 0.09138771637206755, 'end_accuracy': 0.09819639278557114, 'end_precision': 0.11939232029542707, 'end_recall': 0.09819639278557114, 'end_f1_score': 0.10002901971365892, 'joint_exact_match': 0.042585170340681364, 'span_overlap_f1': 0.09633674970195714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|| 625/625 [00:13<00:00, 47.31it/s, loss=2.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Loss: 2.4950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 58.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 13.2809\n",
      "Validation Metrics: {'start_accuracy': 0.0966933867735471, 'start_precision': 0.10735280227626734, 'start_recall': 0.0966933867735471, 'start_f1_score': 0.09671939519151963, 'end_accuracy': 0.10721442885771543, 'end_precision': 0.12250935652548683, 'end_recall': 0.10721442885771543, 'end_f1_score': 0.10804315968793071, 'joint_exact_match': 0.05661322645290581, 'span_overlap_f1': 0.10454776873496263}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|| 625/625 [00:13<00:00, 47.12it/s, loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Loss: 2.3907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 57.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 13.5123\n",
      "Validation Metrics: {'start_accuracy': 0.10220440881763528, 'start_precision': 0.11610948837031201, 'start_recall': 0.10220440881763528, 'start_f1_score': 0.10206028126821445, 'end_accuracy': 0.10821643286573146, 'end_precision': 0.13493741055753386, 'end_recall': 0.10821643286573146, 'end_f1_score': 0.11066853035798485, 'joint_exact_match': 0.052104208416833664, 'span_overlap_f1': 0.10657400214469415}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|| 625/625 [00:13<00:00, 47.35it/s, loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Loss: 2.2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:00<00:00, 63.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 13.6919\n",
      "Validation Metrics: {'start_accuracy': 0.10420841683366733, 'start_precision': 0.11071402800185225, 'start_recall': 0.10420841683366733, 'start_f1_score': 0.1017015276174891, 'end_accuracy': 0.10220440881763528, 'end_precision': 0.1083039678215278, 'end_recall': 0.10220440881763528, 'end_f1_score': 0.10023017935446951, 'joint_exact_match': 0.05911823647294589, 'span_overlap_f1': 0.10561843451127072}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|| 625/625 [00:13<00:00, 47.50it/s, loss=2.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Loss: 2.2261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 57.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 13.6926\n",
      "Validation Metrics: {'start_accuracy': 0.09819639278557114, 'start_precision': 0.10881023978921717, 'start_recall': 0.09819639278557114, 'start_f1_score': 0.09855841665043548, 'end_accuracy': 0.10170340681362726, 'end_precision': 0.11785989804258928, 'end_recall': 0.10170340681362726, 'end_f1_score': 0.10280387158197411, 'joint_exact_match': 0.05711422845691383, 'span_overlap_f1': 0.10456681986193782}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|| 625/625 [00:13<00:00, 47.99it/s, loss=1.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Loss: 2.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:00<00:00, 63.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 14.4768\n",
      "Validation Metrics: {'start_accuracy': 0.10521042084168336, 'start_precision': 0.12297231832958605, 'start_recall': 0.10521042084168336, 'start_f1_score': 0.10579041277384872, 'end_accuracy': 0.09919839679358718, 'end_precision': 0.11450950798487769, 'end_recall': 0.09919839679358718, 'end_f1_score': 0.10015437010796296, 'joint_exact_match': 0.05410821643286573, 'span_overlap_f1': 0.10539120836965879}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|| 625/625 [00:13<00:00, 47.97it/s, loss=2.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Loss: 2.0599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:00<00:00, 63.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 14.2404\n",
      "Validation Metrics: {'start_accuracy': 0.09769539078156313, 'start_precision': 0.09853809306529956, 'start_recall': 0.09769539078156313, 'start_f1_score': 0.09356674127455053, 'end_accuracy': 0.11022044088176353, 'end_precision': 0.11981862069081534, 'end_recall': 0.11022044088176353, 'end_f1_score': 0.10880288056714386, 'joint_exact_match': 0.05911823647294589, 'span_overlap_f1': 0.10608735212311239}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|| 625/625 [00:12<00:00, 48.15it/s, loss=2.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Loss: 1.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 14.2522\n",
      "Validation Metrics: {'start_accuracy': 0.10170340681362726, 'start_precision': 0.10757442282625423, 'start_recall': 0.10170340681362726, 'start_f1_score': 0.09962550382382326, 'end_accuracy': 0.10521042084168336, 'end_precision': 0.11855651647929123, 'end_recall': 0.10521042084168336, 'end_f1_score': 0.10600591706968134, 'joint_exact_match': 0.05711422845691383, 'span_overlap_f1': 0.1054559365849322}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|| 625/625 [00:13<00:00, 47.49it/s, loss=2.06] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Loss: 1.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 59.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 14.8410\n",
      "Validation Metrics: {'start_accuracy': 0.093687374749499, 'start_precision': 0.1049729775933591, 'start_recall': 0.093687374749499, 'start_f1_score': 0.09281381586791908, 'end_accuracy': 0.10270541082164329, 'end_precision': 0.10605293946000767, 'end_recall': 0.10270541082164329, 'end_f1_score': 0.1009739320056804, 'joint_exact_match': 0.05060120240480962, 'span_overlap_f1': 0.10134332070533908}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|| 625/625 [00:13<00:00, 48.03it/s, loss=1.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Loss: 1.7809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 60.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 14.9443\n",
      "Validation Metrics: {'start_accuracy': 0.1092184368737475, 'start_precision': 0.11533200842353628, 'start_recall': 0.1092184368737475, 'start_f1_score': 0.10615001447660057, 'end_accuracy': 0.10971943887775551, 'end_precision': 0.1201493930327751, 'end_recall': 0.10971943887775551, 'end_f1_score': 0.10760751681915863, 'joint_exact_match': 0.06663326653306613, 'span_overlap_f1': 0.1115621360112143}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|| 625/625 [00:13<00:00, 46.85it/s, loss=1.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Loss: 1.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 55.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 15.1326\n",
      "Validation Metrics: {'start_accuracy': 0.1062124248496994, 'start_precision': 0.11176811727112901, 'start_recall': 0.1062124248496994, 'start_f1_score': 0.10417281166792777, 'end_accuracy': 0.10871743486973948, 'end_precision': 0.116417977573441, 'end_recall': 0.10871743486973948, 'end_f1_score': 0.1069674351598202, 'joint_exact_match': 0.06362725450901803, 'span_overlap_f1': 0.11537715499149132}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|| 625/625 [00:13<00:00, 45.01it/s, loss=2.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Loss: 1.6290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 60.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 14.6982\n",
      "Validation Metrics: {'start_accuracy': 0.09569138276553106, 'start_precision': 0.107134529778978, 'start_recall': 0.09569138276553106, 'start_f1_score': 0.09731979573724737, 'end_accuracy': 0.11072144288577154, 'end_precision': 0.12399724971204076, 'end_recall': 0.11072144288577154, 'end_f1_score': 0.11170142377241174, 'joint_exact_match': 0.06062124248496994, 'span_overlap_f1': 0.11036002936895205}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|| 625/625 [00:13<00:00, 45.85it/s, loss=1.52] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Loss: 1.5895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:00<00:00, 64.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 14.9373\n",
      "Validation Metrics: {'start_accuracy': 0.10170340681362726, 'start_precision': 0.10648920893933525, 'start_recall': 0.10170340681362726, 'start_f1_score': 0.09938015156426384, 'end_accuracy': 0.10771543086172344, 'end_precision': 0.11095689753558564, 'end_recall': 0.10771543086172344, 'end_f1_score': 0.10406023408008266, 'joint_exact_match': 0.05911823647294589, 'span_overlap_f1': 0.10942382370781968}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|| 625/625 [00:13<00:00, 45.38it/s, loss=1.04] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Loss: 1.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 15.8202\n",
      "Validation Metrics: {'start_accuracy': 0.10070140280561123, 'start_precision': 0.1092138863268157, 'start_recall': 0.10070140280561123, 'start_f1_score': 0.09939098400300199, 'end_accuracy': 0.11322645290581163, 'end_precision': 0.1166366597309901, 'end_recall': 0.11322645290581163, 'end_f1_score': 0.11011637785535155, 'joint_exact_match': 0.061122244488977955, 'span_overlap_f1': 0.1110151297206692}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|| 625/625 [00:14<00:00, 43.99it/s, loss=1.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Loss: 1.4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 51.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 15.2542\n",
      "Validation Metrics: {'start_accuracy': 0.09869739478957916, 'start_precision': 0.10584369200208682, 'start_recall': 0.09869739478957916, 'start_f1_score': 0.09850001155287613, 'end_accuracy': 0.1187374749498998, 'end_precision': 0.12460139139176549, 'end_recall': 0.1187374749498998, 'end_f1_score': 0.11756974461965458, 'joint_exact_match': 0.06212424849699399, 'span_overlap_f1': 0.1108451590227068}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|| 625/625 [00:13<00:00, 45.52it/s, loss=2.1]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Loss: 1.3590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 56.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 16.0508\n",
      "Validation Metrics: {'start_accuracy': 0.09769539078156313, 'start_precision': 0.10686286136736185, 'start_recall': 0.09769539078156313, 'start_f1_score': 0.09754899491028986, 'end_accuracy': 0.10571142284569138, 'end_precision': 0.12393538219638509, 'end_recall': 0.10571142284569138, 'end_f1_score': 0.10714977631089215, 'joint_exact_match': 0.05861723446893788, 'span_overlap_f1': 0.10819209829233402}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|| 625/625 [00:13<00:00, 45.21it/s, loss=0.975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Loss: 1.3096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 15.9766\n",
      "Validation Metrics: {'start_accuracy': 0.09969939879759519, 'start_precision': 0.11199375346912897, 'start_recall': 0.09969939879759519, 'start_f1_score': 0.09911672571460683, 'end_accuracy': 0.11022044088176353, 'end_precision': 0.125171486493265, 'end_recall': 0.11022044088176353, 'end_f1_score': 0.1116291639887294, 'joint_exact_match': 0.05711422845691383, 'span_overlap_f1': 0.1132821645456342}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|| 625/625 [00:13<00:00, 45.33it/s, loss=1.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Loss: 1.2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 57.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 15.4987\n",
      "Validation Metrics: {'start_accuracy': 0.10320641282565131, 'start_precision': 0.10981939033133366, 'start_recall': 0.10320641282565131, 'start_f1_score': 0.10214083625065686, 'end_accuracy': 0.11072144288577154, 'end_precision': 0.12190302248680042, 'end_recall': 0.11072144288577154, 'end_f1_score': 0.11173170661569473, 'joint_exact_match': 0.06062124248496994, 'span_overlap_f1': 0.11056553110810889}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|| 625/625 [00:13<00:00, 44.80it/s, loss=1.06] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Loss: 1.2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 53.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 16.6681\n",
      "Validation Metrics: {'start_accuracy': 0.10120240480961924, 'start_precision': 0.10685057767497232, 'start_recall': 0.10120240480961924, 'start_f1_score': 0.10038364973889596, 'end_accuracy': 0.1062124248496994, 'end_precision': 0.12333199444459204, 'end_recall': 0.1062124248496994, 'end_f1_score': 0.10876970165370467, 'joint_exact_match': 0.06412825651302605, 'span_overlap_f1': 0.1103977887430107}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|| 625/625 [00:14<00:00, 43.63it/s, loss=1.13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Loss: 1.1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 56.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 16.7655\n",
      "Validation Metrics: {'start_accuracy': 0.09969939879759519, 'start_precision': 0.10589094208895786, 'start_recall': 0.09969939879759519, 'start_f1_score': 0.09822070845847826, 'end_accuracy': 0.11122244488977956, 'end_precision': 0.12021103728391568, 'end_recall': 0.11122244488977956, 'end_f1_score': 0.1101509978807064, 'joint_exact_match': 0.06312625250501001, 'span_overlap_f1': 0.11107206714946315}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|| 625/625 [00:13<00:00, 46.57it/s, loss=0.502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Loss: 1.1257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:00<00:00, 63.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 16.4123\n",
      "Validation Metrics: {'start_accuracy': 0.09919839679358718, 'start_precision': 0.10771661940274146, 'start_recall': 0.09919839679358718, 'start_f1_score': 0.0990322504083811, 'end_accuracy': 0.1062124248496994, 'end_precision': 0.11533362318827003, 'end_recall': 0.1062124248496994, 'end_f1_score': 0.10537368497626211, 'joint_exact_match': 0.059619238476953905, 'span_overlap_f1': 0.10978696558144128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|| 625/625 [00:12<00:00, 48.51it/s, loss=1.86] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Loss: 1.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 55.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 16.6241\n",
      "Validation Metrics: {'start_accuracy': 0.09168336673346693, 'start_precision': 0.10005351953808014, 'start_recall': 0.09168336673346693, 'start_f1_score': 0.09164673492084714, 'end_accuracy': 0.10671342685370741, 'end_precision': 0.11962510557821222, 'end_recall': 0.10671342685370741, 'end_f1_score': 0.10718957618128862, 'joint_exact_match': 0.05410821643286573, 'span_overlap_f1': 0.10753354516243421}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|| 625/625 [00:12<00:00, 48.77it/s, loss=1.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Loss: 1.0405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 16.4385\n",
      "Validation Metrics: {'start_accuracy': 0.09919839679358718, 'start_precision': 0.1108022071392918, 'start_recall': 0.09919839679358718, 'start_f1_score': 0.0992754502321566, 'end_accuracy': 0.11172344689378758, 'end_precision': 0.1294220138949885, 'end_recall': 0.11172344689378758, 'end_f1_score': 0.11473446499941733, 'joint_exact_match': 0.05811623246492986, 'span_overlap_f1': 0.1107472252525685}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|| 625/625 [00:12<00:00, 48.50it/s, loss=1.38] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Loss: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 16.9093\n",
      "Validation Metrics: {'start_accuracy': 0.09769539078156313, 'start_precision': 0.10761312050804955, 'start_recall': 0.09769539078156313, 'start_f1_score': 0.09788576654876076, 'end_accuracy': 0.10671342685370741, 'end_precision': 0.11743720803115884, 'end_recall': 0.10671342685370741, 'end_f1_score': 0.10658558349252166, 'joint_exact_match': 0.05861723446893788, 'span_overlap_f1': 0.10974454650255197}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|| 625/625 [00:13<00:00, 47.28it/s, loss=1.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Loss: 0.9770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 62.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 17.7613\n",
      "Validation Metrics: {'start_accuracy': 0.09619238476953908, 'start_precision': 0.11237808089073831, 'start_recall': 0.09619238476953908, 'start_f1_score': 0.09696781224460507, 'end_accuracy': 0.09969939879759519, 'end_precision': 0.11921101780321978, 'end_recall': 0.09969939879759519, 'end_f1_score': 0.10138373741776605, 'joint_exact_match': 0.0531062124248497, 'span_overlap_f1': 0.10048689240635261}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "\n",
    "# Initialize the model\n",
    "model = RNN_QA_Model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=256,\n",
    "    hidden_dim=256,\n",
    "    num_layers=3,\n",
    "    dropout=0.5,\n",
    "    pad_idx=1\n",
    ")\n",
    "\n",
    "#  loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#  optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "# Training the model\n",
    "train_qa_context_model(\n",
    "    model=model, \n",
    "    train_dataloader=train_dataloader, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    num_epochs=50,\n",
    "    device='cuda', \n",
    "    val_dataloader=dev_dataloader, \n",
    "    evaluate_val_dataset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_path = \"models/qa_context_model_50_epochs.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/qa_context_model_50_epochs.pkl\n"
     ]
    }
   ],
   "source": [
    "save_model(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\001\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Evaluating: 100%|| 625/625 [00:13<00:00, 46.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7426\n",
      "Validation Metrics: {'start_accuracy': 0.8548491972190266, 'start_precision': 0.8557190291565817, 'start_recall': 0.8548491972190266, 'start_f1_score': 0.8546518976122449, 'end_accuracy': 0.8546991447006452, 'end_precision': 0.855531368214943, 'end_recall': 0.8546991447006452, 'end_f1_score': 0.8546104879522957, 'joint_exact_match': 0.8216875906567298, 'span_overlap_f1': 0.8409046768683703}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.742624153137207,\n",
       " {'start_accuracy': 0.8548491972190266,\n",
       "  'start_precision': 0.8557190291565817,\n",
       "  'start_recall': 0.8548491972190266,\n",
       "  'start_f1_score': 0.8546518976122449,\n",
       "  'end_accuracy': 0.8546991447006452,\n",
       "  'end_precision': 0.855531368214943,\n",
       "  'end_recall': 0.8546991447006452,\n",
       "  'end_f1_score': 0.8546104879522957,\n",
       "  'joint_exact_match': 0.8216875906567298,\n",
       "  'span_overlap_f1': 0.8409046768683703})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model on the dev set\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "evaluate_qa_context_model(model=model, dataloader=train_dataloader, criterion=criterion, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]c:\\Users\\001\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Evaluating: 100%|| 63/63 [00:01<00:00, 44.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 17.7613\n",
      "Validation Metrics: {'start_accuracy': 0.09619238476953908, 'start_precision': 0.11237808089073831, 'start_recall': 0.09619238476953908, 'start_f1_score': 0.09696781224460507, 'end_accuracy': 0.09969939879759519, 'end_precision': 0.11921101780321978, 'end_recall': 0.09969939879759519, 'end_f1_score': 0.10138373741776605, 'joint_exact_match': 0.0531062124248497, 'span_overlap_f1': 0.10048689240635261}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17.761287598382857,\n",
       " {'start_accuracy': 0.09619238476953908,\n",
       "  'start_precision': 0.11237808089073831,\n",
       "  'start_recall': 0.09619238476953908,\n",
       "  'start_f1_score': 0.09696781224460507,\n",
       "  'end_accuracy': 0.09969939879759519,\n",
       "  'end_precision': 0.11921101780321978,\n",
       "  'end_recall': 0.09969939879759519,\n",
       "  'end_f1_score': 0.10138373741776605,\n",
       "  'joint_exact_match': 0.0531062124248497,\n",
       "  'span_overlap_f1': 0.10048689240635261})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model on the dev set\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "evaluate_qa_context_model(model=model, dataloader=dev_dataloader, criterion=criterion, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/63 [00:00<?, ?it/s]c:\\Users\\001\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Predicting: 100%|| 63/63 [00:01<00:00, 41.56it/s]\n"
     ]
    }
   ],
   "source": [
    "preds, true_labels = predict_qa_context_model(model=model, dataloader=dev_dataloader, tokenizer=tokenizer, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer: high school level\n",
      "True Answer: rugby\n",
      "--------------------------------------------------\n",
      "Predicted Answer: high school level\n",
      "True Answer: an official school sport\n",
      "--------------------------------------------------\n",
      "Predicted Answer: high school level\n",
      "True Answer: high school\n",
      "--------------------------------------------------\n",
      "Predicted Answer: complexity\n",
      "True Answer: framework\n",
      "--------------------------------------------------\n",
      "Predicted Answer: complexity\n",
      "True Answer: complexity classes\n",
      "--------------------------------------------------\n",
      "Predicted Answer: complexity\n",
      "True Answer: complicated definitions\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: palm springs\n",
      "--------------------------------------------------\n",
      "Predicted Answer: popular beaches\n",
      "True Answer: southern\n",
      "--------------------------------------------------\n",
      "Predicted Answer: popular beaches\n",
      "True Answer: open spaces\n",
      "--------------------------------------------------\n",
      "Predicted Answer: popular beaches\n",
      "True Answer: beaches\n",
      "--------------------------------------------------\n",
      "Predicted Answer: orange\n",
      "True Answer: united states\n",
      "--------------------------------------------------\n",
      "Predicted Answer: orange\n",
      "True Answer: counties\n",
      "--------------------------------------------------\n",
      "Predicted Answer: orange , san diego , san bernardino\n",
      "True Answer: counties\n",
      "--------------------------------------------------\n",
      "Predicted Answer: orange\n",
      "True Answer: 15\n",
      "--------------------------------------------------\n",
      "Predicted Answer: orange\n",
      "True Answer: los angeles\n",
      "--------------------------------------------------\n",
      "Predicted Answer: colorado\n",
      "True Answer: mexico  united states border\n",
      "--------------------------------------------------\n",
      "Predicted Answer: colorado\n",
      "True Answer: colorado desert\n",
      "--------------------------------------------------\n",
      "Predicted Answer: colorado desert and the colorado river\n",
      "True Answer: mojave desert\n",
      "--------------------------------------------------\n",
      "Predicted Answer: colorado desert and the colorado river at the border with arizona , and the mojave desert at the border with the state of nevada\n",
      "True Answer: colorado river\n",
      "--------------------------------------------------\n",
      "Predicted Answer: important complexity\n",
      "True Answer: bounding\n",
      "--------------------------------------------------\n",
      "Predicted Answer: complexity\n",
      "True Answer: complexity classes\n",
      "--------------------------------------------------\n",
      "Predicted Answer: algorithm\n",
      "True Answer: time or space\n",
      "--------------------------------------------------\n",
      "Predicted Answer: san bernardino and downtown riverside .\n",
      "True Answer: business\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: riverside\n",
      "--------------------------------------------------\n",
      "Predicted Answer: san bernardino\n",
      "True Answer: hospitality business / financial centre\n",
      "--------------------------------------------------\n",
      "Predicted Answer: college sports\n",
      "True Answer: ucla\n",
      "--------------------------------------------------\n",
      "Predicted Answer: college sports are also popular in southern california . the ucla bruins\n",
      "True Answer: trojans\n",
      "--------------------------------------------------\n",
      "Predicted Answer: college sports\n",
      "True Answer: division i\n",
      "--------------------------------------------------\n",
      "Predicted Answer: college sports are also popular in southern california . the ucla bruins\n",
      "True Answer: college\n",
      "--------------------------------------------------\n",
      "Predicted Answer: pac - 12 conference\n",
      "True Answer: pac - 12\n",
      "--------------------------------------------------\n",
      "Predicted Answer: los angeles\n",
      "True Answer: port of los angeles\n",
      "--------------------------------------------------\n",
      "Predicted Answer: los angeles\n",
      "True Answer: southern\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the adjacent port of long beach\n",
      "True Answer: port of san diego\n",
      "--------------------------------------------------\n",
      "Predicted Answer: bethencourt\n",
      "True Answer: maciot de bethencourt\n",
      "--------------------------------------------------\n",
      "Predicted Answer: king of the canary islands\n",
      "True Answer: enrique prez de guzmn\n",
      "--------------------------------------------------\n",
      "Predicted Answer: bethencourt\n",
      "True Answer: bethencourt\n",
      "--------------------------------------------------\n",
      "Predicted Answer: central business districts ( cbd\n",
      "True Answer: central business districts\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: business\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: south coast metro\n",
      "--------------------------------------------------\n",
      "Predicted Answer: san bernardino\n",
      "True Answer: los angeles times\n",
      "--------------------------------------------------\n",
      "Predicted Answer: san bernardino\n",
      "True Answer: imperial\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1900\n",
      "True Answer: 1900\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1900\n",
      "True Answer: 1999\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1999\n",
      "True Answer: seven\n",
      "--------------------------------------------------\n",
      "Predicted Answer: expansive\n",
      "True Answer: mexican\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 8\n",
      "True Answer: 11\n",
      "--------------------------------------------------\n",
      "Predicted Answer: expansive\n",
      "True Answer: nevada\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: tijuana\n",
      "--------------------------------------------------\n",
      "Predicted Answer: expansive\n",
      "True Answer: southern california megaregion\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: metrolink\n",
      "--------------------------------------------------\n",
      "Predicted Answer: seven\n",
      "True Answer: six\n",
      "--------------------------------------------------\n",
      "Predicted Answer: seven\n",
      "True Answer: seven\n",
      "--------------------------------------------------\n",
      "Predicted Answer: directly .\n",
      "True Answer: orange\n",
      "--------------------------------------------------\n",
      "Predicted Answer: nl and nc\n",
      "True Answer: nl and nc\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the time and space hierarchy theorems\n",
      "True Answer: time and space hierarchy theorems\n",
      "--------------------------------------------------\n",
      "Predicted Answer: nl and nc\n",
      "True Answer: l\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: exptime\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: pspace\n",
      "--------------------------------------------------\n",
      "Predicted Answer: nl and nc\n",
      "True Answer: strictly contained in p or equal to p\n",
      "--------------------------------------------------\n",
      "Predicted Answer: nl and nc\n",
      "True Answer: complexity classes\n",
      "--------------------------------------------------\n",
      "Predicted Answer: nl and nc\n",
      "True Answer: if they are distinct or equal classes\n",
      "--------------------------------------------------\n",
      "Predicted Answer: inputs of the same size\n",
      "True Answer: time\n",
      "--------------------------------------------------\n",
      "Predicted Answer: complexity ( or any other complexity measure ) of different inputs of the same size\n",
      "True Answer: best , worst and average\n",
      "--------------------------------------------------\n",
      "Predicted Answer: inputs of the same size . since some inputs of size n\n",
      "True Answer: complexity measure\n",
      "--------------------------------------------------\n",
      "Predicted Answer: inputs of the same size\n",
      "True Answer: inputs\n",
      "--------------------------------------------------\n",
      "Predicted Answer:  the la galaxy\n",
      "True Answer: chivas usa\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 2005 to 2014\n",
      "True Answer: two\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 2018\n",
      "True Answer: 2018\n",
      "--------------------------------------------------\n",
      "Predicted Answer:  the la galaxy\n",
      "True Answer: stubhub center\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 2005 to 2014\n",
      "True Answer: 2014\n",
      "--------------------------------------------------\n",
      "Predicted Answer: upper and lower bounds are usually stated using the big o notation , which hides constant factors and smaller terms\n",
      "True Answer: constant factors and smaller terms\n",
      "--------------------------------------------------\n",
      "Predicted Answer: upper and lower bounds are usually stated using the big o notation\n",
      "True Answer: t ( n ) = o ( n2 )\n",
      "--------------------------------------------------\n",
      "Predicted Answer: = 7n2 + 15n + 40 , in big o notation one would write t ( n ) = o ( n2 ).\n",
      "True Answer: big o notation\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: the computational model\n",
      "--------------------------------------------------\n",
      "Predicted Answer: high byzantine officials\n",
      "True Answer: the adriatic\n",
      "--------------------------------------------------\n",
      "Predicted Answer: norman army invaded dyrrachium\n",
      "True Answer: dyrrachium\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1185\n",
      "True Answer: 1185\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the nfl\n",
      "True Answer: mlb\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: nba\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ( los angeles kings , anaheim ducks ); and mls ( la galaxy ).\n",
      "True Answer: la galaxy\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: nfl\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: los angeles kings\n",
      "--------------------------------------------------\n",
      "Predicted Answer: yes or no\n",
      "True Answer: a computational problem\n",
      "--------------------------------------------------\n",
      "Predicted Answer: chapter in the history of the island\n",
      "True Answer: 380 years\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: a single output\n",
      "--------------------------------------------------\n",
      "Predicted Answer: yes or no\n",
      "True Answer: a function problem\n",
      "--------------------------------------------------\n",
      "Predicted Answer: integer factorization problem\n",
      "True Answer: complex\n",
      "--------------------------------------------------\n",
      "Predicted Answer: yes or no\n",
      "True Answer: the integer factorization problem\n",
      "--------------------------------------------------\n",
      "Predicted Answer: aforementioned ralph\n",
      "True Answer: edward the confessor\n",
      "--------------------------------------------------\n",
      "Predicted Answer: normans\n",
      "True Answer: hereford\n",
      "--------------------------------------------------\n",
      "Predicted Answer: aforementioned ralph\n",
      "True Answer: the welsh\n",
      "--------------------------------------------------\n",
      "Predicted Answer: odo , the bishop of bayeux and first earl of kent , employing natives from kent\n",
      "True Answer: odo\n",
      "--------------------------------------------------\n",
      "Predicted Answer: kent\n",
      "True Answer: bayeux tapestry\n",
      "--------------------------------------------------\n",
      "Predicted Answer: two complexity\n",
      "True Answer: reversed\n",
      "--------------------------------------------------\n",
      "Predicted Answer: np problems\n",
      "True Answer: co - np\n",
      "--------------------------------------------------\n",
      "Predicted Answer: odo\n",
      "True Answer: embroidery\n",
      "--------------------------------------------------\n",
      "Predicted Answer: not yet been proven\n",
      "True Answer: not equal\n",
      "--------------------------------------------------\n",
      "Predicted Answer: concrete\n",
      "True Answer: input encoding\n",
      "--------------------------------------------------\n",
      "Predicted Answer: two complexity\n",
      "True Answer: p is not equal to np\n",
      "--------------------------------------------------\n",
      "Predicted Answer: abstract enough to be independent of the choice of encoding\n",
      "True Answer: encoding\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compare the predictions with the actual answers\n",
    "for i in range(100):\n",
    "    print(f\"Predicted Answer: {preds[i]}\")\n",
    "    print(f\"True Answer: {true_labels[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\001\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Predicting: 100%|| 625/625 [00:15<00:00, 41.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_preds, train_true_labels = predict_qa_context_model(model=model, dataloader=train_dataloader, tokenizer=tokenizer, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer: united church of christ  congregational in the marshall islands\n",
      "True Answer: united church of christ  congregational in the marshall islands\n",
      "--------------------------------------------------\n",
      "Predicted Answer: threat of arrest\n",
      "True Answer: many families\n",
      "--------------------------------------------------\n",
      "Predicted Answer: lenox avenue\n",
      "True Answer: lenox avenue\n",
      "--------------------------------------------------\n",
      "Predicted Answer: united airlines\n",
      "True Answer: united airlines\n",
      "--------------------------------------------------\n",
      "Predicted Answer: william mcgregor\n",
      "True Answer: william mcgregor\n",
      "--------------------------------------------------\n",
      "Predicted Answer: constitutional ban against aid to religious schools\n",
      "True Answer: constitutional ban against aid to religious schools\n",
      "--------------------------------------------------\n",
      "Predicted Answer: mahmood had lied at a pre - trial hearing and tried to manipulate evidence against the co - defendant tulisa\n",
      "True Answer: mahmood had lied at a pre - trial hearing and tried to manipulate evidence against the co\n",
      "--------------------------------------------------\n",
      "Predicted Answer: christ\n",
      "True Answer: christ\n",
      "--------------------------------------------------\n",
      "Predicted Answer: complicate\n",
      "True Answer: complicate\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 100  f ( 37 . 8  c )\n",
      "True Answer: 15 inches\n",
      "--------------------------------------------------\n",
      "Predicted Answer: all of its ports of entry in the north were closed\n",
      "True Answer: all of its ports of entry in the north were closed\n",
      "--------------------------------------------------\n",
      "Predicted Answer: over 100 , 000\n",
      "True Answer: over 100 , 000\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1800\n",
      "True Answer: 1800\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \" rose\n",
      "True Answer: rose\n",
      "--------------------------------------------------\n",
      "Predicted Answer: could be expelled\n",
      "True Answer: could be expelled\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the nature of dukkha\n",
      "True Answer: dukkha\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1 march\n",
      "True Answer: 1 march\n",
      "--------------------------------------------------\n",
      "Predicted Answer: those that are more exclusively evangelical\n",
      "True Answer: mainstream liberal churches\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \" bardo\n",
      "True Answer: bardo\n",
      "--------------------------------------------------\n",
      "Predicted Answer: idol gives back\n",
      "True Answer: idol gives back\n",
      "--------------------------------------------------\n",
      "Predicted Answer: reapportionment following the 2010 united states census gave the state two more seats in the house of representatives\n",
      "True Answer: reapportionment following the 2010 united states census gave the state two more seats in the house of representatives\n",
      "--------------------------------------------------\n",
      "Predicted Answer: asia\n",
      "True Answer: asia\n",
      "--------------------------------------------------\n",
      "Predicted Answer: many professional sports teams\n",
      "True Answer: many professional sports teams\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the 1970s\n",
      "True Answer: the 1970s\n",
      "--------------------------------------------------\n",
      "Predicted Answer: circulating\n",
      "True Answer: circulating\n",
      "--------------------------------------------------\n",
      "Predicted Answer: nutrients\n",
      "True Answer: nutrients\n",
      "--------------------------------------------------\n",
      "Predicted Answer: aeromedical evacuation is \" the movement of patients under medical supervision to and between medical treatment facilities by air transportation \" ( jp 1 - 02 ). jp 4 - 02 , health service support\n",
      "True Answer: aeromedical evacuation\n",
      "--------------------------------------------------\n",
      "Predicted Answer: executive vice - president\n",
      "True Answer: executive vice - president\n",
      "--------------------------------------------------\n",
      "Predicted Answer: replaceable hoods with asa scales were available from the manufacturer . the company continued to publish recommended film values after that date , however , they were now aligned to the asa scale\n",
      "True Answer: they were now aligned to the asa scale\n",
      "--------------------------------------------------\n",
      "Predicted Answer: center for left - wing politics\n",
      "True Answer: center for left - wing politics\n",
      "--------------------------------------------------\n",
      "Predicted Answer: pennsylvania german\n",
      "True Answer: pennsylvania german\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 33 , 000 megawatts\n",
      "True Answer: 33 , 000 megawatts\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: six\n",
      "--------------------------------------------------\n",
      "Predicted Answer: intelligence at 8\n",
      "True Answer: intelligence at 8\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 35 . 6\n",
      "True Answer: 35 . 6\n",
      "--------------------------------------------------\n",
      "Predicted Answer: into battalions\n",
      "True Answer: light gun or shorad\n",
      "--------------------------------------------------\n",
      "Predicted Answer: nine\n",
      "True Answer: 1840\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: member state\n",
      "--------------------------------------------------\n",
      "Predicted Answer: voices\n",
      "True Answer: the brain\n",
      "--------------------------------------------------\n",
      "Predicted Answer: drought or pests\n",
      "True Answer: drought or pests\n",
      "--------------------------------------------------\n",
      "Predicted Answer: fragile\n",
      "True Answer: fragile\n",
      "--------------------------------------------------\n",
      "Predicted Answer: arenabowl xxii\n",
      "True Answer: arenabowl xxii\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \" indygenat\n",
      "True Answer: indygenat\n",
      "--------------------------------------------------\n",
      "Predicted Answer: against apple\n",
      "True Answer: against apple\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the code of canons of the eastern churches\n",
      "True Answer: the code of canons of the eastern churches\n",
      "--------------------------------------------------\n",
      "Predicted Answer: pieces of bone and turtle shell\n",
      "True Answer: pieces of bone and turtle shell\n",
      "--------------------------------------------------\n",
      "Predicted Answer: protocol\n",
      "True Answer: the kyoto protocol\n",
      "--------------------------------------------------\n",
      "Predicted Answer: salicetti\n",
      "True Answer: salicetti\n",
      "--------------------------------------------------\n",
      "Predicted Answer: arpajhnas , the highest object of meditation\n",
      "True Answer: arpajhnas\n",
      "--------------------------------------------------\n",
      "Predicted Answer: sparta\n",
      "True Answer: sparta\n",
      "--------------------------------------------------\n",
      "Predicted Answer: romantic era\n",
      "True Answer: romantic era\n",
      "--------------------------------------------------\n",
      "Predicted Answer: bsc young boys\n",
      "True Answer: bsc young boys\n",
      "--------------------------------------------------\n",
      "Predicted Answer: rights of commoners\n",
      "True Answer: requirement that military forces and new taxes be approved by provincial sejms\n",
      "--------------------------------------------------\n",
      "Predicted Answer: jena irene\n",
      "True Answer: jena irene\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 2011\n",
      "True Answer: 2011\n",
      "--------------------------------------------------\n",
      "Predicted Answer: spring 2016\n",
      "True Answer: spring 2016\n",
      "--------------------------------------------------\n",
      "Predicted Answer: euler angles\n",
      "True Answer: euler angles\n",
      "--------------------------------------------------\n",
      "Predicted Answer: $ 3 . 5 million\n",
      "True Answer: $ 3 . 5 million\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 270\n",
      "True Answer: 500\n",
      "--------------------------------------------------\n",
      "Predicted Answer: greek and latin\n",
      "True Answer: greek and latin\n",
      "--------------------------------------------------\n",
      "Predicted Answer: season five\n",
      "True Answer: season five\n",
      "--------------------------------------------------\n",
      "Predicted Answer: cjoc\n",
      "True Answer: the canadian special operations forces command\n",
      "--------------------------------------------------\n",
      "Predicted Answer: eastern fennoscandia\n",
      "True Answer: eastern fennoscandia\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 2001\n",
      "True Answer: 2001\n",
      "--------------------------------------------------\n",
      "Predicted Answer: management\n",
      "True Answer: management\n",
      "--------------------------------------------------\n",
      "Predicted Answer: unsystematic .\n",
      "True Answer: unsystematic .\n",
      "--------------------------------------------------\n",
      "Predicted Answer: pharonic , roman , greek , islamic\n",
      "True Answer: pharonic , roman , greek , islamic\n",
      "--------------------------------------------------\n",
      "Predicted Answer: religious clauses in the state constitutions\n",
      "True Answer: religious clauses in the state constitutions\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ( 0 . 7204 %\n",
      "True Answer: 0 . 7204 %\n",
      "--------------------------------------------------\n",
      "Predicted Answer: early triassic\n",
      "True Answer: early triassic\n",
      "--------------------------------------------------\n",
      "Predicted Answer: global economic growth\n",
      "True Answer: global economic growth\n",
      "--------------------------------------------------\n",
      "Predicted Answer: africa and the pacific\n",
      "True Answer: africa and the pacific\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1840\n",
      "True Answer: 1840\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ann\n",
      "True Answer: ann\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \" old parthian\n",
      "True Answer: old parthian\n",
      "--------------------------------------------------\n",
      "Predicted Answer: general council of the pyrnes - orientales\n",
      "True Answer: general council of the pyrnes - orientales\n",
      "--------------------------------------------------\n",
      "Predicted Answer: mundhum\n",
      "True Answer: animistic\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 56 . 1\n",
      "True Answer: 120\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the near or far east of a field , village or shire .\n",
      "True Answer: the near or far east of a field , village or shire .\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1498\n",
      "True Answer: 1498\n",
      "--------------------------------------------------\n",
      "Predicted Answer: resignation of the prime minister and his or her government\n",
      "True Answer: resignation of the prime minister and his or her government\n",
      "--------------------------------------------------\n",
      "Predicted Answer: western union\n",
      "True Answer: western union\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ( 11\n",
      "True Answer: 11\n",
      "--------------------------------------------------\n",
      "Predicted Answer: japan , europe , and australia\n",
      "True Answer: japan , europe , and australia\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1 , 300\n",
      "True Answer: 1 . 94 million\n",
      "--------------------------------------------------\n",
      "Predicted Answer: north africa\n",
      "True Answer: north africa\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 500 users\n",
      "True Answer: 500 users\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1 , 185\n",
      "True Answer: 1 , 185\n",
      "--------------------------------------------------\n",
      "Predicted Answer: microsequencer\n",
      "True Answer: microsequencer\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the international association for the study of pain\n",
      "True Answer: the international association for the study of pain\n",
      "--------------------------------------------------\n",
      "Predicted Answer: two\n",
      "True Answer: two\n",
      "--------------------------------------------------\n",
      "Predicted Answer: franklin school\n",
      "True Answer: franklin school\n",
      "--------------------------------------------------\n",
      "Predicted Answer: raymond plant\n",
      "True Answer: raymond plant\n",
      "--------------------------------------------------\n",
      "Predicted Answer: liberal democrats\n",
      "True Answer: liberal democrats\n",
      "--------------------------------------------------\n",
      "Predicted Answer: shell oil company\n",
      "True Answer: shell oil company\n",
      "--------------------------------------------------\n",
      "Predicted Answer: historical buildings\n",
      "True Answer: historical buildings\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 18 . 7\n",
      "True Answer: 18 . 7\n",
      "--------------------------------------------------\n",
      "Predicted Answer: dukkha can be known\n",
      "True Answer: dukkha can be known .\n",
      "--------------------------------------------------\n",
      "Predicted Answer: mostly by walking\n",
      "True Answer: mostly by walking\n",
      "--------------------------------------------------\n",
      "Predicted Answer: that china formally requested the support of the international community\n",
      "True Answer: unicef\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compare the predictions with the actual answers\n",
    "for i in range(100):\n",
    "    print(f\"Predicted Answer: {train_preds[i]}\")\n",
    "    print(f\"True Answer: {train_true_labels[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question [SEP] Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 19993 out of original 20000\n",
      "Filtered dataset size: 1996 out of original 2000\n",
      "Number of training samples: 19993\n",
      "Number of dev samples: 1996\n",
      "Sample from the dataset:\n",
      "Question encoded: tensor([   3, 2087, 2778, 2180, 4779, 4400, 1989, 5835, 2580, 3314, 2021, 4097,\n",
      "        1390,    4,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1])\n",
      "Question decoded:  what does not allow windows to pop up without consent ?\n",
      "Answer encoded: tensor([   3, 5835, 1330, 2580, 5570, 4049,    4,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1])\n",
      "Answer decoded:  pop - up blockers\n",
      "Context encoded: tensor([   3, 2125, 2683, 7168, 8298,   61, 2058, 4779, 1966, 6672, 1989, 4092,\n",
      "        5364, 3979, 6001, 1996, 1966, 2890, 2339, 1283, 3861, 1979, 2962, 8298,\n",
      "          61, 1983, 4400, 2003, 1979, 2962, 6427, 1266, 1974, 1966, 2890, 3704,\n",
      "        2216, 1321, 2683, 8298,   61, 2058, 2183, 2869, 5835, 1330, 2580, 5570,\n",
      "        4049, 1989, 5642, 2014, 6366, 4400, 2075, 1314, 2297, 3613, 2580, 1314,\n",
      "        3314, 1966, 6672, 1359, 1266, 2021, 4097, 1321,    4,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1])\n",
      "Context decoded:  all major web browsers allow the user to open multiple information resources at the same time , either in different browser windows or in different tabs of the same window . major browsers also include pop - up blockers to prevent unwanted windows from \" popping up \" without the user ' s consent .\n",
      "Context Question encoded: tensor([   3, 2087, 2778, 2180, 4779, 4400, 1989, 5835, 2580, 3314, 2021, 4097,\n",
      "        1390,    5, 2125, 2683, 7168, 8298,   61, 2058, 4779, 1966, 6672, 1989,\n",
      "        4092, 5364, 3979, 6001, 1996, 1966, 2890, 2339, 1283, 3861, 1979, 2962,\n",
      "        8298,   61, 1983, 4400, 2003, 1979, 2962, 6427, 1266, 1974, 1966, 2890,\n",
      "        3704, 2216, 1321, 2683, 8298,   61, 2058, 2183, 2869, 5835, 1330, 2580,\n",
      "        5570, 4049, 1989, 5642, 2014, 6366, 4400, 2075, 1314, 2297, 3613, 2580,\n",
      "        1314, 3314, 1966, 6672, 1359, 1266, 2021, 4097, 1321,    4,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1])\n",
      "Context Question decoded:  what does not allow windows to pop up without consent ? all major web browsers allow the user to open multiple information resources at the same time , either in different browser windows or in different tabs of the same window . major browsers also include pop - up blockers to prevent unwanted windows from \" popping up \" without the user ' s consent .\n",
      "Answer Start: tensor(44)\n",
      "Answer End: tensor(48)\n",
      "Answer Start: End decoded: pop - up blockers\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Sample from the dev dataset:\n",
      "Context encoded: tensor([   3, 9600, 2361, 2114, 3880, 1989, 4554, 1979, 1267, 2621, 1974, 3455,\n",
      "        1407, 1966, 8430, 2510, 2361, 3225, 3560, 2229, 4105, 2003, 7682, 2906,\n",
      "        1989, 6285, 4105, 1990, 1267, 5539, 1407, 1267, 5150, 1974, 1966, 4554,\n",
      "        2361, 3715, 1267, 5539, 1979, 2132, 1974, 1966, 3063, 2521, 2129, 1975,\n",
      "        7198, 1407, 1267, 4003, 1974, 1966, 8430, 4554, 2361, 3225, 3560, 1267,\n",
      "        5539, 1990, 1267, 3821, 4003, 1407, 2003, 1267, 3821, 5539, 2361, 2114,\n",
      "        2413, 6276, 1989, 4554, 2036, 1994, 4114, 6175, 1983, 1321, 2227, 3326,\n",
      "        2563, 4105, 2069, 2510, 9600, 3880, 2036, 7715, 1979, 1966, 8083, 3121,\n",
      "        1321, 9600, 6317, 2594, 4554, 1979, 1267, 2621, 1974, 8202, 1307,    4,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1])\n",
      "Context decoded:  bills can be introduced to parliament in a number of ways ; the scottish government can introduce new laws or amendments to existing laws as a bill ; a committee of the parliament can present a bill in one of the areas under its remit ; a member of the scottish parliament can introduce a bill as a private member ; or a private bill can be submitted to parliament by an outside proposer . most draft laws are government bills introduced by ministers in the governing party . bills pass through parliament in a number of stages :\n",
      "Question encoded: tensor([   3, 2475, 2557, 9600, 6317, 2594, 4554, 1390,    4,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1])\n",
      "Question decoded:  how do bills pass through parliament ?\n",
      "Answer encoded: tensor([   3, 1979, 1267, 2621, 1974, 8202,    4,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1])\n",
      "Answer decoded:  in a number of stages\n",
      "Context Question encoded: tensor([   3, 2475, 2557, 9600, 6317, 2594, 4554, 1390,    5, 9600, 2361, 2114,\n",
      "        3880, 1989, 4554, 1979, 1267, 2621, 1974, 3455, 1407, 1966, 8430, 2510,\n",
      "        2361, 3225, 3560, 2229, 4105, 2003, 7682, 2906, 1989, 6285, 4105, 1990,\n",
      "        1267, 5539, 1407, 1267, 5150, 1974, 1966, 4554, 2361, 3715, 1267, 5539,\n",
      "        1979, 2132, 1974, 1966, 3063, 2521, 2129, 1975, 7198, 1407, 1267, 4003,\n",
      "        1974, 1966, 8430, 4554, 2361, 3225, 3560, 1267, 5539, 1990, 1267, 3821,\n",
      "        4003, 1407, 2003, 1267, 3821, 5539, 2361, 2114, 2413, 6276, 1989, 4554,\n",
      "        2036, 1994, 4114, 6175, 1983, 1321, 2227, 3326, 2563, 4105, 2069, 2510,\n",
      "        9600, 3880, 2036, 7715, 1979, 1966, 8083, 3121, 1321, 9600, 6317, 2594,\n",
      "        4554, 1979, 1267, 2621, 1974, 8202, 1307,    4,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1])\n",
      "Context Question decoded:  how do bills pass through parliament ? bills can be introduced to parliament in a number of ways ; the scottish government can introduce new laws or amendments to existing laws as a bill ; a committee of the parliament can present a bill in one of the areas under its remit ; a member of the scottish parliament can introduce a bill as a private member ; or a private bill can be submitted to parliament by an outside proposer . most draft laws are government bills introduced by ministers in the governing party . bills pass through parliament in a number of stages :\n",
      "Answer Start: tensor(101)\n",
      "Answer End: tensor(105)\n",
      "Answer Start: End decoded: in a number of stages\n"
     ]
    }
   ],
   "source": [
    "train_dataset_context_question_swapped = QADataset(train_data, tokenizer, context_max_length=context_max_length, question_max_length=question_max_length, answer_max_length=answer_max_length, include_context=True, context_question_swap=True)\n",
    "dev_dataset_context_question_swapped = QADataset(dev_data, tokenizer, context_max_length=context_max_length, question_max_length=question_max_length, answer_max_length=answer_max_length, include_context=True, context_question_swap=True)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_dataset_context_question_swapped))\n",
    "print(\"Number of dev samples:\", len(dev_dataset_context_question_swapped))\n",
    "\n",
    "# View a sample from the dataset\n",
    "random_idx = np.random.randint(0, len(train_dataset_context_question_swapped))\n",
    "print(\"Sample from the dataset:\")\n",
    "print(\"Question encoded:\", train_dataset_context_question_swapped[random_idx][\"question\"])\n",
    "print(\"Question decoded: \", tokenizer.decode(train_dataset_context_question_swapped[random_idx][\"question\"].tolist()))\n",
    "print(\"Answer encoded:\", train_dataset_context_question_swapped[random_idx][\"answer\"])\n",
    "print(\"Answer decoded: \", tokenizer.decode(train_dataset_context_question_swapped[random_idx][\"answer\"].tolist()))\n",
    "print(\"Context encoded:\", train_dataset_context_question_swapped[random_idx][\"context\"])\n",
    "print(\"Context decoded: \", tokenizer.decode(train_dataset_context_question_swapped[random_idx][\"context\"].tolist()))\n",
    "print(\"Context Question encoded:\", train_dataset_context_question_swapped[random_idx][\"context_question\"])\n",
    "print(\"Context Question decoded: \", tokenizer.decode(train_dataset_context_question_swapped[random_idx][\"context_question\"].tolist()))\n",
    "print(\"Answer Start:\", train_dataset_context_question_swapped[random_idx][\"answer_start\"])\n",
    "print(\"Answer End:\", train_dataset_context_question_swapped[random_idx][\"answer_end\"])\n",
    "print(\"Answer Start: End decoded:\", tokenizer.decode(train_dataset_context_question_swapped[random_idx][\"context\"][train_dataset_context_question_swapped[random_idx][\"answer_start\"]:train_dataset_context_question_swapped[random_idx][\"answer_end\"]+1].tolist()))\n",
    "print(\"\\n\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# View a sample from the dev dataset\n",
    "random_idx = np.random.randint(0, len(dev_dataset_context_question_swapped))\n",
    "print(\"Sample from the dev dataset:\")\n",
    "print(\"Context encoded:\", dev_dataset_context_question_swapped[random_idx][\"context\"])\n",
    "print(\"Context decoded: \", tokenizer.decode(dev_dataset_context_question_swapped[random_idx][\"context\"].tolist()))\n",
    "print(\"Question encoded:\", dev_dataset_context_question_swapped[random_idx][\"question\"])\n",
    "print(\"Question decoded: \", tokenizer.decode(dev_dataset_context_question_swapped[random_idx][\"question\"].tolist()))\n",
    "print(\"Answer encoded:\", dev_dataset_context_question_swapped[random_idx][\"answer\"])\n",
    "print(\"Answer decoded: \", tokenizer.decode(dev_dataset_context_question_swapped[random_idx][\"answer\"].tolist()))\n",
    "print(\"Context Question encoded:\", dev_dataset_context_question_swapped[random_idx][\"context_question\"])\n",
    "print(\"Context Question decoded: \", tokenizer.decode(dev_dataset_context_question_swapped[random_idx][\"context_question\"].tolist()))\n",
    "print(\"Answer Start:\", dev_dataset_context_question_swapped[random_idx][\"answer_start\"])\n",
    "print(\"Answer End:\", dev_dataset_context_question_swapped[random_idx][\"answer_end\"])\n",
    "print(\"Answer Start: End decoded:\", tokenizer.decode(dev_dataset_context_question_swapped[random_idx][\"context\"][dev_dataset_context_question_swapped[random_idx][\"answer_start\"]:dev_dataset_context_question_swapped[random_idx][\"answer_end\"]+1].tolist()))\n",
    "\n",
    "\n",
    "# Creating Dataloaders\n",
    "train_dataloader_context_question_swapped = DataLoader(train_dataset_context_question_swapped, batch_size=32, shuffle=True) # add this `num_workers=0` if you want to see print in __getitem__ in dataset class\n",
    "dev_dataloader_context_question_swapped = DataLoader(dev_dataset_context_question_swapped, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|| 625/625 [00:13<00:00, 47.20it/s, loss=9.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 9.2263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:10<00:00, 56.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 9.1506\n",
      "Training Metrics: {'start_accuracy': 0.04411544040414145, 'start_precision': 0.005191159637787621, 'start_recall': 0.04411544040414145, 'start_f1_score': 0.006498772940137371, 'end_accuracy': 0.01590556694843195, 'end_precision': 0.004195837024200039, 'end_recall': 0.01590556694843195, 'end_f1_score': 0.004472926912014007, 'joint_exact_match': 0.007152503376181663, 'span_overlap_f1': 0.06054743805079413}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.6496\n",
      "Validation Metrics: {'start_accuracy': 0.03657314629258517, 'start_precision': 0.002270407882231229, 'start_recall': 0.03657314629258517, 'start_f1_score': 0.004064053992065025, 'end_accuracy': 0.010521042084168337, 'end_precision': 0.0036635761902108245, 'end_recall': 0.010521042084168337, 'end_f1_score': 0.0037936979921538235, 'joint_exact_match': 0.0045090180360721445, 'span_overlap_f1': 0.04830175489154546}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|| 625/625 [00:13<00:00, 47.42it/s, loss=9.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 9.1460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 8.9681\n",
      "Training Metrics: {'start_accuracy': 0.0440654228980143, 'start_precision': 0.02901252883953555, 'start_recall': 0.0440654228980143, 'start_f1_score': 0.019695857844314803, 'end_accuracy': 0.026409243235132298, 'end_precision': 0.023997469149897015, 'end_recall': 0.026409243235132298, 'end_f1_score': 0.01696636954016232, 'joint_exact_match': 0.007352573400690242, 'span_overlap_f1': 0.0713897208155863}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 54.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.6352\n",
      "Validation Metrics: {'start_accuracy': 0.03156312625250501, 'start_precision': 0.008720392600982011, 'start_recall': 0.03156312625250501, 'start_f1_score': 0.010556156436852692, 'end_accuracy': 0.010521042084168337, 'end_precision': 0.010181837606478254, 'end_recall': 0.010521042084168337, 'end_f1_score': 0.007164896343640406, 'joint_exact_match': 0.004008016032064128, 'span_overlap_f1': 0.04727856939051548}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|| 625/625 [00:13<00:00, 45.50it/s, loss=9.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 8.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:12<00:00, 50.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 8.7272\n",
      "Training Metrics: {'start_accuracy': 0.06127144500575201, 'start_precision': 0.04723038154910436, 'start_recall': 0.06127144500575201, 'start_f1_score': 0.036761175623355444, 'end_accuracy': 0.04431551042865003, 'end_precision': 0.03918883087307947, 'end_recall': 0.04431551042865003, 'end_f1_score': 0.03849881109806511, 'joint_exact_match': 0.011754113939878958, 'span_overlap_f1': 0.11006727661032427}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 55.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.6599\n",
      "Validation Metrics: {'start_accuracy': 0.03406813627254509, 'start_precision': 0.012452899154458762, 'start_recall': 0.03406813627254509, 'start_f1_score': 0.012561039703661677, 'end_accuracy': 0.012525050100200401, 'end_precision': 0.01112289953129527, 'end_recall': 0.012525050100200401, 'end_f1_score': 0.009845389003981716, 'joint_exact_match': 0.0045090180360721445, 'span_overlap_f1': 0.05708392658948749}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|| 625/625 [00:13<00:00, 45.29it/s, loss=9.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 8.7251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:10<00:00, 58.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 8.2951\n",
      "Training Metrics: {'start_accuracy': 0.06982443855349373, 'start_precision': 0.06347561237235697, 'start_recall': 0.06982443855349373, 'start_f1_score': 0.04483410757031016, 'end_accuracy': 0.06157155004251488, 'end_precision': 0.05895337202792402, 'end_recall': 0.06157155004251488, 'end_f1_score': 0.05443590823947376, 'joint_exact_match': 0.01590556694843195, 'span_overlap_f1': 0.12486739797896826}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 61.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.8073\n",
      "Validation Metrics: {'start_accuracy': 0.034569138276553106, 'start_precision': 0.013746201027497365, 'start_recall': 0.034569138276553106, 'start_f1_score': 0.010077425581689482, 'end_accuracy': 0.012525050100200401, 'end_precision': 0.007547061419084825, 'end_recall': 0.012525050100200401, 'end_f1_score': 0.007798972809049272, 'joint_exact_match': 0.0045090180360721445, 'span_overlap_f1': 0.05394089869515318}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|| 625/625 [00:13<00:00, 47.53it/s, loss=8.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 8.3646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 7.7063\n",
      "Training Metrics: {'start_accuracy': 0.10163557245035762, 'start_precision': 0.09257559485633823, 'start_recall': 0.10163557245035762, 'start_f1_score': 0.08165018366264153, 'end_accuracy': 0.09073175611464013, 'end_precision': 0.08944417276893708, 'end_recall': 0.09073175611464013, 'end_f1_score': 0.0860085418736562, 'joint_exact_match': 0.02420847296553794, 'span_overlap_f1': 0.17044476356949959}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 52.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 10.1383\n",
      "Validation Metrics: {'start_accuracy': 0.029559118236472944, 'start_precision': 0.013351246181534417, 'start_recall': 0.029559118236472944, 'start_f1_score': 0.012792675459931877, 'end_accuracy': 0.008016032064128256, 'end_precision': 0.00601240067214925, 'end_recall': 0.008016032064128256, 'end_f1_score': 0.005962584654510727, 'joint_exact_match': 0.003006012024048096, 'span_overlap_f1': 0.050667115449666546}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|| 625/625 [00:13<00:00, 47.24it/s, loss=7.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 7.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 7.1670\n",
      "Training Metrics: {'start_accuracy': 0.13579752913519733, 'start_precision': 0.11917575469849587, 'start_recall': 0.13579752913519733, 'start_f1_score': 0.11672807124963128, 'end_accuracy': 0.11894162957034962, 'end_precision': 0.11336508923239486, 'end_recall': 0.11894162957034962, 'end_f1_score': 0.11217109981211265, 'joint_exact_match': 0.03421197419096684, 'span_overlap_f1': 0.21501888089198581}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 52.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 10.4875\n",
      "Validation Metrics: {'start_accuracy': 0.025050100200400802, 'start_precision': 0.011972914174275305, 'start_recall': 0.025050100200400802, 'start_f1_score': 0.012843274855503718, 'end_accuracy': 0.013527054108216433, 'end_precision': 0.013511425902508534, 'end_recall': 0.013527054108216433, 'end_f1_score': 0.011791137327807472, 'joint_exact_match': 0.0035070140280561123, 'span_overlap_f1': 0.04874319894074456}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|| 625/625 [00:13<00:00, 46.98it/s, loss=7.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 7.3159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.3804\n",
      "Training Metrics: {'start_accuracy': 0.18431451007852748, 'start_precision': 0.1699042056711674, 'start_recall': 0.18431451007852748, 'start_f1_score': 0.17149293912625382, 'end_accuracy': 0.1632071224928725, 'end_precision': 0.1565366989612871, 'end_recall': 0.1632071224928725, 'end_f1_score': 0.15748297869587827, 'joint_exact_match': 0.05536937928274896, 'span_overlap_f1': 0.2619700443364025}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 11.3094\n",
      "Validation Metrics: {'start_accuracy': 0.019539078156312624, 'start_precision': 0.01369242386526315, 'start_recall': 0.019539078156312624, 'start_f1_score': 0.014510483453710959, 'end_accuracy': 0.008517034068136272, 'end_precision': 0.010362645036993735, 'end_recall': 0.008517034068136272, 'end_f1_score': 0.008654964472113474, 'joint_exact_match': 0.001503006012024048, 'span_overlap_f1': 0.03740256496916357}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|| 625/625 [00:13<00:00, 47.15it/s, loss=6.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 6.7409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 54.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 5.9282\n",
      "Training Metrics: {'start_accuracy': 0.21357475116290703, 'start_precision': 0.2030485631737885, 'start_recall': 0.21357475116290703, 'start_f1_score': 0.20269223925980603, 'end_accuracy': 0.19306757365077779, 'end_precision': 0.18806508162180172, 'end_recall': 0.19306757365077779, 'end_f1_score': 0.18900895961187236, 'joint_exact_match': 0.06547291552043215, 'span_overlap_f1': 0.2970762710204996}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 12.2981\n",
      "Validation Metrics: {'start_accuracy': 0.022044088176352707, 'start_precision': 0.01689781543435783, 'start_recall': 0.022044088176352707, 'start_f1_score': 0.017031208140216827, 'end_accuracy': 0.012525050100200401, 'end_precision': 0.01059624115214722, 'end_recall': 0.012525050100200401, 'end_f1_score': 0.010820372237728445, 'joint_exact_match': 0.00250501002004008, 'span_overlap_f1': 0.04566664890485655}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|| 625/625 [00:13<00:00, 47.02it/s, loss=7.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 6.2252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 5.4328\n",
      "Training Metrics: {'start_accuracy': 0.24213474716150651, 'start_precision': 0.23680363733118215, 'start_recall': 0.24213474716150651, 'start_f1_score': 0.236898461405327, 'end_accuracy': 0.21867653678787577, 'end_precision': 0.21508970585078718, 'end_recall': 0.21867653678787577, 'end_f1_score': 0.21480652609778403, 'joint_exact_match': 0.07982793977892262, 'span_overlap_f1': 0.3189137752173306}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 13.5959\n",
      "Validation Metrics: {'start_accuracy': 0.015531062124248497, 'start_precision': 0.015152858519267124, 'start_recall': 0.015531062124248497, 'start_f1_score': 0.014888851378386836, 'end_accuracy': 0.009519038076152305, 'end_precision': 0.008273545154441673, 'end_recall': 0.009519038076152305, 'end_f1_score': 0.008675542049341813, 'joint_exact_match': 0.001503006012024048, 'span_overlap_f1': 0.03917337409624562}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|| 625/625 [00:13<00:00, 47.10it/s, loss=6.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 5.7923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 54.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 5.0073\n",
      "Training Metrics: {'start_accuracy': 0.2816485770019507, 'start_precision': 0.2799378608611072, 'start_recall': 0.2816485770019507, 'start_f1_score': 0.2788145367320129, 'end_accuracy': 0.2557395088280898, 'end_precision': 0.25630650968707197, 'end_recall': 0.2557395088280898, 'end_f1_score': 0.25379235395550276, 'joint_exact_match': 0.10323613264642625, 'span_overlap_f1': 0.3513090450033114}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 52.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 14.2845\n",
      "Validation Metrics: {'start_accuracy': 0.013026052104208416, 'start_precision': 0.013402615788649716, 'start_recall': 0.013026052104208416, 'start_f1_score': 0.012973805796278068, 'end_accuracy': 0.0070140280561122245, 'end_precision': 0.007300701975729781, 'end_recall': 0.0070140280561122245, 'end_f1_score': 0.007001035210461433, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.038056455396968246}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|| 625/625 [00:13<00:00, 47.26it/s, loss=5.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 5.4397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:10<00:00, 57.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.7272\n",
      "Training Metrics: {'start_accuracy': 0.30295603461211423, 'start_precision': 0.29729700927340097, 'start_recall': 0.30295603461211423, 'start_f1_score': 0.29703774087756957, 'end_accuracy': 0.2794478067323563, 'end_precision': 0.2773583261576394, 'end_recall': 0.2794478067323563, 'end_f1_score': 0.276279672789248, 'joint_exact_match': 0.11709098184364528, 'span_overlap_f1': 0.3634393643030003}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 52.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 14.7942\n",
      "Validation Metrics: {'start_accuracy': 0.01603206412825651, 'start_precision': 0.015152014280813675, 'start_recall': 0.01603206412825651, 'start_f1_score': 0.014677644626805583, 'end_accuracy': 0.009519038076152305, 'end_precision': 0.009675001258009356, 'end_recall': 0.009519038076152305, 'end_f1_score': 0.00921270734122881, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.042964842421887584}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|| 625/625 [00:13<00:00, 47.12it/s, loss=5.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 5.1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.4091\n",
      "Training Metrics: {'start_accuracy': 0.3284149452308308, 'start_precision': 0.32285075473152747, 'start_recall': 0.3284149452308308, 'start_f1_score': 0.32257261047949654, 'end_accuracy': 0.3014555094282999, 'end_precision': 0.2995581288906815, 'end_recall': 0.3014555094282999, 'end_f1_score': 0.2970444722761386, 'joint_exact_match': 0.13729805431901165, 'span_overlap_f1': 0.38492160069325054}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 54.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 16.3251\n",
      "Validation Metrics: {'start_accuracy': 0.015531062124248497, 'start_precision': 0.013974477374729894, 'start_recall': 0.015531062124248497, 'start_f1_score': 0.014047894444168629, 'end_accuracy': 0.011523046092184368, 'end_precision': 0.010038811061733956, 'end_recall': 0.011523046092184368, 'end_f1_score': 0.010341968285641295, 'joint_exact_match': 0.00250501002004008, 'span_overlap_f1': 0.04076363979215303}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|| 625/625 [00:13<00:00, 47.82it/s, loss=4.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 4.8899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 56.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.3050\n",
      "Training Metrics: {'start_accuracy': 0.34747161506527285, 'start_precision': 0.35495511452927586, 'start_recall': 0.34747161506527285, 'start_f1_score': 0.3451632057306375, 'end_accuracy': 0.3176611814134947, 'end_precision': 0.3294035395462617, 'end_recall': 0.3176611814134947, 'end_f1_score': 0.3161994738566256, 'joint_exact_match': 0.15595458410443655, 'span_overlap_f1': 0.4068276381911186}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 17.3787\n",
      "Validation Metrics: {'start_accuracy': 0.012525050100200401, 'start_precision': 0.013850983801868543, 'start_recall': 0.012525050100200401, 'start_f1_score': 0.012781387700312462, 'end_accuracy': 0.0070140280561122245, 'end_precision': 0.0060252893135764145, 'end_recall': 0.0070140280561122245, 'end_f1_score': 0.005896273687419943, 'joint_exact_match': 0.000501002004008016, 'span_overlap_f1': 0.03524846757301265}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|| 625/625 [00:13<00:00, 47.72it/s, loss=4.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss: 4.6571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 56.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.8792\n",
      "Training Metrics: {'start_accuracy': 0.39368779072675436, 'start_precision': 0.40059910492928613, 'start_recall': 0.39368779072675436, 'start_f1_score': 0.39444948077608155, 'end_accuracy': 0.35882558895613464, 'end_precision': 0.36611997967209625, 'end_recall': 0.35882558895613464, 'end_f1_score': 0.35932395834795844, 'joint_exact_match': 0.182413844845696, 'span_overlap_f1': 0.4318986454602132}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 52.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18.6843\n",
      "Validation Metrics: {'start_accuracy': 0.011523046092184368, 'start_precision': 0.013274424218681153, 'start_recall': 0.011523046092184368, 'start_f1_score': 0.011876106133892433, 'end_accuracy': 0.01002004008016032, 'end_precision': 0.010597238518134489, 'end_recall': 0.01002004008016032, 'end_f1_score': 0.009631810145990703, 'joint_exact_match': 0.000501002004008016, 'span_overlap_f1': 0.03490785093209194}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|| 625/625 [00:13<00:00, 47.27it/s, loss=4.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss: 4.4303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:10<00:00, 57.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.7043\n",
      "Training Metrics: {'start_accuracy': 0.4227479617866253, 'start_precision': 0.4298064024775411, 'start_recall': 0.4227479617866253, 'start_f1_score': 0.4235571024068744, 'end_accuracy': 0.3985895063272145, 'end_precision': 0.40358371310964203, 'end_recall': 0.3985895063272145, 'end_f1_score': 0.3984035878434149, 'joint_exact_match': 0.22182763967388586, 'span_overlap_f1': 0.45570174876323066}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 54.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18.7110\n",
      "Validation Metrics: {'start_accuracy': 0.015531062124248497, 'start_precision': 0.018445379984284284, 'start_recall': 0.015531062124248497, 'start_f1_score': 0.016386077592934613, 'end_accuracy': 0.011523046092184368, 'end_precision': 0.014337339756976987, 'end_recall': 0.011523046092184368, 'end_f1_score': 0.012387592810846379, 'joint_exact_match': 0.001002004008016032, 'span_overlap_f1': 0.037490555992537616}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|| 625/625 [00:13<00:00, 47.54it/s, loss=4.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss: 4.2614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:10<00:00, 58.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.5087\n",
      "Training Metrics: {'start_accuracy': 0.4510578702545891, 'start_precision': 0.45906966372391844, 'start_recall': 0.4510578702545891, 'start_f1_score': 0.45099103412552904, 'end_accuracy': 0.4261991697093983, 'end_precision': 0.43557000640938653, 'end_recall': 0.4261991697093983, 'end_f1_score': 0.42636852883266607, 'joint_exact_match': 0.25463912369329267, 'span_overlap_f1': 0.49055413369337364}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 53.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18.4956\n",
      "Validation Metrics: {'start_accuracy': 0.01503006012024048, 'start_precision': 0.017744619544703088, 'start_recall': 0.01503006012024048, 'start_f1_score': 0.01572939070467658, 'end_accuracy': 0.009018036072144289, 'end_precision': 0.009021045069327696, 'end_recall': 0.009018036072144289, 'end_f1_score': 0.008473946006144664, 'joint_exact_match': 0.001002004008016032, 'span_overlap_f1': 0.039527373810681804}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|| 625/625 [00:13<00:00, 45.03it/s, loss=4.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss: 4.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 54.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.3232\n",
      "Training Metrics: {'start_accuracy': 0.47571650077527133, 'start_precision': 0.4835659573767371, 'start_recall': 0.47571650077527133, 'start_f1_score': 0.4771134494833037, 'end_accuracy': 0.4562596908918121, 'end_precision': 0.46059639010420406, 'end_recall': 0.4562596908918121, 'end_f1_score': 0.4559449621660897, 'joint_exact_match': 0.28254889211223927, 'span_overlap_f1': 0.5069321253141548}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 51.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 19.5426\n",
      "Validation Metrics: {'start_accuracy': 0.013026052104208416, 'start_precision': 0.01482853073036148, 'start_recall': 0.013026052104208416, 'start_f1_score': 0.013508009985974104, 'end_accuracy': 0.014529058116232466, 'end_precision': 0.01635489316561179, 'end_recall': 0.014529058116232466, 'end_f1_score': 0.014991795386774963, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.03515679005563666}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|| 625/625 [00:13<00:00, 46.41it/s, loss=4.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss: 3.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 56.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.2256\n",
      "Training Metrics: {'start_accuracy': 0.48967138498474466, 'start_precision': 0.5022097758884001, 'start_recall': 0.48967138498474466, 'start_f1_score': 0.49052288309507097, 'end_accuracy': 0.4661131395988596, 'end_precision': 0.47701440932707206, 'end_recall': 0.4661131395988596, 'end_f1_score': 0.4670768227337243, 'joint_exact_match': 0.30015505426899414, 'span_overlap_f1': 0.5161369468786274}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 19.7014\n",
      "Validation Metrics: {'start_accuracy': 0.016533066132264528, 'start_precision': 0.02160019034094481, 'start_recall': 0.016533066132264528, 'start_f1_score': 0.01810617654827776, 'end_accuracy': 0.009018036072144289, 'end_precision': 0.011023206329453498, 'end_recall': 0.009018036072144289, 'end_f1_score': 0.00949707943224388, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.04055043868424989}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|| 625/625 [00:13<00:00, 47.43it/s, loss=4.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss: 3.7424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 56.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.9798\n",
      "Training Metrics: {'start_accuracy': 0.5248837092982543, 'start_precision': 0.5286510857039296, 'start_recall': 0.5248837092982543, 'start_f1_score': 0.5240538340375761, 'end_accuracy': 0.5050767768719052, 'end_precision': 0.5088329139727904, 'end_recall': 0.5050767768719052, 'end_f1_score': 0.5038690832541319, 'joint_exact_match': 0.3425698994648127, 'span_overlap_f1': 0.5478572331010371}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 20.8569\n",
      "Validation Metrics: {'start_accuracy': 0.01503006012024048, 'start_precision': 0.01567812465216861, 'start_recall': 0.01503006012024048, 'start_f1_score': 0.015120605977145917, 'end_accuracy': 0.008016032064128256, 'end_precision': 0.007370644260678199, 'end_recall': 0.008016032064128256, 'end_f1_score': 0.0073400136852040665, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.036974509545606306}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|| 625/625 [00:13<00:00, 47.35it/s, loss=3.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss: 3.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.8221\n",
      "Training Metrics: {'start_accuracy': 0.5650477667183514, 'start_precision': 0.5702961697156668, 'start_recall': 0.5650477667183514, 'start_f1_score': 0.5646541690156465, 'end_accuracy': 0.5491421997699195, 'end_precision': 0.5549135351441639, 'end_recall': 0.5491421997699195, 'end_f1_score': 0.5488047122610392, 'joint_exact_match': 0.3961886660331116, 'span_overlap_f1': 0.5958894160815266}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 51.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 20.9304\n",
      "Validation Metrics: {'start_accuracy': 0.01603206412825651, 'start_precision': 0.016463366478615786, 'start_recall': 0.01603206412825651, 'start_f1_score': 0.015867548241553318, 'end_accuracy': 0.011523046092184368, 'end_precision': 0.011547842425131565, 'end_recall': 0.011523046092184368, 'end_f1_score': 0.011111916554550176, 'joint_exact_match': 0.0035070140280561123, 'span_overlap_f1': 0.04118359158412919}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|| 625/625 [00:13<00:00, 47.48it/s, loss=3.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Loss: 3.4405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 56.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.6294\n",
      "Training Metrics: {'start_accuracy': 0.5786025108788075, 'start_precision': 0.5859007121497015, 'start_recall': 0.5786025108788075, 'start_f1_score': 0.5787522870965762, 'end_accuracy': 0.5602460861301456, 'end_precision': 0.5659083048964271, 'end_recall': 0.5602460861301456, 'end_f1_score': 0.5598711380663947, 'joint_exact_match': 0.40424148451958186, 'span_overlap_f1': 0.5995663995938924}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 20.9106\n",
      "Validation Metrics: {'start_accuracy': 0.011022044088176353, 'start_precision': 0.014667645218644916, 'start_recall': 0.011022044088176353, 'start_f1_score': 0.012150991021479155, 'end_accuracy': 0.01002004008016032, 'end_precision': 0.009632088972115775, 'end_recall': 0.01002004008016032, 'end_f1_score': 0.00949700750679324, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.03778352685182661}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|| 625/625 [00:13<00:00, 47.49it/s, loss=3.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Loss: 3.4165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.4934\n",
      "Training Metrics: {'start_accuracy': 0.6061121392487371, 'start_precision': 0.6064815364069764, 'start_recall': 0.6061121392487371, 'start_f1_score': 0.6049864643952799, 'end_accuracy': 0.5929075176311709, 'end_precision': 0.5933187571070427, 'end_recall': 0.5929075176311709, 'end_f1_score': 0.5918908232609871, 'joint_exact_match': 0.44165457910268596, 'span_overlap_f1': 0.6285470778336492}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 21.9725\n",
      "Validation Metrics: {'start_accuracy': 0.013026052104208416, 'start_precision': 0.01397057781753661, 'start_recall': 0.013026052104208416, 'start_f1_score': 0.01310700058404264, 'end_accuracy': 0.008517034068136272, 'end_precision': 0.008391902920472443, 'end_recall': 0.008517034068136272, 'end_f1_score': 0.0081616518967999, 'joint_exact_match': 0.001002004008016032, 'span_overlap_f1': 0.03951418635541681}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|| 625/625 [00:13<00:00, 47.12it/s, loss=3.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Loss: 3.1415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 56.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.4278\n",
      "Training Metrics: {'start_accuracy': 0.6190166558295404, 'start_precision': 0.6214513093697681, 'start_recall': 0.6190166558295404, 'start_f1_score': 0.6179989145073601, 'end_accuracy': 0.6013604761666583, 'end_precision': 0.6054572788207119, 'end_recall': 0.6013604761666583, 'end_f1_score': 0.6006299337915244, 'joint_exact_match': 0.4589106187165508, 'span_overlap_f1': 0.6388675179594339}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 21.9202\n",
      "Validation Metrics: {'start_accuracy': 0.01503006012024048, 'start_precision': 0.01620709176159834, 'start_recall': 0.01503006012024048, 'start_f1_score': 0.015205044999423946, 'end_accuracy': 0.01002004008016032, 'end_precision': 0.011949627302831854, 'end_recall': 0.01002004008016032, 'end_f1_score': 0.010520368983274322, 'joint_exact_match': 0.003006012024048096, 'span_overlap_f1': 0.041647703645954486}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|| 625/625 [00:13<00:00, 47.64it/s, loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Loss: 2.9969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 56.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.4020\n",
      "Training Metrics: {'start_accuracy': 0.6059120692242285, 'start_precision': 0.6119150262017485, 'start_recall': 0.6059120692242285, 'start_f1_score': 0.6060153876798978, 'end_accuracy': 0.5928074826189166, 'end_precision': 0.5983165440138793, 'end_recall': 0.5928074826189166, 'end_f1_score': 0.5930040478593727, 'joint_exact_match': 0.4429550342619917, 'span_overlap_f1': 0.6230239449176277}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 22.5145\n",
      "Validation Metrics: {'start_accuracy': 0.01002004008016032, 'start_precision': 0.013679355785255564, 'start_recall': 0.01002004008016032, 'start_f1_score': 0.01099154017217623, 'end_accuracy': 0.006012024048096192, 'end_precision': 0.006619063975798637, 'end_recall': 0.006012024048096192, 'end_f1_score': 0.006211192895627914, 'joint_exact_match': 0.001002004008016032, 'span_overlap_f1': 0.03567820305018659}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|| 625/625 [00:13<00:00, 47.41it/s, loss=3.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Loss: 2.9206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2253\n",
      "Training Metrics: {'start_accuracy': 0.6544290501675586, 'start_precision': 0.661736179948008, 'start_recall': 0.6544290501675586, 'start_f1_score': 0.6537165204453255, 'end_accuracy': 0.6392237283049067, 'end_precision': 0.6465469776775281, 'end_recall': 0.6392237283049067, 'end_f1_score': 0.6381537908707788, 'joint_exact_match': 0.5114790176561796, 'span_overlap_f1': 0.6815368796709504}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 23.3072\n",
      "Validation Metrics: {'start_accuracy': 0.013026052104208416, 'start_precision': 0.015751619364021512, 'start_recall': 0.013026052104208416, 'start_f1_score': 0.013645612626532463, 'end_accuracy': 0.010521042084168337, 'end_precision': 0.013346192247376968, 'end_recall': 0.010521042084168337, 'end_f1_score': 0.011129778850407382, 'joint_exact_match': 0.001503006012024048, 'span_overlap_f1': 0.03912154438951495}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|| 625/625 [00:13<00:00, 46.91it/s, loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Loss: 2.7027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:10<00:00, 57.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.0337\n",
      "Training Metrics: {'start_accuracy': 0.6630820787275546, 'start_precision': 0.6730195382003223, 'start_recall': 0.6630820787275546, 'start_f1_score': 0.6641505181799556, 'end_accuracy': 0.6520782273795829, 'end_precision': 0.6622476210710838, 'end_recall': 0.6520782273795829, 'end_f1_score': 0.6528813682343269, 'joint_exact_match': 0.530285599959986, 'span_overlap_f1': 0.6806877450163261}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 55.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 23.8980\n",
      "Validation Metrics: {'start_accuracy': 0.016533066132264528, 'start_precision': 0.018754002919893473, 'start_recall': 0.016533066132264528, 'start_f1_score': 0.01667043653230746, 'end_accuracy': 0.009018036072144289, 'end_precision': 0.008325090499947686, 'end_recall': 0.009018036072144289, 'end_f1_score': 0.008427131756228445, 'joint_exact_match': 0.00250501002004008, 'span_overlap_f1': 0.040967431603209196}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|| 625/625 [00:13<00:00, 46.70it/s, loss=3.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Loss: 2.6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 54.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.8688\n",
      "Training Metrics: {'start_accuracy': 0.6991947181513529, 'start_precision': 0.7039253776387402, 'start_recall': 0.6991947181513529, 'start_f1_score': 0.6982719521383458, 'end_accuracy': 0.6869404291502026, 'end_precision': 0.6923961638414391, 'end_recall': 0.6869404291502026, 'end_f1_score': 0.6863808719483022, 'joint_exact_match': 0.5753513729805432, 'span_overlap_f1': 0.720759169289978}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 54.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 24.8430\n",
      "Validation Metrics: {'start_accuracy': 0.014529058116232466, 'start_precision': 0.01601842026511218, 'start_recall': 0.014529058116232466, 'start_f1_score': 0.014784270227055191, 'end_accuracy': 0.009018036072144289, 'end_precision': 0.009844120506673232, 'end_recall': 0.009018036072144289, 'end_f1_score': 0.009070002424666044, 'joint_exact_match': 0.001503006012024048, 'span_overlap_f1': 0.04212606971336581}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|| 625/625 [00:13<00:00, 45.53it/s, loss=2.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Loss: 2.5183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 54.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7682\n",
      "Training Metrics: {'start_accuracy': 0.7192017206022108, 'start_precision': 0.7234722375024253, 'start_recall': 0.7192017206022108, 'start_f1_score': 0.7191349995729858, 'end_accuracy': 0.7022958035312359, 'end_precision': 0.7054790341032682, 'end_recall': 0.7022958035312359, 'end_f1_score': 0.7017616880498766, 'joint_exact_match': 0.5899564847696693, 'span_overlap_f1': 0.7318622736811511}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 25.6495\n",
      "Validation Metrics: {'start_accuracy': 0.014028056112224449, 'start_precision': 0.015370776646669226, 'start_recall': 0.014028056112224449, 'start_f1_score': 0.01440345218521575, 'end_accuracy': 0.008517034068136272, 'end_precision': 0.009051226643431684, 'end_recall': 0.008517034068136272, 'end_f1_score': 0.008531220015469836, 'joint_exact_match': 0.001503006012024048, 'span_overlap_f1': 0.041231222713483305}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|| 625/625 [00:13<00:00, 45.76it/s, loss=3.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Loss: 2.4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 56.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.6434\n",
      "Training Metrics: {'start_accuracy': 0.7328064822687941, 'start_precision': 0.7356841620314603, 'start_recall': 0.7328064822687941, 'start_f1_score': 0.7321711413138886, 'end_accuracy': 0.7252038213374681, 'end_precision': 0.7278765210378502, 'end_recall': 0.7252038213374681, 'end_f1_score': 0.7243576758798782, 'joint_exact_match': 0.6141149402290802, 'span_overlap_f1': 0.7531442299840452}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 51.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 25.0266\n",
      "Validation Metrics: {'start_accuracy': 0.012024048096192385, 'start_precision': 0.01585577937955942, 'start_recall': 0.012024048096192385, 'start_f1_score': 0.013268341484476387, 'end_accuracy': 0.009519038076152305, 'end_precision': 0.011327613404558887, 'end_recall': 0.009519038076152305, 'end_f1_score': 0.009795902568816465, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.03957834009059021}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|| 625/625 [00:13<00:00, 45.37it/s, loss=2.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Loss: 2.3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 54.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7055\n",
      "Training Metrics: {'start_accuracy': 0.7199019656879908, 'start_precision': 0.7270175090915016, 'start_recall': 0.7199019656879908, 'start_f1_score': 0.7210632762505854, 'end_accuracy': 0.7128995148301905, 'end_precision': 0.7198678526733078, 'end_recall': 0.7128995148301905, 'end_f1_score': 0.7140124937089961, 'joint_exact_match': 0.6061121392487371, 'span_overlap_f1': 0.7361898744606454}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 51.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 24.7840\n",
      "Validation Metrics: {'start_accuracy': 0.010521042084168337, 'start_precision': 0.01567135438009539, 'start_recall': 0.010521042084168337, 'start_f1_score': 0.01191055674405709, 'end_accuracy': 0.008517034068136272, 'end_precision': 0.009439378375362472, 'end_recall': 0.008517034068136272, 'end_f1_score': 0.008647434812264472, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.0404103094075878}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|| 625/625 [00:13<00:00, 47.84it/s, loss=2.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Loss: 2.2511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:10<00:00, 56.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5174\n",
      "Training Metrics: {'start_accuracy': 0.7536637823238134, 'start_precision': 0.754087264063131, 'start_recall': 0.7536637823238134, 'start_f1_score': 0.7528336557425713, 'end_accuracy': 0.7457109988495974, 'end_precision': 0.7461212164985541, 'end_recall': 0.7457109988495974, 'end_f1_score': 0.7446021258264209, 'joint_exact_match': 0.6448256889911469, 'span_overlap_f1': 0.7704287902409183}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 24.9621\n",
      "Validation Metrics: {'start_accuracy': 0.011523046092184368, 'start_precision': 0.015677908092190312, 'start_recall': 0.011523046092184368, 'start_f1_score': 0.012550943807545826, 'end_accuracy': 0.00751503006012024, 'end_precision': 0.006800270631802038, 'end_recall': 0.00751503006012024, 'end_f1_score': 0.00677399048787871, 'joint_exact_match': 0.000501002004008016, 'span_overlap_f1': 0.03645057909015716}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|| 625/625 [00:13<00:00, 47.97it/s, loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Loss: 2.1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 56.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.6002\n",
      "Training Metrics: {'start_accuracy': 0.7396088631020857, 'start_precision': 0.7467718383768456, 'start_recall': 0.7396088631020857, 'start_f1_score': 0.740199158903024, 'end_accuracy': 0.7367578652528385, 'end_precision': 0.7432860342604396, 'end_recall': 0.7367578652528385, 'end_f1_score': 0.7371371003265802, 'joint_exact_match': 0.6399239733906867, 'span_overlap_f1': 0.755454468185122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 25.6075\n",
      "Validation Metrics: {'start_accuracy': 0.013026052104208416, 'start_precision': 0.013961151561787618, 'start_recall': 0.013026052104208416, 'start_f1_score': 0.012989080503320802, 'end_accuracy': 0.005511022044088177, 'end_precision': 0.005788263270739834, 'end_recall': 0.005511022044088177, 'end_f1_score': 0.005465353311044693, 'joint_exact_match': 0.000501002004008016, 'span_overlap_f1': 0.03882971923128603}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|| 625/625 [00:13<00:00, 47.03it/s, loss=2.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Loss: 2.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4436\n",
      "Training Metrics: {'start_accuracy': 0.7709198219376782, 'start_precision': 0.7720224763907594, 'start_recall': 0.7709198219376782, 'start_f1_score': 0.7700591856460107, 'end_accuracy': 0.7643175111288951, 'end_precision': 0.76646417777811, 'end_recall': 0.7643175111288951, 'end_f1_score': 0.7638927989603335, 'joint_exact_match': 0.6684339518831591, 'span_overlap_f1': 0.787197197203462}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 25.2602\n",
      "Validation Metrics: {'start_accuracy': 0.010521042084168337, 'start_precision': 0.017346128088033895, 'start_recall': 0.010521042084168337, 'start_f1_score': 0.011648404856783002, 'end_accuracy': 0.008517034068136272, 'end_precision': 0.009822618088169921, 'end_recall': 0.008517034068136272, 'end_f1_score': 0.008491600333478922, 'joint_exact_match': 0.001503006012024048, 'span_overlap_f1': 0.043675432452803455}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|| 625/625 [00:13<00:00, 47.32it/s, loss=2.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Loss: 1.9802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 54.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2747\n",
      "Training Metrics: {'start_accuracy': 0.7952283299154704, 'start_precision': 0.7996036363270763, 'start_recall': 0.7952283299154704, 'start_f1_score': 0.7957836453594627, 'end_accuracy': 0.7827239533836843, 'end_precision': 0.7871155190311134, 'end_recall': 0.7827239533836843, 'end_f1_score': 0.7833088835663873, 'joint_exact_match': 0.6979442804981744, 'span_overlap_f1': 0.8106403793661988}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 54.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 26.8196\n",
      "Validation Metrics: {'start_accuracy': 0.011022044088176353, 'start_precision': 0.01512414946488454, 'start_recall': 0.011022044088176353, 'start_f1_score': 0.01240616516754669, 'end_accuracy': 0.008016032064128256, 'end_precision': 0.009940817221904165, 'end_recall': 0.008016032064128256, 'end_f1_score': 0.008418364848768073, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.03760885931652915}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|| 625/625 [00:13<00:00, 47.58it/s, loss=1.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Loss: 1.8805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 53.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4414\n",
      "Training Metrics: {'start_accuracy': 0.7664182463862352, 'start_precision': 0.7679342824459677, 'start_recall': 0.7664182463862352, 'start_f1_score': 0.7650397833087421, 'end_accuracy': 0.7675686490271595, 'end_precision': 0.770447386814383, 'end_recall': 0.7675686490271595, 'end_f1_score': 0.7670657606701201, 'joint_exact_match': 0.6707847746711348, 'span_overlap_f1': 0.7791050492502465}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 25.7588\n",
      "Validation Metrics: {'start_accuracy': 0.012525050100200401, 'start_precision': 0.017947897086504766, 'start_recall': 0.012525050100200401, 'start_f1_score': 0.012978277393232639, 'end_accuracy': 0.009519038076152305, 'end_precision': 0.010795206438233979, 'end_recall': 0.009519038076152305, 'end_f1_score': 0.009672459096752106, 'joint_exact_match': 0.001503006012024048, 'span_overlap_f1': 0.041500475953183846}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|| 625/625 [00:13<00:00, 47.31it/s, loss=2.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Loss: 1.7877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1973\n",
      "Training Metrics: {'start_accuracy': 0.8062321812634422, 'start_precision': 0.8081561683185451, 'start_recall': 0.8062321812634422, 'start_f1_score': 0.8059675006261654, 'end_accuracy': 0.8004801680588206, 'end_precision': 0.8032097461816993, 'end_recall': 0.8004801680588206, 'end_f1_score': 0.8004746466433994, 'joint_exact_match': 0.7204021407492622, 'span_overlap_f1': 0.8214899262435177}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 26.6148\n",
      "Validation Metrics: {'start_accuracy': 0.01503006012024048, 'start_precision': 0.01800780614436677, 'start_recall': 0.01503006012024048, 'start_f1_score': 0.015515999118496542, 'end_accuracy': 0.008517034068136272, 'end_precision': 0.011598786240348779, 'end_recall': 0.008517034068136272, 'end_f1_score': 0.00886914421466107, 'joint_exact_match': 0.0035070140280561123, 'span_overlap_f1': 0.04270026080945831}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|| 625/625 [00:13<00:00, 47.34it/s, loss=2.17] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Loss: 1.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 55.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2155\n",
      "Training Metrics: {'start_accuracy': 0.8080828289901466, 'start_precision': 0.810179996153463, 'start_recall': 0.8080828289901466, 'start_f1_score': 0.8079823007075906, 'end_accuracy': 0.8023808332916521, 'end_precision': 0.804598569866599, 'end_recall': 0.8023808332916521, 'end_f1_score': 0.8022472289398638, 'joint_exact_match': 0.7240534186965438, 'span_overlap_f1': 0.8205111019032488}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 26.1260\n",
      "Validation Metrics: {'start_accuracy': 0.016533066132264528, 'start_precision': 0.018208459386972332, 'start_recall': 0.016533066132264528, 'start_f1_score': 0.016715224591146473, 'end_accuracy': 0.006513026052104208, 'end_precision': 0.008671815587180843, 'end_recall': 0.006513026052104208, 'end_f1_score': 0.006903864112398828, 'joint_exact_match': 0.001002004008016032, 'span_overlap_f1': 0.041332894423366434}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|| 625/625 [00:13<00:00, 47.21it/s, loss=1.43] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Loss: 1.7187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:15<00:00, 41.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1019\n",
      "Training Metrics: {'start_accuracy': 0.8230880808282899, 'start_precision': 0.8239390040705475, 'start_recall': 0.8230880808282899, 'start_f1_score': 0.822211891966087, 'end_accuracy': 0.8176361726604312, 'end_precision': 0.8191484345544353, 'end_recall': 0.8176361726604312, 'end_f1_score': 0.8170619536263657, 'joint_exact_match': 0.7446606312209273, 'span_overlap_f1': 0.8348488500430682}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 43.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 28.5827\n",
      "Validation Metrics: {'start_accuracy': 0.015531062124248497, 'start_precision': 0.01748473026895146, 'start_recall': 0.015531062124248497, 'start_f1_score': 0.015943017254959342, 'end_accuracy': 0.006012024048096192, 'end_precision': 0.0064625840467965896, 'end_recall': 0.006012024048096192, 'end_f1_score': 0.005842550367370799, 'joint_exact_match': 0.00250501002004008, 'span_overlap_f1': 0.040038051562548936}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|| 625/625 [00:14<00:00, 44.08it/s, loss=1.51] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Loss: 1.6184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:12<00:00, 51.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1085\n",
      "Training Metrics: {'start_accuracy': 0.8191366978442455, 'start_precision': 0.8208544764262679, 'start_recall': 0.8191366978442455, 'start_f1_score': 0.8188345757309338, 'end_accuracy': 0.8187365577952284, 'end_precision': 0.8208878937693256, 'end_recall': 0.8187365577952284, 'end_f1_score': 0.8186214878183564, 'joint_exact_match': 0.7428600010003501, 'span_overlap_f1': 0.8332052425216956}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:02<00:00, 26.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 27.3555\n",
      "Validation Metrics: {'start_accuracy': 0.013527054108216433, 'start_precision': 0.014162076194728831, 'start_recall': 0.013527054108216433, 'start_f1_score': 0.013446340292609878, 'end_accuracy': 0.009519038076152305, 'end_precision': 0.010465053016145913, 'end_recall': 0.009519038076152305, 'end_f1_score': 0.009468188390403075, 'joint_exact_match': 0.001002004008016032, 'span_overlap_f1': 0.041394357096161974}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|| 625/625 [00:15<00:00, 39.44it/s, loss=1.13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Loss: 1.5889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:14<00:00, 43.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0078\n",
      "Training Metrics: {'start_accuracy': 0.8399939978992648, 'start_precision': 0.8411351656631078, 'start_recall': 0.8399939978992648, 'start_f1_score': 0.8396892707599268, 'end_accuracy': 0.8360426149152204, 'end_precision': 0.8369241477592859, 'end_recall': 0.8360426149152204, 'end_f1_score': 0.8356179378962237, 'joint_exact_match': 0.7658680538188366, 'span_overlap_f1': 0.8527171361899409}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 49.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 27.7381\n",
      "Validation Metrics: {'start_accuracy': 0.010521042084168337, 'start_precision': 0.013313234373618874, 'start_recall': 0.010521042084168337, 'start_f1_score': 0.010724200919559236, 'end_accuracy': 0.009018036072144289, 'end_precision': 0.009178241952887354, 'end_recall': 0.009018036072144289, 'end_f1_score': 0.00864935731791139, 'joint_exact_match': 0.000501002004008016, 'span_overlap_f1': 0.04174532779952531}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|| 625/625 [00:13<00:00, 44.78it/s, loss=1.43] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Loss: 1.5472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:12<00:00, 51.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0324\n",
      "Training Metrics: {'start_accuracy': 0.8313909868453959, 'start_precision': 0.832276363339239, 'start_recall': 0.8313909868453959, 'start_f1_score': 0.8308290110276958, 'end_accuracy': 0.8328915120292102, 'end_precision': 0.8339767478000294, 'end_recall': 0.8328915120292102, 'end_f1_score': 0.832570528759486, 'joint_exact_match': 0.7593657780223078, 'span_overlap_f1': 0.84572761960656}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 44.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 27.5229\n",
      "Validation Metrics: {'start_accuracy': 0.01002004008016032, 'start_precision': 0.010334667590949604, 'start_recall': 0.01002004008016032, 'start_f1_score': 0.009701156160970673, 'end_accuracy': 0.009519038076152305, 'end_precision': 0.010858158083211639, 'end_recall': 0.009519038076152305, 'end_f1_score': 0.009398002403632987, 'joint_exact_match': 0.001503006012024048, 'span_overlap_f1': 0.04269653401490113}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|| 625/625 [00:13<00:00, 44.71it/s, loss=2.09] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Loss: 1.4721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 54.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9322\n",
      "Training Metrics: {'start_accuracy': 0.8473465712999549, 'start_precision': 0.849123163610097, 'start_recall': 0.8473465712999549, 'start_f1_score': 0.8472948210987662, 'end_accuracy': 0.8478967638673536, 'end_precision': 0.8497333617528434, 'end_recall': 0.8478967638673536, 'end_f1_score': 0.847818532188129, 'joint_exact_match': 0.7850747761716601, 'span_overlap_f1': 0.8588968030411801}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 27.6566\n",
      "Validation Metrics: {'start_accuracy': 0.012024048096192385, 'start_precision': 0.013610771352736419, 'start_recall': 0.012024048096192385, 'start_f1_score': 0.012221848176239808, 'end_accuracy': 0.008016032064128256, 'end_precision': 0.008834886961227304, 'end_recall': 0.008016032064128256, 'end_f1_score': 0.007800103380851131, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.04427311117952496}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|| 625/625 [00:13<00:00, 45.62it/s, loss=1.49] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Loss: 1.4225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 54.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0738\n",
      "Training Metrics: {'start_accuracy': 0.8226379232731456, 'start_precision': 0.8238756228934043, 'start_recall': 0.8226379232731456, 'start_f1_score': 0.8222896761011329, 'end_accuracy': 0.8193867853748812, 'end_precision': 0.8214780775236705, 'end_recall': 0.8193867853748812, 'end_f1_score': 0.8192007824904826, 'joint_exact_match': 0.7526634322012704, 'span_overlap_f1': 0.8315111037276224}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 51.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 27.6663\n",
      "Validation Metrics: {'start_accuracy': 0.01002004008016032, 'start_precision': 0.013625623710441178, 'start_recall': 0.01002004008016032, 'start_f1_score': 0.011009983324293954, 'end_accuracy': 0.005511022044088177, 'end_precision': 0.007512331249935818, 'end_recall': 0.005511022044088177, 'end_f1_score': 0.0053588977044084956, 'joint_exact_match': 0.000501002004008016, 'span_overlap_f1': 0.039529598810141404}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|| 625/625 [00:13<00:00, 45.83it/s, loss=1.15] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Loss: 1.4053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:10<00:00, 57.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9401\n",
      "Training Metrics: {'start_accuracy': 0.8499474816185665, 'start_precision': 0.8505565443619167, 'start_recall': 0.8499474816185665, 'start_f1_score': 0.849211264314889, 'end_accuracy': 0.8484469564347522, 'end_precision': 0.8491340009432162, 'end_recall': 0.8484469564347522, 'end_f1_score': 0.8476746843734075, 'joint_exact_match': 0.7856749862451858, 'span_overlap_f1': 0.8581023551697321}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 48.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 27.4720\n",
      "Validation Metrics: {'start_accuracy': 0.011523046092184368, 'start_precision': 0.012997940993405607, 'start_recall': 0.011523046092184368, 'start_f1_score': 0.011736710422205641, 'end_accuracy': 0.008016032064128256, 'end_precision': 0.00851198936634109, 'end_recall': 0.008016032064128256, 'end_f1_score': 0.007816220574002804, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.03978333175401014}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|| 625/625 [00:13<00:00, 45.44it/s, loss=0.887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Loss: 1.3469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 54.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9153\n",
      "Training Metrics: {'start_accuracy': 0.8491972190266593, 'start_precision': 0.8503892339213315, 'start_recall': 0.8491972190266593, 'start_f1_score': 0.8490415357731254, 'end_accuracy': 0.8507477617166008, 'end_precision': 0.8519283135058003, 'end_recall': 0.8507477617166008, 'end_f1_score': 0.8505192678374144, 'joint_exact_match': 0.7904766668333917, 'span_overlap_f1': 0.8609158512507514}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 47.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 27.6025\n",
      "Validation Metrics: {'start_accuracy': 0.015531062124248497, 'start_precision': 0.017253936645413095, 'start_recall': 0.015531062124248497, 'start_f1_score': 0.015430499291729015, 'end_accuracy': 0.0070140280561122245, 'end_precision': 0.009348463149235882, 'end_recall': 0.0070140280561122245, 'end_f1_score': 0.007342350470374802, 'joint_exact_match': 0.001503006012024048, 'span_overlap_f1': 0.03979107299449551}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|| 625/625 [00:13<00:00, 44.80it/s, loss=1.23] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Loss: 1.2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:12<00:00, 50.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8425\n",
      "Training Metrics: {'start_accuracy': 0.86670334617116, 'start_precision': 0.8671999548696623, 'start_recall': 0.86670334617116, 'start_f1_score': 0.8660723597448137, 'end_accuracy': 0.8623518231380983, 'end_precision': 0.8631822011869472, 'end_recall': 0.8623518231380983, 'end_f1_score': 0.8618608974237297, 'joint_exact_match': 0.8046316210673736, 'span_overlap_f1': 0.8779951097536539}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 48.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 28.7222\n",
      "Validation Metrics: {'start_accuracy': 0.014028056112224449, 'start_precision': 0.015828024620507218, 'start_recall': 0.014028056112224449, 'start_f1_score': 0.01433550436632469, 'end_accuracy': 0.0070140280561122245, 'end_precision': 0.009171755131321322, 'end_recall': 0.0070140280561122245, 'end_f1_score': 0.007767818666009471, 'joint_exact_match': 0.00250501002004008, 'span_overlap_f1': 0.04096505225275032}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|| 625/625 [00:14<00:00, 44.22it/s, loss=1.76] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Loss: 1.2729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:12<00:00, 49.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7990\n",
      "Training Metrics: {'start_accuracy': 0.8723053068574, 'start_precision': 0.8730638665772673, 'start_recall': 0.8723053068574, 'start_f1_score': 0.8718644729311394, 'end_accuracy': 0.8655029260241084, 'end_precision': 0.8664087127235616, 'end_recall': 0.8655029260241084, 'end_f1_score': 0.8652511947882814, 'joint_exact_match': 0.8102335817536138, 'span_overlap_f1': 0.8804365102812199}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 42.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 29.1729\n",
      "Validation Metrics: {'start_accuracy': 0.011523046092184368, 'start_precision': 0.01208613168825672, 'start_recall': 0.011523046092184368, 'start_f1_score': 0.011379663470115235, 'end_accuracy': 0.01002004008016032, 'end_precision': 0.01161648153633875, 'end_recall': 0.01002004008016032, 'end_f1_score': 0.010089084556219905, 'joint_exact_match': 0.001002004008016032, 'span_overlap_f1': 0.04007422622455266}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|| 625/625 [00:14<00:00, 42.83it/s, loss=1.36] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Loss: 1.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:12<00:00, 51.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8521\n",
      "Training Metrics: {'start_accuracy': 0.8631521032361327, 'start_precision': 0.8637224229673435, 'start_recall': 0.8631521032361327, 'start_f1_score': 0.8626328607202268, 'end_accuracy': 0.8558495473415696, 'end_precision': 0.8561708870029021, 'end_recall': 0.8558495473415696, 'end_f1_score': 0.8553164777942851, 'joint_exact_match': 0.8013804831691091, 'span_overlap_f1': 0.8689010041961517}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 50.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 29.8117\n",
      "Validation Metrics: {'start_accuracy': 0.014529058116232466, 'start_precision': 0.01646412599238968, 'start_recall': 0.014529058116232466, 'start_f1_score': 0.015006288558264946, 'end_accuracy': 0.010521042084168337, 'end_precision': 0.01227530350679125, 'end_recall': 0.010521042084168337, 'end_f1_score': 0.010337805297327075, 'joint_exact_match': 0.001503006012024048, 'span_overlap_f1': 0.04152872780040555}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|| 625/625 [00:13<00:00, 44.67it/s, loss=1.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Loss: 1.2090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:11<00:00, 52.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7679\n",
      "Training Metrics: {'start_accuracy': 0.8756564797679187, 'start_precision': 0.8766045163397597, 'start_recall': 0.8756564797679187, 'start_f1_score': 0.8754295725243071, 'end_accuracy': 0.8773570749762417, 'end_precision': 0.8785686672954808, 'end_recall': 0.8773570749762417, 'end_f1_score': 0.8772993031332287, 'joint_exact_match': 0.8220377131996198, 'span_overlap_f1': 0.8881753099198784}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 43.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 29.1626\n",
      "Validation Metrics: {'start_accuracy': 0.010521042084168337, 'start_precision': 0.013213320936662356, 'start_recall': 0.010521042084168337, 'start_f1_score': 0.010864239930759988, 'end_accuracy': 0.009519038076152305, 'end_precision': 0.007863297244026667, 'end_recall': 0.009519038076152305, 'end_f1_score': 0.008347054689902085, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.03600730884810334}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|| 625/625 [00:14<00:00, 43.90it/s, loss=0.797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Loss: 1.1707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 625/625 [00:12<00:00, 51.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6839\n",
      "Training Metrics: {'start_accuracy': 0.8918621517531136, 'start_precision': 0.8924111720696236, 'start_recall': 0.8918621517531136, 'start_f1_score': 0.8915140511328007, 'end_accuracy': 0.8884109438303406, 'end_precision': 0.8887756431154721, 'end_recall': 0.8884109438303406, 'end_f1_score': 0.887993827721797, 'joint_exact_match': 0.8400440154053919, 'span_overlap_f1': 0.899802584023019}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 63/63 [00:01<00:00, 44.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 28.8369\n",
      "Validation Metrics: {'start_accuracy': 0.013026052104208416, 'start_precision': 0.015848075140071603, 'start_recall': 0.013026052104208416, 'start_f1_score': 0.013420503861789237, 'end_accuracy': 0.009519038076152305, 'end_precision': 0.011872572684845366, 'end_recall': 0.009519038076152305, 'end_f1_score': 0.00988768177355613, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.036085276216779545}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "\n",
    "# Initialize the model\n",
    "model = RNN_QA_Model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=256,\n",
    "    hidden_dim=256,\n",
    "    num_layers=3,\n",
    "    dropout=0.5,\n",
    "    pad_idx=1\n",
    ")\n",
    "\n",
    "#  loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#  optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "# Training the model\n",
    "train_qa_context_model(\n",
    "    model=model, \n",
    "    train_dataloader=train_dataloader_context_question_swapped, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    num_epochs=50,\n",
    "    device='cuda', \n",
    "    val_dataloader=dev_dataloader_context_question_swapped, \n",
    "    evaluate_val_dataset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/qa_context_model_50_epochs_swapped.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/qa_context_model_50_epochs_swapped.pkl\n"
     ]
    }
   ],
   "source": [
    "save_model(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/qa_context_model_50_epochs_swapped.pkl\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\001\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Evaluating: 100%|| 625/625 [00:12<00:00, 49.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6841\n",
      "Validation Metrics: {'start_accuracy': 0.8918621517531136, 'start_precision': 0.8924111720696236, 'start_recall': 0.8918621517531136, 'start_f1_score': 0.8915140511328007, 'end_accuracy': 0.8884109438303406, 'end_precision': 0.8887756431154721, 'end_recall': 0.8884109438303406, 'end_f1_score': 0.887993827721797, 'joint_exact_match': 0.8400440154053919, 'span_overlap_f1': 0.899802584023019}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6840926529407502,\n",
       " {'start_accuracy': 0.8918621517531136,\n",
       "  'start_precision': 0.8924111720696236,\n",
       "  'start_recall': 0.8918621517531136,\n",
       "  'start_f1_score': 0.8915140511328007,\n",
       "  'end_accuracy': 0.8884109438303406,\n",
       "  'end_precision': 0.8887756431154721,\n",
       "  'end_recall': 0.8884109438303406,\n",
       "  'end_f1_score': 0.887993827721797,\n",
       "  'joint_exact_match': 0.8400440154053919,\n",
       "  'span_overlap_f1': 0.899802584023019})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on the dev set\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "evaluate_qa_context_model(model=model, dataloader=train_dataloader_context_question_swapped, criterion=criterion, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]c:\\Users\\001\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Evaluating: 100%|| 63/63 [00:01<00:00, 45.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 28.8369\n",
      "Validation Metrics: {'start_accuracy': 0.013026052104208416, 'start_precision': 0.015848075140071603, 'start_recall': 0.013026052104208416, 'start_f1_score': 0.013420503861789237, 'end_accuracy': 0.009519038076152305, 'end_precision': 0.011872572684845366, 'end_recall': 0.009519038076152305, 'end_f1_score': 0.00988768177355613, 'joint_exact_match': 0.002004008016032064, 'span_overlap_f1': 0.036085276216779545}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28.836876611860973,\n",
       " {'start_accuracy': 0.013026052104208416,\n",
       "  'start_precision': 0.015848075140071603,\n",
       "  'start_recall': 0.013026052104208416,\n",
       "  'start_f1_score': 0.013420503861789237,\n",
       "  'end_accuracy': 0.009519038076152305,\n",
       "  'end_precision': 0.011872572684845366,\n",
       "  'end_recall': 0.009519038076152305,\n",
       "  'end_f1_score': 0.00988768177355613,\n",
       "  'joint_exact_match': 0.002004008016032064,\n",
       "  'span_overlap_f1': 0.036085276216779545})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on the dev set\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "evaluate_qa_context_model(model=model, dataloader=dev_dataloader_context_question_swapped, criterion=criterion, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/63 [00:00<?, ?it/s]c:\\Users\\001\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Predicting: 100%|| 63/63 [00:01<00:00, 39.89it/s]\n"
     ]
    }
   ],
   "source": [
    "preds, true_labels = predict_qa_context_model(model=model, dataloader=dev_dataloader_context_question_swapped, tokenizer=tokenizer, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer: schools adding rug\n",
      "True Answer: rugby\n",
      "--------------------------------------------------\n",
      "Predicted Answer: adding rugby\n",
      "True Answer: an official school sport\n",
      "--------------------------------------------------\n",
      "Predicted Answer: by as an\n",
      "True Answer: high school\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ity\n",
      "True Answer: framework\n",
      "--------------------------------------------------\n",
      "Predicted Answer: framework\n",
      "True Answer: complexity classes\n",
      "--------------------------------------------------\n",
      "Predicted Answer: :\n",
      "True Answer: complicated definitions\n",
      "--------------------------------------------------\n",
      "Predicted Answer: southern california\n",
      "True Answer: palm springs\n",
      "--------------------------------------------------\n",
      "Predicted Answer: for\n",
      "True Answer: southern\n",
      "--------------------------------------------------\n",
      "Predicted Answer: feel and\n",
      "True Answer: open spaces\n",
      "--------------------------------------------------\n",
      "Predicted Answer: tourists frequent the southern california coast\n",
      "True Answer: beaches\n",
      "--------------------------------------------------\n",
      "Predicted Answer: angeles\n",
      "True Answer: united states\n",
      "--------------------------------------------------\n",
      "Predicted Answer: most\n",
      "True Answer: counties\n",
      "--------------------------------------------------\n",
      "Predicted Answer: most\n",
      "True Answer: counties\n",
      "--------------------------------------------------\n",
      "Predicted Answer: , san diego ,\n",
      "True Answer: 15\n",
      "--------------------------------------------------\n",
      "Predicted Answer: san ber\n",
      "True Answer: los angeles\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the\n",
      "True Answer: mexico  united states border\n",
      "--------------------------------------------------\n",
      "Predicted Answer: river at the border with\n",
      "True Answer: colorado desert\n",
      "--------------------------------------------------\n",
      "Predicted Answer: at the border with arizona ,\n",
      "True Answer: mojave desert\n",
      "--------------------------------------------------\n",
      "Predicted Answer: colorado desert and the\n",
      "True Answer: colorado river\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ity classes of decision problems defined in\n",
      "True Answer: bounding\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ity classes of decision problems defined in this manner are the\n",
      "True Answer: complexity classes\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: time or space\n",
      "--------------------------------------------------\n",
      "Predicted Answer: dino ,\n",
      "True Answer: business\n",
      "--------------------------------------------------\n",
      "Predicted Answer: side .\n",
      "True Answer: riverside\n",
      "--------------------------------------------------\n",
      "Predicted Answer: maintains the business districts of\n",
      "True Answer: hospitality business / financial centre\n",
      "--------------------------------------------------\n",
      "Predicted Answer: in ncaa division i in the pac - 12 conference , and\n",
      "True Answer: ucla\n",
      "--------------------------------------------------\n",
      "Predicted Answer: college sports are\n",
      "True Answer: trojans\n",
      "--------------------------------------------------\n",
      "Predicted Answer: sports are also popular in southern california\n",
      "True Answer: division i\n",
      "--------------------------------------------------\n",
      "Predicted Answer: a longtime\n",
      "True Answer: college\n",
      "--------------------------------------------------\n",
      "Predicted Answer: a longtime\n",
      "True Answer: pac - 12\n",
      "--------------------------------------------------\n",
      "Predicted Answer: southern california is also home to the port of los angeles , the united states ' busiest commercial port ; the adjacent port of long beach , the united states ' second\n",
      "True Answer: port of los angeles\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ' busiest\n",
      "True Answer: southern\n",
      "--------------------------------------------------\n",
      "Predicted Answer: er port ; and\n",
      "True Answer: port of san diego\n",
      "--------------------------------------------------\n",
      "Predicted Answer: of castile .\n",
      "True Answer: maciot de bethencourt\n",
      "--------------------------------------------------\n",
      "Predicted Answer: , jean ' s nephew maci\n",
      "True Answer: enrique prez de guzmn\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1418 , jean\n",
      "True Answer: bethencourt\n",
      "--------------------------------------------------\n",
      "Predicted Answer: business\n",
      "True Answer: central business districts\n",
      "--------------------------------------------------\n",
      "Predicted Answer: many\n",
      "True Answer: business\n",
      "--------------------------------------------------\n",
      "Predicted Answer: districts ( cbd ) include downtown los angeles\n",
      "True Answer: south coast metro\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1999 ,\n",
      "True Answer: los angeles times\n",
      "--------------------------------------------------\n",
      "Predicted Answer: a new\n",
      "True Answer: imperial\n",
      "--------------------------------------------------\n",
      "Predicted Answer: added a\n",
      "True Answer: 1900\n",
      "--------------------------------------------------\n",
      "Predicted Answer: a new\n",
      "True Answer: 1999\n",
      "--------------------------------------------------\n",
      "Predicted Answer: newer\n",
      "True Answer: seven\n",
      "--------------------------------------------------\n",
      "Predicted Answer: , one of the 11 megaregions of the united states . the megaregi\n",
      "True Answer: mexican\n",
      "--------------------------------------------------\n",
      "Predicted Answer: for\n",
      "True Answer: 11\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ons of the united states . the megaregion ' s area is more expansive ,\n",
      "True Answer: nevada\n",
      "--------------------------------------------------\n",
      "Predicted Answer: , one of the 11 megaregions of the united states . the megaregion ' s area is more expansive ,\n",
      "True Answer: tijuana\n",
      "--------------------------------------------------\n",
      "Predicted Answer: - and\n",
      "True Answer: southern california megaregion\n",
      "--------------------------------------------------\n",
      "Predicted Answer: diego counties with the other line connecting san bernardino , riverside , and\n",
      "True Answer: metrolink\n",
      "--------------------------------------------------\n",
      "Predicted Answer: link ,\n",
      "True Answer: six\n",
      "--------------------------------------------------\n",
      "Predicted Answer: diego\n",
      "True Answer: seven\n",
      "--------------------------------------------------\n",
      "Predicted Answer: san bernardino , riverside , and orange counties directly .\n",
      "True Answer: orange\n",
      "--------------------------------------------------\n",
      "Predicted Answer: c , and it is not known if they are distinct or equal classes .\n",
      "True Answer: nl and nc\n",
      "--------------------------------------------------\n",
      "Predicted Answer: y theorem tells\n",
      "True Answer: time and space hierarchy theorems\n",
      "--------------------------------------------------\n",
      "Predicted Answer: not known if they are distinct\n",
      "True Answer: l\n",
      "--------------------------------------------------\n",
      "Predicted Answer: that l is strictly\n",
      "True Answer: exptime\n",
      "--------------------------------------------------\n",
      "Predicted Answer: l is strictly contained\n",
      "True Answer: pspace\n",
      "--------------------------------------------------\n",
      "Predicted Answer: . again , there are many\n",
      "True Answer: strictly contained in p or equal to p\n",
      "--------------------------------------------------\n",
      "Predicted Answer: or equal classes .\n",
      "True Answer: complexity classes\n",
      "--------------------------------------------------\n",
      "Predicted Answer: similarly ,\n",
      "True Answer: if they are distinct or equal classes\n",
      "--------------------------------------------------\n",
      "Predicted Answer: be\n",
      "True Answer: time\n",
      "--------------------------------------------------\n",
      "Predicted Answer: to\n",
      "True Answer: best , worst and average\n",
      "--------------------------------------------------\n",
      "Predicted Answer: complexity ( or any other complexity measure ) of different inputs of the same size . since some inputs of size n may be faster to solve than\n",
      "True Answer: complexity measure\n",
      "--------------------------------------------------\n",
      "Predicted Answer: define\n",
      "True Answer: inputs\n",
      "--------------------------------------------------\n",
      "Predicted Answer: two major league soccer teams in los angeles  the la galaxy and chivas usa  that both played at the stubhub center and were local\n",
      "True Answer: chivas usa\n",
      "--------------------------------------------------\n",
      "Predicted Answer: center and were local rivals . however , chivas were suspended following the 2014\n",
      "True Answer: two\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: 2018\n",
      "--------------------------------------------------\n",
      "Predicted Answer: , there were\n",
      "True Answer: stubhub center\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \n",
      "True Answer: 2014\n",
      "--------------------------------------------------\n",
      "Predicted Answer: n ) = 7n2 + 15n + 40\n",
      "True Answer: constant factors and smaller terms\n",
      "--------------------------------------------------\n",
      "Predicted Answer: big o notation one would write t ( n )\n",
      "True Answer: t ( n ) = o ( n2 )\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 2 + 15n + 40 , in big o no\n",
      "True Answer: big o notation\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 15n + 40 , in big o notation one\n",
      "True Answer: the computational model\n",
      "--------------------------------------------------\n",
      "Predicted Answer: norman army invaded dyrrachium , owing to the betrayal of high byzantine officials .\n",
      "True Answer: the adriatic\n",
      "--------------------------------------------------\n",
      "Predicted Answer: of - affairs paved the road to\n",
      "True Answer: dyrrachium\n",
      "--------------------------------------------------\n",
      "Predicted Answer: dyrrachium , owing to the betrayal of high byzantine officials . some time later\n",
      "True Answer: 1185\n",
      "--------------------------------------------------\n",
      "Predicted Answer: im duc\n",
      "True Answer: mlb\n",
      "--------------------------------------------------\n",
      "Predicted Answer: nba ( los angeles lakers , los angeles clippers ); m\n",
      "True Answer: nba\n",
      "--------------------------------------------------\n",
      "Predicted Answer: nba ( los angeles lakers , los angeles clippers ); m\n",
      "True Answer: la galaxy\n",
      "--------------------------------------------------\n",
      "Predicted Answer: im duc\n",
      "True Answer: nfl\n",
      "--------------------------------------------------\n",
      "Predicted Answer: axy\n",
      "True Answer: los angeles kings\n",
      "--------------------------------------------------\n",
      "Predicted Answer: esman\n",
      "True Answer: a computational problem\n",
      "--------------------------------------------------\n",
      "Predicted Answer: of the island , which would be under western european domination for the following 380 years . although\n",
      "True Answer: 380 years\n",
      "--------------------------------------------------\n",
      "Predicted Answer: tor\n",
      "True Answer: a single output\n",
      "--------------------------------------------------\n",
      "Predicted Answer: factor\n",
      "True Answer: a function problem\n",
      "--------------------------------------------------\n",
      "Predicted Answer: computational\n",
      "True Answer: complex\n",
      "--------------------------------------------------\n",
      "Predicted Answer: .\n",
      "True Answer: the integer factorization problem\n",
      "--------------------------------------------------\n",
      "Predicted Answer: up the aforementioned ralph as earl\n",
      "True Answer: edward the confessor\n",
      "--------------------------------------------------\n",
      "Predicted Answer: set\n",
      "True Answer: hereford\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ralph as earl of hereford and\n",
      "True Answer: the welsh\n",
      "--------------------------------------------------\n",
      "Predicted Answer: nordic traditions imported in the previous half century by the\n",
      "True Answer: odo\n",
      "--------------------------------------------------\n",
      "Predicted Answer: do , the bishop of bayeux and first earl of kent , employing natives from kent who were learned\n",
      "True Answer: bayeux tapestry\n",
      "--------------------------------------------------\n",
      "Predicted Answer: p .\n",
      "True Answer: reversed\n",
      "--------------------------------------------------\n",
      "Predicted Answer: , it has not yet been proven\n",
      "True Answer: co - np\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the nordic traditions imported in the previous\n",
      "True Answer: embroidery\n",
      "--------------------------------------------------\n",
      "Predicted Answer: equal to n\n",
      "True Answer: not equal\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ensuring that\n",
      "True Answer: input encoding\n",
      "--------------------------------------------------\n",
      "Predicted Answer: has been shown that if these two complex\n",
      "True Answer: p is not equal to np\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ensuring that\n",
      "True Answer: encoding\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compare the predictions with the actual answers\n",
    "for i in range(100):\n",
    "    print(f\"Predicted Answer: {preds[i]}\")\n",
    "    print(f\"True Answer: {true_labels[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|| 625/625 [00:15<00:00, 41.08it/s]\n"
     ]
    }
   ],
   "source": [
    "train_preds, train_true_labels = predict_qa_context_model(model=model, dataloader=train_dataloader_context_question_swapped, tokenizer=tokenizer, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer: cannon\n",
      "True Answer: cannon\n",
      "--------------------------------------------------\n",
      "Predicted Answer: over two - thirds\n",
      "True Answer: over two - thirds\n",
      "--------------------------------------------------\n",
      "Predicted Answer: social life\n",
      "True Answer: social life\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ( suffering\n",
      "True Answer: suffering\n",
      "--------------------------------------------------\n",
      "Predicted Answer: sufficientia\n",
      "True Answer: sufficientia\n",
      "--------------------------------------------------\n",
      "Predicted Answer: dunkirk\n",
      "True Answer: dunkirk\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 2 . 4\n",
      "True Answer: 2 . 4\n",
      "--------------------------------------------------\n",
      "Predicted Answer: mixed portuguese and chinese ancestry\n",
      "True Answer: mixed portuguese and chinese ancestry\n",
      "--------------------------------------------------\n",
      "Predicted Answer: song dynasty ( 960  1279 ). the song\n",
      "True Answer: song dynasty\n",
      "--------------------------------------------------\n",
      "Predicted Answer: october 6 , 2000\n",
      "True Answer: october 6 , 2000\n",
      "--------------------------------------------------\n",
      "Predicted Answer: faster processors , as well as advances in software noise reduction techniques\n",
      "True Answer: faster processors , as well as advances in software noise reduction techniques\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1938\n",
      "True Answer: 1938\n",
      "--------------------------------------------------\n",
      "Predicted Answer: in watts and depends\n",
      "True Answer: the actual power consumed ( in watts ) and the apparent power ( in volt - amperes )\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ( 1878\n",
      "True Answer: 1878\n",
      "--------------------------------------------------\n",
      "Predicted Answer: increases in neurotransmitter levels , improved oxygen and nutrient delivery , and increased neurogenesis in the hippocampus\n",
      "True Answer: increases in neurotransmitter levels , improved oxygen and nutrient delivery , and increased neurogenesis in the hi\n",
      "--------------------------------------------------\n",
      "Predicted Answer: organisation for economic co - operation and development ( oecd ).\n",
      "True Answer: organisation for economic co - operation and development ( oecd )\n",
      "--------------------------------------------------\n",
      "Predicted Answer: large\n",
      "True Answer: large\n",
      "--------------------------------------------------\n",
      "Predicted Answer: lithuania\n",
      "True Answer: lithuania\n",
      "--------------------------------------------------\n",
      "Predicted Answer: lord howe\n",
      "True Answer: lord howe\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 50  150 km\n",
      "True Answer: 50  150 km\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1904\n",
      "True Answer: 1904\n",
      "--------------------------------------------------\n",
      "Predicted Answer: necklaces\n",
      "True Answer: necklaces\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ( a single phase\n",
      "True Answer: a single phase\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the luftwaffe\n",
      "True Answer: the luftwaffe\n",
      "--------------------------------------------------\n",
      "Predicted Answer: government of mexico city\n",
      "True Answer: government of mexico city\n",
      "--------------------------------------------------\n",
      "Predicted Answer: defensive contra - identification\n",
      "True Answer: defensive contra - identification\n",
      "--------------------------------------------------\n",
      "Predicted Answer: kostas montis\n",
      "True Answer: kostas montis\n",
      "--------------------------------------------------\n",
      "Predicted Answer: against the rati\n",
      "True Answer: against the ratification of the treaty of versailles , thus preventing american participation in the league\n",
      "--------------------------------------------------\n",
      "Predicted Answer: light - emitting diode\n",
      "True Answer: light - emitting diode\n",
      "--------------------------------------------------\n",
      "Predicted Answer: farming spread from the near east\n",
      "True Answer: farming\n",
      "--------------------------------------------------\n",
      "Predicted Answer: south - east cornwall\n",
      "True Answer: south - east cornwall\n",
      "--------------------------------------------------\n",
      "Predicted Answer: a manufacturer ' s prefix\n",
      "True Answer: a manufacturer ' s prefix\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the russian orthodox church\n",
      "True Answer: the russian orthodox church\n",
      "--------------------------------------------------\n",
      "Predicted Answer: fox\n",
      "True Answer: fox\n",
      "--------------------------------------------------\n",
      "Predicted Answer: joaquim de almeida , daniela ruah , maria de medeiros , diogo infante , sora\n",
      "True Answer: joaquim de almeida , daniela ruah , maria de medeiros ,\n",
      "--------------------------------------------------\n",
      "Predicted Answer: , field engineers\n",
      "True Answer: the minister of national defence\n",
      "--------------------------------------------------\n",
      "Predicted Answer: softwood\n",
      "True Answer: softwood\n",
      "--------------------------------------------------\n",
      "Predicted Answer: temporarily binding\n",
      "True Answer: temporarily binding\n",
      "--------------------------------------------------\n",
      "Predicted Answer: aspirated stops\n",
      "True Answer: aspirated stops\n",
      "--------------------------------------------------\n",
      "Predicted Answer: a highly specialized criminal investigation police\n",
      "True Answer: a highly specialized criminal investigation police\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ins , sowing and harvesting seasons . luddi , bhangra and sammi\n",
      "True Answer: luddi , bhangra and sammi\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the defender\n",
      "True Answer: the defender\n",
      "--------------------------------------------------\n",
      "Predicted Answer: for a system subject only to pressure forces and heat transfer ( e . g ., a cylinder - full of gas ) without chemical\n",
      "True Answer: for a system subject only to pressure forces and heat transfer ( e . g ., a cylinder - full of\n",
      "--------------------------------------------------\n",
      "Predicted Answer: apollo\n",
      "True Answer: apollo\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the premier league rank second in the uefa coefficients of leagues\n",
      "True Answer: the premier league rank second in the uefa coefficients of leagues\n",
      "--------------------------------------------------\n",
      "Predicted Answer: million\n",
      "True Answer: 26 million\n",
      "--------------------------------------------------\n",
      "Predicted Answer: knurled roller ( s ),\n",
      "True Answer: knurled roller ( s )\n",
      "--------------------------------------------------\n",
      "Predicted Answer: independent cities , four of the boroughs ( brooklyn , queens , manhattan , and the bronx\n",
      "True Answer: brooklyn , queens , manhattan , and the bronx\n",
      "--------------------------------------------------\n",
      "Predicted Answer: five\n",
      "True Answer: five\n",
      "--------------------------------------------------\n",
      "Predicted Answer: three gorges dam\n",
      "True Answer: three gorges dam\n",
      "--------------------------------------------------\n",
      "Predicted Answer: foothills of monsoon regions\n",
      "True Answer: foothills of monsoon regions\n",
      "--------------------------------------------------\n",
      "Predicted Answer: over a hundred thousand\n",
      "True Answer: over a hundred thousand\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the wombles\n",
      "True Answer: the wombles\n",
      "--------------------------------------------------\n",
      "Predicted Answer: a landing signal officer\n",
      "True Answer: a landing signal officer\n",
      "--------------------------------------------------\n",
      "Predicted Answer: glaciers\n",
      "True Answer: glaciers\n",
      "--------------------------------------------------\n",
      "Predicted Answer: september 30 , 1987\n",
      "True Answer: september 30 , 1987\n",
      "--------------------------------------------------\n",
      "Predicted Answer: among the top 30\n",
      "True Answer: among the top 30\n",
      "--------------------------------------------------\n",
      "Predicted Answer: palm\n",
      "True Answer: palm\n",
      "--------------------------------------------------\n",
      "Predicted Answer: invertebrate\n",
      "True Answer: invertebrate\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 3 , 000\n",
      "True Answer: over 3 , 000\n",
      "--------------------------------------------------\n",
      "Predicted Answer: not all of these small streams\n",
      "True Answer: not all of these small streams\n",
      "--------------------------------------------------\n",
      "Predicted Answer: toronto\n",
      "True Answer: toronto\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ( cct\n",
      "True Answer: cct\n",
      "--------------------------------------------------\n",
      "Predicted Answer: they often connect kitchens to rooms on other floors\n",
      "True Answer: they often connect kitchens to rooms on other floors\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the sealed ruins of the beichuan county seat\n",
      "True Answer: the sealed ruins of the beichuan county seat\n",
      "--------------------------------------------------\n",
      "Predicted Answer: east village\n",
      "True Answer: east village\n",
      "--------------------------------------------------\n",
      "Predicted Answer: announced on december 12\n",
      "True Answer: net10 wireless arena football league\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the fall of the cab if the cable broke\n",
      "True Answer: prevented the fall of the cab if the cable broke\n",
      "--------------------------------------------------\n",
      "Predicted Answer: due to their g7\n",
      "True Answer: italy\n",
      "--------------------------------------------------\n",
      "Predicted Answer: baltimore dialect\n",
      "True Answer: baltimore dialect\n",
      "--------------------------------------------------\n",
      "Predicted Answer: $ 31 , 997\n",
      "True Answer: $ 31 , 997\n",
      "--------------------------------------------------\n",
      "Predicted Answer: gametrailers\n",
      "True Answer: gametrailers\n",
      "--------------------------------------------------\n",
      "Predicted Answer: deira\n",
      "True Answer: deira\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the wii\n",
      "True Answer: the wii\n",
      "--------------------------------------------------\n",
      "Predicted Answer: agrarian communities\n",
      "True Answer: agrarian communities\n",
      "--------------------------------------------------\n",
      "Predicted Answer: ( latin scripts only\n",
      "True Answer: latin scripts only\n",
      "--------------------------------------------------\n",
      "Predicted Answer: gunnar myrdal\n",
      "True Answer: gunnar myrdal\n",
      "--------------------------------------------------\n",
      "Predicted Answer: jazz\n",
      "True Answer: jazz\n",
      "--------------------------------------------------\n",
      "Predicted Answer: randy jackson\n",
      "True Answer: randy jackson\n",
      "--------------------------------------------------\n",
      "Predicted Answer: a dielectric spacer\n",
      "True Answer: a dielectric spacer\n",
      "--------------------------------------------------\n",
      "Predicted Answer: tenth - busiest\n",
      "True Answer: tenth - busiest\n",
      "--------------------------------------------------\n",
      "Predicted Answer: decay to silence\n",
      "True Answer: decay to silence\n",
      "--------------------------------------------------\n",
      "Predicted Answer: eightfold\n",
      "True Answer: eightfold\n",
      "--------------------------------------------------\n",
      "Predicted Answer: rainians\n",
      "True Answer: ethnic russians , belarusians , and ukrainians\n",
      "--------------------------------------------------\n",
      "Predicted Answer: secretary of state for education\n",
      "True Answer: secretary of state for education\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 24 % of soil samples taken from public parks contained t . canis eggs . untreated toxocariasis can cause retinal damage\n",
      "True Answer: 24\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 1960\n",
      "True Answer: 1960\n",
      "--------------------------------------------------\n",
      "Predicted Answer: the medieval period\n",
      "True Answer: the medieval period\n",
      "--------------------------------------------------\n",
      "Predicted Answer: braslia , brazil\n",
      "True Answer: braslia , brazil\n",
      "--------------------------------------------------\n",
      "Predicted Answer: by what it is not rather than what it is\n",
      "True Answer: by what it is not rather than what it is\n",
      "--------------------------------------------------\n",
      "Predicted Answer: muslim brotherhood\n",
      "True Answer: muslim brotherhood\n",
      "--------------------------------------------------\n",
      "Predicted Answer: as designers '\n",
      "True Answer: designers ' way\n",
      "--------------------------------------------------\n",
      "Predicted Answer: bicycles and rickshaws\n",
      "True Answer: bicycles and rickshaws\n",
      "--------------------------------------------------\n",
      "Predicted Answer: restricted use pesticides\n",
      "True Answer: restricted use pesticides\n",
      "--------------------------------------------------\n",
      "Predicted Answer: as a coolant in generators\n",
      "True Answer: as a coolant in generators\n",
      "--------------------------------------------------\n",
      "Predicted Answer: sony and philips fell through , ( although a prototype console was produced by sony ) with philips gaining the right to release a series of titles based on nintendo franchises for its cd - i multimedia player and sony going on to develop\n",
      "True Answer: sony and philips\n",
      "--------------------------------------------------\n",
      "Predicted Answer: 14\n",
      "True Answer: 1425\n",
      "--------------------------------------------------\n",
      "Predicted Answer: five\n",
      "True Answer: five\n",
      "--------------------------------------------------\n",
      "Predicted Answer: activist bob maza\n",
      "True Answer: activist bob maza\n",
      "--------------------------------------------------\n",
      "Predicted Answer: \" the hildebrand rarity\n",
      "True Answer: the hildebrand rarity\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compare the predictions with the actual answers\n",
    "for i in range(100):\n",
    "    print(f\"Predicted Answer: {train_preds[i]}\")\n",
    "    print(f\"True Answer: {train_true_labels[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
